<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>环境 配置</title>
    <link href="/2023/11/09/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2023/11/09/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="大电脑环境配置"><a href="#大电脑环境配置" class="headerlink" title="大电脑环境配置"></a>大电脑环境配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create -n torch_chen1 python=<span class="hljs-number">3.8</span><br>conda activate torch_chen1<br><br>pip3 install torch==<span class="hljs-number">1.10</span><span class="hljs-number">.0</span>+cu113 torchvision==<span class="hljs-number">0.11</span><span class="hljs-number">.1</span>+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html -i https://pypi.douban.com/simple<br>pip install xlrd==<span class="hljs-number">1.2</span><span class="hljs-number">.0</span><br>pip install xlrd==<span class="hljs-number">4.64</span><span class="hljs-number">.1</span><br>cudnn-windows-x86_64-<span class="hljs-number">8.8</span><span class="hljs-number">.0</span><span class="hljs-number">.121</span>_cuda12-archive.<span class="hljs-built_in">zip</span><br>cuda_12<span class="hljs-number">.0</span><span class="hljs-number">.0_527</span><span class="hljs-number">.41</span>_windows.exe<br><br><br>pip install matplotlib==<span class="hljs-number">3.2</span><span class="hljs-number">.0</span> -i https://pypi.douban.com/simple/<br><br><br>conda create –n py35 python=<span class="hljs-number">3.5</span><br>activate py35<br><br><span class="hljs-comment"># 设置路径</span><br>https://blog.csdn.net/m0_67313306/article/details/<span class="hljs-number">124204890</span><br>conda create -n torch1<span class="hljs-number">.11</span> python=<span class="hljs-number">3.8</span><br>conda activate torch1<span class="hljs-number">.11</span><br>conda install pytorch==<span class="hljs-number">1.8</span><span class="hljs-number">.1</span> torchvision==<span class="hljs-number">0.9</span><span class="hljs-number">.1</span> torchaudio==<span class="hljs-number">0.8</span><span class="hljs-number">.1</span> cudatoolkit=<span class="hljs-number">10.2</span> -c pytorch<br>pip install xlrd==<span class="hljs-number">1.2</span><span class="hljs-number">.0</span><br>pip install matplotlib==<span class="hljs-number">3.2</span><span class="hljs-number">.0</span> -i https://pypi.douban.com/simple/<br><br><br><br><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>第二章 Transformer</title>
    <link href="/2023/11/08/Transformer/Transformer%E7%AC%AC%E4%BA%8C%E7%AB%A0/"/>
    <url>/2023/11/08/Transformer/Transformer%E7%AC%AC%E4%BA%8C%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="2-2-输入部分实现-P4"><a href="#2-2-输入部分实现-P4" class="headerlink" title="2.2 输入部分实现 P4"></a>2.2 输入部分实现 P4</h2><ul><li><p>学习目标</p><ul><li><p>了解文本嵌入层和位置编码的作用.</p></li><li><p>掌握文本嵌入层和位置编码的实现过程.</p></li></ul></li></ul><hr><ul><li>输入部分包含:<ul><li>源文本嵌入层及其位置编码器</li><li>目标文本嵌入层及其位置编码器</li></ul></li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/image-20231108193413280.png" alt="image-20231108193413280"></p><h3 id="文本嵌入层的作用"><a href="#文本嵌入层的作用" class="headerlink" title="文本嵌入层的作用"></a>文本嵌入层的作用</h3><ul><li>无论是源文本嵌入还是目标文本嵌入，都是为了将文本中词汇的数字表示转变为向量表示, 希望在这样的高维空间捕捉词汇间的关系.</li></ul><hr><ul><li><p>pytorch 0.3.0及其必备工具包的安装:</p><h3 id="安装版本"><a href="#安装版本" class="headerlink" title="安装版本"></a>安装版本</h3></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用pip安装的工具包包括pytorch-0.3.0, numpy, matplotlib, seaborn</span><br>pip install http://download.pytorch.org/whl/cu80/torch-<span class="hljs-number">0.3</span><span class="hljs-number">.0</span>.post4-cp36-cp36m-linux_x86_64.whl numpy matplotlib seaborn<br><br><span class="hljs-comment"># MAC系统安装, python版本&lt;=3.6</span><br>pip install torch==<span class="hljs-number">0.3</span><span class="hljs-number">.0</span>.post4 numpy matplotlib seaborn<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create -n postcoding python=<span class="hljs-number">3.0</span><br>conda activate postcoding<br><br>pip3 install torch==<span class="hljs-number">1.10</span><span class="hljs-number">.0</span>+cu113 torchvision==<span class="hljs-number">0.11</span><span class="hljs-number">.1</span>+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html -i https://pypi.douban.com/simple<br>pip install xlrd==<span class="hljs-number">1.2</span><span class="hljs-number">.0</span><br>pip install xlrd==<span class="hljs-number">4.64</span><span class="hljs-number">.1</span><br>pip install matplotlib==<span class="hljs-number">3.2</span><span class="hljs-number">.0</span> -i https://pypi.douban.com/simple/<br></code></pre></td></tr></table></figure><ul><li>文本嵌入层的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入必备的工具包</span><br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-comment"># 预定义的网络层torch.nn, 工具开发者已经帮助我们开发好的一些常用层, </span><br><span class="hljs-comment"># 比如，卷积层, lstm层, embedding层等, 不需要我们再重新造轮子.</span><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 数学计算工具包</span><br><span class="hljs-keyword">import</span> math<br><br><span class="hljs-comment"># torch中变量封装函数Variable.</span><br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><br><span class="hljs-comment"># 定义Embeddings类来实现文本嵌入层，这里s说明代表两个一模一样的嵌入层, 他们共享参数.</span><br><span class="hljs-comment"># 该类继承nn.Module, 这样就有标准层的一些功能, 这里我们也可以理解为一种模式, 我们自己实现的所有层都会这样去写.</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Embeddings</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;类的初始化函数, 有两个参数, d_model: 指词嵌入的维度, vocab: 指词表的大小.&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 接着就是使用super的方式指明继承nn.Module的初始化函数, 我们自己实现的所有层都会这样去写.</span><br>        <span class="hljs-built_in">super</span>(Embeddings, self).__init__()<br>        <span class="hljs-comment"># 之后就是调用nn中的预定义层Embedding, 获得一个词嵌入对象self.lut</span><br>        self.lut = nn.Embedding(vocab, d_model)<br>        <span class="hljs-comment"># 最后就是将d_model传入类中</span><br>        self.d_model = d_model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;可以将其理解为该层的前向传播逻辑，所有层中都会有此函数</span><br><span class="hljs-string">           当传给该类的实例化对象参数时, 自动调用该类函数</span><br><span class="hljs-string">           参数x: 因为Embedding层是首层, 所以代表输入给模型的文本通过词汇映射后的张量&quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># 将x传给self.lut并与根号下self.d_model相乘作为结果返回</span><br>        <span class="hljs-keyword">return</span> self.lut(x) * math.sqrt(self.d_model)<span class="hljs-comment"># sqrt(self.d_model)缩放作用</span><br></code></pre></td></tr></table></figure><p><code>P5</code></p><ul><li>nn.Embedding演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.LongTensor([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">9</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>embedding(<span class="hljs-built_in">input</span>)<br>tensor([[[-<span class="hljs-number">0.0251</span>, -<span class="hljs-number">1.6902</span>,  <span class="hljs-number">0.7172</span>],<br>         [-<span class="hljs-number">0.6431</span>,  <span class="hljs-number">0.0748</span>,  <span class="hljs-number">0.6969</span>],<br>         [ <span class="hljs-number">1.4970</span>,  <span class="hljs-number">1.3448</span>, -<span class="hljs-number">0.9685</span>],<br>         [-<span class="hljs-number">0.3677</span>, -<span class="hljs-number">2.7265</span>, -<span class="hljs-number">0.1685</span>]],<br><br>        [[ <span class="hljs-number">1.4970</span>,  <span class="hljs-number">1.3448</span>, -<span class="hljs-number">0.9685</span>],<br>         [ <span class="hljs-number">0.4362</span>, -<span class="hljs-number">0.4004</span>,  <span class="hljs-number">0.9400</span>],<br>         [-<span class="hljs-number">0.6431</span>,  <span class="hljs-number">0.0748</span>,  <span class="hljs-number">0.6969</span>],<br>         [ <span class="hljs-number">0.9124</span>, -<span class="hljs-number">2.3616</span>,  <span class="hljs-number">1.1151</span>]]])<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>embedding = nn.Embedding(<span class="hljs-number">10</span>, <span class="hljs-number">3</span>, padding_idx=<span class="hljs-number">0</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.LongTensor([[<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">5</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>embedding(<span class="hljs-built_in">input</span>)<br>tensor([[[ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>],<br>         [ <span class="hljs-number">0.1535</span>, -<span class="hljs-number">2.0309</span>,  <span class="hljs-number">0.9315</span>],<br>         [ <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>,  <span class="hljs-number">0.0000</span>],<br>         [-<span class="hljs-number">0.1655</span>,  <span class="hljs-number">0.9897</span>,  <span class="hljs-number">0.0635</span>]]])<br></code></pre></td></tr></table></figure><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 词嵌入维度是512维</span><br>d_model = <span class="hljs-number">512</span><br><br><span class="hljs-comment"># 词表大小是1000</span><br>vocab = <span class="hljs-number">1000</span><br></code></pre></td></tr></table></figure><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入x是一个使用Variable封装的长整型张量, 形状是2 x 4</span><br>x = Variable(torch.LongTensor([[<span class="hljs-number">100</span>,<span class="hljs-number">2</span>,<span class="hljs-number">421</span>,<span class="hljs-number">508</span>],[<span class="hljs-number">491</span>,<span class="hljs-number">998</span>,<span class="hljs-number">1</span>,<span class="hljs-number">221</span>]]))<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">emb = Embeddings(d_model, vocab)<br>embr = emb(x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;embr:&quot;</span>, embr)<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">embr: Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">35.9321</span>   <span class="hljs-number">3.2582</span> -<span class="hljs-number">17.7301</span>  ...    <span class="hljs-number">3.4109</span>  <span class="hljs-number">13.8832</span>  <span class="hljs-number">39.0272</span><br>   <span class="hljs-number">8.5410</span>  -<span class="hljs-number">3.5790</span> -<span class="hljs-number">12.0460</span>  ...   <span class="hljs-number">40.1880</span>  <span class="hljs-number">36.6009</span>  <span class="hljs-number">34.7141</span><br> -<span class="hljs-number">17.0650</span>  -<span class="hljs-number">1.8705</span> -<span class="hljs-number">20.1807</span>  ...  -<span class="hljs-number">12.5556</span> -<span class="hljs-number">34.0739</span>  <span class="hljs-number">35.6536</span><br>  <span class="hljs-number">20.6105</span>   <span class="hljs-number">4.4314</span>  <span class="hljs-number">14.9912</span>  ...   -<span class="hljs-number">0.1342</span>  -<span class="hljs-number">9.9270</span>  <span class="hljs-number">28.6771</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br>  <span class="hljs-number">27.7016</span>  <span class="hljs-number">16.7183</span>  <span class="hljs-number">46.6900</span>  ...   <span class="hljs-number">17.9840</span>  <span class="hljs-number">17.2525</span>  -<span class="hljs-number">3.9709</span><br>   <span class="hljs-number">3.0645</span>  -<span class="hljs-number">5.5105</span>  <span class="hljs-number">10.8802</span>  ...  -<span class="hljs-number">13.0069</span>  <span class="hljs-number">30.8834</span> -<span class="hljs-number">38.3209</span><br>  <span class="hljs-number">33.1378</span> -<span class="hljs-number">32.1435</span>  -<span class="hljs-number">3.9369</span>  ...   <span class="hljs-number">15.6094</span> -<span class="hljs-number">29.7063</span>  <span class="hljs-number">40.1361</span><br> -<span class="hljs-number">31.5056</span>   <span class="hljs-number">3.3648</span>   <span class="hljs-number">1.4726</span>  ...    <span class="hljs-number">2.8047</span>  -<span class="hljs-number">9.6514</span> -<span class="hljs-number">23.4909</span><br>[torch.FloatTensor of size 2x4x512]<br></code></pre></td></tr></table></figure><ul><li>输出效果</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> copy<br><br><br><span class="hljs-comment"># embedding = nn.Embedding(10, 3)</span><br><span class="hljs-comment"># input1 = torch.LongTensor([[1,2,4,5],[4,3,2,9]])</span><br><span class="hljs-comment"># embedding = nn.Embedding(10, 3)</span><br><span class="hljs-comment"># input1 = torch.LongTensor([[1 ,2, 4, 5], [4, 3, 2, 9]])</span><br><span class="hljs-comment"># print(embedding(input1))</span><br><span class="hljs-comment"># embedding = nn.Embedding(10, 3, padding_idx=0)</span><br><span class="hljs-comment"># input1 = torch.LongTensor([[0, 2, 0, 5]])</span><br><span class="hljs-comment"># print(embedding(input1))</span><br><span class="hljs-comment"># 构建Embedding类来实现文本嵌入层</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Embeddings</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab</span>):<br>        <span class="hljs-comment"># d_model: 词嵌入的维度</span><br>        <span class="hljs-comment"># vocab: 词表的大小</span><br>        <span class="hljs-built_in">super</span>(Embeddings, self).__init__()<br>        <span class="hljs-comment"># 定义Embedding层</span><br>        self.lut = nn.Embedding(vocab, d_model)<br>        <span class="hljs-comment"># 将参数传入到类中</span><br>        self.d_model = d_model<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># x：代表输入进模型的文本通过词汇映射后的数字张量</span><br>        <span class="hljs-keyword">return</span> self.lut(x) * math.sqrt(self.d_model)<br><br><br><span class="hljs-comment"># 实例化参数</span><br>d_model = <span class="hljs-number">512</span><br>vocab = <span class="hljs-number">1000</span><br><br>x = Variable(torch.LongTensor([[<span class="hljs-number">100</span>, <span class="hljs-number">2</span>, <span class="hljs-number">421</span>, <span class="hljs-number">508</span>], [<span class="hljs-number">491</span>, <span class="hljs-number">998</span>, <span class="hljs-number">1</span>, <span class="hljs-number">221</span>]]))<br><br>emb = Embeddings(d_model, vocab)<br>embr = emb(x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;embr:&quot;</span>, embr)<br><span class="hljs-built_in">print</span>(embr.shape)<br></code></pre></td></tr></table></figure><p><code>P 6 位置编码器的作用</code></p><p>因为在Transformer的编码器结构中, 并没有针对词汇位置信息的处理，因此需要在Embedding层后加入位置编码器，将词汇位置不同可能会产生不同语义的信息加入到词嵌入张量中, 以弥补位置信息的缺失</p><ul><li>位置编码器的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义位置编码器类, 我们同样把它看做一个层, 因此会继承nn.Module    </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionalEncoding</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, dropout, max_len=<span class="hljs-number">5000</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;位置编码器类的初始化函数, 共有三个参数, 分别是d_model: 词嵌入维度, </span><br><span class="hljs-string">           dropout: 置0比率, max_len: 每个句子的最大长度&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(PositionalEncoding, self).__init__()<br><br>        <span class="hljs-comment"># 实例化nn中预定义的Dropout层, 并将dropout传入其中, 获得对象self.dropout</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>        <span class="hljs-comment"># 初始化一个位置编码矩阵, 它是一个0阵，矩阵的大小是max_len x d_model.</span><br>        pe = torch.zeros(max_len, d_model)<span class="hljs-comment"># 行 和 列</span><br><br>        <span class="hljs-comment"># 初始化一个绝对位置矩阵, 在我们这里，词汇的绝对位置就是用它的索引去表示. </span><br>        <span class="hljs-comment"># 所以我们首先使用arange方法获得一个连续自然数向量，然后再使用unsqueeze方法拓展向量维度使其成为矩阵， </span><br>        <span class="hljs-comment"># 又因为参数传的是1，代表矩阵拓展的位置，会使向量变成一个max_len x 1 的矩阵， </span><br>        position = torch.arange(<span class="hljs-number">0</span>, max_len).unsqueeze(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 绝对位置矩阵初始化之后，接下来就是考虑如何将这些位置信息加入到位置编码矩阵中，</span><br>        <span class="hljs-comment"># 最简单思路就是先将max_len x 1的绝对位置矩阵， 变换成max_len x d_model形状，然后覆盖原来的初始位置编码矩阵即可， </span><br>        <span class="hljs-comment"># 要做这种矩阵变换，就需要一个1xd_model形状的变换矩阵div_term，我们对这个变换矩阵的要求除了形状外，</span><br>        <span class="hljs-comment"># 还希望它能够将自然数的绝对位置编码缩放成足够小的数字，有助于在之后的梯度下降过程中更快的收敛.  这样我们就可以开始初始化这个变换矩阵了.</span><br>        <span class="hljs-comment"># 首先使用arange获得一个自然数矩阵， 但是细心的同学们会发现， 我们这里并没有按照预计的一样初始化一个1xd_model的矩阵， </span><br>        <span class="hljs-comment"># 而是有了一个跳跃，只初始化了一半即1xd_model/2 的矩阵。 为什么是一半呢，其实这里并不是真正意义上的初始化了一半的矩阵，</span><br>        <span class="hljs-comment"># 我们可以把它看作是初始化了两次，而每次初始化的变换矩阵会做不同的处理，第一次初始化的变换矩阵分布在正弦波上， 第二次初始化的变换矩阵分布在余弦波上， </span><br>        <span class="hljs-comment"># 并把这两个矩阵分别填充在位置编码矩阵的偶数和奇数位置上，组成最终的位置编码矩阵.</span><br>        div_term = torch.exp(torch.arange(<span class="hljs-number">0</span>, d_model, <span class="hljs-number">2</span>) *<br>                             -(math.log(<span class="hljs-number">10000.0</span>) / d_model))<br>        pe[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>] = torch.sin(position * div_term)<span class="hljs-comment"># 偶数列</span><br>        pe[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>] = torch.cos(position * div_term)<br><br>        <span class="hljs-comment"># 这样我们就得到了位置编码矩阵pe, pe现在还只是一个二维矩阵，要想和embedding的输出（一个三维张量）相加，</span><br>        <span class="hljs-comment"># 就必须拓展一个维度，所以这里使用unsqueeze拓展维度.</span><br>        pe = pe.unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 最后把pe位置编码矩阵注册成模型的buffer，什么是buffer呢，</span><br>        <span class="hljs-comment"># 我们把它认为是对模型效果有帮助的，但是却不是模型结构中超参数或者参数，不需要随着优化步骤进行更新的增益对象. </span><br>        <span class="hljs-comment"># 注册之后我们就可以在模型保存后重加载时和模型结构与参数一同被加载.</span><br>        self.register_buffer(<span class="hljs-string">&#x27;pe&#x27;</span>, pe)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;forward函数的参数是x, 表示文本序列的词嵌入表示&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 在相加之前我们对pe做一些适配工作， 将这个三维张量的第二维也就是句子最大长度的那一维将切片到与输入的x的第二维相同即x.size(1)，</span><br>        <span class="hljs-comment"># 因为我们默认max_len为5000一般来讲实在太大了，很难有一条句子包含5000个词汇，所以要进行与输入张量的适配. </span><br>        <span class="hljs-comment"># 最后使用Variable进行封装，使其与x的样式相同，但是它是不需要进行梯度求解的，因此把requires_grad设置成false.</span><br>        x = x + Variable(self.pe[:, :x.size(<span class="hljs-number">1</span>)], <br>                         requires_grad=<span class="hljs-literal">False</span>)<br>        <span class="hljs-comment"># 最后使用self.dropout对象进行&#x27;丢弃&#x27;操作, 并返回结果.</span><br>        <span class="hljs-keyword">return</span> self.dropout(x)<br></code></pre></td></tr></table></figure><ul><li>nn.Dropout演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Dropout(p=<span class="hljs-number">0.2</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">4</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output = m(<span class="hljs-built_in">input</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output<br>Variable containing:<br> <span class="hljs-number">0.0000</span> -<span class="hljs-number">0.5856</span> -<span class="hljs-number">1.4094</span>  <span class="hljs-number">0.0000</span> -<span class="hljs-number">1.0290</span><br> <span class="hljs-number">2.0591</span> -<span class="hljs-number">1.3400</span> -<span class="hljs-number">1.7247</span> -<span class="hljs-number">0.9885</span>  <span class="hljs-number">0.1286</span><br> <span class="hljs-number">0.5099</span>  <span class="hljs-number">1.3715</span>  <span class="hljs-number">0.0000</span>  <span class="hljs-number">2.2079</span> -<span class="hljs-number">0.5497</span><br>-<span class="hljs-number">0.0000</span> -<span class="hljs-number">0.7839</span> -<span class="hljs-number">1.2434</span> -<span class="hljs-number">0.1222</span>  <span class="hljs-number">1.2815</span><br>[torch.FloatTensor of size 4x5]<br></code></pre></td></tr></table></figure><ul><li>torch.unsqueeze演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="hljs-number">0</span>)<br>tensor([[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>,  <span class="hljs-number">4</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.unsqueeze(x, <span class="hljs-number">1</span>)<br>tensor([[ <span class="hljs-number">1</span>],<br>        [ <span class="hljs-number">2</span>],<br>        [ <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">4</span>]])<br></code></pre></td></tr></table></figure><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 词嵌入维度是512维</span><br>d_model = <span class="hljs-number">512</span><br><br><span class="hljs-comment"># 置0比率为0.1</span><br>dropout = <span class="hljs-number">0.1</span><br><br><span class="hljs-comment"># 句子最大长度</span><br>max_len=<span class="hljs-number">60</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入x是Embedding层的输出的张量, 形状是2 x 4 x 512</span><br>x = embr<br>Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">35.9321</span>   <span class="hljs-number">3.2582</span> -<span class="hljs-number">17.7301</span>  ...    <span class="hljs-number">3.4109</span>  <span class="hljs-number">13.8832</span>  <span class="hljs-number">39.0272</span><br>   <span class="hljs-number">8.5410</span>  -<span class="hljs-number">3.5790</span> -<span class="hljs-number">12.0460</span>  ...   <span class="hljs-number">40.1880</span>  <span class="hljs-number">36.6009</span>  <span class="hljs-number">34.7141</span><br> -<span class="hljs-number">17.0650</span>  -<span class="hljs-number">1.8705</span> -<span class="hljs-number">20.1807</span>  ...  -<span class="hljs-number">12.5556</span> -<span class="hljs-number">34.0739</span>  <span class="hljs-number">35.6536</span><br>  <span class="hljs-number">20.6105</span>   <span class="hljs-number">4.4314</span>  <span class="hljs-number">14.9912</span>  ...   -<span class="hljs-number">0.1342</span>  -<span class="hljs-number">9.9270</span>  <span class="hljs-number">28.6771</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br>  <span class="hljs-number">27.7016</span>  <span class="hljs-number">16.7183</span>  <span class="hljs-number">46.6900</span>  ...   <span class="hljs-number">17.9840</span>  <span class="hljs-number">17.2525</span>  -<span class="hljs-number">3.9709</span><br>   <span class="hljs-number">3.0645</span>  -<span class="hljs-number">5.5105</span>  <span class="hljs-number">10.8802</span>  ...  -<span class="hljs-number">13.0069</span>  <span class="hljs-number">30.8834</span> -<span class="hljs-number">38.3209</span><br>  <span class="hljs-number">33.1378</span> -<span class="hljs-number">32.1435</span>  -<span class="hljs-number">3.9369</span>  ...   <span class="hljs-number">15.6094</span> -<span class="hljs-number">29.7063</span>  <span class="hljs-number">40.1361</span><br> -<span class="hljs-number">31.5056</span>   <span class="hljs-number">3.3648</span>   <span class="hljs-number">1.4726</span>  ...    <span class="hljs-number">2.8047</span>  -<span class="hljs-number">9.6514</span> -<span class="hljs-number">23.4909</span><br>[torch.FloatTensor of size 2x4x512]<br></code></pre></td></tr></table></figure><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">pe = PositionalEncoding(d_model, dropout, max_len)<br>pe_result = pe(x)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;pe_result:&quot;</span>, pe_result)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">pe_result: Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br> -<span class="hljs-number">19.7050</span>   <span class="hljs-number">0.0000</span>   <span class="hljs-number">0.0000</span>  ...  -<span class="hljs-number">11.7557</span>  -<span class="hljs-number">0.0000</span>  <span class="hljs-number">23.4553</span><br>  -<span class="hljs-number">1.4668</span> -<span class="hljs-number">62.2510</span>  -<span class="hljs-number">2.4012</span>  ...   <span class="hljs-number">66.5860</span> -<span class="hljs-number">24.4578</span> -<span class="hljs-number">37.7469</span><br>   <span class="hljs-number">9.8642</span> -<span class="hljs-number">41.6497</span> -<span class="hljs-number">11.4968</span>  ...  -<span class="hljs-number">21.1293</span> -<span class="hljs-number">42.0945</span>  <span class="hljs-number">50.7943</span><br>   <span class="hljs-number">0.0000</span>  <span class="hljs-number">34.1785</span> -<span class="hljs-number">33.0712</span>  ...   <span class="hljs-number">48.5520</span>   <span class="hljs-number">3.2540</span>  <span class="hljs-number">54.1348</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br>   <span class="hljs-number">7.7598</span> -<span class="hljs-number">21.0359</span>  <span class="hljs-number">15.0595</span>  ...  -<span class="hljs-number">35.6061</span>  -<span class="hljs-number">0.0000</span>   <span class="hljs-number">4.1772</span><br> -<span class="hljs-number">38.7230</span>   <span class="hljs-number">8.6578</span>  <span class="hljs-number">34.2935</span>  ...  -<span class="hljs-number">43.3556</span>  <span class="hljs-number">26.6052</span>   <span class="hljs-number">4.3084</span><br>  <span class="hljs-number">24.6962</span>  <span class="hljs-number">37.3626</span> -<span class="hljs-number">26.9271</span>  ...   <span class="hljs-number">49.8989</span>   <span class="hljs-number">0.0000</span>  <span class="hljs-number">44.9158</span><br> -<span class="hljs-number">28.8435</span> -<span class="hljs-number">48.5963</span>  -<span class="hljs-number">0.9892</span>  ...  -<span class="hljs-number">52.5447</span>  -<span class="hljs-number">4.1475</span>  -<span class="hljs-number">3.0450</span><br>[torch.FloatTensor of size 2x4x512]<br></code></pre></td></tr></table></figure><hr><ul><li>绘制词汇向量中特征的分布曲线:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-comment"># 创建一张15 x 5大小的画布</span><br>plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">5</span>))<br><br><span class="hljs-comment"># 实例化PositionalEncoding类得到pe对象, 输入参数是20和0</span><br>pe = PositionalEncoding(<span class="hljs-number">20</span>, <span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 然后向pe传入被Variable封装的tensor, 这样pe会直接执行forward函数, </span><br><span class="hljs-comment"># 且这个tensor里的数值都是0, 被处理后相当于位置编码张量</span><br>y = pe(Variable(torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>, <span class="hljs-number">20</span>)))<br><br><span class="hljs-comment"># 然后定义画布的横纵坐标, 横坐标到100的长度, 纵坐标是某一个词汇中的某维特征在不同长度下对应的值</span><br><span class="hljs-comment"># 因为总共有20维之多, 我们这里只查看4，5，6，7维的值.</span><br>plt.plot(np.arange(<span class="hljs-number">100</span>), y[<span class="hljs-number">0</span>, :, <span class="hljs-number">4</span>:<span class="hljs-number">8</span>].data.numpy())<br><br><span class="hljs-comment"># 在画布上填写维度提示信息</span><br>plt.legend([<span class="hljs-string">&quot;dim %d&quot;</span>%p <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> [<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>]])<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><p><img src="https://pic3.zhimg.com/80/v2-0c210867908a13e1f477e491ec5a2062_720w.webp" alt="img"></p><p>效果分析:</p><ul><li><p>每条颜色的曲线代表某一个词汇中的特征在不同位置的含义.</p></li><li><p>保证同一词汇随着所在位置不同它对应位置嵌入向量会发生变化.</p></li><li><p>正弦波和余弦波的值域范围都是1到-1这又很好的控制了嵌入数值的大小, 有助于梯度的快速计算.</p></li></ul><p><code>小节总结</code> p8</p><ul><li>学习了文本嵌入层的作用:<ul><li>无论是源文本嵌入还是目标文本嵌入，都是为了将文本中词汇的数字表示转变为向量表示, 希望在这样的高维空间捕捉词汇间的关系.</li></ul></li></ul><hr><ul><li>学习并实现了文本嵌入层的类: Embeddings<ul><li>初始化函数以d_model, 词嵌入维度, 和vocab, 词汇总数为参数, 内部主要使用了nn中的预定层Embedding进行词嵌入.</li><li>在forward函数中, 将输入x传入到Embedding的实例化对象中, 然后乘以一个根号下d_model进行缩放, 控制数值大小.</li><li>它的输出是文本嵌入后的结果.</li></ul></li></ul><hr><ul><li>学习了位置编码器的作用:<ul><li>因为在Transformer的编码器结构中, 并没有针对词汇位置信息的处理，因此需要在Embedding层后加入位置编码器，将词汇位置不同可能会产生不同语义的信息加入到词嵌入张量中, 以弥补位置信息的缺失.</li></ul></li></ul><hr><ul><li>学习并实现了位置编码器的类: PositionalEncoding<ul><li>初始化函数以d_model, dropout, max_len为参数, 分别代表d_model: 词嵌入维度, dropout: 置0比率, max_len: 每个句子的最大长度.</li><li>forward函数中的输入参数为x, 是Embedding层的输出.</li><li>最终输出一个加入了位置编码信息的词嵌入张量.</li></ul></li></ul><hr><ul><li>实现了绘制词汇向量中特征的分布曲线:<ul><li>保证同一词汇随着所在位置不同它对应位置嵌入向量会发生变化.</li><li>正弦波和余弦波的值域范围都是1到-1, 这又很好的控制了嵌入数值的大小, 有助于梯度的快速计算.</li></ul></li></ul><h2 id="2-3-编码器部分实现-P10"><a href="#2-3-编码器部分实现-P10" class="headerlink" title="2.3 编码器部分实现 P10"></a>2.3 编码器部分实现 P10</h2><ul><li><p>学习目标</p><ul><li><p>了解编码器中各个组成部分的作用.</p></li><li><p>掌握编码器中各个组成部分的实现过程.</p></li></ul></li></ul><hr><ul><li>编码器部分:<ul><li>由N个编码器层堆叠而成</li><li>每个编码器层由两个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul></li></ul><p><img src="https://pic1.zhimg.com/80/v2-306c89830ea9efe5953ae4d8b76492a4_1440w.webp" alt="img"></p><ul><li>什么是掩码张量:<ul><li>掩代表遮掩，码就是我们张量中的数值，它的尺寸不定，里面一般只有<code>1</code>和<code>0</code>的元素，代表位置被遮掩或者不被遮掩，至于是0位置被遮掩还是1位置被遮掩可以自定义，因此它的作用就是<code>让另外一个张量中的一些数值被遮掩</code>，也可以说被替换, 它的表现形式是一个张量.</li></ul></li></ul><hr><ul><li>掩码张量的作用:<ul><li>在transformer中, 掩码张量的主要作用在应用<code>attention</code>(将在下一小节讲解)时，有一些生成的attention张量中的值计算有可能已知了未来信息而得到的，未来信息被看到是因为训练时会把整个输出结果都一次性进行Embedding，但是理论上解码器的的输出却不是一次就能产生最终结果的，而是一次次通过上一次结果综合得出的，因此，未来的信息可能被提前利用. 所以，我们会进行遮掩. 关于解码器的有关知识将在后面的章节中讲解.</li></ul></li></ul><hr><ul><li>生成掩码张量的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">subsequent_mask</span>(<span class="hljs-params">size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;生成向后遮掩的掩码张量, 参数size是掩码张量最后两个维度的大小, 它的最后两维形成一个方阵&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 在函数中, 首先定义掩码张量的形状</span><br>    attn_shape = (<span class="hljs-number">1</span>, size, size)<br><br>    <span class="hljs-comment"># 然后使用np.ones方法向这个形状中添加1元素,形成上三角阵, 最后为了节约空间, </span><br>    <span class="hljs-comment"># 再使其中的数据类型变为无符号8位整形unit8 </span><br>    subsequent_mask = np.triu(np.ones(attn_shape), k=<span class="hljs-number">1</span>).astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br><br>    <span class="hljs-comment"># 最后将numpy类型转化为torch中的tensor, 内部做一个1 - 的操作, </span><br>    <span class="hljs-comment"># 在这个其实是做了一个三角阵的反转, subsequent_mask中的每个元素都会被1减, </span><br>    <span class="hljs-comment"># 如果是0, subsequent_mask中的该位置由0变成1</span><br>    <span class="hljs-comment"># 如果是1, subsequent_mask中的该位置由1变成0 </span><br>    <span class="hljs-keyword">return</span> torch.from_numpy(<span class="hljs-number">1</span> - subsequent_mask)<br></code></pre></td></tr></table></figure><hr><ul><li>np.triu演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>np.triu([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>],[<span class="hljs-number">10</span>,<span class="hljs-number">11</span>,<span class="hljs-number">12</span>]], k=-<span class="hljs-number">1</span>)<br>array([[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>       [ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>, <span class="hljs-number">12</span>]])<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>np.triu([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>],[<span class="hljs-number">10</span>,<span class="hljs-number">11</span>,<span class="hljs-number">12</span>]], k=<span class="hljs-number">0</span>)<br>array([[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">9</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br><br><br><span class="hljs-meta">&gt;&gt;&gt; </span>np.triu([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">6</span>],[<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>],[<span class="hljs-number">10</span>,<span class="hljs-number">11</span>,<span class="hljs-number">12</span>]], k=<span class="hljs-number">1</span>)<br>array([[ <span class="hljs-number">0</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">6</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>],<br>       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></td></tr></table></figure><hr><ul><li>输入实例:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 生成的掩码张量的最后两维的大小</span><br>size = <span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">sm = subsequent_mask(size)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;sm:&quot;</span>, sm)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 最后两维形成一个下三角阵</span><br>sm: (<span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span>  <span class="hljs-number">1</span><br>[torch.ByteTensor of size 1x5x5]<br></code></pre></td></tr></table></figure><hr><p><code>P 11 </code></p><ul><li>掩码张量的可视化:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.figure(figsize=(<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>plt.imshow(subsequent_mask(<span class="hljs-number">20</span>)[<span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><p><img src="https://pic1.zhimg.com/80/v2-7e76569222acd94a74de6d2ba5efa824_1440w.webp" alt="img"></p><p>效果分析:</p><ul><li>通过观察可视化方阵, 黄色是1的部分, 这里代表被遮掩, 紫色代表没有被遮掩的信息, 横坐标代表目标词汇的位置, 纵坐标代表可查看的位置;</li><li>我们看到, 在0的位置我们一看望过去都是黄色的, 都被遮住了，1的位置一眼望过去还是黄色, 说明第一次词还没有产生, 从第二个位置看过去, 就能看到位置1的词, 其他位置看不到, 以此类推.</li></ul><p><code>总结</code></p><ul><li>学习了什么是掩码张量:<ul><li>掩代表遮掩，码就是我们张量中的数值，它的尺寸不定，里面一般只有1和0的元素，代表位置被遮掩或者不被遮掩，至于是0位置被遮掩还是1位置被遮掩可以自定义，因此它的作用就是让另外一个张量中的一些数值被遮掩, 也可以说被替换, 它的表现形式是一个张量.</li></ul></li></ul><hr><ul><li>学习了掩码张量的作用:<ul><li>在transformer中, 掩码张量的主要作用在应用attention(将在下一小节讲解)时，有一些生成的attetion张量中的值计算有可能已知量未来信息而得到的，未来信息被看到是因为训练时会把整个输出结果都一次性进行Embedding，但是理论上解码器的的输出却不是一次就能产生最终结果的，而是一次次通过上一次结果综合得出的，因此，未来的信息可能被提前利用. 所以，我们会进行遮掩. 关于解码器的有关知识将在后面的章节中讲解.</li></ul></li></ul><hr><ul><li>学习并实现了生成向后遮掩的掩码张量函数: subsequent_mask<ul><li>它的输入是size, 代表掩码张量的大小.</li><li>它的输出是一个最后两维形成1方阵的下三角阵.</li><li>最后对生成的掩码张量进行了可视化分析, 更深一步理解了它的用途.</li></ul></li></ul><h3 id="2-3-2-注意力机制-P13"><a href="#2-3-2-注意力机制-P13" class="headerlink" title="2.3.2 注意力机制 P13"></a>2.3.2 注意力机制 P13</h3><ul><li>学习目标:<ul><li>了解什么是注意力计算规则和注意力机制.</li><li>掌握注意力计算规则的实现过程.</li></ul></li></ul><hr><ul><li>什么是注意力:<ul><li>我们观察事物时，之所以能够快速判断一种事物(当然允许判断是错误的), 是因为我们大脑能够很快把注意力放在事物最具有辨识度的部分从而作出判断，而并非是从头到尾的观察一遍事物后，才能有判断结果. 正是基于这样的理论，就产生了注意力机制.</li></ul></li></ul><hr><ul><li>什么是注意力计算规则:<ul><li>它需要三个指定的输入Q(query), K(key), V(value), 然后通过公式得到注意力的计算结果, 这个结果代表query在key和value作用下的表示. 而这个具体的计算规则有很多种, 我这里只介绍我们用到的这一种.</li></ul></li></ul><hr><ul><li><p>我们这里使用的注意力的计算规则:<br>$$<br>\mathrm{Attention}(Q,K,V)&#x3D;\mathrm{softmax}(\frac{QK^{T}}{\sqrt{d_{k}}})V<br>$$</p></li><li><p>Q, K, V 的比喻解释:</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">假如我们有一个问题: 给出一段文本，使用一些关键词对它进行描述!<br>为了方便统一正确答案，这道题可能预先已经给大家写出了一些关键词作为提示.其中这些给出的提示就可以看作是key<br>而整个的文本信息就相当于是query，value的含义则更抽象，可以比作是你看到这段文本信息后，脑子里浮现的答案信息<br>这里我们又假设大家最开始都不是很聪明，第一次看到这段文本后脑子里基本上浮现的信息就只有提示这些信息<br>因此key与value基本是相同的，但是随着我们对这个问题的深入理解，通过我们的思考脑子里想起来的东西原来越多<br>并且能够开始对我们query也就是这段文本，提取关键信息进行表示.  这就是注意力作用的过程， 通过这个过程，<br>我们最终脑子里的value发生了变化<br>根据提示key生成了query的关键词表示方法，也就是另外一种特征表示方法.<br><br>刚刚我们说到key和value一般情况下默认是相同，与query是不同的，这种是我们一般的注意力输入形式<br><span class="hljs-comment"># 但有一种特殊情况，就是我们query与key和value相同，这种情况我们称为自注意力机制，就如同我们的刚刚的例子</span><br>使用一般注意力机制，是使用不同于给定文本的关键词表示它. 而自注意力机制<br>需要用给定文本自身来表达自己，也就是说你需要从给定文本中抽取关键词来表述它, 相当于对文本自身的一次特征提取.<br></code></pre></td></tr></table></figure><hr><ul><li>什么是注意力机制:<ul><li>注意力机制是注意力计算规则能够应用的深度学习网络的载体, 除了注意力计算规则外, 还包括一些必要的全连接层以及相关张量处理, 使其与应用网络融为一体. 使用自注意力计算规则的注意力机制称为自注意力机制.</li></ul></li></ul><hr><ul><li>注意力机制在网络中实现的图形表示:</li></ul><p><img src="https://pic1.zhimg.com/80/v2-d7913da8a83d6ca9d67524560b263688_1440w.webp" alt="img"></p><p><code>P14</code> </p><ul><li>注意力计算规则的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">attention</span>(<span class="hljs-params">query, key, value, mask=<span class="hljs-literal">None</span>, dropout=<span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;注意力机制的实现, 输入分别是query, key, value, mask: 掩码张量, </span><br><span class="hljs-string">       dropout是nn.Dropout层的实例化对象, 默认为None&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 在函数中, 首先取query的最后一维的大小, 一般情况下就等同于我们的词嵌入维度, 命名为d_k</span><br>    d_k = query.size(-<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 按照注意力公式, 将query与key的转置相乘, 这里面key是将最后两个维度进行转置, 再除以缩放系数根号下d_k, 这种计算方法也称为缩放点积注意力计算.</span><br>    <span class="hljs-comment"># 得到注意力得分张量scores</span><br>    scores = torch.matmul(query, key.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)) / math.sqrt(d_k)<br><br>    <span class="hljs-comment"># 接着判断是否使用掩码张量</span><br>    <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># 使用tensor的masked_fill方法, 将掩码张量和scores张量每个位置一一比较, 如果掩码张量处为0</span><br>        <span class="hljs-comment"># 则对应的scores张量用-1e9这个值来替换, 如下演示</span><br>        scores = scores.masked_fill(mask == <span class="hljs-number">0</span>, -<span class="hljs-number">1e9</span>)<br><br>    <span class="hljs-comment"># 对scores的最后一维进行softmax操作, 使用F.softmax方法, 第一个参数是softmax对象, 第二个是目标维度.</span><br>    <span class="hljs-comment"># 这样获得最终的注意力张量</span><br>    p_attn = F.softmax(scores, dim = -<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 之后判断是否使用dropout进行随机置0</span><br>    <span class="hljs-keyword">if</span> dropout <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        <span class="hljs-comment"># 将p_attn传入dropout对象中进行&#x27;丢弃&#x27;处理</span><br>        p_attn = dropout(p_attn)<br><br>    <span class="hljs-comment"># 最后, 根据公式将p_attn与value张量相乘获得最终的query注意力表示, 同时返回注意力张量</span><br>    <span class="hljs-keyword">return</span> torch.matmul(p_attn, value), p_attn<br></code></pre></td></tr></table></figure><ul><li>tensor.masked_fill演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = Variable(torch.randn(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> <br>Variable containing:<br> <span class="hljs-number">2.0344</span> -<span class="hljs-number">0.5450</span>  <span class="hljs-number">0.3365</span> -<span class="hljs-number">0.1888</span> -<span class="hljs-number">2.1803</span><br> <span class="hljs-number">1.5221</span> -<span class="hljs-number">0.3823</span>  <span class="hljs-number">0.8414</span>  <span class="hljs-number">0.7836</span> -<span class="hljs-number">0.8481</span><br>-<span class="hljs-number">0.0345</span> -<span class="hljs-number">0.8643</span>  <span class="hljs-number">0.6476</span> -<span class="hljs-number">0.2713</span>  <span class="hljs-number">1.5645</span><br> <span class="hljs-number">0.8788</span> -<span class="hljs-number">2.2142</span>  <span class="hljs-number">0.4022</span>  <span class="hljs-number">0.1997</span>  <span class="hljs-number">0.1474</span><br> <span class="hljs-number">2.9109</span>  <span class="hljs-number">0.6006</span> -<span class="hljs-number">0.6745</span> -<span class="hljs-number">1.7262</span>  <span class="hljs-number">0.6977</span><br>[torch.FloatTensor of size 5x5]<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>mask = Variable(torch.zeros(<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>mask<br>Variable containing:<br> <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br> <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br> <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br> <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br> <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>[torch.FloatTensor of size 5x5]<br><br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span>.masked_fill(mask == <span class="hljs-number">0</span>, -<span class="hljs-number">1e9</span>)<br>Variable containing:<br>-<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span><br>-<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span><br>-<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span><br>-<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span><br>-<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span> -<span class="hljs-number">1.0000e+09</span><br>[torch.FloatTensor of size 5x5]<br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 我们令输入的query, key, value都相同, 位置编码的输出</span><br>query = key = value = pe_result<br>Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">46.5196</span>  <span class="hljs-number">16.2057</span> -<span class="hljs-number">41.5581</span>  ...  -<span class="hljs-number">16.0242</span> -<span class="hljs-number">17.8929</span> -<span class="hljs-number">43.0405</span><br> -<span class="hljs-number">32.6040</span>  <span class="hljs-number">16.1096</span> -<span class="hljs-number">29.5228</span>  ...    <span class="hljs-number">4.2721</span>  <span class="hljs-number">20.6034</span>  -<span class="hljs-number">1.2747</span><br> -<span class="hljs-number">18.6235</span>  <span class="hljs-number">14.5076</span>  -<span class="hljs-number">2.0105</span>  ...   <span class="hljs-number">15.6462</span> -<span class="hljs-number">24.6081</span> -<span class="hljs-number">30.3391</span><br>   <span class="hljs-number">0.0000</span> -<span class="hljs-number">66.1486</span> -<span class="hljs-number">11.5123</span>  ...   <span class="hljs-number">20.1519</span>  -<span class="hljs-number">4.6823</span>   <span class="hljs-number">0.4916</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br> -<span class="hljs-number">24.8681</span>   <span class="hljs-number">7.5495</span>  -<span class="hljs-number">5.0765</span>  ...   -<span class="hljs-number">7.5992</span> -<span class="hljs-number">26.6630</span>  <span class="hljs-number">40.9517</span><br>  <span class="hljs-number">13.1581</span>  -<span class="hljs-number">3.1918</span> -<span class="hljs-number">30.9001</span>  ...   <span class="hljs-number">25.1187</span> -<span class="hljs-number">26.4621</span>   <span class="hljs-number">2.9542</span><br> -<span class="hljs-number">49.7690</span> -<span class="hljs-number">42.5019</span>   <span class="hljs-number">8.0198</span>  ...   -<span class="hljs-number">5.4809</span>  <span class="hljs-number">25.9403</span> -<span class="hljs-number">27.4931</span><br> -<span class="hljs-number">52.2775</span>  <span class="hljs-number">10.4006</span>   <span class="hljs-number">0.0000</span>  ...   -<span class="hljs-number">1.9985</span>   <span class="hljs-number">7.0106</span>  -<span class="hljs-number">0.5189</span><br>[torch.FloatTensor of size 2x4x512]<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">attn, p_attn = attention(query, key, value)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;attn:&quot;</span>, attn)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;p_attn:&quot;</span>, p_attn)<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将得到两个结果</span><br><span class="hljs-comment"># query的注意力表示:</span><br>attn: Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br>   <span class="hljs-number">12.8269</span>    <span class="hljs-number">7.7403</span>   <span class="hljs-number">41.2225</span>  ...     <span class="hljs-number">1.4603</span>   <span class="hljs-number">27.8559</span>  -<span class="hljs-number">12.2600</span><br>   <span class="hljs-number">12.4904</span>    <span class="hljs-number">0.0000</span>   <span class="hljs-number">24.1575</span>  ...     <span class="hljs-number">0.0000</span>    <span class="hljs-number">2.5838</span>   <span class="hljs-number">18.0647</span><br>  -<span class="hljs-number">32.5959</span>   -<span class="hljs-number">4.6252</span>  -<span class="hljs-number">29.1050</span>  ...     <span class="hljs-number">0.0000</span>  -<span class="hljs-number">22.6409</span>  -<span class="hljs-number">11.8341</span><br>    <span class="hljs-number">8.9921</span>  -<span class="hljs-number">33.0114</span>   -<span class="hljs-number">0.7393</span>  ...     <span class="hljs-number">4.7871</span>   -<span class="hljs-number">5.7735</span>    <span class="hljs-number">8.3374</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br>  -<span class="hljs-number">25.6705</span>   -<span class="hljs-number">4.0860</span>  -<span class="hljs-number">36.8226</span>  ...    <span class="hljs-number">37.2346</span>  -<span class="hljs-number">27.3576</span>    <span class="hljs-number">2.5497</span><br>  -<span class="hljs-number">16.6674</span>   <span class="hljs-number">73.9788</span>  -<span class="hljs-number">33.3296</span>  ...    <span class="hljs-number">28.5028</span>   -<span class="hljs-number">5.5488</span>  -<span class="hljs-number">13.7564</span><br>    <span class="hljs-number">0.0000</span>  -<span class="hljs-number">29.9039</span>   -<span class="hljs-number">3.0405</span>  ...     <span class="hljs-number">0.0000</span>   <span class="hljs-number">14.4408</span>   <span class="hljs-number">14.8579</span><br>   <span class="hljs-number">30.7819</span>    <span class="hljs-number">0.0000</span>   <span class="hljs-number">21.3908</span>  ...   -<span class="hljs-number">29.0746</span>    <span class="hljs-number">0.0000</span>   -<span class="hljs-number">5.8475</span><br>[torch.FloatTensor of size 2x4x512]<br><br><span class="hljs-comment"># 注意力张量:</span><br>p_attn: Variable containing:<br>(<span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span><br><br>(<span class="hljs-number">1</span> ,.,.) = <br>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span>  <span class="hljs-number">0</span><br>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">0</span>  <span class="hljs-number">1</span><br>[torch.FloatTensor of size 2x4x4]<br></code></pre></td></tr></table></figure><ul><li>带有mask的输入参数：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">query = key = value = pe_result<br><br><span class="hljs-comment"># 令mask为一个2x4x4的零张量</span><br>mask = Variable(torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">attn, p_attn = attention(query, key, value, mask=mask)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;attn:&quot;</span>, attn)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;p_attn:&quot;</span>, p_attn)<br></code></pre></td></tr></table></figure><hr><ul><li>带有mask的输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># query的注意力表示:</span><br>attn: Variable containing:<br>( <span class="hljs-number">0</span> ,.,.) = <br>   <span class="hljs-number">0.4284</span>  -<span class="hljs-number">7.4741</span>   <span class="hljs-number">8.8839</span>  ...    <span class="hljs-number">1.5618</span>   <span class="hljs-number">0.5063</span>   <span class="hljs-number">0.5770</span><br>   <span class="hljs-number">0.4284</span>  -<span class="hljs-number">7.4741</span>   <span class="hljs-number">8.8839</span>  ...    <span class="hljs-number">1.5618</span>   <span class="hljs-number">0.5063</span>   <span class="hljs-number">0.5770</span><br>   <span class="hljs-number">0.4284</span>  -<span class="hljs-number">7.4741</span>   <span class="hljs-number">8.8839</span>  ...    <span class="hljs-number">1.5618</span>   <span class="hljs-number">0.5063</span>   <span class="hljs-number">0.5770</span><br>   <span class="hljs-number">0.4284</span>  -<span class="hljs-number">7.4741</span>   <span class="hljs-number">8.8839</span>  ...    <span class="hljs-number">1.5618</span>   <span class="hljs-number">0.5063</span>   <span class="hljs-number">0.5770</span><br><br>( <span class="hljs-number">1</span> ,.,.) = <br>  -<span class="hljs-number">2.8890</span>   <span class="hljs-number">9.9972</span> -<span class="hljs-number">12.9505</span>  ...    <span class="hljs-number">9.1657</span>  -<span class="hljs-number">4.6164</span>  -<span class="hljs-number">0.5491</span><br>  -<span class="hljs-number">2.8890</span>   <span class="hljs-number">9.9972</span> -<span class="hljs-number">12.9505</span>  ...    <span class="hljs-number">9.1657</span>  -<span class="hljs-number">4.6164</span>  -<span class="hljs-number">0.5491</span><br>  -<span class="hljs-number">2.8890</span>   <span class="hljs-number">9.9972</span> -<span class="hljs-number">12.9505</span>  ...    <span class="hljs-number">9.1657</span>  -<span class="hljs-number">4.6164</span>  -<span class="hljs-number">0.5491</span><br>  -<span class="hljs-number">2.8890</span>   <span class="hljs-number">9.9972</span> -<span class="hljs-number">12.9505</span>  ...    <span class="hljs-number">9.1657</span>  -<span class="hljs-number">4.6164</span>  -<span class="hljs-number">0.5491</span><br>[torch.FloatTensor of size 2x4x512]<br><br><span class="hljs-comment"># 注意力张量:</span><br>p_attn: Variable containing:<br>(<span class="hljs-number">0</span> ,.,.) = <br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br><br>(<span class="hljs-number">1</span> ,.,.) = <br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span>  <span class="hljs-number">0.2500</span><br>[torch.FloatTensor of size 2x4x4]<br></code></pre></td></tr></table></figure><p><code>总结</code>：</p><ul><li>学习了什么是注意力:<ul><li>我们观察事物时，之所以能够快速判断一种事物(当然允许判断是错误的), 是因为我们大脑能够很快把注意力放在事物最具有辨识度的部分从而作出判断，而并非是从头到尾的观察一遍事物后，才能有判断结果. 正是基于这样的理论，就产生了注意力机制.</li></ul></li></ul><hr><ul><li>什么是注意力计算规则:<ul><li>它需要三个指定的输入Q(query), K(key), V(value), 然后通过公式得到注意力的计算结果, 这个结果代表query在key和value作用下的表示. 而这个具体的计算规则有很多种, 我这里只介绍我们用到的这一种.</li></ul></li></ul><hr><ul><li>学习了<code>Q, K, V</code>的比喻解释:<ul><li>Q是一段准备被概括的文本; K是给出的提示; V是大脑中的对提示K的延伸.</li><li><code>当Q=K=V时</code>, 称作自注意力机制.</li></ul></li></ul><hr><ul><li>什么是注意力机制:<ul><li>注意力机制是注意力计算规则能够应用的深度学习网络的载体, 除了注意力计算规则外, 还包括一些必要的全连接层以及相关张量处理, 使其与应用网络融为一体. 使用自注意力计算规则的注意力机制称为自注意力机制.</li></ul></li></ul><hr><ul><li>学习并实现了注意力计算规则的函数: attention<ul><li>它的输入就是Q，K，V以及mask和dropout, mask用于掩码, dropout用于随机置0.</li><li>它的输出有两个, query的注意力表示以及注意力张量.</li></ul></li></ul><h3 id="2-3-3-多头注意力机制-P17"><a href="#2-3-3-多头注意力机制-P17" class="headerlink" title="2.3.3 多头注意力机制 P17"></a>2.3.3 多头注意力机制 P17</h3><ul><li>学习目标:<ul><li>了解多头注意力机制的作用.</li><li>掌握多头注意力机制的实现过程.</li></ul></li></ul><hr><ul><li>什么是多头注意力机制:<ul><li>从多头注意力的结构图中，貌似这个所谓的多个头就是指多组线性变换层，其实并不是，我只有使用了一组线性变化层，即<code>三个变换张量对Q，K，V分别进行线性变换</code>，这些变换<code>不会改变原有张量的尺寸</code>，因此每个变换矩阵都是<code>方阵</code>，得到输出结果后，多头的作用才开始显现，每个头开始从词义层面分割输出的张量，也就是每个头都想获得一组Q，K，V进行注意力机制的计算，但是句子中的每个词的表示只获得一部分，也就是只分割了最后一维的词嵌入向量. 这就是所谓的多头，将每个头的获得的输入送到注意力机制中, 就形成多头注意力机制.</li></ul></li></ul><hr><ul><li><p>多头注意力机制结构图:</p><img src="https://article.biliimg.com/bfs/article/af87236e673d1a082c9941b51678674b155712160.png" style="zoom:80%;" /></li></ul><hr><ul><li>多头注意力机制的作用:<ul><li>这种结构设计能让每个注意力机制去优化每个词汇的不同特征部分，从而均衡同一种注意力机制可能产生的偏差，让词义拥有来自更多元的表达，实验表明可以从而提升模型效果.</li></ul></li></ul><hr><ul><li>多头注意力机制的代码实现:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 用于深度拷贝的copy工具包</span><br><span class="hljs-keyword">import</span> copy<br><br><span class="hljs-comment"># 首先需要定义克隆函数, 因为在多头注意力机制的实现中, 用到多个结构相同的线性层.</span><br><span class="hljs-comment"># 我们将使用clone函数将他们一同初始化在一个网络层列表对象中. 之后的结构中也会用到该函数.</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">clones</span>(<span class="hljs-params">module, N</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用于生成相同网络层的克隆函数, 它的参数module表示要克隆的目标网络层, N代表需要克隆的数量&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 在函数中, 我们通过for循环对module进行N次深度拷贝, 使其每个module成为独立的层,</span><br>    <span class="hljs-comment"># 然后将其放在nn.ModuleList类型的列表中存放.</span><br>    <span class="hljs-keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(N)])<br><br><br><br><br><span class="hljs-comment"># 我们使用一个类来实现多头注意力机制的处理</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadedAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, head, embedding_dim, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;在类的初始化时, 会传入三个参数，head代表头数，embedding_dim代表词嵌入的维度， </span><br><span class="hljs-string">           dropout代表进行dropout操作时置0比率，默认是0.1.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(MultiHeadedAttention, self).__init__()<br><br>        <span class="hljs-comment"># 在函数中，首先使用了一个测试中常用的assert语句，判断h是否能被d_model整除，</span><br>        <span class="hljs-comment"># 这是因为我们之后要给每个头分配等量的词特征.也就是embedding_dim/head个.</span><br>        <span class="hljs-keyword">assert</span> embedding_dim % head == <span class="hljs-number">0</span><br><br>        <span class="hljs-comment"># 得到每个头获得的分割词向量维度d_k</span><br>        self.d_k = embedding_dim // head<br><br>        <span class="hljs-comment"># 传入头数h</span><br>        self.head = head<br><br>        <span class="hljs-comment"># 然后获得线性层对象，通过nn的Linear实例化，它的内部变换矩阵是embedding_dim x embedding_dim，然后使用clones函数克隆四个，</span><br>        <span class="hljs-comment"># 为什么是四个呢，这是因为在多头注意力中，Q，K，V各需要一个，最后拼接的矩阵还需要一个，因此一共是四个.</span><br>        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), <span class="hljs-number">4</span>)<br><br>        <span class="hljs-comment"># self.attn为None，它代表最后得到的注意力张量，现在还没有结果所以为None.</span><br>        self.attn = <span class="hljs-literal">None</span><br><br>        <span class="hljs-comment"># 最后就是一个self.dropout对象，它通过nn中的Dropout实例化而来，置0比率为传进来的参数dropout.</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, key, value, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;前向逻辑函数, 它的输入参数有四个，前三个就是注意力机制需要的Q, K, V，</span><br><span class="hljs-string">           最后一个是注意力机制中可能需要的mask掩码张量，默认是None. &quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># 如果存在掩码张量mask</span><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># 使用unsqueeze拓展维度</span><br>            mask = mask.unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 接着，我们获得一个batch_size的变量，他是query尺寸的第1个数字，代表有多少条样本.</span><br>        batch_size = query.size(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># 之后就进入多头处理环节</span><br>        <span class="hljs-comment"># 首先利用zip将输入QKV与三个线性层组到一起，然后使用for循环，将输入QKV分别传到线性层中，</span><br>        <span class="hljs-comment"># 做完线性变换后，开始为每个头分割输入，这里使用view方法对线性变换的结果进行维度重塑，多加了一个维度h，代表头数，</span><br>        <span class="hljs-comment"># 这样就意味着每个头可以获得一部分词特征组成的句子，其中的-1代表自适应维度，</span><br>        <span class="hljs-comment"># 计算机会根据这种变换自动计算这里的值.然后对第二维和第三维进行转置操作，</span><br>        <span class="hljs-comment"># 为了让代表句子长度维度和词向量维度能够相邻，这样注意力机制才能找到词义与句子位置的关系，</span><br>        <span class="hljs-comment"># 从attention函数中可以看到，利用的是原始输入的倒数第一和第二维.这样我们就得到了每个头的输入.</span><br>        query, key, value = \<br>           [model(x).view(batch_size, -<span class="hljs-number">1</span>, self.head, self.d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">for</span> model, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.linears, (query, key, value))]<br><br>        <span class="hljs-comment"># 得到每个头的输入后，接下来就是将他们传入到attention中，</span><br>        <span class="hljs-comment"># 这里直接调用我们之前实现的attention函数.同时也将mask和dropout传入其中.</span><br>        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)<br><br>        <span class="hljs-comment"># 通过多头注意力计算后，我们就得到了每个头计算结果组成的4维张量，我们需要将其转换为输入的形状以方便后续的计算，</span><br>        <span class="hljs-comment"># 因此这里开始进行第一步处理环节的逆操作，先对第二和第三维进行转置，然后使用contiguous方法，</span><br>        <span class="hljs-comment"># 这个方法的作用就是能够让转置后的张量应用view方法，否则将无法直接使用，</span><br>        <span class="hljs-comment"># 所以，下一步就是使用view重塑形状，变成和输入形状相同.</span><br>        x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(batch_size, -<span class="hljs-number">1</span>, self.head * self.d_k)<br><br>        <span class="hljs-comment"># 最后使用线性层列表中的最后一个线性层对输入进行线性变换得到最终的多头注意力结构的输出.</span><br>        <span class="hljs-keyword">return</span> self.linears[-<span class="hljs-number">1</span>](x)<br></code></pre></td></tr></table></figure><ul><li>tensor.view演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="hljs-number">4</span>, <span class="hljs-number">4</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>x.size()<br>torch.Size([<span class="hljs-number">4</span>, <span class="hljs-number">4</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>y = x.view(<span class="hljs-number">16</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>y.size()<br>torch.Size([<span class="hljs-number">16</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>z = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">8</span>)  <span class="hljs-comment"># the size -1 is inferred from other dimensions</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>z.size()<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">8</span>])<br><br><span class="hljs-meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>a.size()<br>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>b = a.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># Swaps 2nd and 3rd dimension</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>b.size()<br>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>c = a.view(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>)  <span class="hljs-comment"># Does not change tensor layout in memory</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>c.size()<br>torch.Size([<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>])<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.equal(b, c)<br><span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><ul><li>torch.transpose演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>x<br>tensor([[ <span class="hljs-number">1.0028</span>, -<span class="hljs-number">0.9893</span>,  <span class="hljs-number">0.5809</span>],<br>        [-<span class="hljs-number">0.1669</span>,  <span class="hljs-number">0.7299</span>,  <span class="hljs-number">0.4942</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>torch.transpose(x, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>tensor([[ <span class="hljs-number">1.0028</span>, -<span class="hljs-number">0.1669</span>],<br>        [-<span class="hljs-number">0.9893</span>,  <span class="hljs-number">0.7299</span>],<br>        [ <span class="hljs-number">0.5809</span>,  <span class="hljs-number">0.4942</span>]])<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 头数head</span><br>head = <span class="hljs-number">8</span><br><br><span class="hljs-comment"># 词嵌入维度embedding_dim</span><br>embedding_dim = <span class="hljs-number">512</span><br><br><span class="hljs-comment"># 置零比率dropout</span><br>dropout = <span class="hljs-number">0.2</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 假设输入的Q，K，V仍然相等</span><br>query = value = key = pe_result<br><br><span class="hljs-comment"># 输入的掩码张量mask</span><br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">mha = MultiHeadedAttention(head, embedding_dim, dropout)<br>mha_result = mha(query, key, value, mask)<br><span class="hljs-built_in">print</span>(mha_result)<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[-<span class="hljs-number">0.3075</span>,  <span class="hljs-number">1.5687</span>, -<span class="hljs-number">2.5693</span>,  ..., -<span class="hljs-number">1.1098</span>,  <span class="hljs-number">0.0878</span>, -<span class="hljs-number">3.3609</span>],<br>         [ <span class="hljs-number">3.8065</span>, -<span class="hljs-number">2.4538</span>, -<span class="hljs-number">0.3708</span>,  ..., -<span class="hljs-number">1.5205</span>, -<span class="hljs-number">1.1488</span>, -<span class="hljs-number">1.3984</span>],<br>         [ <span class="hljs-number">2.4190</span>,  <span class="hljs-number">0.5376</span>, -<span class="hljs-number">2.8475</span>,  ...,  <span class="hljs-number">1.4218</span>, -<span class="hljs-number">0.4488</span>, -<span class="hljs-number">0.2984</span>],<br>         [ <span class="hljs-number">2.9356</span>,  <span class="hljs-number">0.3620</span>, -<span class="hljs-number">3.8722</span>,  ..., -<span class="hljs-number">0.7996</span>,  <span class="hljs-number">0.1468</span>,  <span class="hljs-number">1.0345</span>]],<br><br>        [[ <span class="hljs-number">1.1423</span>,  <span class="hljs-number">0.6038</span>,  <span class="hljs-number">0.0954</span>,  ...,  <span class="hljs-number">2.2679</span>, -<span class="hljs-number">5.7749</span>,  <span class="hljs-number">1.4132</span>],<br>         [ <span class="hljs-number">2.4066</span>, -<span class="hljs-number">0.2777</span>,  <span class="hljs-number">2.8102</span>,  ...,  <span class="hljs-number">0.1137</span>, -<span class="hljs-number">3.9517</span>, -<span class="hljs-number">2.9246</span>],<br>         [ <span class="hljs-number">5.8201</span>,  <span class="hljs-number">1.1534</span>, -<span class="hljs-number">1.9191</span>,  ...,  <span class="hljs-number">0.1410</span>, -<span class="hljs-number">7.6110</span>,  <span class="hljs-number">1.0046</span>],<br>         [ <span class="hljs-number">3.1209</span>,  <span class="hljs-number">1.0008</span>, -<span class="hljs-number">0.5317</span>,  ...,  <span class="hljs-number">2.8619</span>, -<span class="hljs-number">6.3204</span>, -<span class="hljs-number">1.3435</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>多头注意力机制总结</code>:P 20 – 04:00</p><ul><li>学习了什么是多头注意力机制:<ul><li>每个头开始从词义层面分割输出的张量，也就是每个头都想获得一组Q，K，V进行注意力机制的计算，但是句子中的每个词的表示只获得一部分，也就是只分割了最后一维的词嵌入向量. 这就是所谓的多头.将每个头的获得的输入送到注意力机制中, 就形成了多头注意力机制.</li></ul></li></ul><hr><ul><li>学习了多头注意力机制的作用:<ul><li>这种结构设计能让每个注意力机制去优化每个词汇的不同特征部分，从而均衡同一种注意力机制可能产生的偏差，让词义拥有来自更多元的表达，实验表明可以从而提升模型效果.</li></ul></li></ul><hr><ul><li>学习并实现了多头注意力机制的类: MultiHeadedAttention<ul><li>因为多头注意力机制中需要使用多个相同的线性层, 首先实现了克隆函数clones.</li><li>clones函数的输入是module，N，分别代表克隆的目标层，和克隆个数.</li><li>clones函数的输出是装有N个克隆层的Module列表.</li><li>接着实现MultiHeadedAttention类, 它的初始化函数输入是h, d_model, dropout分别代表头数，词嵌入维度和置零比率.</li><li>它的实例化对象输入是Q, K, V以及掩码张量mask.</li><li>它的实例化对象输出是通过多头注意力机制处理的Q的注意力表示.</li></ul></li></ul><p><code>P19</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 多头注意力机制的类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiHeadedAttention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, head, embedding_dim, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-comment"># head:代表几个头的参数</span><br>        <span class="hljs-comment"># embedding_dim:代表词嵌入的维度</span><br>        <span class="hljs-comment"># dropout:进行dropout操作时，置零的比率</span><br>        <span class="hljs-built_in">super</span>(MultiHeadedAttention, self).__init__()<br><br>        <span class="hljs-comment"># 要确认一个事实:多头的数量head需要整除嵌入词的维度embedding_dim</span><br>        <span class="hljs-keyword">assert</span> embedding_dim % head == <span class="hljs-number">0</span><br><br>        <span class="hljs-comment"># 获得每个头获得的词向量的维度</span><br>        self.d_k = embedding_dim // head<br><br>        self.head = head<br>        self.embedding_dim = embedding_dim<br><br>        <span class="hljs-comment"># 获得线形层，要获得4个，分别是Q,K,V以及最终的输出线形层</span><br>        self.linears = clones(nn.Linear(embedding_dim, embedding_dim), <span class="hljs-number">4</span>)<br><br>        <span class="hljs-comment"># 初始化注意力张量</span><br>        self.attn = <span class="hljs-literal">None</span><br><br>        <span class="hljs-comment"># 初始化drouput对象</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, key, value, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># query, key, value是注意力机制的三个输入张量，mask代表掩码张量</span><br>        <span class="hljs-comment"># 首先判断是否使用掩码张量</span><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># 使用unsqueeze将掩码张量进行维度扩充，代表多头中的第n个头</span><br>            mask = mask.unsqueeze(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># 得到batch_size</span><br>        batch_size = query.size(<span class="hljs-number">0</span>)<br>        <span class="hljs-comment"># 首先使用zip将网络层和输入数据连接在一起，模型的输出利用view和transpose进行维度和形状的改变</span><br>        query, key, value = \<br>            [model(x).view(batch_size, -<span class="hljs-number">1</span>, self.head, self.d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>             <span class="hljs-keyword">for</span> model, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.linears, (query, key, value))]<br>        <br>        <span class="hljs-comment"># 将每个头的输出传入到注意力层</span><br>        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)<br><br>        <span class="hljs-comment"># 得到每个头的计算结果是4维张量，需要进行形状的转换</span><br>        <span class="hljs-comment"># 前面已经将1，2两个维度进行过转置，在这里必须要重新转置回来，</span><br>        <span class="hljs-comment"># 注意：经历了transpose()方法后，必须使用contiguous方法，否则无法使用view(）方法</span><br>        x = x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(batch_size, -<span class="hljs-number">1</span>, self.head * self.d_k)<br>        <br>        <span class="hljs-comment"># 最后将x输入线形层列表中的最后一个线形层中进行处理，得到最终的多头注意力结构输出</span><br>        <span class="hljs-keyword">return</span> self.linears[-<span class="hljs-number">1</span>](x)<br></code></pre></td></tr></table></figure><h3 id="2-3-4-前馈全连接层"><a href="#2-3-4-前馈全连接层" class="headerlink" title="2.3.4 前馈全连接层"></a>2.3.4 前馈全连接层</h3><ul><li>学习目标:<ul><li>了解什么是前馈全连接层及其它的作用.</li><li>掌握前馈全连接层的实现过程.</li></ul></li></ul><hr><ul><li>什么是前馈全连接层:<ul><li>在Transformer中前馈全连接层就是具有两层线性层的全连接网络.</li></ul></li></ul><hr><ul><li>前馈全连接层的作用:<ul><li>考虑注意力机制可能对复杂过程的拟合程度不够, 通过增加两层网络来增强模型的能力.</li></ul></li></ul><hr><ul><li>前馈全连接层的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过类PositionwiseFeedForward来实现前馈全连接层</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PositionwiseFeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, d_ff, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-comment"># d_model：代表词嵌入的维度，同时也是两个线性层的输入维度和输出维度</span><br>        <span class="hljs-comment"># d_ff：代表第一个线性层的输出维度，和第二个线性层的输入维度</span><br>        <span class="hljs-comment"># dropout：经过Dropout层处理时，随机置零的比率</span><br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数有三个输入参数分别是d_model, d_ff,和dropout=0.1，第一个是线性层的输入维度也是第二个线性层的输出维度，</span><br><span class="hljs-string">           因为我们希望输入通过前馈全连接层后输入和输出的维度不变. 第二个参数d_ff就是第二个线性层的输入维度和第一个线性层的输出维度.</span><br><span class="hljs-string">           最后一个是dropout置0比率.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(PositionwiseFeedForward, self).__init__()<br><br>        <span class="hljs-comment"># 首先按照我们预期使用nn实例化了两个线性层对象，self.w1和self.w2</span><br>        <span class="hljs-comment"># 它们的参数分别是d_model, d_ff和d_ff, d_model</span><br>        self.w1 = nn.Linear(d_model, d_ff)<br>        self.w2 = nn.Linear(d_ff, d_model)<br>        <span class="hljs-comment"># 然后使用nn的Dropout实例化了对象self.dropout</span><br>        self.dropout = nn.Dropout(dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;输入参数为x，代表来自上一层的输出&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 首先经过第一个线性层，然后使用Funtional中relu函数进行激活,</span><br>        <span class="hljs-comment"># 之后再使用dropout进行随机置0，最后通过第二个线性层w2，返回最终结果</span><br>        <span class="hljs-keyword">return</span> self.w2(self.dropout(F.relu(self.w1(x))))<br><br>d_model = <span class="hljs-number">512</span><br>d_ff = <span class="hljs-number">64</span><br>dropout = <span class="hljs-number">0.2</span><br><br>x = mha_result<br>ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>ff_result = ff(x)<br><span class="hljs-built_in">print</span>(ff_result)<br><span class="hljs-built_in">print</span>(ff_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>ReLU函数公式: ReLU(x)&#x3D;max(0, x)</li></ul><hr><ul><li>ReLU函数图像:</li></ul><img src="https://article.biliimg.com/bfs/article/7e3ca1eb7eb850ebfa19b2b4039ddd59155712160.png" style="zoom:80%;" /><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">d_model = <span class="hljs-number">512</span><br><br><span class="hljs-comment"># 线性变化的维度</span><br>d_ff = <span class="hljs-number">64</span><br><br>dropout = <span class="hljs-number">0.2</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入参数x可以是多头注意力机制的输出</span><br>x = mha_result<br>tensor([[[-<span class="hljs-number">0.3075</span>,  <span class="hljs-number">1.5687</span>, -<span class="hljs-number">2.5693</span>,  ..., -<span class="hljs-number">1.1098</span>,  <span class="hljs-number">0.0878</span>, -<span class="hljs-number">3.3609</span>],<br>         [ <span class="hljs-number">3.8065</span>, -<span class="hljs-number">2.4538</span>, -<span class="hljs-number">0.3708</span>,  ..., -<span class="hljs-number">1.5205</span>, -<span class="hljs-number">1.1488</span>, -<span class="hljs-number">1.3984</span>],<br>         [ <span class="hljs-number">2.4190</span>,  <span class="hljs-number">0.5376</span>, -<span class="hljs-number">2.8475</span>,  ...,  <span class="hljs-number">1.4218</span>, -<span class="hljs-number">0.4488</span>, -<span class="hljs-number">0.2984</span>],<br>         [ <span class="hljs-number">2.9356</span>,  <span class="hljs-number">0.3620</span>, -<span class="hljs-number">3.8722</span>,  ..., -<span class="hljs-number">0.7996</span>,  <span class="hljs-number">0.1468</span>,  <span class="hljs-number">1.0345</span>]],<br><br>        [[ <span class="hljs-number">1.1423</span>,  <span class="hljs-number">0.6038</span>,  <span class="hljs-number">0.0954</span>,  ...,  <span class="hljs-number">2.2679</span>, -<span class="hljs-number">5.7749</span>,  <span class="hljs-number">1.4132</span>],<br>         [ <span class="hljs-number">2.4066</span>, -<span class="hljs-number">0.2777</span>,  <span class="hljs-number">2.8102</span>,  ...,  <span class="hljs-number">0.1137</span>, -<span class="hljs-number">3.9517</span>, -<span class="hljs-number">2.9246</span>],<br>         [ <span class="hljs-number">5.8201</span>,  <span class="hljs-number">1.1534</span>, -<span class="hljs-number">1.9191</span>,  ...,  <span class="hljs-number">0.1410</span>, -<span class="hljs-number">7.6110</span>,  <span class="hljs-number">1.0046</span>],<br>         [ <span class="hljs-number">3.1209</span>,  <span class="hljs-number">1.0008</span>, -<span class="hljs-number">0.5317</span>,  ...,  <span class="hljs-number">2.8619</span>, -<span class="hljs-number">6.3204</span>, -<span class="hljs-number">1.3435</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>ff_result = ff(x)<br><span class="hljs-built_in">print</span>(ff_result)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[-<span class="hljs-number">1.9488e+00</span>, -<span class="hljs-number">3.4060e-01</span>, -<span class="hljs-number">1.1216e+00</span>,  ...,  <span class="hljs-number">1.8203e-01</span>,<br>          -<span class="hljs-number">2.6336e+00</span>,  <span class="hljs-number">2.0917e-03</span>],<br>         [-<span class="hljs-number">2.5875e-02</span>,  <span class="hljs-number">1.1523e-01</span>, -<span class="hljs-number">9.5437e-01</span>,  ..., -<span class="hljs-number">2.6257e-01</span>,<br>          -<span class="hljs-number">5.7620e-01</span>, -<span class="hljs-number">1.9225e-01</span>],<br>         [-<span class="hljs-number">8.7508e-01</span>,  <span class="hljs-number">1.0092e+00</span>, -<span class="hljs-number">1.6515e+00</span>,  ...,  <span class="hljs-number">3.4446e-02</span>,<br>          -<span class="hljs-number">1.5933e+00</span>, -<span class="hljs-number">3.1760e-01</span>],<br>         [-<span class="hljs-number">2.7507e-01</span>,  <span class="hljs-number">4.7225e-01</span>, -<span class="hljs-number">2.0318e-01</span>,  ...,  <span class="hljs-number">1.0530e+00</span>,<br>          -<span class="hljs-number">3.7910e-01</span>, -<span class="hljs-number">9.7730e-01</span>]],<br><br>        [[-<span class="hljs-number">2.2575e+00</span>, -<span class="hljs-number">2.0904e+00</span>,  <span class="hljs-number">2.9427e+00</span>,  ...,  <span class="hljs-number">9.6574e-01</span>,<br>          -<span class="hljs-number">1.9754e+00</span>,  <span class="hljs-number">1.2797e+00</span>],<br>         [-<span class="hljs-number">1.5114e+00</span>, -<span class="hljs-number">4.7963e-01</span>,  <span class="hljs-number">1.2881e+00</span>,  ..., -<span class="hljs-number">2.4882e-02</span>,<br>          -<span class="hljs-number">1.5896e+00</span>, -<span class="hljs-number">1.0350e+00</span>],<br>         [ <span class="hljs-number">1.7416e-01</span>, -<span class="hljs-number">4.0688e-01</span>,  <span class="hljs-number">1.9289e+00</span>,  ..., -<span class="hljs-number">4.9754e-01</span>,<br>          -<span class="hljs-number">1.6320e+00</span>, -<span class="hljs-number">1.5217e+00</span>],<br>         [-<span class="hljs-number">1.0874e-01</span>, -<span class="hljs-number">3.3842e-01</span>,  <span class="hljs-number">2.9379e-01</span>,  ..., -<span class="hljs-number">5.1276e-01</span>,<br>          -<span class="hljs-number">1.6150e+00</span>, -<span class="hljs-number">1.1295e+00</span>]]], grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>前馈全连接层总结</code>:</p><ul><li>学习了什么是前馈全连接层:<ul><li>在Transformer中前馈全连接层就是具有两层线性层的全连接网络.</li></ul></li></ul><hr><ul><li>学习了前馈全连接层的作用:<ul><li>考虑注意力机制可能对复杂过程的拟合程度不够, 通过增加两层网络来增强模型的能力.</li></ul></li></ul><hr><ul><li>学习并实现了前馈全连接层的类: PositionwiseFeedForward<ul><li>它的实例化参数为d_model, d_ff, dropout, 分别代表词嵌入维度, 线性变换维度, 和置零比率.</li><li>它的输入参数x, 表示上层的输出.</li><li>它的输出是经过2层线性网络变换的特征表示.</li></ul></li></ul><h3 id="2-3-5-规范化层"><a href="#2-3-5-规范化层" class="headerlink" title="2.3.5 规范化层"></a>2.3.5 规范化层</h3><ul><li>学习目标:<ul><li>了解规范化层的作用.</li><li>掌握规范化层的实现过程.</li></ul></li></ul><hr><ul><li>规范化层的作用:<ul><li>它是所有深层网络模型都需要的标准网络层，因为随着网络层数的增加，通过多层的计算后参数可能开始出现过大或过小的情况，这样可能会导致学习过程出现异常，模型可能收敛非常的慢. 因此都会在一定层数后接规范化层进行数值的规范化，使其特征数值在合理范围内.</li></ul></li></ul><hr><ul><li>规范化层的代码实现:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"> 通过LayerNorm实现规范化层的类<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LayerNorm</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, features, eps=<span class="hljs-number">1e-6</span></span>):<br>        <span class="hljs-comment"># features: 词嵌入的维度</span><br>        <span class="hljs-comment"># eps： 一个足够小的正数，用来在规范化计算公式的分母中，放置除零操作</span><br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数有两个参数, 一个是features, 表示词嵌入的维度,</span><br><span class="hljs-string">           另一个是eps它是一个足够小的数, 在规范化公式的分母中出现,</span><br><span class="hljs-string">           防止分母为0.默认是1e-6.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(LayerNorm, self).__init__()<br><br>        <span class="hljs-comment"># 根据features的形状初始化两个参数张量a2，和b2，第一个初始化为1张量，</span><br>        <span class="hljs-comment"># 也就是里面的元素都是1，第二个初始化为0张量，也就是里面的元素都是0，这两个张量就是规范化层的参数，</span><br>        <span class="hljs-comment"># 因为直接对上一层得到的结果做规范化公式计算，将改变结果的正常表征，因此就需要有参数作为调节因子，</span><br>        <span class="hljs-comment"># 使其即能满足规范化要求，又能不改变针对目标的表征.最后使用nn.parameter封装，代表他们是模型的参数。</span><br>        self.a2 = nn.Parameter(torch.ones(features))<br>        self.b2 = nn.Parameter(torch.zeros(features))<br><br>        <span class="hljs-comment"># 把eps传到类中</span><br>        self.eps = eps<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># x：上一层网络的输出</span><br>        <span class="hljs-comment"># 首先对x进行最后一个维度上的求均值操作，同时保持输出维度和输入维度一直</span><br>        <span class="hljs-string">&quot;&quot;&quot;输入参数x代表来自上一层的输出&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 在函数中，首先对输入变量x求其最后一个维度的均值，并保持输出维度与输入维度一致.</span><br>        <span class="hljs-comment"># 接着再求最后一个维度的标准差，然后就是根据规范化公式，用x减去均值除以标准差获得规范化的结果，</span><br>        <span class="hljs-comment"># 最后对结果乘以我们的缩放参数，即a2，*号代表同型点乘，即对应位置进行乘法操作，加上位移参数b2.返回即可.</span><br>        mean = x.mean(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<span class="hljs-comment"># -1:在最后一个维度上</span><br>        <span class="hljs-comment"># 按照规范化公式进行计算并返回</span><br>        std = x.std(-<span class="hljs-number">1</span>, keepdim=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> self.a2 * (x - mean) / (std + self.eps) + self.b2<br><br><br>features = d_model = <span class="hljs-number">512</span><br>eps = <span class="hljs-number">1e-6</span><br><br>x = ff_result<br>ln = LayerNorm(features, eps)<br>ln_result = ln(x)<br><span class="hljs-built_in">print</span>(ln_result)<br><span class="hljs-built_in">print</span>(ln_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">features = d_model = <span class="hljs-number">512</span><br>eps = <span class="hljs-number">1e-6</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入x来自前馈全连接层的输出</span><br>x = ff_result<br>tensor([[[-<span class="hljs-number">1.9488e+00</span>, -<span class="hljs-number">3.4060e-01</span>, -<span class="hljs-number">1.1216e+00</span>,  ...,  <span class="hljs-number">1.8203e-01</span>,<br>          -<span class="hljs-number">2.6336e+00</span>,  <span class="hljs-number">2.0917e-03</span>],<br>         [-<span class="hljs-number">2.5875e-02</span>,  <span class="hljs-number">1.1523e-01</span>, -<span class="hljs-number">9.5437e-01</span>,  ..., -<span class="hljs-number">2.6257e-01</span>,<br>          -<span class="hljs-number">5.7620e-01</span>, -<span class="hljs-number">1.9225e-01</span>],<br>         [-<span class="hljs-number">8.7508e-01</span>,  <span class="hljs-number">1.0092e+00</span>, -<span class="hljs-number">1.6515e+00</span>,  ...,  <span class="hljs-number">3.4446e-02</span>,<br>          -<span class="hljs-number">1.5933e+00</span>, -<span class="hljs-number">3.1760e-01</span>],<br>         [-<span class="hljs-number">2.7507e-01</span>,  <span class="hljs-number">4.7225e-01</span>, -<span class="hljs-number">2.0318e-01</span>,  ...,  <span class="hljs-number">1.0530e+00</span>,<br>          -<span class="hljs-number">3.7910e-01</span>, -<span class="hljs-number">9.7730e-01</span>]],<br><br>        [[-<span class="hljs-number">2.2575e+00</span>, -<span class="hljs-number">2.0904e+00</span>,  <span class="hljs-number">2.9427e+00</span>,  ...,  <span class="hljs-number">9.6574e-01</span>,<br>          -<span class="hljs-number">1.9754e+00</span>,  <span class="hljs-number">1.2797e+00</span>],<br>         [-<span class="hljs-number">1.5114e+00</span>, -<span class="hljs-number">4.7963e-01</span>,  <span class="hljs-number">1.2881e+00</span>,  ..., -<span class="hljs-number">2.4882e-02</span>,<br>          -<span class="hljs-number">1.5896e+00</span>, -<span class="hljs-number">1.0350e+00</span>],<br>         [ <span class="hljs-number">1.7416e-01</span>, -<span class="hljs-number">4.0688e-01</span>,  <span class="hljs-number">1.9289e+00</span>,  ..., -<span class="hljs-number">4.9754e-01</span>,<br>          -<span class="hljs-number">1.6320e+00</span>, -<span class="hljs-number">1.5217e+00</span>],<br>         [-<span class="hljs-number">1.0874e-01</span>, -<span class="hljs-number">3.3842e-01</span>,  <span class="hljs-number">2.9379e-01</span>,  ..., -<span class="hljs-number">5.1276e-01</span>,<br>          -<span class="hljs-number">1.6150e+00</span>, -<span class="hljs-number">1.1295e+00</span>]]], grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">ln = LayerNorm(feature, eps)<br>ln_result = ln(x)<br><span class="hljs-built_in">print</span>(ln_result)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">2.2697</span>,  <span class="hljs-number">1.3911</span>, -<span class="hljs-number">0.4417</span>,  ...,  <span class="hljs-number">0.9937</span>,  <span class="hljs-number">0.6589</span>, -<span class="hljs-number">1.1902</span>],<br>         [ <span class="hljs-number">1.5876</span>,  <span class="hljs-number">0.5182</span>,  <span class="hljs-number">0.6220</span>,  ...,  <span class="hljs-number">0.9836</span>,  <span class="hljs-number">0.0338</span>, -<span class="hljs-number">1.3393</span>],<br>         [ <span class="hljs-number">1.8261</span>,  <span class="hljs-number">2.0161</span>,  <span class="hljs-number">0.2272</span>,  ...,  <span class="hljs-number">0.3004</span>,  <span class="hljs-number">0.5660</span>, -<span class="hljs-number">0.9044</span>],<br>         [ <span class="hljs-number">1.5429</span>,  <span class="hljs-number">1.3221</span>, -<span class="hljs-number">0.2933</span>,  ...,  <span class="hljs-number">0.0406</span>,  <span class="hljs-number">1.0603</span>,  <span class="hljs-number">1.4666</span>]],<br><br>        [[ <span class="hljs-number">0.2378</span>,  <span class="hljs-number">0.9952</span>,  <span class="hljs-number">1.2621</span>,  ..., -<span class="hljs-number">0.4334</span>, -<span class="hljs-number">1.1644</span>,  <span class="hljs-number">1.2082</span>],<br>         [-<span class="hljs-number">1.0209</span>,  <span class="hljs-number">0.6435</span>,  <span class="hljs-number">0.4235</span>,  ..., -<span class="hljs-number">0.3448</span>, -<span class="hljs-number">1.0560</span>,  <span class="hljs-number">1.2347</span>],<br>         [-<span class="hljs-number">0.8158</span>,  <span class="hljs-number">0.7118</span>,  <span class="hljs-number">0.4110</span>,  ...,  <span class="hljs-number">0.0990</span>, -<span class="hljs-number">1.4833</span>,  <span class="hljs-number">1.9434</span>],<br>         [ <span class="hljs-number">0.9857</span>,  <span class="hljs-number">2.3924</span>,  <span class="hljs-number">0.3819</span>,  ...,  <span class="hljs-number">0.0157</span>, -<span class="hljs-number">1.6300</span>,  <span class="hljs-number">1.2251</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>规范化层总结</code>:</p><ul><li>学习了规范化层的作用:<ul><li>它是所有深层网络模型都需要的标准网络层，因为随着网络层数的增加，通过多层的计算后参数可能开始出现过大或过小的情况，这样可能会导致学习过程出现异常，模型可能收敛非常的慢. 因此都会在一定层数后接规范化层进行数值的规范化，使其特征数值在合理范围内.</li></ul></li></ul><hr><ul><li>学习并实现了规范化层的类: LayerNorm<ul><li>它的实例化参数有两个, features和eps，分别表示词嵌入特征大小，和一个足够小的数.</li><li>它的输入参数x代表来自上一层的输出.</li><li>它的输出就是经过规范化的特征表示.</li></ul></li></ul><h3 id="2-3-6-子层连接结构"><a href="#2-3-6-子层连接结构" class="headerlink" title="2.3.6 子层连接结构"></a>2.3.6 子层连接结构</h3><ul><li>学习目标:<ul><li>了解什么是子层连接结构.</li><li>掌握子层连接结构的实现过程.</li></ul></li></ul><hr><ul><li>什么是子层连接结构:<ul><li>如图所示，输入到每个子层以及规范化层的过程中，还使用了残差链接（跳跃连接），因此我们把这一部分结构整体叫做子层连接（代表子层及其链接结构），在每个编码器层中，都有两个子层，这两个子层加上周围的链接结构就形成了两个子层连接结构.</li></ul></li></ul><hr><ul><li><p>子层连接结构图:</p><p><img src="https://article.biliimg.com/bfs/article/122092d91f732d6ea7ef61d100d3f1fc155712160.png"></p></li></ul><hr><p><img src="https://article.biliimg.com/bfs/article/442c5ecb840fdeae191a0184e836f395155712160.png"></p><ul><li>子层连接结构的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用SublayerConnection来实现子层连接结构的类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SublayerConnection</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, dropout=<span class="hljs-number">0.1</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;它输入参数有两个, size以及dropout， size一般是都是词嵌入维度的大小， </span><br><span class="hljs-string">           dropout本身是对模型结构中的节点数进行随机抑制的比率， </span><br><span class="hljs-string">           又因为节点被抑制等效就是该节点的输出都是0，因此也可以把dropout看作是对输出矩阵的随机置0的比率.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(SublayerConnection, self).__init__()<br>        <span class="hljs-comment"># 实例化了规范化对象self.norm</span><br>        self.norm = LayerNorm(size)<br>        <span class="hljs-comment"># 又使用nn中预定义的droupout实例化一个self.dropout对象.</span><br>        self.dropout = nn.Dropout(p=dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, sublayer</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;前向逻辑函数中, 接收上一个层或者子层的输入作为第一个参数，</span><br><span class="hljs-string">           将该子层连接中的子层函数作为第二个参数&quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># 我们首先对输出进行规范化，然后将结果传给子层处理，之后再对子层进行dropout操作，</span><br>        <span class="hljs-comment"># 随机停止一些网络中神经元的作用，来防止过拟合. 最后还有一个add操作， </span><br>        <span class="hljs-comment"># 因为存在跳跃连接，所以是将输入x与dropout后的子层输出结果相加作为最终的子层连接输出.</span><br>        <span class="hljs-keyword">return</span> x + self.dropout(sublayer(self.norm(x)))<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python">size = <span class="hljs-number">512</span><br>dropout = <span class="hljs-number">0.2</span><br>head = <span class="hljs-number">8</span><br>d_model = <span class="hljs-number">512</span><br><span class="hljs-comment">###################################################</span><br>size = <span class="hljs-number">512</span><br>dropout = <span class="hljs-number">0.2</span><br>head = <span class="hljs-number">8</span><br>d_model = <span class="hljs-number">512</span><br>x = pe_result<br>mask = Variable(torch.zeros(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br>self_attn = MultiHeadedAttention(head, d_model)<br><br>sublayer = <span class="hljs-keyword">lambda</span> x: self_attn(x, x, x, mask)<br><br>sc = SublayerConnection(size, dropout)<br>sc_result = sc(x, sublayer)<br><span class="hljs-built_in">print</span>(sc_result)<br><span class="hljs-built_in">print</span>(sc_result.shape)<br></code></pre></td></tr></table></figure><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 令x为位置编码器的输出</span><br>x = pe_result<br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br><br><span class="hljs-comment"># 假设子层中装的是多头注意力层, 实例化这个类</span><br>self_attn =  MultiHeadedAttention(head, d_model)<br><br><span class="hljs-comment"># 使用lambda获得一个函数类型的子层</span><br>sublayer = <span class="hljs-keyword">lambda</span> x: self_attn(x, x, x, mask)<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">sc = SublayerConnection(size, dropout)<br>sc_result = sc(x, sublayer)<br><span class="hljs-built_in">print</span>(sc_result)<br><span class="hljs-built_in">print</span>(sc_result.shape)<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">14.8830</span>,  <span class="hljs-number">22.4106</span>, -<span class="hljs-number">31.4739</span>,  ...,  <span class="hljs-number">21.0882</span>, -<span class="hljs-number">10.0338</span>,  -<span class="hljs-number">0.2588</span>],<br>         [-<span class="hljs-number">25.1435</span>,   <span class="hljs-number">2.9246</span>, -<span class="hljs-number">16.1235</span>,  ...,  <span class="hljs-number">10.5069</span>,  -<span class="hljs-number">7.1007</span>,  -<span class="hljs-number">3.7396</span>],<br>         [  <span class="hljs-number">0.1374</span>,  <span class="hljs-number">32.6438</span>,  <span class="hljs-number">12.3680</span>,  ..., -<span class="hljs-number">12.0251</span>, -<span class="hljs-number">40.5829</span>,   <span class="hljs-number">2.2297</span>],<br>         [-<span class="hljs-number">13.3123</span>,  <span class="hljs-number">55.4689</span>,   <span class="hljs-number">9.5420</span>,  ..., -<span class="hljs-number">12.6622</span>,  <span class="hljs-number">23.4496</span>,  <span class="hljs-number">21.1531</span>]],<br><br>        [[ <span class="hljs-number">13.3533</span>,  <span class="hljs-number">17.5674</span>, -<span class="hljs-number">13.3354</span>,  ...,  <span class="hljs-number">29.1366</span>,  -<span class="hljs-number">6.4898</span>,  <span class="hljs-number">35.8614</span>],<br>         [-<span class="hljs-number">35.2286</span>,  <span class="hljs-number">18.7378</span>, -<span class="hljs-number">31.4337</span>,  ...,  <span class="hljs-number">11.1726</span>,  <span class="hljs-number">20.6372</span>,  <span class="hljs-number">29.8689</span>],<br>         [-<span class="hljs-number">30.7627</span>,   <span class="hljs-number">0.0000</span>, -<span class="hljs-number">57.0587</span>,  ...,  <span class="hljs-number">15.0724</span>, -<span class="hljs-number">10.7196</span>, -<span class="hljs-number">18.6290</span>],<br>         [ -<span class="hljs-number">2.7757</span>, -<span class="hljs-number">19.6408</span>,   <span class="hljs-number">0.0000</span>,  ...,  <span class="hljs-number">12.7660</span>,  <span class="hljs-number">21.6843</span>, -<span class="hljs-number">35.4784</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>子层连接结构总结</code>:</p><ul><li>什么是子层连接结构:<ul><li>如图所示，输入到每个子层以及规范化层的过程中，还使用了残差链接（跳跃连接），因此我们把这一部分结构整体叫做子层连接（代表子层及其链接结构）, 在每个编码器层中，都有两个子层，这两个子层加上周围的链接结构就形成了两个子层连接结构.</li></ul></li></ul><hr><ul><li>学习并实现了子层连接结构的类: SublayerConnection<ul><li>类的初始化函数输入参数是size, dropout, 分别代表<code>词嵌入大小</code>和<code>置零比率</code>.</li><li>它的实例化对象输入参数是x, sublayer, 分别代表上一层输出以及子层的函数表示.</li><li>它的输出就是通过子层连接结构处理的输出.</li></ul></li></ul><h3 id="2-3-7-编码器层"><a href="#2-3-7-编码器层" class="headerlink" title="2.3.7 编码器层"></a>2.3.7 编码器层</h3><ul><li><p>学习目标:</p><ul><li><p>了解编码器层的作用.</p></li><li><p>掌握编码器层的实现过程.</p></li></ul></li></ul><hr><ul><li>编码器层的作用:<ul><li>作为编码器的组成单元, 每个编码器层完成一次对输入的特征提取过程, 即编码过程.</li></ul></li></ul><hr><ul><li>编码器层的构成图:</li></ul><img src="https://article.biliimg.com/bfs/article/f46db8ec8cc3f5cc82fe1a014104a212155712160.png" style="zoom: 67%;" /><ul><li>编码器层的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"> 使用EncoderLayer类实现编码器层 构建编码器层的类<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, self_attn, feed_forward, dropout</span>):<br>        <span class="hljs-comment"># size：代表词嵌入的维度</span><br>        <span class="hljs-comment"># self_at tn：代表传入的多头自注意力子层的实例化对象</span><br>        <span class="hljs-comment"># feed_forward：代表前馈全连接层实例化对象</span><br>        <span class="hljs-comment"># dropout：进行dropout操作时的置零比率</span><br><br>        <span class="hljs-string">&quot;&quot;&quot;它的初始化函数参数有四个，分别是size，其实就是我们词嵌入维度的大小，它也将作为我们编码器层的大小,</span><br><span class="hljs-string">           第二个self_attn，之后我们将传入多头自注意力子层实例化对象, 并且是自注意力机制,</span><br><span class="hljs-string">           第三个是feed_froward, 之后我们将传入前馈全连接层实例化对象, 最后一个是置0比率dropout.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(EncoderLayer, self).__init__()<br><br>        <span class="hljs-comment"># 首先将self_attn和feed_forward传入其中.</span><br>        <span class="hljs-comment"># 将两个实例化对象和参数传入类中</span><br><br>        self.self_attn = self_attn<br>        self.feed_forward = feed_forward<br><br>        <span class="hljs-comment"># 如图所示, 编码器层中有两个子层连接结构, 所以使用clones函数进行克隆操作</span><br>        self.sublayer = clones(SublayerConnection(size, dropout), <span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># 把size传入其中</span><br>        self.size = size<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>        <span class="hljs-comment"># X：代表上一层的传入张量</span><br>        <span class="hljs-comment"># mask：代表掩码张量</span><br>        <span class="hljs-comment"># 首先让经过第一个子层连接结构，内部包含多头自注意力机制子层</span><br>        <span class="hljs-comment"># 再让张量经过第二个子层连接结构，其中包含前馈全连接网络</span><br><br>        <span class="hljs-comment"># forward函数中有两个输入参数，x和mask，分别代表上一层的输出，和掩码张量mask.</span><br>        <span class="hljs-comment"># 里面就是按照结构图左侧的流程. 首先通过第一个子层连接结构，其中包含多头自注意力子层，</span><br>        <span class="hljs-comment"># 然后通过第二个子层连接结构，其中包含前馈全连接子层. 最后返回结果.</span><br>        x = self.sublayer[<span class="hljs-number">0</span>](x, <span class="hljs-keyword">lambda</span> x: self.self_attn(x, x, x, mask))<br>        <span class="hljs-keyword">return</span> self.sublayer[<span class="hljs-number">1</span>](x, self.feed_forward)<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>size = <span class="hljs-number">512</span><br>head = <span class="hljs-number">8</span><br>d_model = <span class="hljs-number">512</span><br>d_ff = <span class="hljs-number">64</span><br>x = pe_result<br>dropout = <span class="hljs-number">0.2</span><br>self_attn = MultiHeadedAttention(head, d_model)<br>ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">el = EncoderLayer(size, self_attn, ff, dropout)<br>el_result = el(x, mask)<br><span class="hljs-built_in">print</span>(el_result)<br><span class="hljs-built_in">print</span>(el_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">33.6988</span>, -<span class="hljs-number">30.7224</span>,  <span class="hljs-number">20.9575</span>,  ...,   <span class="hljs-number">5.2968</span>, -<span class="hljs-number">48.5658</span>,  <span class="hljs-number">20.0734</span>],<br>         [-<span class="hljs-number">18.1999</span>,  <span class="hljs-number">34.2358</span>,  <span class="hljs-number">40.3094</span>,  ...,  <span class="hljs-number">10.1102</span>,  <span class="hljs-number">58.3381</span>,  <span class="hljs-number">58.4962</span>],<br>         [ <span class="hljs-number">32.1243</span>,  <span class="hljs-number">16.7921</span>,  -<span class="hljs-number">6.8024</span>,  ...,  <span class="hljs-number">23.0022</span>, -<span class="hljs-number">18.1463</span>, -<span class="hljs-number">17.1263</span>],<br>         [ -<span class="hljs-number">9.3475</span>,  -<span class="hljs-number">3.3605</span>, -<span class="hljs-number">55.3494</span>,  ...,  <span class="hljs-number">43.6333</span>,  -<span class="hljs-number">0.1900</span>,   <span class="hljs-number">0.1625</span>]],<br><br>        [[ <span class="hljs-number">32.8937</span>, -<span class="hljs-number">46.2808</span>,   <span class="hljs-number">8.5047</span>,  ...,  <span class="hljs-number">29.1837</span>,  <span class="hljs-number">22.5962</span>, -<span class="hljs-number">14.4349</span>],<br>         [ <span class="hljs-number">21.3379</span>,  <span class="hljs-number">20.0657</span>, -<span class="hljs-number">31.7256</span>,  ..., -<span class="hljs-number">13.4079</span>, -<span class="hljs-number">44.0706</span>,  -<span class="hljs-number">9.9504</span>],<br>         [ <span class="hljs-number">19.7478</span>,  -<span class="hljs-number">1.0848</span>,  <span class="hljs-number">11.8884</span>,  ...,  -<span class="hljs-number">9.5794</span>,   <span class="hljs-number">0.0675</span>,  -<span class="hljs-number">4.7123</span>],<br>         [ -<span class="hljs-number">6.8023</span>, -<span class="hljs-number">16.1176</span>,  <span class="hljs-number">20.9476</span>,  ...,  -<span class="hljs-number">6.5469</span>,  <span class="hljs-number">34.8391</span>, -<span class="hljs-number">14.9798</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>编码器层总结</code>：</p><ul><li>学习了编码器层的作用:<ul><li>作为编码器的组成单元, 每个编码器层完成一次对输入的特征提取过程, 即编码过程.</li></ul></li></ul><hr><ul><li>学习并实现了编码器层的类: EncoderLayer<ul><li>类的初始化函数共有4个, 别是size，其实就是我们词嵌入维度的大小. 第二个self_attn，之后我们将传入多头自注意力子层实例化对象, 并且是自注意力机制. 第三个是feed_froward, 之后我们将传入前馈全连接层实例化对象. 最后一个是置0比率dropout.<ul><li>实例化对象的输入参数有2个，x代表来自上一层的输出, mask代表掩码张量.</li><li>它的输出代表经过整个编码层的特征表示.</li></ul></li></ul></li></ul><h3 id="2-3-8-编码器"><a href="#2-3-8-编码器" class="headerlink" title="2.3.8 编码器"></a>2.3.8 编码器</h3><ul><li>学习目标:<ul><li>了解编码器的作用.</li><li>掌握编码器的实现过程.</li></ul></li></ul><hr><ul><li>编码器的作用:<ul><li>编码器用于对输入进行指定的特征提取过程, 也称为编码, 由N个编码器层堆叠而成.</li></ul></li></ul><hr><ul><li>编码器的结构图:</li></ul><p><img src="https://pic1.zhimg.com/80/v2-306c89830ea9efe5953ae4d8b76492a4_1440w.webp" alt="img"></p><ul><li>编码器的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用Encoder类来实现编码器</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Encoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer, N</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数的两个参数分别代表编码器层和编码器层的个数&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(Encoder, self).__init__()<br>        <span class="hljs-comment"># 首先使用clones函数克隆N个编码器层放在self.layers中</span><br>        self.layers = clones(layer, N)<br>        <span class="hljs-comment"># 再初始化一个规范化层, 它将用在编码器的最后面.</span><br>        self.norm = LayerNorm(layer.size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;forward函数的输入和编码器层相同, x代表上一层的输出, mask代表掩码张量&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 首先就是对我们克隆的编码器层进行循环，每次都会得到一个新的x，</span><br>        <span class="hljs-comment"># 这个循环的过程，就相当于输出的x经过了N个编码器层的处理. </span><br>        <span class="hljs-comment"># 最后再通过规范化层的对象self.norm进行处理，最后返回结果. </span><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            x = layer(x, mask)<br>        <span class="hljs-keyword">return</span> self.norm(x)<br></code></pre></td></tr></table></figure><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 第一个实例化参数layer, 它是一个编码器层的实例化对象, 因此需要传入编码器层的参数</span><br><span class="hljs-comment"># 又因为编码器层中的子层是不共享的, 因此需要使用深度拷贝各个对象.</span><br>size = <span class="hljs-number">512</span><br>head = <span class="hljs-number">8</span><br>d_model = <span class="hljs-number">512</span><br>d_ff = <span class="hljs-number">64</span><br>c = copy.deepcopy<br>attn = MultiHeadedAttention(head, d_model)<br>ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>dropout = <span class="hljs-number">0.2</span><br>layer = EncoderLayer(size, c(attn), c(ff), dropout)<br><br><span class="hljs-comment"># 编码器中编码器层的个数N</span><br>N = <span class="hljs-number">8</span><br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">en = Encoder(layer, N)<br>en_result = en(x, mask)<br><span class="hljs-built_in">print</span>(en_result)<br><span class="hljs-built_in">print</span>(en_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[-<span class="hljs-number">0.2081</span>, -<span class="hljs-number">0.3586</span>, -<span class="hljs-number">0.2353</span>,  ...,  <span class="hljs-number">2.5646</span>, -<span class="hljs-number">0.2851</span>,  <span class="hljs-number">0.0238</span>],<br>         [ <span class="hljs-number">0.7957</span>, -<span class="hljs-number">0.5481</span>,  <span class="hljs-number">1.2443</span>,  ...,  <span class="hljs-number">0.7927</span>,  <span class="hljs-number">0.6404</span>, -<span class="hljs-number">0.0484</span>],<br>         [-<span class="hljs-number">0.1212</span>,  <span class="hljs-number">0.4320</span>, -<span class="hljs-number">0.5644</span>,  ...,  <span class="hljs-number">1.3287</span>, -<span class="hljs-number">0.0935</span>, -<span class="hljs-number">0.6861</span>],<br>         [-<span class="hljs-number">0.3937</span>, -<span class="hljs-number">0.6150</span>,  <span class="hljs-number">2.2394</span>,  ..., -<span class="hljs-number">1.5354</span>,  <span class="hljs-number">0.7981</span>,  <span class="hljs-number">1.7907</span>]],<br><br>        [[-<span class="hljs-number">2.3005</span>,  <span class="hljs-number">0.3757</span>,  <span class="hljs-number">1.0360</span>,  ...,  <span class="hljs-number">1.4019</span>,  <span class="hljs-number">0.6493</span>, -<span class="hljs-number">0.1467</span>],<br>         [ <span class="hljs-number">0.5653</span>,  <span class="hljs-number">0.1569</span>,  <span class="hljs-number">0.4075</span>,  ..., -<span class="hljs-number">0.3205</span>,  <span class="hljs-number">1.4774</span>, -<span class="hljs-number">0.5856</span>],<br>         [-<span class="hljs-number">1.0555</span>,  <span class="hljs-number">0.0061</span>, -<span class="hljs-number">1.8165</span>,  ..., -<span class="hljs-number">0.4339</span>, -<span class="hljs-number">1.8780</span>,  <span class="hljs-number">0.2467</span>],<br>         [-<span class="hljs-number">2.1617</span>, -<span class="hljs-number">1.5532</span>, -<span class="hljs-number">1.4330</span>,  ..., -<span class="hljs-number">0.9433</span>, -<span class="hljs-number">0.5304</span>, -<span class="hljs-number">1.7022</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><strong>编码器总结：</strong></p><ul><li>学习了编码器的作用:<ul><li>编码器用于对输入进行指定的特征提取过程, 也称为编码, 由N个编码器层堆叠而成.</li></ul></li></ul><hr><ul><li>学习并实现了编码器的类: Encoder<ul><li>类的初始化函数参数有两个，分别是layer和N，代表编码器层和编码器层的个数.</li><li>forward函数的输入参数也有两个, 和编码器层的forward相同, x代表上一层的输出, mask代码掩码张量.</li><li>编码器类的输出就是Transformer中编码器的特征提取表示, 它将成为解码器的输入的一部分.</li></ul></li></ul><h2 id="2-4-解码器部分实现"><a href="#2-4-解码器部分实现" class="headerlink" title="2.4 解码器部分实现"></a>2.4 解码器部分实现</h2><ul><li><p>学习目标</p><ul><li><p>了解解码器中各个组成部分的作用.</p></li><li><p>掌握解码器中各个组成部分的实现过程.</p></li></ul></li></ul><hr><ul><li><p>解码器部分:</p><ul><li>由N个解码器层堆叠而成</li><li>每个解码器层由三个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和<code>规范化层以及一个残差连接</code></li><li>第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接</li><li>第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul></li></ul><p><img src="https://pic1.zhimg.com/80/v2-4e17a521400c92b41a5927e5c40aeef0_1440w.webp" alt="img"></p><p>说明:</p><ul><li>解码器层中的各个部分，如，多头注意力机制，规范化层，前馈全连接网络，子层连接结构都与编码器中的实现相同. 因此这里可以直接拿来构建解码器层.</li></ul><hr><h3 id="2-4-1-解码器层"><a href="#2-4-1-解码器层" class="headerlink" title="2.4.1 解码器层"></a>2.4.1 解码器层</h3><ul><li>学习目标:<ul><li>了解解码器的作用.</li><li>掌握解码器的实现过程.</li></ul></li></ul><hr><ul><li>解码器的作用:<ul><li>作为解码器的组成单元, 每个解码器层根据给定的输入向目标方向进行特征提取操作，即解码过程.</li></ul></li></ul><hr><ul><li>解码器层的代码实现</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用DecoderLayer的类实现解码器层</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">DecoderLayer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, size, self_attn, src_attn, feed_forward, dropout</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数的参数有5个, 分别是size，代表词嵌入的维度大小, 同时也代表解码器层的尺寸，</span><br><span class="hljs-string">            第二个是self_attn，多头自注意力对象，也就是说这个注意力机制需要Q=K=V， </span><br><span class="hljs-string">            第三个是src_attn，多头注意力对象，这里Q!=K=V， 第四个是前馈全连接层对象，最后就是droupout置0比率.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(DecoderLayer, self).__init__()<br>        <span class="hljs-comment"># 在初始化函数中， 主要就是将这些输入传到类中</span><br>        self.size = size<br>        self.self_attn = self_attn<br>        self.src_attn = src_attn<br>        self.feed_forward = feed_forward<br>        <span class="hljs-comment"># 按照结构图使用clones函数克隆三个子层连接对象.</span><br>        self.sublayer = clones(SublayerConnection(size, dropout), <span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, memory, source_mask, target_mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;forward函数中的参数有4个，分别是来自上一层的输入x，</span><br><span class="hljs-string">           来自编码器层的语义存储变量mermory， 以及源数据掩码张量和目标数据掩码张量.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 将memory表示成m方便之后使用</span><br>        m = memory<br><br>        <span class="hljs-comment"># 将x传入第一个子层结构，第一个子层结构的输入分别是x和self-attn函数，因为是自注意力机制，所以Q,K,V都是x，</span><br>        <span class="hljs-comment"># 最后一个参数是目标数据掩码张量，这时要对目标数据进行遮掩，因为此时模型可能还没有生成任何目标数据，</span><br>        <span class="hljs-comment"># 比如在解码器准备生成第一个字符或词汇时，我们其实已经传入了第一个字符以便计算损失，</span><br>        <span class="hljs-comment"># 但是我们不希望在生成第一个字符时模型能利用这个信息，因此我们会将其遮掩，同样生成第二个字符或词汇时，</span><br>        <span class="hljs-comment"># 模型只能使用第一个字符或词汇信息，第二个字符以及之后的信息都不允许被模型使用.</span><br>        x = self.sublayer[<span class="hljs-number">0</span>](x, <span class="hljs-keyword">lambda</span> x: self.self_attn(x, x, x, target_mask))<br><br>        <span class="hljs-comment"># 接着进入第二个子层，这个子层中常规的注意力机制，q是输入x; k，v是编码层输出memory， </span><br>        <span class="hljs-comment"># 同样也传入source_mask，但是进行源数据遮掩的原因并非是抑制信息泄漏，而是遮蔽掉对结果没有意义的字符而产生的注意力值，</span><br>        <span class="hljs-comment"># 以此提升模型效果和训练速度. 这样就完成了第二个子层的处理.</span><br>        x = self.sublayer[<span class="hljs-number">1</span>](x, <span class="hljs-keyword">lambda</span> x: self.src_attn(x, m, m, source_mask))<br><br>        <span class="hljs-comment"># 最后一个子层就是前馈全连接子层，经过它的处理后就可以返回结果.这就是我们的解码器层结构.</span><br>        <span class="hljs-keyword">return</span> self.sublayer[<span class="hljs-number">2</span>](x, self.feed_forward)<br></code></pre></td></tr></table></figure><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 类的实例化参数与解码器层类似, 相比多出了src_attn, 但是和self_attn是同一个类.</span><br>head = <span class="hljs-number">8</span><br>size = <span class="hljs-number">512</span><br>d_model = <span class="hljs-number">512</span><br>d_ff = <span class="hljs-number">64</span><br>dropout = <span class="hljs-number">0.2</span><br>self_attn = src_attn = MultiHeadedAttention(head, d_model, dropout)<br><br><span class="hljs-comment"># 前馈全连接层也和之前相同 </span><br>ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># x是来自目标数据的词嵌入表示, 但形式和源数据的词嵌入表示相同, 这里使用per充当.</span><br>x = pe_result<br><br><span class="hljs-comment"># memory是来自编码器的输出</span><br>memory = en_result<br><br><span class="hljs-comment"># 实际中source_mask和target_mask并不相同, 这里为了方便计算使他们都为mask</span><br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br>source_mask = target_mask = mask<br></code></pre></td></tr></table></figure><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">dl = DecoderLayer(size, self_attn, src_attn, ff, dropout)<br>dl_result = dl(x, memory, source_mask, target_mask)<br><span class="hljs-built_in">print</span>(dl_result)<br><span class="hljs-built_in">print</span>(dl_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">1.9604e+00</span>,  <span class="hljs-number">3.9288e+01</span>, -<span class="hljs-number">5.2422e+01</span>,  ...,  <span class="hljs-number">2.1041e-01</span>,<br>          -<span class="hljs-number">5.5063e+01</span>,  <span class="hljs-number">1.5233e-01</span>],<br>         [ <span class="hljs-number">1.0135e-01</span>, -<span class="hljs-number">3.7779e-01</span>,  <span class="hljs-number">6.5491e+01</span>,  ...,  <span class="hljs-number">2.8062e+01</span>,<br>          -<span class="hljs-number">3.7780e+01</span>, -<span class="hljs-number">3.9577e+01</span>],<br>         [ <span class="hljs-number">1.9526e+01</span>, -<span class="hljs-number">2.5741e+01</span>,  <span class="hljs-number">2.6926e-01</span>,  ..., -<span class="hljs-number">1.5316e+01</span>,<br>           <span class="hljs-number">1.4543e+00</span>,  <span class="hljs-number">2.7714e+00</span>],<br>         [-<span class="hljs-number">2.1528e+01</span>,  <span class="hljs-number">2.0141e+01</span>,  <span class="hljs-number">2.1999e+01</span>,  ...,  <span class="hljs-number">2.2099e+00</span>,<br>          -<span class="hljs-number">1.7267e+01</span>, -<span class="hljs-number">1.6687e+01</span>]],<br><br>        [[ <span class="hljs-number">6.7259e+00</span>, -<span class="hljs-number">2.6918e+01</span>,  <span class="hljs-number">1.1807e+01</span>,  ..., -<span class="hljs-number">3.6453e+01</span>,<br>          -<span class="hljs-number">2.9231e+01</span>,  <span class="hljs-number">1.1288e+01</span>],<br>         [ <span class="hljs-number">7.7484e+01</span>, -<span class="hljs-number">5.0572e-01</span>, -<span class="hljs-number">1.3096e+01</span>,  ...,  <span class="hljs-number">3.6302e-01</span>,<br>           <span class="hljs-number">1.9907e+01</span>, -<span class="hljs-number">1.2160e+00</span>],<br>         [ <span class="hljs-number">2.6703e+01</span>,  <span class="hljs-number">4.4737e+01</span>, -<span class="hljs-number">3.1590e+01</span>,  ...,  <span class="hljs-number">4.1540e-03</span>,<br>           <span class="hljs-number">5.2587e+00</span>,  <span class="hljs-number">5.2382e+00</span>],<br>         [ <span class="hljs-number">4.7435e+01</span>, -<span class="hljs-number">3.7599e-01</span>,  <span class="hljs-number">5.0898e+01</span>,  ...,  <span class="hljs-number">5.6361e+00</span>,<br>           <span class="hljs-number">3.5891e+01</span>,  <span class="hljs-number">1.5697e+01</span>]]], grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><code>解码器层总结</code>：</p><ul><li>学习了解码器层的作用:<ul><li>作为解码器的组成单元, 每个解码器层根据给定的输入向目标方向进行特征提取操作，即解码过程.</li></ul></li></ul><hr><ul><li>学习并实现了解码器层的类: DecoderLayer<ul><li>类的初始化函数的参数有5个, 分别是size，代表词嵌入的维度大小, 同时也代表解码器层的尺寸，第二个是self_attn，多头自注意力对象，也就是说这个注意力机制需要Q&#x3D;K&#x3D;V，第三个是src_attn，多头注意力对象，这里Q!&#x3D;K&#x3D;V， 第四个是前馈全连接层对象，最后就是droupout置0比率.</li><li>forward函数的参数有4个，分别是来自上一层的输入x，来自编码器层的语义存储变量mermory， 以及源数据掩码张量和目标数据掩码张量.</li><li>最终输出了由编码器输入和目标数据一同作用的特征提取结果.</li></ul></li></ul><h3 id="2-4-2-解码器"><a href="#2-4-2-解码器" class="headerlink" title="2.4.2 解码器"></a>2.4.2 解码器</h3><ul><li>学习目标:<ul><li>了解解码器的作用.</li><li>掌握解码器的实现过程.</li></ul></li></ul><hr><ul><li>解码器的作用:<ul><li>根据编码器的结果以及上一次预测的结果, 对下一次可能出现的’值’进行特征表示.</li></ul></li></ul><hr><ul><li>解码器的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用类Decoder来实现解码器</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Decoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, layer, N</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数的参数有两个，第一个就是解码器层layer，第二个是解码器层的个数N.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(Decoder, self).__init__()<br>        <span class="hljs-comment"># 首先使用clones方法克隆了N个layer，然后实例化了一个规范化层. </span><br>        <span class="hljs-comment"># 因为数据走过了所有的解码器层后最后要做规范化处理. </span><br>        self.layers = clones(layer, N)<br>        self.norm = LayerNorm(layer.size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, memory, source_mask, target_mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;forward函数中的参数有4个，x代表目标数据的嵌入表示，memory是编码器层的输出，</span><br><span class="hljs-string">           source_mask, target_mask代表源数据和目标数据的掩码张量&quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># 然后就是对每个层进行循环，当然这个循环就是变量x通过每一个层的处理，</span><br>        <span class="hljs-comment"># 得出最后的结果，再进行一次规范化返回即可. </span><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            x = layer(x, memory, source_mask, target_mask)<br>        <span class="hljs-keyword">return</span> self.norm(x)<br></code></pre></td></tr></table></figure><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分别是解码器层layer和解码器层的个数N</span><br>size = <span class="hljs-number">512</span><br>d_model = <span class="hljs-number">512</span><br>head = <span class="hljs-number">8</span><br>d_ff = <span class="hljs-number">64</span><br>dropout = <span class="hljs-number">0.2</span><br>c = copy.deepcopy<br>attn = MultiHeadedAttention(head, d_model)<br>ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br>layer = DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout)<br>N = <span class="hljs-number">8</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入参数与解码器层的输入参数相同</span><br>x = pe_result<br>memory = en_result<br>mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br>source_mask = target_mask = mask<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">de = Decoder(layer, N)<br>de_result = de(x, memory, source_mask, target_mask)<br><span class="hljs-built_in">print</span>(de_result)<br><span class="hljs-built_in">print</span>(de_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">0.9898</span>, -<span class="hljs-number">0.3216</span>, -<span class="hljs-number">1.2439</span>,  ...,  <span class="hljs-number">0.7427</span>, -<span class="hljs-number">0.0717</span>, -<span class="hljs-number">0.0814</span>],<br>         [-<span class="hljs-number">0.7432</span>,  <span class="hljs-number">0.6985</span>,  <span class="hljs-number">1.5551</span>,  ...,  <span class="hljs-number">0.5232</span>, -<span class="hljs-number">0.5685</span>,  <span class="hljs-number">1.3387</span>],<br>         [ <span class="hljs-number">0.2149</span>,  <span class="hljs-number">0.5274</span>, -<span class="hljs-number">1.6414</span>,  ...,  <span class="hljs-number">0.7476</span>,  <span class="hljs-number">0.5082</span>, -<span class="hljs-number">3.0132</span>],<br>         [ <span class="hljs-number">0.4408</span>,  <span class="hljs-number">0.9416</span>,  <span class="hljs-number">0.4522</span>,  ..., -<span class="hljs-number">0.1506</span>,  <span class="hljs-number">1.5591</span>, -<span class="hljs-number">0.6453</span>]],<br><br>        [[-<span class="hljs-number">0.9027</span>,  <span class="hljs-number">0.5874</span>,  <span class="hljs-number">0.6981</span>,  ...,  <span class="hljs-number">2.2899</span>,  <span class="hljs-number">0.2933</span>, -<span class="hljs-number">0.7508</span>],<br>         [ <span class="hljs-number">1.2246</span>, -<span class="hljs-number">1.0856</span>, -<span class="hljs-number">0.2497</span>,  ..., -<span class="hljs-number">1.2377</span>,  <span class="hljs-number">0.0847</span>, -<span class="hljs-number">0.0221</span>],<br>         [ <span class="hljs-number">3.4012</span>, -<span class="hljs-number">0.4181</span>, -<span class="hljs-number">2.0968</span>,  ..., -<span class="hljs-number">1.5427</span>,  <span class="hljs-number">0.1090</span>, -<span class="hljs-number">0.3882</span>],<br>         [-<span class="hljs-number">0.1050</span>, -<span class="hljs-number">0.5140</span>, -<span class="hljs-number">0.6494</span>,  ..., -<span class="hljs-number">0.4358</span>, -<span class="hljs-number">1.2173</span>,  <span class="hljs-number">0.4161</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><p><strong>解码器总结：</strong></p><ul><li>学习了解码器的作用:<ul><li>根据编码器的结果以及上一次预测的结果, 对下一次可能出现的’值’进行特征表示.</li></ul></li></ul><hr><ul><li>学习并实现了解码器的类: Decoder<ul><li>类的初始化函数的参数有两个，第一个就是解码器层layer，第二个是解码器层的个数N.</li><li>forward函数中的参数有4个，x代表目标数据的嵌入表示，memory是编码器层的输出，src_mask, tgt_mask代表源数据和目标数据的掩码张量.</li><li>输出解码过程的最终特征表示.</li></ul></li></ul><h2 id="2-5-输出部分实现"><a href="#2-5-输出部分实现" class="headerlink" title="2.5 输出部分实现"></a>2.5 输出部分实现</h2><ul><li><p>学习目标</p><ul><li><p>了解线性层和softmax的作用.</p></li><li><p>掌握线性层和softmax的实现过程.</p></li></ul></li></ul><hr><ul><li>输出部分包含:<ul><li>线性层</li><li>softmax层</li></ul></li></ul><p><img src="https://pic3.zhimg.com/80/v2-4b2d21a7199c6f261c9caca82e213b96_1440w.webp" alt="img"></p><ul><li>线性层的作用<ul><li>通过对上一步的线性变化得到指定维度的输出, 也就是转换维度的作用.</li></ul></li></ul><hr><ul><li>softmax层的作用</li><li>使最后一维的向量中的数字缩放到0-1的概率值域内, 并满足他们的和为1.</li></ul><hr><ul><li>线性层和softmax层的代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># nn.functional工具包装载了网络层中那些只进行计算, 而没有参数的层</span><br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-comment"># 将线性层和softmax计算层一起实现, 因为二者的共同目标是生成最后的结构</span><br><span class="hljs-comment"># 因此把类的名字叫做Generator, 生成器类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Generator</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, vocab_size</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数的输入参数有两个, d_model代表词嵌入维度, vocab_size代表词表大小.&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(Generator, self).__init__()<br>        <span class="hljs-comment"># 首先就是使用nn中的预定义线性层进行实例化, 得到一个对象self.project等待使用, </span><br>        <span class="hljs-comment"># 这个线性层的参数有两个, 就是初始化函数传进来的两个参数: d_model, vocab_size</span><br>        self.project = nn.Linear(d_model, vocab_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;前向逻辑函数中输入是上一层的输出张量x&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 在函数中, 首先使用上一步得到的self.project对x进行线性变化, </span><br>        <span class="hljs-comment"># 然后使用F中已经实现的log_softmax进行的softmax处理.</span><br>        <span class="hljs-comment"># 在这里之所以使用log_softmax是因为和我们这个pytorch版本的损失函数实现有关, 在其他版本中将修复.</span><br>        <span class="hljs-comment"># log_softmax就是对softmax的结果又取了对数, 因为对数函数是单调递增函数, </span><br>        <span class="hljs-comment"># 因此对最终我们取最大的概率值没有影响. 最后返回结果即可.</span><br>        <span class="hljs-keyword">return</span> F.log_softmax(self.project(x), dim=-<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><hr><ul><li>nn.Linear演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>m = nn.Linear(<span class="hljs-number">20</span>, <span class="hljs-number">30</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">input</span> = torch.randn(<span class="hljs-number">128</span>, <span class="hljs-number">20</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>output = m(<span class="hljs-built_in">input</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.size())<br>torch.Size([<span class="hljs-number">128</span>, <span class="hljs-number">30</span>])<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 词嵌入维度是512维</span><br>d_model = <span class="hljs-number">512</span><br><br><span class="hljs-comment"># 词表大小是1000</span><br>vocab_size = <span class="hljs-number">1000</span><br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 输入x是上一层网络的输出, 我们使用来自解码器层的输出</span><br>x = de_result<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">gen = Generator(d_model, vocab_size)<br>gen_result = gen(x)<br><span class="hljs-built_in">print</span>(gen_result)<br><span class="hljs-built_in">print</span>(gen_result.shape)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[-<span class="hljs-number">7.8098</span>, -<span class="hljs-number">7.5260</span>, -<span class="hljs-number">6.9244</span>,  ..., -<span class="hljs-number">7.6340</span>, -<span class="hljs-number">6.9026</span>, -<span class="hljs-number">7.5232</span>],<br>         [-<span class="hljs-number">6.9093</span>, -<span class="hljs-number">7.3295</span>, -<span class="hljs-number">7.2972</span>,  ..., -<span class="hljs-number">6.6221</span>, -<span class="hljs-number">7.2268</span>, -<span class="hljs-number">7.0772</span>],<br>         [-<span class="hljs-number">7.0263</span>, -<span class="hljs-number">7.2229</span>, -<span class="hljs-number">7.8533</span>,  ..., -<span class="hljs-number">6.7307</span>, -<span class="hljs-number">6.9294</span>, -<span class="hljs-number">7.3042</span>],<br>         [-<span class="hljs-number">6.5045</span>, -<span class="hljs-number">6.0504</span>, -<span class="hljs-number">6.6241</span>,  ..., -<span class="hljs-number">5.9063</span>, -<span class="hljs-number">6.5361</span>, -<span class="hljs-number">7.1484</span>]],<br><br>        [[-<span class="hljs-number">7.1651</span>, -<span class="hljs-number">6.0224</span>, -<span class="hljs-number">7.4931</span>,  ..., -<span class="hljs-number">7.9565</span>, -<span class="hljs-number">8.0460</span>, -<span class="hljs-number">6.6490</span>],<br>         [-<span class="hljs-number">6.3779</span>, -<span class="hljs-number">7.6133</span>, -<span class="hljs-number">8.3572</span>,  ..., -<span class="hljs-number">6.6565</span>, -<span class="hljs-number">7.1867</span>, -<span class="hljs-number">6.5112</span>],<br>         [-<span class="hljs-number">6.4914</span>, -<span class="hljs-number">6.9289</span>, -<span class="hljs-number">6.2634</span>,  ..., -<span class="hljs-number">6.2471</span>, -<span class="hljs-number">7.5348</span>, -<span class="hljs-number">6.8541</span>],<br>         [-<span class="hljs-number">6.8651</span>, -<span class="hljs-number">7.0460</span>, -<span class="hljs-number">7.6239</span>,  ..., -<span class="hljs-number">7.1411</span>, -<span class="hljs-number">6.5496</span>, -<span class="hljs-number">7.3749</span>]]],<br>       grad_fn=&lt;LogSoftmaxBackward&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1000</span>])<br></code></pre></td></tr></table></figure><ul><li><p>小节总结</p><ul><li>学习了输出部分包含:<ul><li>线性层</li><li>softmax层</li></ul></li></ul><hr><ul><li>线性层的作用:<ul><li>通过对上一步的线性变化得到指定维度的输出, 也就是转换维度的作用.</li></ul></li></ul><hr><ul><li><p>softmax层的作用:</p><ul><li>使最后一维的向量中的数字缩放到0-1的概率值域内, 并满足他们的和为1.</li></ul></li></ul><hr><ul><li><p>学习并实现了线性层和softmax层的类: Generator</p><ul><li>初始化函数的输入参数有两个, d_model代表词嵌入维度, vocab_size代表词表大小.</li><li>forward函数接受上一层的输出.</li><li>最终获得经过线性层和softmax层处理的结果.</li></ul></li></ul></li></ul><h2 id="2-6-模型的构建"><a href="#2-6-模型的构建" class="headerlink" title="2.6 模型的构建"></a>2.6 模型的构建</h2><ul><li>学习目标<ul><li>掌握编码器-解码器结构的实现过程.</li><li>掌握Transformer模型的构建过程.</li></ul></li></ul><hr><ul><li>通过上面的小节, 我们已经完成了所有组成部分的实现, 接下来就来实现完整的编码器-解码器结构.</li></ul><hr><ul><li>Transformer总体架构图:</li></ul><img src="https://article.biliimg.com/bfs/article/e29cac3e97a731b009805f5fc7842ffa155712160.png" style="zoom:80%;" /><h3 id="编码器-解码器结构的代码实现"><a href="#编码器-解码器结构的代码实现" class="headerlink" title="编码器-解码器结构的代码实现"></a>编码器-解码器结构的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 使用EncoderDecoder类来实现编码器-解码器结构</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">EncoderDecoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, encoder, decoder, source_embed, target_embed, generator</span>):<br>        <span class="hljs-comment"># encoder：代表编码器对象</span><br>        <span class="hljs-comment"># decoder：代表解码器对象</span><br>        <span class="hljs-comment"># source_embed：代表源数据的嵌入函数</span><br>        <span class="hljs-comment"># target_embed：代表目标数据的嵌入函数</span><br>        <span class="hljs-comment"># generator：代表输出部分类别生成器对象</span><br>        <span class="hljs-string">&quot;&quot;&quot;初始化函数中有5个参数, 分别是编码器对象, 解码器对象, </span><br><span class="hljs-string">           源数据嵌入函数, 目标数据嵌入函数,  以及输出部分的类别生成器对象</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(EncoderDecoder, self).__init__()<br>        <span class="hljs-comment"># 将参数传入到类中</span><br>        self.encoder = encoder<br>        self.decoder = decoder<br>        self.src_embed = source_embed<br>        self.tgt_embed = target_embed<br>        self.generator = generator<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, source, target, source_mask, target_mask</span>):<br>        <span class="hljs-comment"># source：代表源数据</span><br>        <span class="hljs-comment"># target：代表目标数据</span><br>        <span class="hljs-comment"># source_mask：代表源数据的掩码张量</span><br>        <span class="hljs-comment"># target_mask：代表目标数据的掩码张量</span><br>        <span class="hljs-string">&quot;&quot;&quot;在forward函数中，有四个参数, source代表源数据, target代表目标数据, </span><br><span class="hljs-string">           source_mask和target_mask代表对应的掩码张量&quot;&quot;&quot;</span><br><br>        <span class="hljs-comment"># 在函数中, 将source, source_mask传入编码函数, 得到结果后,</span><br>        <span class="hljs-comment"># 与source_mask，target，和target_mask一同传给解码函数.</span><br>        <span class="hljs-keyword">return</span> self.generator(self.decode(self.encode(source, source_mask), source_mask,<br>                            target, target_mask))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, source, source_mask</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;编码函数, 以source和source_mask为参数&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 使用src_embed对source做处理, 然后和source_mask一起传给self.encoder</span><br>        <span class="hljs-keyword">return</span> self.encoder(self.src_embed(source), source_mask)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, memory, source_mask, target, target_mask</span>):<br>        <span class="hljs-comment"># memory：代表经历编码器编码后的输出张量</span><br>        <span class="hljs-string">&quot;&quot;&quot;解码函数, 以memory即编码器的输出, source_mask, target, target_mask为参数&quot;&quot;&quot;</span><br>        <span class="hljs-comment"># 使用tgt_embed对target做处理, 然后和source_mask, target_mask, memory一起传给self.decoder</span><br>        <span class="hljs-keyword">return</span> self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)<br></code></pre></td></tr></table></figure><hr><ul><li>实例化参数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">vocab_size = <span class="hljs-number">1000</span><br>d_model = <span class="hljs-number">512</span><br>encoder = en<br>decoder = de<br>source_embed = nn.Embedding(vocab_size, d_model)<br>target_embed = nn.Embedding(vocab_size, d_model)<br>generator = gen<br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 假设源数据与目标数据相同, 实际中并不相同</span><br>source = target = Variable(torch.LongTensor([[<span class="hljs-number">100</span>, <span class="hljs-number">2</span>, <span class="hljs-number">421</span>, <span class="hljs-number">508</span>], [<span class="hljs-number">491</span>, <span class="hljs-number">998</span>, <span class="hljs-number">1</span>, <span class="hljs-number">221</span>]]))<br><br><span class="hljs-comment"># 假设src_mask与tgt_mask相同，实际中并不相同</span><br>source_mask = target_mask = Variable(torch.zeros(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>, <span class="hljs-number">4</span>))<br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">ed = EncoderDecoder(encoder, decoder, source_embed, target_embed, generator)<br>ed_result = ed(source, target, source_mask, target_mask)<br><span class="hljs-built_in">print</span>(ed_result)<br><span class="hljs-built_in">print</span>(ed_result.shape)<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor([[[ <span class="hljs-number">0.2102</span>, -<span class="hljs-number">0.0826</span>, -<span class="hljs-number">0.0550</span>,  ...,  <span class="hljs-number">1.5555</span>,  <span class="hljs-number">1.3025</span>, -<span class="hljs-number">0.6296</span>],<br>         [ <span class="hljs-number">0.8270</span>, -<span class="hljs-number">0.5372</span>, -<span class="hljs-number">0.9559</span>,  ...,  <span class="hljs-number">0.3665</span>,  <span class="hljs-number">0.4338</span>, -<span class="hljs-number">0.7505</span>],<br>         [ <span class="hljs-number">0.4956</span>, -<span class="hljs-number">0.5133</span>, -<span class="hljs-number">0.9323</span>,  ...,  <span class="hljs-number">1.0773</span>,  <span class="hljs-number">1.1913</span>, -<span class="hljs-number">0.6240</span>],<br>         [ <span class="hljs-number">0.5770</span>, -<span class="hljs-number">0.6258</span>, -<span class="hljs-number">0.4833</span>,  ...,  <span class="hljs-number">0.1171</span>,  <span class="hljs-number">1.0069</span>, -<span class="hljs-number">1.9030</span>]],<br><br>        [[-<span class="hljs-number">0.4355</span>, -<span class="hljs-number">1.7115</span>, -<span class="hljs-number">1.5685</span>,  ..., -<span class="hljs-number">0.6941</span>, -<span class="hljs-number">0.1878</span>, -<span class="hljs-number">0.1137</span>],<br>         [-<span class="hljs-number">0.8867</span>, -<span class="hljs-number">1.2207</span>, -<span class="hljs-number">1.4151</span>,  ..., -<span class="hljs-number">0.9618</span>,  <span class="hljs-number">0.1722</span>, -<span class="hljs-number">0.9562</span>],<br>         [-<span class="hljs-number">0.0946</span>, -<span class="hljs-number">0.9012</span>, -<span class="hljs-number">1.6388</span>,  ..., -<span class="hljs-number">0.2604</span>, -<span class="hljs-number">0.3357</span>, -<span class="hljs-number">0.6436</span>],<br>         [-<span class="hljs-number">1.1204</span>, -<span class="hljs-number">1.4481</span>, -<span class="hljs-number">1.5888</span>,  ..., -<span class="hljs-number">0.8816</span>, -<span class="hljs-number">0.6497</span>,  <span class="hljs-number">0.0606</span>]]],<br>       grad_fn=&lt;AddBackward0&gt;)<br>torch.Size([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">512</span>])<br></code></pre></td></tr></table></figure><hr><ul><li>接着将基于以上结构构建用于训练的模型.</li></ul><hr><ul><li>Tansformer模型构建过程的代码分析</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">make_model</span>(<span class="hljs-params">source_vocab, target_vocab, N=<span class="hljs-number">6</span>, </span><br><span class="hljs-params">               d_model=<span class="hljs-number">512</span>, d_ff=<span class="hljs-number">2048</span>, head=<span class="hljs-number">8</span>, dropout=<span class="hljs-number">0.1</span></span>):<br>    <span class="hljs-comment">#source_voc ab：代表源数据的词汇总数</span><br>    <span class="hljs-comment">#target_voc ab：代表目标数据的词汇总数</span><br>    <span class="hljs-comment">#N：代表编码器和解码器堆叠的层数</span><br>    <span class="hljs-comment">#d_model：代表词嵌入的维度</span><br>    <span class="hljs-comment">#d_ff：代表前馈全连接层中变换矩阵的维度</span><br>    <span class="hljs-comment">#head：多头注意力机制中的头数</span><br>    <span class="hljs-comment">#dropout：指置零的比率</span><br><br>    <span class="hljs-string">&quot;&quot;&quot;该函数用来构建模型, 有7个参数，分别是源数据特征(词汇)总数，目标数据特征(词汇)总数，</span><br><span class="hljs-string">       编码器和解码器堆叠数，词向量映射维度，前馈全连接网络中变换矩阵的维度，</span><br><span class="hljs-string">       多头注意力结构中的多头数，以及置零比率dropout.&quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 首先得到一个深度拷贝命令，接下来很多结构都需要进行深度拷贝，</span><br>    <span class="hljs-comment"># 来保证他们彼此之间相互独立，不受干扰.</span><br>    c = copy.deepcopy<br><br>    <span class="hljs-comment"># 实例化了多头注意力类，得到对象attn</span><br>    attn = MultiHeadedAttention(head, d_model)<br><br>    <span class="hljs-comment"># 然后实例化前馈全连接类，得到对象ff </span><br>    ff = PositionwiseFeedForward(d_model, d_ff, dropout)<br><br>    <span class="hljs-comment"># 实例化位置编码类，得到对象position</span><br>    position = PositionalEncoding(d_model, dropout)<br><br>    <span class="hljs-comment"># 根据结构图, 最外层是EncoderDecoder，在EncoderDecoder中，</span><br>    <span class="hljs-comment"># 分别是编码器层，解码器层，源数据Embedding层和位置编码组成的有序结构，</span><br>    <span class="hljs-comment"># 目标数据Embedding层和位置编码组成的有序结构，以及类别生成器层. </span><br>    <span class="hljs-comment"># 在编码器层中有attention子层以及前馈全连接子层，</span><br>    <span class="hljs-comment"># 在解码器层中有两个attention子层以及前馈全连接层.</span><br>    <br>    <span class="hljs-comment">#实例化模型model，利用的是Encoder Decoder类</span><br><span class="hljs-comment">#编码器的结构里面有2个子层，attention层和前馈全连接层</span><br><span class="hljs-comment">#解码器的结构中有3个子层，两个attention层和前馈全连接层</span><br><br>    model = EncoderDecoder(<br>        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),<br>        Decoder(DecoderLayer(d_model, c(attn), c(attn), <br>                             c(ff), dropout), N),<br>        nn.Sequential(Embeddings(d_model, source_vocab), c(position)),<br>        nn.Sequential(Embeddings(d_model, target_vocab), c(position)),<br>        Generator(d_model, target_vocab))<br><br>    <span class="hljs-comment"># 模型结构完成后，接下来就是初始化模型中的参数，比如线性层中的变换矩阵</span><br>    <span class="hljs-comment"># 这里一但判断参数的维度大于1，则会将其初始化成一个服从均匀分布的矩阵，</span><br>    <span class="hljs-comment">#初始化整个模型中的参数，判断参数的维度大于1，将矩阵初始化成一个服从均匀分布的矩阵</span><br><br>    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters():<br>        <span class="hljs-keyword">if</span> p.dim() &gt; <span class="hljs-number">1</span>:<br>            nn.init.xavier_uniform(p)<br>    <span class="hljs-keyword">return</span> model<br></code></pre></td></tr></table></figure><ul><li>nn.init.xavier_uniform演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 结果服从均匀分布U(-a, a)</span><br><span class="hljs-meta">&gt;&gt;&gt; </span>w = torch.empty(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><span class="hljs-meta">&gt;&gt;&gt; </span>w = nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain(<span class="hljs-string">&#x27;relu&#x27;</span>))<br><span class="hljs-meta">&gt;&gt;&gt; </span>w<br>tensor([[-<span class="hljs-number">0.7742</span>,  <span class="hljs-number">0.5413</span>,  <span class="hljs-number">0.5478</span>, -<span class="hljs-number">0.4806</span>, -<span class="hljs-number">0.2555</span>],<br>        [-<span class="hljs-number">0.8358</span>,  <span class="hljs-number">0.4673</span>,  <span class="hljs-number">0.3012</span>,  <span class="hljs-number">0.3882</span>, -<span class="hljs-number">0.6375</span>],<br>        [ <span class="hljs-number">0.4622</span>, -<span class="hljs-number">0.0794</span>,  <span class="hljs-number">0.1851</span>,  <span class="hljs-number">0.8462</span>, -<span class="hljs-number">0.3591</span>]])<br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">source_vocab = <span class="hljs-number">11</span><br>target_vocab = <span class="hljs-number">11</span> <br>N = <span class="hljs-number">6</span><br><span class="hljs-comment"># 其他参数都使用默认值 </span><br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    res = make_model(source_vocab, target_vocab, N)<br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 根据Transformer结构图构建的最终模型结构</span><br>EncoderDecoder(<br>  (encoder): Encoder(<br>    (layers): ModuleList(<br>      (<span class="hljs-number">0</span>): EncoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w_1): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">2048</span>)<br>          (w_2): Linear(in_features=<span class="hljs-number">2048</span>, out_features=<span class="hljs-number">512</span>)<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (<span class="hljs-number">0</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">1</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>        )<br>      )<br>      (<span class="hljs-number">1</span>): EncoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w_1): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">2048</span>)<br>          (w_2): Linear(in_features=<span class="hljs-number">2048</span>, out_features=<span class="hljs-number">512</span>)<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (<span class="hljs-number">0</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">1</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>        )<br>      )<br>    )<br>    (norm): LayerNorm(<br>    )<br>  )<br>  (decoder): Decoder(<br>    (layers): ModuleList(<br>      (<span class="hljs-number">0</span>): DecoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (src_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w_1): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">2048</span>)<br>          (w_2): Linear(in_features=<span class="hljs-number">2048</span>, out_features=<span class="hljs-number">512</span>)<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (<span class="hljs-number">0</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">1</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">2</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>        )<br>      )<br>      (<span class="hljs-number">1</span>): DecoderLayer(<br>        (self_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (src_attn): MultiHeadedAttention(<br>          (linears): ModuleList(<br>            (<span class="hljs-number">0</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">1</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">2</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>            (<span class="hljs-number">3</span>): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">512</span>)<br>          )<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (feed_forward): PositionwiseFeedForward(<br>          (w_1): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">2048</span>)<br>          (w_2): Linear(in_features=<span class="hljs-number">2048</span>, out_features=<span class="hljs-number">512</span>)<br>          (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>        )<br>        (sublayer): ModuleList(<br>          (<span class="hljs-number">0</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">1</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>          (<span class="hljs-number">2</span>): SublayerConnection(<br>            (norm): LayerNorm(<br>            )<br>            (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>          )<br>        )<br>      )<br>    )<br>    (norm): LayerNorm(<br>    )<br>  )<br>  (src_embed): Sequential(<br>    (<span class="hljs-number">0</span>): Embeddings(<br>      (lut): Embedding(<span class="hljs-number">11</span>, <span class="hljs-number">512</span>)<br>    )<br>    (<span class="hljs-number">1</span>): PositionalEncoding(<br>      (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>    )<br>  )<br>  (tgt_embed): Sequential(<br>    (<span class="hljs-number">0</span>): Embeddings(<br>      (lut): Embedding(<span class="hljs-number">11</span>, <span class="hljs-number">512</span>)<br>    )<br>    (<span class="hljs-number">1</span>): PositionalEncoding(<br>      (dropout): Dropout(p=<span class="hljs-number">0.1</span>)<br>    )<br>  )<br>  (generator): Generator(<br>    (proj): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">11</span>)<br>  )<br>)<br></code></pre></td></tr></table></figure><p><strong>小节总结</strong></p><ul><li>学习并实现了编码器-解码器结构的类: EncoderDecoder<ul><li>类的初始化函数传入5个参数, 分别是编码器对象, 解码器对象, 源数据嵌入函数, 目标数据嵌入函数, 以及输出部分的类别生成器对象.</li><li>类中共实现三个函数, forward, encode, decode</li><li>forward是主要逻辑函数, 有四个参数, source代表源数据, target代表目标数据, source_mask和target_mask代表对应的掩码张量.</li><li>encode是编码函数, 以source和source_mask为参数.</li><li>decode是解码函数, 以memory即编码器的输出, source_mask, target, target_mask为参数</li></ul></li></ul><hr><ul><li>学习并实现了模型构建函数: make_model<ul><li>有7个参数，分别是源数据特征(词汇)总数，目标数据特征(词汇)总数，编码器和解码器堆叠数，词向量映射维度，前馈全连接网络中变换矩阵的维度，多头注意力结构中的多头数，以及置零比率dropout.</li></ul></li></ul><h2 id="2-7-模型基本测试运行-P44"><a href="#2-7-模型基本测试运行-P44" class="headerlink" title="2.7 模型基本测试运行 P44"></a>2.7 模型基本测试运行 P44</h2><ul><li><p>学习目标</p><ul><li><p>了解Transformer模型基本测试的copy任务.</p></li><li><p>掌握实现copy任务的四步曲.</p></li></ul></li></ul><hr><ul><li><p>copy任务介绍:</p><ul><li>任务描述: 针对数字序列进行学习, 学习的最终目标是使输出与输入的序列相同. 如输入[1, 5, 8, 9, 3], 输出也是[1, 5, 8, 9, 3].</li><li>任务意义: copy任务在模型基础测试中具有重要意义，因为copy操作对于模型来讲是一条明显规律, 因此模型能否在短时间内，小数据集中学会它，可以帮助我们断定模型所有过程是否正常，是否已具备基本学习能力.</li></ul></li></ul><hr><ul><li>使用copy任务进行模型基本测试的四步曲<ul><li>第一步: 构建数据集生成器</li><li>第二步: 获得Transformer模型及其优化器和损失函数</li><li>第三步: 运行模型进行训练和评估</li><li>第四步: 使用模型进行贪婪解码</li></ul></li></ul><hr><ul><li>第一步: 构建数据集生成器</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入工具包Batch, 它能够对原始样本数据生成对应批次的掩码张量</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> Batch  <br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> get_std_opt<br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> LabelSmoothing<br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> SimpleLossCompute<br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> run_epoch<br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> greedy_decode<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_generator</span>(<span class="hljs-params">V, batch, num_batch</span>):<br>    <span class="hljs-comment"># V：随机生成数据的最大值+1</span><br><span class="hljs-comment"># batch_size：每次输送给模型的样本数量，经历这些样本训练后进行一次参数的更新</span><br><span class="hljs-comment"># num_batch：一共输送模型多少轮数据</span><br><br>    <span class="hljs-string">&quot;&quot;&quot;该函数用于随机生成copy任务的数据, 它的三个输入参数是V: 随机生成数字的最大值+1, </span><br><span class="hljs-string">       batch: 每次输送给模型更新一次参数的数据量, num_batch: 一共输送num_batch次完成一轮</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 使用for循环遍历nbatches</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_batch):<br>        <span class="hljs-comment"># 使用num py中的random.rand in t（）来随机生成[1，V)</span><br><span class="hljs-comment"># 分布的形状(batch，10）</span><br><br>        <span class="hljs-comment"># 在循环中使用np的random.randint方法随机生成[1, V)的整数, </span><br>        <span class="hljs-comment"># 分布在(batch, 10)形状的矩阵中, 然后再把numpy形式转换称torch中的tensor.</span><br>        data = torch.from_numpy(np.random.randint(<span class="hljs-number">1</span>, V, size=(batch, <span class="hljs-number">10</span>)))<br><br>        <span class="hljs-comment"># 接着使数据矩阵中的第一列数字都为1, 这一列也就成为了起始标志列, </span><br>        <span class="hljs-comment"># 当解码器进行第一次解码的时候, 会使用起始标志列作为输入.</span><br>        data[:, <span class="hljs-number">0</span>] = <span class="hljs-number">1</span><br><br>        <span class="hljs-comment"># 因为是copy任务, 所有source与target是完全相同的, 且数据样本作用变量不需要求梯度</span><br>        <span class="hljs-comment"># 因此requires_grad设置为False</span><br>        source = Variable(data, requires_grad=<span class="hljs-literal">False</span>)<br>        target = Variable(data, requires_grad=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-comment"># 使用Batch对source和target进行对应批次的掩码张量生成, 最后使用yield返回</span><br>        <span class="hljs-keyword">yield</span> Batch(source, target)<br></code></pre></td></tr></table></figure><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 将生成0-10的整数</span><br>V = <span class="hljs-number">11</span><br><br><span class="hljs-comment"># 每次喂给模型20个数据进行参数更新</span><br>batch = <span class="hljs-number">20</span> <br><br><span class="hljs-comment"># 连续喂30次完成全部数据的遍历, 也就是1轮</span><br>num_batch = <span class="hljs-number">30</span><br></code></pre></td></tr></table></figure><hr><ul><li>调用:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    res = data_generator(V, batch, num_batch)<br>    <span class="hljs-built_in">print</span>(res)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 会得到一个数据生成器(生成器对象)</span><br>&lt;generator <span class="hljs-built_in">object</span> data_gen at <span class="hljs-number">0x10c053e08</span>&gt;<br></code></pre></td></tr></table></figure><hr><ul><li>第二步: 获得Transformer模型及其优化器和损失函数</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入优化器工具包get_std_opt, 该工具用于获得标准的针对Transformer模型的优化器 </span><br><span class="hljs-comment"># 该标准优化器基于Adam优化器, 使其对序列到序列的任务更有效.</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> get_std_opt<br><br><span class="hljs-comment"># 导入标签平滑工具包, 该工具用于标签平滑, 标签平滑的作用就是小幅度的改变原有标签值的值域</span><br><span class="hljs-comment"># 因为在理论上即使是人工的标注数据也可能并非完全正确, 会受到一些外界因素的影响而产生一些微小的偏差</span><br><span class="hljs-comment"># 因此使用标签平滑来弥补这种偏差, 减少模型对某一条规律的绝对认知, 以防止过拟合. 通过下面示例了解更多.</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> LabelSmoothing<br><br><span class="hljs-comment"># 导入损失计算工具包, 该工具能够使用标签平滑后的结果进行损失的计算, </span><br><span class="hljs-comment"># 损失的计算方法可以认为是交叉熵损失函数.</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> SimpleLossCompute<br><br><span class="hljs-comment"># 使用make_model获得model</span><br>model = make_model(V, V, N=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># 使用get_std_opt获得模型优化器</span><br>model_optimizer = get_std_opt(model)<br><br><span class="hljs-comment"># 使用LabelSmoothing获得标签平滑对象</span><br>criterion = LabelSmoothing(size=V, padding_idx=<span class="hljs-number">0</span>, smoothing=<span class="hljs-number">0.0</span>)<br><br><span class="hljs-comment"># 使用SimpleLossCompute获得利用标签平滑结果的损失计算方法</span><br>loss = SimpleLossCompute(model.generator, criterion, model_optimizer)<br></code></pre></td></tr></table></figure><hr><ul><li>标签平滑示例:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> LabelSmoothing<br><br><span class="hljs-comment"># 使用LabelSmoothing实例化一个crit对象.</span><br><span class="hljs-comment"># 第一个参数size代表目标数据的词汇总数, 也是模型最后一层得到张量的最后一维大小</span><br><span class="hljs-comment"># 这里是5说明目标词汇总数是5个. 第二个参数padding_idx表示要将那些tensor中的数字</span><br><span class="hljs-comment"># 替换成0, 一般padding_idx=0表示不进行替换. 第三个参数smoothing, 表示标签的平滑程度</span><br><span class="hljs-comment"># 如原来标签的表示值为1, 则平滑后它的值域变为[1-smoothing, 1+smoothing].</span><br>crit = LabelSmoothing(size=<span class="hljs-number">5</span>, padding_idx=<span class="hljs-number">0</span>, smoothing=<span class="hljs-number">0.5</span>)<br><br><span class="hljs-comment"># 假定一个任意的模型最后输出预测结果和真实结果</span><br>predict = Variable(torch.FloatTensor([[<span class="hljs-number">0</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0</span>],<br>                             [<span class="hljs-number">0</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0</span>], <br>                             [<span class="hljs-number">0</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.7</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0</span>]]))<br><br><span class="hljs-comment"># 标签的表示值是0，1，2</span><br>target = Variable(torch.LongTensor([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]))<br><br><span class="hljs-comment"># 将predict, target传入到对象中</span><br>crit(predict, target)<br><br><span class="hljs-comment"># 绘制标签平滑图像</span><br>plt.imshow(crit.true_dist)<br></code></pre></td></tr></table></figure><hr><ul><li>标签平滑图像:</li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/202311052258109.png" alt="image-20231105223915947"></p><ul><li><p>标签平滑图像分析:</p><ul><li>我们目光集中在<code>黄色小方块</code>上, 它相对于横坐标横跨的值域就是标签平滑后的正向平滑值域, 我们可以看到大致是从0.5到2.5.</li><li>它相对于纵坐标横跨的值域就是标签平滑后的负向平滑值域, 我们可以看到大致是从-0.5到1.5, 总的值域空间由原来的[0, 2]变成了[-0.5, 2.5].</li></ul></li></ul><hr><ul><li>第三步: 运行模型进行训练和评估</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入模型单轮训练工具包run_epoch, 该工具将对模型使用给定的损失函数计算方法进行单轮参数更新.</span><br><span class="hljs-comment"># 并打印每轮参数更新的损失结果.</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> run_epoch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">model, loss, epochs=<span class="hljs-number">10</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;模型训练函数, 共有三个参数, model代表将要进行训练的模型</span><br><span class="hljs-string">       loss代表使用的损失计算方法, epochs代表模型训练的轮数&quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 遍历轮数</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-comment"># 模型使用训练模式, 所有参数将被更新</span><br>        model.train()<br>        <span class="hljs-comment"># 训练时, batch_size是20</span><br>        run_epoch(data_generator(V, <span class="hljs-number">8</span>, <span class="hljs-number">20</span>), model, loss)<br><br>        <span class="hljs-comment"># 模型使用评估模式, 参数将不会变化 </span><br>        model.<span class="hljs-built_in">eval</span>()<br>        <span class="hljs-comment"># 评估时, batch_size是5</span><br>        run_epoch(data_generator(V, <span class="hljs-number">8</span>, <span class="hljs-number">5</span>), model, loss)<br></code></pre></td></tr></table></figure><hr><ul><li>输入参数:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 进行10轮训练</span><br>epochs = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># model和loss都是来自上一步的结果</span><br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">3.315704</span> Tokens per Sec: <span class="hljs-number">309.740843</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">2.602743</span> Tokens per Sec: <span class="hljs-number">393.885743</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">2.563469</span> Tokens per Sec: <span class="hljs-number">347.746994</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">2.065951</span> Tokens per Sec: <span class="hljs-number">422.632783</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">2.218468</span> Tokens per Sec: <span class="hljs-number">346.982987</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.771149</span> Tokens per Sec: <span class="hljs-number">396.451901</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.979203</span> Tokens per Sec: <span class="hljs-number">350.384045</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.648887</span> Tokens per Sec: <span class="hljs-number">361.534817</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.824539</span> Tokens per Sec: <span class="hljs-number">349.660287</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.550169</span> Tokens per Sec: <span class="hljs-number">319.302558</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.676636</span> Tokens per Sec: <span class="hljs-number">369.678638</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.394759</span> Tokens per Sec: <span class="hljs-number">364.660371</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.473153</span> Tokens per Sec: <span class="hljs-number">324.016068</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.142609</span> Tokens per Sec: <span class="hljs-number">422.345444</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.410883</span> Tokens per Sec: <span class="hljs-number">365.395922</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">0.828656</span> Tokens per Sec: <span class="hljs-number">401.538655</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">1.254409</span> Tokens per Sec: <span class="hljs-number">346.133228</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">0.745532</span> Tokens per Sec: <span class="hljs-number">402.395937</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">0.952969</span> Tokens per Sec: <span class="hljs-number">324.858870</span><br>Epoch Step: <span class="hljs-number">1</span> Loss: <span class="hljs-number">0.373509</span> Tokens per Sec: <span class="hljs-number">358.814760</span><br></code></pre></td></tr></table></figure><hr><ul><li>第四步: 使用模型进行贪婪解码</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入贪婪解码工具包greedy_decode, 该工具将对最终结进行贪婪解码</span><br><span class="hljs-comment"># 贪婪解码的方式是每次预测都选择概率最大的结果作为输出, </span><br><span class="hljs-comment"># 它不一定能获得全局最优性, 但却拥有最高的执行效率.</span><br><span class="hljs-keyword">from</span> pyitcast.transformer_utils <span class="hljs-keyword">import</span> greedy_decode <br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">model, loss, epochs=<span class="hljs-number">10</span></span>):<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-comment"># 首先进入训练模式，所有的参数将会被更新</span><br>        model.train()<br><br>        run_epoch(data_generator(V, <span class="hljs-number">8</span>, <span class="hljs-number">20</span>), model, loss)<br><br>        <span class="hljs-comment"># 训练结束后， 进入评估模式，所有的参数固定不变</span><br>        model.<span class="hljs-built_in">eval</span>()<br><br>        run_epoch(data_generator(V, <span class="hljs-number">8</span>, <span class="hljs-number">5</span>), model, loss)<br><br>    <span class="hljs-comment"># 跳出for循环后，掉膘模型训练结束，进入评估模式</span><br>    <span class="hljs-comment"># 模型进入测试模式</span><br>    model.<span class="hljs-built_in">eval</span>()<br><br>    <span class="hljs-comment"># 假定的输入张量</span><br>    <span class="hljs-comment"># 初始化一个输入张量</span><br>    source = Variable(torch.LongTensor([[<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>,<span class="hljs-number">8</span>,<span class="hljs-number">9</span>,<span class="hljs-number">10</span>]]))<br><br>    <span class="hljs-comment"># 定义源数据掩码张量, 因为元素都是1, 在我们这里1代表不遮掩</span><br>    <span class="hljs-comment"># 因此相当于对源数据没有任何遮掩.</span><br>    <span class="hljs-comment"># 初始化一个输入张量的掩码张量，全1代表没有任何的遮掩</span><br>    source_mask = Variable(torch.ones(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>))<br><br>    <span class="hljs-comment"># 最后将model, src, src_mask, 解码的最大长度限制max_len, 默认为10</span><br>    <span class="hljs-comment"># 以及起始标志数字, 默认为1, 我们这里使用的也是1</span><br>    <span class="hljs-comment">#设定解码的最大长度max_len等于10，起始数字的标志默认等于1</span><br><br>    result = greedy_decode(model, source, source_mask, max_len=<span class="hljs-number">10</span>, start_symbol=<span class="hljs-number">1</span>)<br>    <span class="hljs-built_in">print</span>(result)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    run(model, loss) <br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">    <span class="hljs-number">1</span>     <span class="hljs-number">3</span>     <span class="hljs-number">2</span>     <span class="hljs-number">5</span>     <span class="hljs-number">4</span>     <span class="hljs-number">6</span>     <span class="hljs-number">7</span>     <span class="hljs-number">8</span>     <span class="hljs-number">9</span>    <span class="hljs-number">10</span><br>[torch.LongTensor of size 1x10]<br></code></pre></td></tr></table></figure><hr><p><strong>小节总结</strong></p><ul><li><p>学习了copy任务的相关知识:</p><ul><li>任务描述: 针对数字序列进行学习, 学习的最终目标是使输出与输入的序列相同. 如输入[1, 5, 8, 9, 3], 输出也是[1, 5, 8, 9, 3].</li><li>任务意义: <code>copy任务</code>在模型基础测试中具有重要意义，因为copy操作对于模型来讲是一条明显规律, 因此模型能否在短时间内，小数据集中学会它，可以帮助我们断定模型所有过程是否正常，是否已具备基本学习能力.</li></ul></li></ul><hr><ul><li><p>学习了使用copy任务进行模型基本测试的四步曲:</p><ul><li>第一步: 构建数据集生成器</li><li>第二步: 获得Transformer模型及其优化器和损失函数</li><li>第三步: 运行模型进行训练和评估</li><li>第四步: 使用模型进行贪婪解码</li></ul></li></ul><hr><ul><li><p>学习并实现了构建数据集生成器函数: data_gen</p><ul><li>它有三个输入参数, 分别是V: 随机生成数字的最大值+1, batch: 每次输送给模型更新一次参数的数据量, nbatches: 一共输送nbatches次完成一轮.</li><li>该函数最终得到一个生成器对象.</li></ul></li></ul><hr><ul><li><p>学习了获得Transformer模型及其优化器和损失函数:</p><ul><li>通过导入优化器工具包get_std_opt, 获得标准优化器.</li><li>通过导入标签平滑工具包LabelSmoothing, 进行标签平滑.</li><li>通过导入损失计算工具包SimpleLossCompute, 计算损失.</li></ul></li></ul><hr><ul><li><p>学习并实现了运行模型进行训练和评估函数: run</p><ul><li>在函数中导入模型单轮训练工具包run_epoch, 对模型进行单轮训练.</li><li>函数共有三个参数, model代表将要进行训练的模型, slc代表使用的损失计算方法, epochs代表模型训练的轮数.</li><li>函数最终打印了模型训练和评估两个过程的损失.</li></ul></li></ul><hr><ul><li><p>学习并实现了使用模型进行贪婪解码:</p><ul><li>通过导入贪婪解码工具包greedy_decode, 根据输入得到最后输出, 完成了copy任务.</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1 3 Transformer</title>
    <link href="/2023/11/08/Transformer/1.3/"/>
    <url>/2023/11/08/Transformer/1.3/</url>
    
    <content type="html"><![CDATA[<h1 id="第一章-Transformer背景介绍"><a href="#第一章-Transformer背景介绍" class="headerlink" title="第一章 Transformer背景介绍"></a>第一章 Transformer背景介绍</h1><h2 id="1-1-Transformer的诞生"><a href="#1-1-Transformer的诞生" class="headerlink" title="1.1 Transformer的诞生"></a>1.1 Transformer的诞生</h2><hr><p>2018年10月，Google发出一篇论文《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》, BERT模型横空出世, 并横扫NLP领域11项任务的最佳成绩!</p><hr><p>论文地址: <a href="http://link.zhihu.com/?target=https://arxiv.org/pdf/1810.04805.pdf">https://arxiv.org/pdf/1810.04805.pdf</a></p><hr><p>而在BERT中发挥重要作用的结构就是Transformer, 之后又相继出现XLNET，roBERT等模型击败了BERT，但是他们的核心没有变，仍然是：Transformer.</p><hr><h2 id="1-2-Transformer的优势"><a href="#1-2-Transformer的优势" class="headerlink" title="1.2 Transformer的优势"></a>1.2 Transformer的优势</h2><hr><p>相比之前占领市场的LSTM和GRU模型，Transformer有两个显著的优势:</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">1, Transformer能够利用分布式GPU进行并行训练，提升模型训练效率.    <br>2, 在分析预测更长的文本时, 捕捉间隔较长的语义关联效果更好.   <br></code></pre></td></tr></table></figure><hr><p>下面是一张在测评比较图:</p><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/v2-b07ae6d625c826984a7e357ee1c3ae79_1440w.webp" alt="img"></p><hr><h2 id="1-3-Transformer的市场"><a href="#1-3-Transformer的市场" class="headerlink" title="1.3 Transformer的市场"></a>1.3 Transformer的市场</h2><hr><p>在著名的SOTA机器翻译榜单上, 几乎所有排名靠前的模型都使用Transformer,</p><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/v2-493d94f73e744d3eaefbd18e394a6db0_1440w.webp" alt="img"></p><p>其基本上可以看作是工业界的风向标, 市场空间自然不必多说！</p><h1 id="第二章：-Transformer架构解析"><a href="#第二章：-Transformer架构解析" class="headerlink" title="第二章： Transformer架构解析"></a>第二章： Transformer架构解析</h1><h2 id="2-1-认识Transformer架构"><a href="#2-1-认识Transformer架构" class="headerlink" title="2.1 认识Transformer架构"></a>2.1 认识Transformer架构</h2><ul><li><p>学习目标</p><ul><li><p>了解Transformer模型的作用.</p></li><li><p>了解Transformer总体架构图中各个组成部分的名称.</p></li></ul></li><li><p>Transformer模型的作用</p><ul><li>基于seq2seq架构的transformer模型可以完成NLP领域研究的典型任务, 如机器翻译, 文本生成等. 同时又可以构建预训练语言模型，用于不同任务的迁移学习.</li></ul></li></ul><hr><ul><li><p>声明:</p><ul><li>在接下来的架构分析中, 我们将假设使用Transformer模型架构处理从一种语言文本到另一种语言文本的翻译工作, 因此很多命名方式遵循NLP中的规则. 比如: Embeddding层将称作文本嵌入层, Embedding层产生的张量称为词嵌入张量, 它的最后一维将称作词向量等.</li></ul></li><li><p>Transformer总体架构图</p></li></ul><p><img src="https://pic1.zhimg.com/80/v2-da7519ddb2c983cfc671d884a7646010_1440w.webp" alt="img"></p><ul><li>Transformer总体架构可分为四个部分:<ul><li>输入部分</li><li>输出部分</li><li>编码器部分</li><li>解码器部分</li></ul></li></ul><hr><ul><li>输入部分包含:<ul><li>源文本嵌入层及其位置编码器</li><li>目标文本嵌入层及其位置编码器</li></ul></li></ul><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/image-20231108192804130.png" alt="image-20231108192804130" style="zoom:80%;" /><p>输出部分包含:</p><ul><li>线性层</li><li>softmax层</li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/v2-4b2d21a7199c6f261c9caca82e213b96_1440w.webp" alt="img"></p><p>编码器部分:</p><ul><li>由N个编码器层堆叠而成</li><li>每个编码器层由两个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/v2-306c89830ea9efe5953ae4d8b76492a4_1440w.webp" alt="img"></p><p>解码器部分:</p><ul><li>由N个解码器层堆叠而成</li><li>每个解码器层由三个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接</li><li>第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/20231108192527.png" alt="img"></p><p><code>小节总结</code></p><ul><li>学习了Transformer模型的作用:<ul><li>基于seq2seq架构的transformer模型可以完成NLP领域研究的典型任务, 如机器翻译, 文本生成等. 同时又可以构建预训练语言模型，用于不同任务的迁移学习.</li></ul></li></ul><hr><ul><li>Transformer总体架构可分为四个部分:<ul><li>输入部分</li><li>输出部分</li><li>编码器部分</li><li>解码器部分</li></ul></li></ul><hr><ul><li>输入部分包含:<ul><li>源文本嵌入层及其位置编码器</li><li>目标文本嵌入层及其位置编码器</li></ul></li></ul><hr><ul><li>输出部分包含:<ul><li>线性层</li><li>softmax处理器</li></ul></li></ul><hr><ul><li><p>编码器部分:</p></li><li><ul><li>由N个编码器层堆叠而成</li><li>每个编码器层由两个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul></li></ul><hr><ul><li><p>解码器部分:</p></li><li><ul><li>由N个解码器层堆叠而成</li><li>每个解码器层由三个子层连接结构组成</li><li>第一个子层连接结构包括一个多头自注意力子层和规范化层以及一个残差连接</li><li>第二个子层连接结构包括一个多头注意力子层和规范化层以及一个残差连接</li><li>第三个子层连接结构包括一个前馈全连接子层和规范化层以及一个残差连接</li></ul></li></ul><h1 id="第三章：Transformer经典案例"><a href="#第三章：Transformer经典案例" class="headerlink" title="第三章：Transformer经典案例"></a>第三章：Transformer经典案例</h1><h2 id="3-1-使用Transformer构建语言模型"><a href="#3-1-使用Transformer构建语言模型" class="headerlink" title="3.1 使用Transformer构建语言模型"></a>3.1 使用Transformer构建语言模型</h2><p><strong>学习目标</strong></p><ul><li>了解有关语言模型的知识.</li><li>掌握使用Transformer构建语言模型的实现过程.</li></ul><hr><ul><li><p>什么是语言模型:</p></li><li><ul><li>以一个符合语言规律的序列为输入，模型将利用序列间关系等特征，输出一个在所有词汇上的概率分布.这样的模型称为语言模型.</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 语言模型的训练语料一般来自于文章，对应的源文本和目标文本形如:</span><br>src1 = <span class="hljs-string">&quot;I can do&quot;</span> tgt1 = <span class="hljs-string">&quot;can do it&quot;</span><br>src2 = <span class="hljs-string">&quot;can do it&quot;</span>, tgt2 = <span class="hljs-string">&quot;do it &lt;eos&gt;&quot;</span><br></code></pre></td></tr></table></figure><hr><ul><li><p>语言模型能解决哪些问题:</p></li><li><ul><li>1, 根据语言模型的定义，可以在它的基础上完成机器翻译，文本生成等任务，因为我们通过最后输出的概率分布来预测下一个词汇是什么.</li><li>2, 语言模型可以判断输入的序列是否为一句完整的话，因为我们可以根据输出的概率分布查看最大概率是否落在句子结束符上，来判断完整性.</li><li>3, 语言模型本身的训练目标是预测下一个词，因为它的特征提取部分会抽象很多语言序列之间的关系，这些关系可能同样对其他语言类任务有效果.因此可以作为预训练模型进行迁移学习.</li></ul></li></ul><hr><h3 id="整个案例的实现可分为以下五个步骤"><a href="#整个案例的实现可分为以下五个步骤" class="headerlink" title="整个案例的实现可分为以下五个步骤"></a>整个案例的实现可分为以下五个步骤</h3><ul><li>第一步: 导入必备的工具包</li><li>第二步: 导入wikiText-2数据集并作基本处理</li><li>第三步: 构建用于模型输入的批次化数据</li><li>第四步: 构建训练和评估函数</li><li>第五步: 进行训练和评估(包括验证以及测试)</li></ul><hr><h4 id="第一步-导入必备的工具包"><a href="#第一步-导入必备的工具包" class="headerlink" title="第一步: 导入必备的工具包"></a>第一步: 导入必备的工具包</h4><p>环境配置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create -n py37_torch131 python=<span class="hljs-number">3.7</span><br><br>conda activate py37_torch131<br>conda install pytorch=<span class="hljs-number">1.3</span><span class="hljs-number">.1</span> torchvision cudatoolkit=<span class="hljs-number">10.0</span><br>pip install jupyter tqdm opencv-python matplotlib pandas -i https://pypi.tuna.tsinghua.edu.cn/simple<br><br></code></pre></td></tr></table></figure><ul><li>pytorch版本必须使用1.3.1, python版本使用3.6.x</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">pip install torch==<span class="hljs-number">1.3</span><span class="hljs-number">.1</span><br>conda create -n post1 python=<span class="hljs-number">3.6</span><br>conda activate post1<br></code></pre></td></tr></table></figure><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 数学计算工具包math</span><br><span class="hljs-keyword">import</span> math<br><br><span class="hljs-comment"># torch以及torch.nn, torch.nn.functional</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-comment"># torch中经典文本数据集有关的工具包</span><br><span class="hljs-comment"># 具体详情参考下方torchtext介绍</span><br><span class="hljs-keyword">import</span> torchtext<br><br><span class="hljs-comment"># torchtext中的数据处理工具, get_tokenizer用于英文分词</span><br><span class="hljs-keyword">from</span> torchtext.data.utils <span class="hljs-keyword">import</span> get_tokenizer<br><br><span class="hljs-comment"># 已经构建完成的TransformerModel</span><br><span class="hljs-keyword">from</span> pyitcast.transformer <span class="hljs-keyword">import</span> TransformerModel<br></code></pre></td></tr></table></figure><hr><ul><li><p>torchtext介绍:</p><ul><li>它是torch工具中处理NLP问题的常用数据处理包.</li></ul></li></ul><hr><ul><li><p>torchtext的重要功能:</p><ul><li>对文本数据进行处理, 比如文本语料加载, 文本迭代器构建等.</li><li>包含很多经典文本语料的预加载方法. 其中包括的语料有：用于情感分析的SST和IMDB, 用于问题分类的TREC, 用于及其翻译的 WMT14， IWSLT，以及用于语言模型任务wikiText-2, WikiText103, PennTreebank.</li></ul></li></ul><hr><ul><li>我们这里使用wikiText-2来训练语言模型, 下面有关该数据集的相关详情:</li></ul><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/v2-c3b86dbc06ce07be24c262652041c9ba_720w.webp" alt="img"></p><p><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/image-20231108201728406.png" alt="image-20231108201728406"></p><ul><li>wikiText-2数据集的体量中等, 训练集共有600篇短文, 共208万左右的词汇, 33278个不重复词汇, OoV（有多少正常英文词汇不在该数据集中的占比）为2.6%，数据集中的短文都是维基百科中对一些概念的介绍和描述.</li></ul><hr><p><strong>第二步: 导入wikiText-2数据集并作基本处理</strong> P48</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建语料域, 语料域是存放语料的数据结构, </span><br><span class="hljs-comment"># 它的四个参数代表给存放语料（或称作文本）施加的作用. </span><br><span class="hljs-comment"># 分别为 tokenize,使用get_tokenizer(&quot;basic_english&quot;)获得一个分割器对象,</span><br><span class="hljs-comment"># 分割方式按照文本为基础英文进行分割. </span><br><span class="hljs-comment"># init_token为给文本施加的起始符 &lt;sos&gt;给文本施加的终止符&lt;eos&gt;, </span><br><span class="hljs-comment"># 最后一个lower为True, 存放的文本字母全部小写.</span><br>TEXT = torchtext.data.Field(tokenize=get_tokenizer(<span class="hljs-string">&quot;basic_english&quot;</span>),<br>                            init_token=<span class="hljs-string">&#x27;&lt;sos&gt;&#x27;</span>,<br>                            eos_token=<span class="hljs-string">&#x27;&lt;eos&gt;&#x27;</span>,<br>                            lower=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 最终获得一个Field对象.</span><br><span class="hljs-comment"># &lt;torchtext.data.field.Field object at 0x7fc42a02e7f0&gt;</span><br><br><span class="hljs-comment"># 然后使用torchtext的数据集方法导入WikiText2数据, </span><br><span class="hljs-comment"># 并切分为对应训练文本, 验证文本，测试文本, 并对这些文本施加刚刚创建的语料域.</span><br>train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)<br><br><span class="hljs-comment"># 我们可以通过examples[0].text取出文本对象进行查看.</span><br><span class="hljs-comment"># &gt;&gt;&gt; test_txt.examples[0].text[:10]</span><br><span class="hljs-comment"># [&#x27;&lt;eos&gt;&#x27;, &#x27;=&#x27;, &#x27;robert&#x27;, &#x27;&lt;unk&gt;&#x27;, &#x27;=&#x27;, &#x27;&lt;eos&gt;&#x27;, &#x27;&lt;eos&gt;&#x27;, &#x27;robert&#x27;, &#x27;&lt;unk&gt;&#x27;, &#x27;is&#x27;]</span><br><br><span class="hljs-comment"># 将训练集文本数据构建一个vocab对象, </span><br><span class="hljs-comment"># 这样可以使用vocab对象的stoi方法统计文本共包含的不重复词汇总数.</span><br>TEXT.build_vocab(train_txt)<br><br><span class="hljs-comment"># 然后选择设备cuda或者cpu</span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br></code></pre></td></tr></table></figure><hr><h4 id="第三步-构建用于模型输入的批次化数据-P50"><a href="#第三步-构建用于模型输入的批次化数据-P50" class="headerlink" title="第三步: 构建用于模型输入的批次化数据 P50"></a>第三步: 构建用于模型输入的批次化数据 P50</h4><ul><li>批次化过程的第一个函数batchify代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">batchify</span>(<span class="hljs-params">data, bsz</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;batchify函数用于将文本数据映射成连续数字, 并转换成指定的样式, 指定的样式可参考下图.</span><br><span class="hljs-string">       它有两个输入参数, data就是我们之前得到的文本数据(train_txt, val_txt, test_txt),</span><br><span class="hljs-string">       bsz是就是batch_size, 每次模型更新参数的数据量&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 使用TEXT的numericalize方法将单词映射成对应的连续数字.</span><br>    data = TEXT.numericalize([data.examples[<span class="hljs-number">0</span>].text])<br>    <span class="hljs-comment"># &gt;&gt;&gt; data</span><br>    <span class="hljs-comment"># tensor([[   3],</span><br>    <span class="hljs-comment">#    [  12],</span><br>    <span class="hljs-comment">#    [3852],</span><br>    <span class="hljs-comment">#    ...,</span><br>    <span class="hljs-comment">#    [   6],</span><br>    <span class="hljs-comment">#    [   3],</span><br>    <span class="hljs-comment">#    [   3]])</span><br><br>    <span class="hljs-comment"># 接着用数据词汇总数除以bsz,</span><br>    <span class="hljs-comment"># 取整数得到一个nbatch代表需要多少次batch后能够遍历完所有数据</span><br>    nbatch = data.size(<span class="hljs-number">0</span>) // bsz<br><br>    <span class="hljs-comment"># 之后使用narrow方法对不规整的剩余数据进行删除,</span><br>    <span class="hljs-comment"># 第一个参数是代表横轴删除还是纵轴删除, 0为横轴，1为纵轴</span><br>    <span class="hljs-comment"># 第二个和第三个参数代表保留开始轴到结束轴的数值.类似于切片</span><br>    <span class="hljs-comment"># 可参考下方演示示例进行更深理解.</span><br>    data = data.narrow(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, nbatch * bsz)<br>    <span class="hljs-comment"># &gt;&gt;&gt; data</span><br>    <span class="hljs-comment"># tensor([[   3],</span><br>    <span class="hljs-comment">#    [  12],</span><br>    <span class="hljs-comment">#    [3852],</span><br>    <span class="hljs-comment">#    ...,</span><br>    <span class="hljs-comment">#    [  78],</span><br>    <span class="hljs-comment">#    [ 299],</span><br>    <span class="hljs-comment">#    [  36]])</span><br>    <span class="hljs-comment"># 后面不能形成bsz个的一组数据被删除</span><br><br>    <span class="hljs-comment"># 接着我们使用view方法对data进行矩阵变换, 使其成为如下样式:</span><br>    <span class="hljs-comment"># tensor([[    3,    25,  1849,  ...,     5,    65,    30],</span><br>    <span class="hljs-comment">#    [   12,    66,    13,  ...,    35,  2438,  4064],</span><br>    <span class="hljs-comment">#    [ 3852, 13667,  2962,  ...,   902,    33,    20],</span><br>    <span class="hljs-comment">#    ...,</span><br>    <span class="hljs-comment">#    [  154,     7,    10,  ...,     5,  1076,    78],</span><br>    <span class="hljs-comment">#    [   25,     4,  4135,  ...,     4,    56,   299],</span><br>    <span class="hljs-comment">#    [    6,    57,   385,  ...,  3168,   737,    36]])</span><br>    <span class="hljs-comment"># 因为会做转置操作, 因此这个矩阵的形状是[None, bsz],</span><br>    <span class="hljs-comment"># 如果输入是训练数据的话，形状为[104335, 20], 可以通过打印data.shape获得.</span><br>    <span class="hljs-comment"># 也就是data的列数是等于bsz的值的.</span><br>    data = data.view(bsz, -<span class="hljs-number">1</span>).t().contiguous()<br>    <span class="hljs-comment"># 最后将数据分配在指定的设备上.</span><br>    <span class="hljs-keyword">return</span> data.to(device)<br></code></pre></td></tr></table></figure><hr><ul><li>batchify的样式转化图:</li></ul><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/image-20231108133731374.png" alt="image-20231108133731374" style="zoom:80%;" /><ul><li>大写字母A，B，C … 代表句子中的每个单词.</li></ul><hr><ul><li>torch.narrow演示:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-meta">&gt;&gt;&gt; </span>x = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>], [<span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">9</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>x.narrow(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br>tensor([[ <span class="hljs-number">1</span>,  <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">4</span>,  <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>]])<br><span class="hljs-meta">&gt;&gt;&gt; </span>x.narrow(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>tensor([[ <span class="hljs-number">2</span>,  <span class="hljs-number">3</span>],<br>        [ <span class="hljs-number">5</span>,  <span class="hljs-number">6</span>],<br>        [ <span class="hljs-number">8</span>,  <span class="hljs-number">9</span>]])<br></code></pre></td></tr></table></figure><hr><ul><li>接下来我们将使用batchify来处理训练数据，验证数据以及测试数据 <code>P51</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 训练数据的batch size</span><br>batch_size = <span class="hljs-number">20</span><br><br><span class="hljs-comment"># 验证和测试数据（统称为评估数据）的batch size</span><br>eval_batch_size = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># 获得train_data, val_data, test_data</span><br>train_data = batchify(train_txt, batch_size)<br>val_data = batchify(val_txt, eval_batch_size)<br>test_data = batchify(test_txt, eval_batch_size)<br></code></pre></td></tr></table></figure><hr><ul><li>上面的分割批次并没有进行源数据与目标数据的处理, 接下来我们将根据语言模型训练的语料规定来构建源数据与目标数据.</li></ul><p>语言模型训练的语料规定:</p><ul><li>如果源数据为句子ABCD, ABCD代表句子中的词汇或符号, 则它的目标数据为BCDE, BCDE分别代表ABCD的下一个词汇.</li></ul><img src="https://cdn.jsdelivr.net/gh/beiyoudaxue/pic2023@main/img/image-20231108134624521.png" alt="image-20231108134624521" style="zoom:80%;" /><ul><li>如图所示，我们这里的句子序列是竖着的, 而且我们发现如果用一个批次处理完所有数据, 以训练数据为例, 每个句子长度高达104335, 这明显是不科学的, 因此我们在这里要限定每个批次中的句子<code>长度允许的最大值</code>bptt.</li></ul><hr><ul><li>批次化过程的第二个函数get_batch代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 令子长度允许的最大值bptt为35</span><br>bptt = <span class="hljs-number">35</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_batch</span>(<span class="hljs-params">source, i</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;用于获得每个批次合理大小的源数据和目标数据.</span><br><span class="hljs-string">       参数source是通过batchify得到的train_data/val_data/test_data.</span><br><span class="hljs-string">       i是具体的批次次数.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># 首先我们确定句子长度, 它将是在bptt和len(source) - 1 - i中最小值</span><br>    <span class="hljs-comment"># 实质上, 前面的批次中都会是bptt的值, 只不过最后一个批次中, 句子长度</span><br>    <span class="hljs-comment"># 可能不够bptt的35个, 因此会变为len(source) - 1 - i的值.</span><br>    seq_len = <span class="hljs-built_in">min</span>(bptt, <span class="hljs-built_in">len</span>(source) - <span class="hljs-number">1</span> - i)<br><br>    <span class="hljs-comment"># 语言模型训练的源数据的第i批数据将是batchify的结果的切片[i:i+seq_len]</span><br>    data = source[i:i+seq_len]<br><br>    <span class="hljs-comment"># 根据语言模型训练的语料规定, 它的目标数据是源数据向后移动一位</span><br>    <span class="hljs-comment"># 因为最后目标数据的切片会越界, 因此使用view(-1)来保证形状正常.</span><br>    target = source[i+<span class="hljs-number">1</span>:i+<span class="hljs-number">1</span>+seq_len].view(-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> data, target<br></code></pre></td></tr></table></figure><ul><li>输入实例:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 以测试集数据为例</span><br>source = test_data<br>i = <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python">data = tensor([[   <span class="hljs-number">12</span>,  <span class="hljs-number">1053</span>,   <span class="hljs-number">355</span>,   <span class="hljs-number">134</span>,    <span class="hljs-number">37</span>,     <span class="hljs-number">7</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">835</span>,  <span class="hljs-number">9834</span>],<br>        [  <span class="hljs-number">635</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">5</span>,   <span class="hljs-number">421</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">88</span>,     <span class="hljs-number">8</span>,   <span class="hljs-number">573</span>,  <span class="hljs-number">2511</span>],<br>        [    <span class="hljs-number">0</span>,    <span class="hljs-number">58</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">692</span>,   <span class="hljs-number">544</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">212</span>,     <span class="hljs-number">5</span>],<br>        [   <span class="hljs-number">12</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">105</span>,    <span class="hljs-number">26</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">56</span>],<br>        [    <span class="hljs-number">3</span>, <span class="hljs-number">16074</span>, <span class="hljs-number">21254</span>,   <span class="hljs-number">320</span>,     <span class="hljs-number">3</span>,   <span class="hljs-number">262</span>,    <span class="hljs-number">16</span>,     <span class="hljs-number">6</span>,  <span class="hljs-number">1087</span>,    <span class="hljs-number">89</span>],<br>        [    <span class="hljs-number">3</span>,   <span class="hljs-number">751</span>,  <span class="hljs-number">3866</span>,    <span class="hljs-number">10</span>,    <span class="hljs-number">12</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">246</span>,   <span class="hljs-number">238</span>,    <span class="hljs-number">79</span>,    <span class="hljs-number">49</span>],<br>        [  <span class="hljs-number">635</span>,   <span class="hljs-number">943</span>,    <span class="hljs-number">78</span>,    <span class="hljs-number">36</span>,    <span class="hljs-number">12</span>,   <span class="hljs-number">475</span>,    <span class="hljs-number">66</span>,    <span class="hljs-number">10</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">924</span>],<br>        [    <span class="hljs-number">0</span>,  <span class="hljs-number">2358</span>,    <span class="hljs-number">52</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">19831</span>,    <span class="hljs-number">21</span>],<br>        [   <span class="hljs-number">26</span>,    <span class="hljs-number">38</span>,    <span class="hljs-number">54</span>,    <span class="hljs-number">40</span>,  <span class="hljs-number">1589</span>,  <span class="hljs-number">3729</span>,  <span class="hljs-number">1014</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">4</span>],<br>        [   <span class="hljs-number">33</span>, <span class="hljs-number">17597</span>,    <span class="hljs-number">33</span>,  <span class="hljs-number">1661</span>,    <span class="hljs-number">15</span>,     <span class="hljs-number">7</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">170</span>],<br>        [  <span class="hljs-number">335</span>,   <span class="hljs-number">268</span>,   <span class="hljs-number">117</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">3144</span>,  <span class="hljs-number">1557</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">160</span>],<br>        [  <span class="hljs-number">106</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">4706</span>,  <span class="hljs-number">2245</span>,    <span class="hljs-number">12</span>,  <span class="hljs-number">1074</span>,    <span class="hljs-number">13</span>,  <span class="hljs-number">2105</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">29</span>],<br>        [    <span class="hljs-number">5</span>, <span class="hljs-number">16074</span>,    <span class="hljs-number">10</span>,  <span class="hljs-number">1087</span>,    <span class="hljs-number">12</span>,   <span class="hljs-number">137</span>,   <span class="hljs-number">251</span>, <span class="hljs-number">13238</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">4</span>],<br>        [  <span class="hljs-number">394</span>,   <span class="hljs-number">746</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">9</span>,    <span class="hljs-number">12</span>,  <span class="hljs-number">6032</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">2190</span>,   <span class="hljs-number">303</span>, <span class="hljs-number">12651</span>],<br>        [    <span class="hljs-number">8</span>,   <span class="hljs-number">616</span>,  <span class="hljs-number">2107</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">425</span>,     <span class="hljs-number">0</span>,    <span class="hljs-number">10</span>,   <span class="hljs-number">510</span>],<br>        [ <span class="hljs-number">1339</span>,   <span class="hljs-number">112</span>,    <span class="hljs-number">23</span>,   <span class="hljs-number">335</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">22251</span>,  <span class="hljs-number">1162</span>,     <span class="hljs-number">9</span>,    <span class="hljs-number">11</span>,     <span class="hljs-number">9</span>],<br>        [ <span class="hljs-number">1212</span>,   <span class="hljs-number">468</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">820</span>,     <span class="hljs-number">9</span>,     <span class="hljs-number">7</span>,  <span class="hljs-number">1231</span>,  <span class="hljs-number">4202</span>,  <span class="hljs-number">2866</span>,   <span class="hljs-number">382</span>],<br>        [    <span class="hljs-number">6</span>,    <span class="hljs-number">24</span>,   <span class="hljs-number">104</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">7</span>,    <span class="hljs-number">10</span>,     <span class="hljs-number">9</span>,   <span class="hljs-number">588</span>],<br>        [   <span class="hljs-number">31</span>,   <span class="hljs-number">190</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">230</span>,   <span class="hljs-number">267</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">273</span>,   <span class="hljs-number">278</span>,     <span class="hljs-number">6</span>],<br>        [   <span class="hljs-number">34</span>,    <span class="hljs-number">25</span>,    <span class="hljs-number">47</span>,    <span class="hljs-number">26</span>,  <span class="hljs-number">1864</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">694</span>,     <span class="hljs-number">0</span>,  <span class="hljs-number">2112</span>,     <span class="hljs-number">3</span>],<br>        [   <span class="hljs-number">11</span>,     <span class="hljs-number">6</span>,    <span class="hljs-number">52</span>,   <span class="hljs-number">798</span>,     <span class="hljs-number">8</span>,    <span class="hljs-number">69</span>,    <span class="hljs-number">20</span>,    <span class="hljs-number">31</span>,    <span class="hljs-number">63</span>,     <span class="hljs-number">9</span>],<br>        [ <span class="hljs-number">1800</span>,    <span class="hljs-number">25</span>,  <span class="hljs-number">2141</span>,  <span class="hljs-number">2442</span>,   <span class="hljs-number">117</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">196</span>,  <span class="hljs-number">7290</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">298</span>],<br>        [   <span class="hljs-number">15</span>,   <span class="hljs-number">171</span>,    <span class="hljs-number">15</span>,    <span class="hljs-number">17</span>,  <span class="hljs-number">1712</span>,    <span class="hljs-number">13</span>,   <span class="hljs-number">217</span>,    <span class="hljs-number">59</span>,   <span class="hljs-number">736</span>,     <span class="hljs-number">5</span>],<br>        [ <span class="hljs-number">4210</span>,   <span class="hljs-number">191</span>,   <span class="hljs-number">142</span>,    <span class="hljs-number">14</span>,  <span class="hljs-number">5251</span>,   <span class="hljs-number">939</span>,    <span class="hljs-number">59</span>,    <span class="hljs-number">38</span>, <span class="hljs-number">10055</span>, <span class="hljs-number">25132</span>],<br>        [  <span class="hljs-number">302</span>,    <span class="hljs-number">23</span>, <span class="hljs-number">11718</span>,    <span class="hljs-number">11</span>,    <span class="hljs-number">11</span>,   <span class="hljs-number">599</span>,   <span class="hljs-number">382</span>,   <span class="hljs-number">317</span>,     <span class="hljs-number">8</span>,    <span class="hljs-number">13</span>],<br>        [   <span class="hljs-number">16</span>,  <span class="hljs-number">1564</span>,     <span class="hljs-number">9</span>,  <span class="hljs-number">4808</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">4</span>],<br>        [    <span class="hljs-number">4</span>,     <span class="hljs-number">7</span>,    <span class="hljs-number">39</span>,     <span class="hljs-number">7</span>,  <span class="hljs-number">3934</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">9</span>,     <span class="hljs-number">3</span>,  <span class="hljs-number">8047</span>,   <span class="hljs-number">557</span>],<br>        [  <span class="hljs-number">394</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">10715</span>,  <span class="hljs-number">3580</span>,  <span class="hljs-number">8682</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">242</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">10055</span>,   <span class="hljs-number">170</span>],<br>        [   <span class="hljs-number">96</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">144</span>,  <span class="hljs-number">3403</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">13</span>,  <span class="hljs-number">1014</span>,    <span class="hljs-number">14</span>,     <span class="hljs-number">6</span>,  <span class="hljs-number">2395</span>],<br>        [    <span class="hljs-number">4</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">13729</span>,    <span class="hljs-number">14</span>,    <span class="hljs-number">40</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">18</span>,   <span class="hljs-number">676</span>,  <span class="hljs-number">3267</span>],<br>        [ <span class="hljs-number">1031</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">628</span>,  <span class="hljs-number">1589</span>,    <span class="hljs-number">22</span>, <span class="hljs-number">10916</span>, <span class="hljs-number">10969</span>,     <span class="hljs-number">5</span>, <span class="hljs-number">22548</span>],<br>        [    <span class="hljs-number">9</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">6</span>,    <span class="hljs-number">84</span>,    <span class="hljs-number">15</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">3144</span>,     <span class="hljs-number">7</span>,   <span class="hljs-number">102</span>,    <span class="hljs-number">15</span>],<br>        [  <span class="hljs-number">916</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">203</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">273</span>,   <span class="hljs-number">303</span>,   <span class="hljs-number">333</span>,  <span class="hljs-number">4318</span>,     <span class="hljs-number">0</span>],<br>        [    <span class="hljs-number">6</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">0</span>,  <span class="hljs-number">4842</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">17</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">47</span>,  <span class="hljs-number">4138</span>,  <span class="hljs-number">2072</span>],<br>        [   <span class="hljs-number">38</span>,   <span class="hljs-number">237</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">50</span>,    <span class="hljs-number">35</span>,    <span class="hljs-number">27</span>, <span class="hljs-number">18530</span>,   <span class="hljs-number">244</span>,    <span class="hljs-number">20</span>,     <span class="hljs-number">6</span>]])<br><br>target =  tensor([  <span class="hljs-number">635</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">5</span>,   <span class="hljs-number">421</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">88</span>,     <span class="hljs-number">8</span>,   <span class="hljs-number">573</span>,  <span class="hljs-number">2511</span>,<br>            <span class="hljs-number">0</span>,    <span class="hljs-number">58</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">692</span>,   <span class="hljs-number">544</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">212</span>,     <span class="hljs-number">5</span>,<br>           <span class="hljs-number">12</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">105</span>,    <span class="hljs-number">26</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">56</span>,<br>            <span class="hljs-number">3</span>, <span class="hljs-number">16074</span>, <span class="hljs-number">21254</span>,   <span class="hljs-number">320</span>,     <span class="hljs-number">3</span>,   <span class="hljs-number">262</span>,    <span class="hljs-number">16</span>,     <span class="hljs-number">6</span>,  <span class="hljs-number">1087</span>,    <span class="hljs-number">89</span>,<br>            <span class="hljs-number">3</span>,   <span class="hljs-number">751</span>,  <span class="hljs-number">3866</span>,    <span class="hljs-number">10</span>,    <span class="hljs-number">12</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">246</span>,   <span class="hljs-number">238</span>,    <span class="hljs-number">79</span>,    <span class="hljs-number">49</span>,<br>          <span class="hljs-number">635</span>,   <span class="hljs-number">943</span>,    <span class="hljs-number">78</span>,    <span class="hljs-number">36</span>,    <span class="hljs-number">12</span>,   <span class="hljs-number">475</span>,    <span class="hljs-number">66</span>,    <span class="hljs-number">10</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">924</span>,<br>            <span class="hljs-number">0</span>,  <span class="hljs-number">2358</span>,    <span class="hljs-number">52</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">19831</span>,    <span class="hljs-number">21</span>,<br>           <span class="hljs-number">26</span>,    <span class="hljs-number">38</span>,    <span class="hljs-number">54</span>,    <span class="hljs-number">40</span>,  <span class="hljs-number">1589</span>,  <span class="hljs-number">3729</span>,  <span class="hljs-number">1014</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">4</span>,<br>           <span class="hljs-number">33</span>, <span class="hljs-number">17597</span>,    <span class="hljs-number">33</span>,  <span class="hljs-number">1661</span>,    <span class="hljs-number">15</span>,     <span class="hljs-number">7</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">170</span>,<br>          <span class="hljs-number">335</span>,   <span class="hljs-number">268</span>,   <span class="hljs-number">117</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">3144</span>,  <span class="hljs-number">1557</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">160</span>,<br>          <span class="hljs-number">106</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">4706</span>,  <span class="hljs-number">2245</span>,    <span class="hljs-number">12</span>,  <span class="hljs-number">1074</span>,    <span class="hljs-number">13</span>,  <span class="hljs-number">2105</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">29</span>,<br>            <span class="hljs-number">5</span>, <span class="hljs-number">16074</span>,    <span class="hljs-number">10</span>,  <span class="hljs-number">1087</span>,    <span class="hljs-number">12</span>,   <span class="hljs-number">137</span>,   <span class="hljs-number">251</span>, <span class="hljs-number">13238</span>,     <span class="hljs-number">8</span>,     <span class="hljs-number">4</span>,<br>          <span class="hljs-number">394</span>,   <span class="hljs-number">746</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">9</span>,    <span class="hljs-number">12</span>,  <span class="hljs-number">6032</span>,     <span class="hljs-number">4</span>,  <span class="hljs-number">2190</span>,   <span class="hljs-number">303</span>, <span class="hljs-number">12651</span>,<br>            <span class="hljs-number">8</span>,   <span class="hljs-number">616</span>,  <span class="hljs-number">2107</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">425</span>,     <span class="hljs-number">0</span>,    <span class="hljs-number">10</span>,   <span class="hljs-number">510</span>,<br>         <span class="hljs-number">1339</span>,   <span class="hljs-number">112</span>,    <span class="hljs-number">23</span>,   <span class="hljs-number">335</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">22251</span>,  <span class="hljs-number">1162</span>,     <span class="hljs-number">9</span>,    <span class="hljs-number">11</span>,     <span class="hljs-number">9</span>,<br>         <span class="hljs-number">1212</span>,   <span class="hljs-number">468</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">820</span>,     <span class="hljs-number">9</span>,     <span class="hljs-number">7</span>,  <span class="hljs-number">1231</span>,  <span class="hljs-number">4202</span>,  <span class="hljs-number">2866</span>,   <span class="hljs-number">382</span>,<br>            <span class="hljs-number">6</span>,    <span class="hljs-number">24</span>,   <span class="hljs-number">104</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">7</span>,    <span class="hljs-number">10</span>,     <span class="hljs-number">9</span>,   <span class="hljs-number">588</span>,<br>           <span class="hljs-number">31</span>,   <span class="hljs-number">190</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">230</span>,   <span class="hljs-number">267</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">273</span>,   <span class="hljs-number">278</span>,     <span class="hljs-number">6</span>,<br>           <span class="hljs-number">34</span>,    <span class="hljs-number">25</span>,    <span class="hljs-number">47</span>,    <span class="hljs-number">26</span>,  <span class="hljs-number">1864</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">694</span>,     <span class="hljs-number">0</span>,  <span class="hljs-number">2112</span>,     <span class="hljs-number">3</span>,<br>           <span class="hljs-number">11</span>,     <span class="hljs-number">6</span>,    <span class="hljs-number">52</span>,   <span class="hljs-number">798</span>,     <span class="hljs-number">8</span>,    <span class="hljs-number">69</span>,    <span class="hljs-number">20</span>,    <span class="hljs-number">31</span>,    <span class="hljs-number">63</span>,     <span class="hljs-number">9</span>,<br>         <span class="hljs-number">1800</span>,    <span class="hljs-number">25</span>,  <span class="hljs-number">2141</span>,  <span class="hljs-number">2442</span>,   <span class="hljs-number">117</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">196</span>,  <span class="hljs-number">7290</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">298</span>,<br>           <span class="hljs-number">15</span>,   <span class="hljs-number">171</span>,    <span class="hljs-number">15</span>,    <span class="hljs-number">17</span>,  <span class="hljs-number">1712</span>,    <span class="hljs-number">13</span>,   <span class="hljs-number">217</span>,    <span class="hljs-number">59</span>,   <span class="hljs-number">736</span>,     <span class="hljs-number">5</span>,<br>         <span class="hljs-number">4210</span>,   <span class="hljs-number">191</span>,   <span class="hljs-number">142</span>,    <span class="hljs-number">14</span>,  <span class="hljs-number">5251</span>,   <span class="hljs-number">939</span>,    <span class="hljs-number">59</span>,    <span class="hljs-number">38</span>, <span class="hljs-number">10055</span>, <span class="hljs-number">25132</span>,<br>          <span class="hljs-number">302</span>,    <span class="hljs-number">23</span>, <span class="hljs-number">11718</span>,    <span class="hljs-number">11</span>,    <span class="hljs-number">11</span>,   <span class="hljs-number">599</span>,   <span class="hljs-number">382</span>,   <span class="hljs-number">317</span>,     <span class="hljs-number">8</span>,    <span class="hljs-number">13</span>,<br>           <span class="hljs-number">16</span>,  <span class="hljs-number">1564</span>,     <span class="hljs-number">9</span>,  <span class="hljs-number">4808</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">6</span>,     <span class="hljs-number">4</span>,     <span class="hljs-number">4</span>,<br>            <span class="hljs-number">4</span>,     <span class="hljs-number">7</span>,    <span class="hljs-number">39</span>,     <span class="hljs-number">7</span>,  <span class="hljs-number">3934</span>,     <span class="hljs-number">5</span>,     <span class="hljs-number">9</span>,     <span class="hljs-number">3</span>,  <span class="hljs-number">8047</span>,   <span class="hljs-number">557</span>,<br>          <span class="hljs-number">394</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">10715</span>,  <span class="hljs-number">3580</span>,  <span class="hljs-number">8682</span>,    <span class="hljs-number">31</span>,   <span class="hljs-number">242</span>,     <span class="hljs-number">0</span>, <span class="hljs-number">10055</span>,   <span class="hljs-number">170</span>,<br>           <span class="hljs-number">96</span>,     <span class="hljs-number">6</span>,   <span class="hljs-number">144</span>,  <span class="hljs-number">3403</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">13</span>,  <span class="hljs-number">1014</span>,    <span class="hljs-number">14</span>,     <span class="hljs-number">6</span>,  <span class="hljs-number">2395</span>,<br>            <span class="hljs-number">4</span>,     <span class="hljs-number">3</span>, <span class="hljs-number">13729</span>,    <span class="hljs-number">14</span>,    <span class="hljs-number">40</span>,     <span class="hljs-number">0</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">18</span>,   <span class="hljs-number">676</span>,  <span class="hljs-number">3267</span>,<br>         <span class="hljs-number">1031</span>,     <span class="hljs-number">3</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">628</span>,  <span class="hljs-number">1589</span>,    <span class="hljs-number">22</span>, <span class="hljs-number">10916</span>, <span class="hljs-number">10969</span>,     <span class="hljs-number">5</span>, <span class="hljs-number">22548</span>,<br>            <span class="hljs-number">9</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">6</span>,    <span class="hljs-number">84</span>,    <span class="hljs-number">15</span>,    <span class="hljs-number">49</span>,  <span class="hljs-number">3144</span>,     <span class="hljs-number">7</span>,   <span class="hljs-number">102</span>,    <span class="hljs-number">15</span>,<br>          <span class="hljs-number">916</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">4</span>,   <span class="hljs-number">203</span>,     <span class="hljs-number">0</span>,   <span class="hljs-number">273</span>,   <span class="hljs-number">303</span>,   <span class="hljs-number">333</span>,  <span class="hljs-number">4318</span>,     <span class="hljs-number">0</span>,<br>            <span class="hljs-number">6</span>,    <span class="hljs-number">12</span>,     <span class="hljs-number">0</span>,  <span class="hljs-number">4842</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">17</span>,     <span class="hljs-number">4</span>,    <span class="hljs-number">47</span>,  <span class="hljs-number">4138</span>,  <span class="hljs-number">2072</span>,<br>           <span class="hljs-number">38</span>,   <span class="hljs-number">237</span>,     <span class="hljs-number">5</span>,    <span class="hljs-number">50</span>,    <span class="hljs-number">35</span>,    <span class="hljs-number">27</span>, <span class="hljs-number">18530</span>,   <span class="hljs-number">244</span>,    <span class="hljs-number">20</span>,     <span class="hljs-number">6</span>,<br>           <span class="hljs-number">13</span>,  <span class="hljs-number">1083</span>,    <span class="hljs-number">35</span>,  <span class="hljs-number">1990</span>,   <span class="hljs-number">653</span>,    <span class="hljs-number">13</span>,    <span class="hljs-number">10</span>,    <span class="hljs-number">11</span>,  <span class="hljs-number">1538</span>,    <span class="hljs-number">56</span>])<br></code></pre></td></tr></table></figure><hr><h4 id="第四步-构建训练和评估函数-P52"><a href="#第四步-构建训练和评估函数-P52" class="headerlink" title="第四步: 构建训练和评估函数 P52"></a>第四步: 构建训练和评估函数 P52</h4><ul><li>设置模型超参数和初始化模型</li><li>设置模型超参数和初始化模型</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 通过TEXT.vocab.stoi方法获得不重复词汇总数</span><br>ntokens = <span class="hljs-built_in">len</span>(TEXT.vocab.stoi)<br><br><span class="hljs-comment"># 词嵌入大小为200</span><br>emsize = <span class="hljs-number">200</span><br><br><span class="hljs-comment"># 前馈全连接层的节点数</span><br>nhid = <span class="hljs-number">200</span><br><br><span class="hljs-comment"># 编码器层的数量</span><br>nlayers = <span class="hljs-number">2</span><br><br><span class="hljs-comment"># 多头注意力机制的头数</span><br>nhead = <span class="hljs-number">2</span><br><br><span class="hljs-comment"># 置0比率</span><br>dropout = <span class="hljs-number">0.2</span><br><br><span class="hljs-comment"># 将参数输入到TransformerModel中</span><br>model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to(device)<br><br><span class="hljs-comment"># 模型初始化后, 接下来进行损失函数和优化方法的选择.</span><br><br><span class="hljs-comment"># 关于损失函数, 我们使用nn自带的交叉熵损失</span><br>criterion = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># 学习率初始值定为5.0</span><br>lr = <span class="hljs-number">5.0</span><br><br><span class="hljs-comment"># 优化器选择torch自带的SGD随机梯度下降方法, 并把lr传入其中</span><br>optimizer = torch.optim.SGD(model.parameters(), lr=lr)<br><br><span class="hljs-comment"># 定义学习率调整方法, 使用torch自带的lr_scheduler, 将优化器传入其中.</span><br>scheduler = torch.optim.lr_scheduler.StepLR(optimizer, <span class="hljs-number">1.0</span>, gamma=<span class="hljs-number">0.95</span>)<br></code></pre></td></tr></table></figure><hr><ul><li>模型训练代码分析: P53</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 导入时间工具包</span><br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;训练函数&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 模型开启训练模式</span><br>    model.train()<br>    <span class="hljs-comment"># 定义初始损失为0</span><br>    total_loss = <span class="hljs-number">0.</span><br>    <span class="hljs-comment"># 获得当前时间</span><br>    start_time = time.time()<br>    <span class="hljs-comment"># 开始遍历批次数据</span><br>    <span class="hljs-keyword">for</span> batch, i <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, train_data.size(<span class="hljs-number">0</span>) - <span class="hljs-number">1</span>, bptt)):<br>        <span class="hljs-comment"># 通过get_batch获得源数据和目标数据</span><br>        data, targets = get_batch(train_data, i)<br>        <span class="hljs-comment"># 设置优化器初始梯度为0梯度</span><br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># 将数据装入model得到输出</span><br>        output = model(data)<br>        <span class="hljs-comment"># 将输出和目标数据传入损失函数对象</span><br>        loss = criterion(output.view(-<span class="hljs-number">1</span>, ntokens), targets)<br>        <span class="hljs-comment"># 损失进行反向传播以获得总的损失</span><br>        loss.backward()<br>        <span class="hljs-comment"># 使用nn自带的clip_grad_norm_方法进行梯度规范化, 防止出现梯度消失或爆炸</span><br>        torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">0.5</span>)<br>        <span class="hljs-comment"># 模型参数进行更新</span><br>        optimizer.step()<br>        <span class="hljs-comment"># 将每层的损失相加获得总的损失</span><br>        total_loss += loss.item()<br>        <span class="hljs-comment"># 日志打印间隔定为200</span><br>        log_interval = <span class="hljs-number">200</span><br>        <span class="hljs-comment"># 如果batch是200的倍数且大于0，则打印相关日志</span><br>        <span class="hljs-keyword">if</span> batch % log_interval == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> batch &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># 平均损失为总损失除以log_interval</span><br>            cur_loss = total_loss / log_interval<br>            <span class="hljs-comment"># 需要的时间为当前时间减去开始时间</span><br>            elapsed = time.time() - start_time<br>            <span class="hljs-comment"># 打印轮数, 当前批次和总批次, 当前学习率, 训练速度(每豪秒处理多少批次),</span><br>            <span class="hljs-comment"># 平均损失, 以及困惑度, 困惑度是衡量语言模型的重要指标, 它的计算方法就是</span><br>            <span class="hljs-comment"># 对交叉熵平均损失取自然对数的底数.</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | &#123;:5d&#125;/&#123;:5d&#125; batches | &#x27;</span><br>                  <span class="hljs-string">&#x27;lr &#123;:02.2f&#125; | ms/batch &#123;:5.2f&#125; | &#x27;</span><br>                  <span class="hljs-string">&#x27;loss &#123;:5.2f&#125; | ppl &#123;:8.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                    epoch, batch, <span class="hljs-built_in">len</span>(train_data) // bptt, scheduler.get_lr()[<span class="hljs-number">0</span>],<br>                    elapsed * <span class="hljs-number">1000</span> / log_interval,<br>                    cur_loss, math.exp(cur_loss)))<br><br>            <span class="hljs-comment"># 每个批次结束后, 总损失归0</span><br>            total_loss = <span class="hljs-number">0</span><br>            <span class="hljs-comment"># 开始时间取当前时间</span><br>            start_time = time.time()<br></code></pre></td></tr></table></figure><ul><li>模型评估代码分析: <code>P54</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">eval_model, data_source</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;评估函数, 评估阶段包括验证和测试,</span><br><span class="hljs-string">       它的两个参数eval_model为每轮训练产生的模型</span><br><span class="hljs-string">       data_source代表验证或测试数据集&quot;&quot;&quot;</span><br>    <span class="hljs-comment"># 模型开启评估模式</span><br>    eval_model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-comment"># 总损失归0</span><br>    total_loss = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># 因为评估模式模型参数不变, 因此反向传播不需要求导, 以加快计算</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># 与训练过程相同, 但是因为过程不需要打印信息, 因此不需要batch数</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, data_source.size(<span class="hljs-number">0</span>) - <span class="hljs-number">1</span>, bptt):<br>            <span class="hljs-comment"># 首先还是通过通过get_batch获得验证数据集的源数据和目标数据</span><br>            data, targets = get_batch(data_source, i)<br>            <span class="hljs-comment"># 通过eval_model获得输出</span><br>            output = eval_model(data)<br>            <span class="hljs-comment"># 对输出形状扁平化, 变为全部词汇的概率分布</span><br>            output_flat = output.view(-<span class="hljs-number">1</span>, ntokens)<br>            <span class="hljs-comment"># 获得评估过程的总损失</span><br>            total_loss += criterion(output_flat, targets).item()<br>            <span class="hljs-comment"># 计算平均损失</span><br>            cur_loss = total_loss / ((data_source.size(<span class="hljs-number">0</span>) - <span class="hljs-number">1</span>) / bptt)            <br><br>    <span class="hljs-comment"># 返回平均损失</span><br>    <span class="hljs-keyword">return</span> cur_loss<br></code></pre></td></tr></table></figure><hr><h4 id="第五步-进行训练和评估-包括验证以及测试-P55"><a href="#第五步-进行训练和评估-包括验证以及测试-P55" class="headerlink" title="第五步: 进行训练和评估(包括验证以及测试) P55"></a>第五步: 进行训练和评估(包括验证以及测试) P55</h4><ul><li>模型的训练与验证代码分析:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 首先初始化最佳验证损失，初始值为无穷大</span><br><span class="hljs-keyword">import</span> copy<br>best_val_loss = <span class="hljs-built_in">float</span>(<span class="hljs-string">&quot;inf&quot;</span>)<br><br><span class="hljs-comment"># 定义训练轮数</span><br>epochs = <span class="hljs-number">3</span><br><br><span class="hljs-comment"># 定义最佳模型变量, 初始值为None</span><br>best_model = <span class="hljs-literal">None</span><br><br><span class="hljs-comment"># 使用for循环遍历轮数</span><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>    <span class="hljs-comment"># 首先获得轮数开始时间</span><br>    epoch_start_time = time.time()<br>    <span class="hljs-comment"># 调用训练函数</span><br>    train()<br>    <span class="hljs-comment"># 该轮训练后我们的模型参数已经发生了变化</span><br>    <span class="hljs-comment"># 将模型和评估数据传入到评估函数中</span><br>    val_loss = evaluate(model, val_data)<br>    <span class="hljs-comment"># 之后打印每轮的评估日志，分别有轮数，耗时，验证损失以及验证困惑度</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span> * <span class="hljs-number">89</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;| end of epoch &#123;:3d&#125; | time: &#123;:5.2f&#125;s | valid loss &#123;:5.2f&#125; | &#x27;</span><br>          <span class="hljs-string">&#x27;valid ppl &#123;:8.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, (time.time() - epoch_start_time),<br>                                     val_loss, math.exp(val_loss)))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span> * <span class="hljs-number">89</span>)<br>    <span class="hljs-comment"># 我们将比较哪一轮损失最小，赋值给best_val_loss，</span><br>    <span class="hljs-comment"># 并取该损失下的模型为best_model</span><br>    <span class="hljs-keyword">if</span> val_loss &lt; best_val_loss:<br>        best_val_loss = val_loss<br>        <span class="hljs-comment"># 使用深拷贝，拷贝最优模型</span><br>        best_model = copy.deepcopy(model)<br>    <span class="hljs-comment"># 每轮都会对优化方法的学习率做调整</span><br>    scheduler.step()<br></code></pre></td></tr></table></figure><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python">| epoch   <span class="hljs-number">1</span> |   <span class="hljs-number">200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">30.03</span> | loss  <span class="hljs-number">7.68</span> | ppl  <span class="hljs-number">2158.52</span><br>| epoch   <span class="hljs-number">1</span> |   <span class="hljs-number">400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.90</span> | loss  <span class="hljs-number">5.26</span> | ppl   <span class="hljs-number">193.39</span><br>| epoch   <span class="hljs-number">1</span> |   <span class="hljs-number">600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.90</span> | loss  <span class="hljs-number">4.07</span> | ppl    <span class="hljs-number">58.44</span><br>| epoch   <span class="hljs-number">1</span> |   <span class="hljs-number">800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.88</span> | loss  <span class="hljs-number">3.41</span> | ppl    <span class="hljs-number">30.26</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">1000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.89</span> | loss  <span class="hljs-number">2.98</span> | ppl    <span class="hljs-number">19.72</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">1200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.90</span> | loss  <span class="hljs-number">2.79</span> | ppl    <span class="hljs-number">16.30</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">1400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.91</span> | loss  <span class="hljs-number">2.67</span> | ppl    <span class="hljs-number">14.38</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">1600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.92</span> | loss  <span class="hljs-number">2.58</span> | ppl    <span class="hljs-number">13.19</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">1800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.91</span> | loss  <span class="hljs-number">2.43</span> | ppl    <span class="hljs-number">11.32</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">2000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.92</span> | loss  <span class="hljs-number">2.39</span> | ppl    <span class="hljs-number">10.93</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">2200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.91</span> | loss  <span class="hljs-number">2.33</span> | ppl    <span class="hljs-number">10.24</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">2400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.91</span> | loss  <span class="hljs-number">2.36</span> | ppl    <span class="hljs-number">10.59</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">2600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.90</span> | loss  <span class="hljs-number">2.33</span> | ppl    <span class="hljs-number">10.31</span><br>| epoch   <span class="hljs-number">1</span> |  <span class="hljs-number">2800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">5.00</span> | ms/batch <span class="hljs-number">28.92</span> | loss  <span class="hljs-number">2.26</span> | ppl     <span class="hljs-number">9.54</span><br>-----------------------------------------------------------------------------------------<br>| end of epoch   <span class="hljs-number">1</span> | time: <span class="hljs-number">90.01</span>s | valid loss  <span class="hljs-number">1.32</span> | valid ppl     <span class="hljs-number">3.73</span><br>-----------------------------------------------------------------------------------------<br>| epoch   <span class="hljs-number">2</span> |   <span class="hljs-number">200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">29.08</span> | loss  <span class="hljs-number">2.18</span> | ppl     <span class="hljs-number">8.83</span><br>| epoch   <span class="hljs-number">2</span> |   <span class="hljs-number">400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">2.11</span> | ppl     <span class="hljs-number">8.24</span><br>| epoch   <span class="hljs-number">2</span> |   <span class="hljs-number">600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">1.98</span> | ppl     <span class="hljs-number">7.23</span><br>| epoch   <span class="hljs-number">2</span> |   <span class="hljs-number">800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">2.00</span> | ppl     <span class="hljs-number">7.39</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">1000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.94</span> | loss  <span class="hljs-number">1.94</span> | ppl     <span class="hljs-number">6.96</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">1200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.92</span> | loss  <span class="hljs-number">1.97</span> | ppl     <span class="hljs-number">7.15</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">1400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.94</span> | loss  <span class="hljs-number">1.98</span> | ppl     <span class="hljs-number">7.28</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">1600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.92</span> | loss  <span class="hljs-number">1.97</span> | ppl     <span class="hljs-number">7.16</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">1800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">1.92</span> | ppl     <span class="hljs-number">6.84</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">2000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">1.96</span> | ppl     <span class="hljs-number">7.11</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">2200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.93</span> | loss  <span class="hljs-number">1.92</span> | ppl     <span class="hljs-number">6.80</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">2400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.94</span> | loss  <span class="hljs-number">1.94</span> | ppl     <span class="hljs-number">6.93</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">2600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.76</span> | loss  <span class="hljs-number">1.91</span> | ppl     <span class="hljs-number">6.76</span><br>| epoch   <span class="hljs-number">2</span> |  <span class="hljs-number">2800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.75</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.89</span> | ppl     <span class="hljs-number">6.64</span><br>-----------------------------------------------------------------------------------------<br>| end of epoch   <span class="hljs-number">2</span> | time: <span class="hljs-number">89.71</span>s | valid loss  <span class="hljs-number">1.01</span> | valid ppl     <span class="hljs-number">2.74</span><br>-----------------------------------------------------------------------------------------<br>| epoch   <span class="hljs-number">3</span> |   <span class="hljs-number">200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.88</span> | loss  <span class="hljs-number">1.78</span> | ppl     <span class="hljs-number">5.96</span><br>| epoch   <span class="hljs-number">3</span> |   <span class="hljs-number">400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.89</span> | ppl     <span class="hljs-number">6.59</span><br>| epoch   <span class="hljs-number">3</span> |   <span class="hljs-number">600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.72</span> | ppl     <span class="hljs-number">5.58</span><br>| epoch   <span class="hljs-number">3</span> |   <span class="hljs-number">800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.73</span> | ppl     <span class="hljs-number">5.63</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">1000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.73</span> | loss  <span class="hljs-number">1.65</span> | ppl     <span class="hljs-number">5.22</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">1200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.74</span> | loss  <span class="hljs-number">1.69</span> | ppl     <span class="hljs-number">5.40</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">1400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.74</span> | loss  <span class="hljs-number">1.73</span> | ppl     <span class="hljs-number">5.66</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">1600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.75</span> | ppl     <span class="hljs-number">5.73</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">1800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.74</span> | loss  <span class="hljs-number">1.67</span> | ppl     <span class="hljs-number">5.33</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">2000</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.74</span> | loss  <span class="hljs-number">1.69</span> | ppl     <span class="hljs-number">5.41</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">2200</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.74</span> | loss  <span class="hljs-number">1.66</span> | ppl     <span class="hljs-number">5.26</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">2400</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.76</span> | loss  <span class="hljs-number">1.69</span> | ppl     <span class="hljs-number">5.43</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">2600</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.71</span> | ppl     <span class="hljs-number">5.55</span><br>| epoch   <span class="hljs-number">3</span> |  <span class="hljs-number">2800</span>/ <span class="hljs-number">2981</span> batches | lr <span class="hljs-number">4.51</span> | ms/batch <span class="hljs-number">28.75</span> | loss  <span class="hljs-number">1.72</span> | ppl     <span class="hljs-number">5.58</span><br>-----------------------------------------------------------------------------------------<br>| end of epoch   <span class="hljs-number">3</span> | time: <span class="hljs-number">89.26</span>s | valid loss  <span class="hljs-number">0.85</span> | valid ppl     <span class="hljs-number">2.33</span><br>-----------------------------------------------------------------------------------------<br></code></pre></td></tr></table></figure><hr><ul><li>模型测试代码分析: <code>P56</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 我们仍然使用evaluate函数，这次它的参数是best_model以及测试数据</span><br>test_loss = evaluate(best_model, test_data)<br><br><span class="hljs-comment"># 打印测试日志，包括测试损失和测试困惑度</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;=&#x27;</span> * <span class="hljs-number">89</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;| End of training | test loss &#123;:5.2f&#125; | test ppl &#123;:8.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>    test_loss, math.exp(test_loss)))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;=&#x27;</span> * <span class="hljs-number">89</span>)<br></code></pre></td></tr></table></figure><hr><ul><li>输出效果:</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">=========================================================================================<br>| End of training | test loss  <span class="hljs-number">0.83</span> | test ppl     <span class="hljs-number">2.30</span><br>=========================================================================================<br></code></pre></td></tr></table></figure><hr><h3 id="小节总结"><a href="#小节总结" class="headerlink" title="小节总结"></a>小节总结</h3><ul><li>学习了什么是语言模型:<ul><li>以一个符合语言规律的序列为输入，模型将利用序列间关系等特征，输出一个在所有词汇上的概率分布.这样的模型称为语言模型.</li></ul></li></ul><hr><ul><li>学习了语言模型能解决哪些问题:<ul><li>1, 根据语言模型的定义，可以在它的基础上完成机器翻译，文本生成等任务，因为我们通过最后输出的概率分布来预测下一个词汇是什么.</li><li>2, 语言模型可以判断输入的序列是否为一句完整的话，因为我们可以根据输出的概率分布查看最大概率是否落在句子结束符上，来判断完整性.</li><li>3, 语言模型本身的训练目标是预测下一个词，因为它的特征提取部分会抽象很多语言序列之间的关系，这些关系可能同样对其他语言类任务有效果.因此可以作为预训练模型进行迁移学习.</li></ul></li></ul><hr><ul><li>学习并实现了整个案例的五个步骤:<ul><li>第一步: 导入必备的工具包</li><li>第二步: 导入wikiText-2数据集并作基本处理</li><li>第三步: 构建用于模型输入的批次化数据</li><li>第四步: 构建训练和评估函数</li><li>第五步: 进行训练和评估(包括验证以及测试)</li></ul></li></ul><hr><ul><li>第一步: 导入必备的工具包<ul><li>torchtext介绍: 它是torch工具中处理NLP问题的常用数据处理包.</li><li>对文本数据进行处理, 比如文本语料加载, 文本迭代器构建等.</li><li>包含很多经典文本语料的预加载方法. 其中包括的语料有：用于情感分析的SST和IMDB, 用于问题分类的TREC, 用于及其翻译的 WMT14， IWSLT，以及用于语言模型任务wikiText-2, WikiText103, PennTreebank.</li><li>wikiText-2数据集的体量中等, 训练集共有600篇短文, 共208万左右的词汇, 33278个不重复词汇, OvV（有多少正常英文词汇不在该数据集中的占比）为2.6%，数据集中的短文都是维基百科中对一些概念的介绍和描述.</li></ul></li></ul><hr><ul><li>第二步: 导入wikiText-2数据集并作基本处理<ul><li>通过torchtext中的方法获得了train_txt, val_txt, test_txt.</li></ul></li></ul><hr><ul><li>第三步: 构建用于模型输入的批次化数据<ul><li>实现了批次化过程的第一个函数batchify, 用于将文本数据映射成连续数字, 并转换成指定的样式.</li><li>实现了批次化过程的第二个函数get_batch, 用于获得每个批次合理大小的源数据和目标数据.</li></ul></li></ul><hr><ul><li>第四步: 构建训练和评估函数<ul><li>构建了用于训练的函数train()</li><li>构建了用于评估的函数evaluate()</li></ul></li></ul><hr><ul><li>第五步: 进行训练和评估(包括验证以及测试)<ul><li>首先实现了模型训练与验证过程, 并打印了结果.</li><li>最后实现了模型的测试过程, 得到了不错的困惑度指标.</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网站代码</title>
    <link href="/2023/11/08/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/08/%E7%BD%91%E7%AB%99/%E7%BD%91%E7%AB%99%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="view程序"><a href="#view程序" class="headerlink" title="view程序"></a>view程序</h1><h2 id="view主程序"><a href="#view主程序" class="headerlink" title="view主程序"></a>view主程序</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Template Name: Book view</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="title function_ invoke__">get_header</span>();</span><br><span class="line"><span class="keyword">if</span> (True === <span class="title function_ invoke__">apply_filters</span>(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="literal">true</span>)) :</span><br><span class="line">    <span class="keyword">global</span> <span class="variable">$wpdb</span>;</span><br><span class="line">    <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from boy&quot;</span>);</span><br><span class="line">    <span class="variable">$num_boys</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        <span class="meta">&lt;?php</span></span><br><span class="line">        <span class="keyword">echo</span> <span class="string">&quot;男生投递的人数: &quot;</span> . <span class="variable">$num_boys</span> . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line">        <span class="meta">?&gt;</span></span><br><span class="line">    &lt;/div&gt;</span><br><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="keyword">endif</span>;</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">Template Name: Book view</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="title function_ invoke__">get_header</span>();</span><br><span class="line"><span class="keyword">if</span> (True === <span class="title function_ invoke__">apply_filters</span>(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="literal">true</span>)) :</span><br><span class="line">    <span class="keyword">global</span> <span class="variable">$wpdb</span>;</span><br><span class="line">    <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from boy&quot;</span>);</span><br><span class="line">    <span class="variable">$num_boys</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line">    <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from girl&quot;</span>);</span><br><span class="line">    <span class="variable">$num_girls</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line"><span class="meta">?&gt;</span></span><br><span class="line">    &lt;div&gt;</span><br><span class="line">        <span class="meta">&lt;?php</span></span><br><span class="line">        <span class="keyword">echo</span> <span class="string">&quot;&lt;br&gt;&lt;br&gt;男生投递的人数: &quot;</span> . <span class="variable">$num_boys</span> . <span class="string">&quot;&lt;br&gt;&lt;br&gt;&quot;</span>;</span><br><span class="line">        <span class="keyword">echo</span> <span class="string">&quot;女生投递的人数: &quot;</span> . <span class="variable">$num_girls</span> . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line">        <span class="meta">?&gt;</span></span><br><span class="line">    &lt;/div&gt;</span><br><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="keyword">endif</span>;</span><br><span class="line"><span class="title function_ invoke__">get_footer</span>();</span><br><span class="line"><span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><h2 id="能显示代码"><a href="#能显示代码" class="headerlink" title="能显示代码"></a>能显示代码</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;?php /* Template Name: Book view */ </span><br><span class="line">get_header(); </span><br><span class="line"><span class="keyword">if</span> (True === apply_filters(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="built_in">true</span>)) : </span><br><span class="line"><span class="keyword">global</span> $wpdb; $num_boys = <span class="number">0</span>; <span class="keyword">if</span> (isset($_POST[<span class="string">&#x27;submit&#x27;</span>])) &#123; $hcaptcha_secret_key = <span class="string">&#x27;0xfC0436A04C39D94998Ce3655b3760F46698c45d6&#x27;</span>; // 替换成你的hCaptcha私钥 </span><br><span class="line">$hcaptcha_response = sanitize_text_field($_POST[<span class="string">&#x27;h-captcha-response&#x27;</span>]); </span><br><span class="line">$response = wp_remote_post(<span class="string">&#x27;https://hcaptcha.com/siteverify&#x27;</span>, array( <span class="string">&#x27;body&#x27;</span> =&gt; array( <span class="string">&#x27;secret&#x27;</span> =&gt; $hcaptcha_secret_key, <span class="string">&#x27;response&#x27;</span> =&gt; $hcaptcha_response ) )); </span><br><span class="line">$response_body = json_decode(wp_remote_retrieve_body($response)); <span class="keyword">if</span> ($response_body-&gt;success) &#123; $boy = $wpdb-&gt;get_results(<span class="string">&quot;select * from boy&quot;</span>); </span><br><span class="line">$num_boys = $wpdb-&gt;num_rows; &#125; <span class="keyword">else</span> &#123; echo <span class="string">&quot;验证码输入错误，请重新输入！&lt;br&gt;&quot;</span>; &#125; &#125; ?&gt; &lt;form method=<span class="string">&quot;post&quot;</span>&gt; &lt;div class=<span class="string">&quot;h-captcha&quot;</span> data-sitekey=<span class="string">&quot;a784c10d-6304-4d2e-8d7c-7b5bdf2382f7&quot;</span>&gt;&lt;/div&gt; </span><br><span class="line">&lt;!-- 替换成你的hCaptcha站点密钥 --&gt; </span><br><span class="line">&lt;input <span class="built_in">type</span>=<span class="string">&quot;submit&quot;</span> name=<span class="string">&quot;submit&quot;</span> value=<span class="string">&quot;提交&quot;</span>&gt; &lt;/form&gt; &lt;div&gt; &lt;?php <span class="keyword">if</span> ($num_boys &gt; <span class="number">0</span>) &#123; echo <span class="string">&quot;男生投递的人数: &quot;</span> . $num_boys . <span class="string">&quot;&lt;br&gt;&quot;</span>; &#125; ?&gt; </span><br><span class="line">&lt;/div&gt; &lt;script src=<span class="string">&quot;https://hcaptcha.com/1/api.js&quot;</span> async defer&gt;&lt;/script&gt; &lt;?php endif; ?&gt;</span><br></pre></td></tr></table></figure><h2 id="能够显示代码2"><a href="#能够显示代码2" class="headerlink" title="能够显示代码2"></a>能够显示代码2</h2><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">/* Template Name: Book view */</span></span><br><span class="line"><span class="title function_ invoke__">get_header</span>();</span><br><span class="line"><span class="keyword">if</span> (True === <span class="title function_ invoke__">apply_filters</span>(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="literal">true</span>)) :</span><br><span class="line">    <span class="keyword">global</span> <span class="variable">$wpdb</span>; <span class="variable">$num_boys</span> = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">isset</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;submit&#x27;</span>])) &#123;</span><br><span class="line">        <span class="variable">$hcaptcha_secret_key</span> = <span class="string">&#x27;0xfC0436A04C39D94998Ce3655b3760F46698c45d6&#x27;</span>; <span class="comment">// 替换成你的hCaptcha私钥 </span></span><br><span class="line">        <span class="variable">$hcaptcha_response</span> = <span class="title function_ invoke__">sanitize_text_field</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;h-captcha-response&#x27;</span>]);</span><br><span class="line">        <span class="variable">$response</span> = <span class="title function_ invoke__">wp_remote_post</span>(<span class="string">&#x27;https://hcaptcha.com/siteverify&#x27;</span>, <span class="keyword">array</span>(<span class="string">&#x27;body&#x27;</span> =&gt; <span class="keyword">array</span>(<span class="string">&#x27;secret&#x27;</span> =&gt; <span class="variable">$hcaptcha_secret_key</span>, <span class="string">&#x27;response&#x27;</span> =&gt; <span class="variable">$hcaptcha_response</span>)));</span><br><span class="line">        <span class="variable">$response_body</span> = <span class="title function_ invoke__">json_decode</span>(<span class="title function_ invoke__">wp_remote_retrieve_body</span>(<span class="variable">$response</span>));</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$response_body</span>-&gt;success) &#123;</span><br><span class="line">            <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from boy&quot;</span>);</span><br><span class="line">            <span class="variable">$num_boys</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line">            <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from girl&quot;</span>);</span><br><span class="line">            <span class="variable">$num_girls</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">echo</span> <span class="string">&quot;验证码输入错误，请重新输入！&lt;br&gt;&quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="meta">?&gt;</span></span><br><span class="line">    &lt;form method=<span class="string">&quot;post&quot;</span>&gt;</span><br><span class="line">        &lt;div <span class="class"><span class="keyword">class</span>=&quot;<span class="title">h</span>-<span class="title">captcha</span>&quot; <span class="title">data</span>-<span class="title">sitekey</span>=&quot;<span class="title">a784c10d</span>-6304-4<span class="title">d2e</span>-8<span class="title">d7c</span>-7<span class="title">b5bdf2382f7</span>&quot;&gt;&lt;/<span class="title">div</span>&gt; &lt;!-- 替换成你的<span class="title">hCaptcha</span>站点密钥 --&gt;</span></span><br><span class="line"><span class="class">        &lt;<span class="title">input</span> <span class="title">type</span>=&quot;<span class="title">submit</span>&quot; <span class="title">name</span>=&quot;<span class="title">submit</span>&quot; <span class="title">value</span>=&quot;提交&quot;&gt;</span></span><br><span class="line"><span class="class">    &lt;/<span class="title">form</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">div</span>&gt; &lt;?<span class="title">php</span> <span class="title">if</span> ($<span class="title">num_boys</span> &gt; 0) </span>&#123;</span><br><span class="line">                <span class="keyword">echo</span> <span class="string">&quot;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;男生投递的人数: &quot;</span> . <span class="variable">$num_boys</span> . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line">                <span class="keyword">echo</span> <span class="string">&quot;女生投递的人数: &quot;</span> . <span class="variable">$num_girls</span> . <span class="string">&quot;&lt;br&gt;&quot;</span>;</span><br><span class="line">            &#125; <span class="meta">?&gt;</span></span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">    &lt;script src=<span class="string">&quot;https://hcaptcha.com/1/api.js&quot;</span> async defer&gt;&lt;/script&gt;</span><br><span class="line"><span class="meta">&lt;?php</span> <span class="keyword">endif</span>; <span class="meta">?&gt;</span></span><br></pre></td></tr></table></figure><h2 id="完整代码-有验证码"><a href="#完整代码-有验证码" class="headerlink" title="完整代码 有验证码"></a>完整代码 有验证码</h2><p>···matlab</p><p>···matlab</p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="comment">/* Template Name: Book view */</span></span><br><span class="line"><span class="title function_ invoke__">get_header</span>();</span><br><span class="line"><span class="keyword">if</span> (True === <span class="title function_ invoke__">apply_filters</span>(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="literal">true</span>)) :</span><br><span class="line"><span class="keyword">global</span> <span class="variable">$wpdb</span>; <span class="variable">$num_boys</span> = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">if</span> (<span class="keyword">isset</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;submit&#x27;</span>])) &#123;</span><br><span class="line"><span class="variable">$hcaptcha_secret_key</span> = <span class="string">&#x27;0xfC0436A04C39D94998Ce3655b3760F46698c45d6&#x27;</span>; <span class="comment">// 替换成你的hCaptcha私钥</span></span><br><span class="line"><span class="variable">$hcaptcha_response</span> = <span class="title function_ invoke__">sanitize_text_field</span>(<span class="variable">$_POST</span>[<span class="string">&#x27;h-captcha-response&#x27;</span>]);</span><br><span class="line"><span class="variable">$response</span> = <span class="title function_ invoke__">wp_remote_post</span>(<span class="string">&#x27;https://hcaptcha.com/siteverify&#x27;</span>, <span class="keyword">array</span>(</span><br><span class="line">    <span class="string">&#x27;body&#x27;</span> =&gt; <span class="keyword">array</span>(</span><br><span class="line">        <span class="string">&#x27;secret&#x27;</span> =&gt; <span class="variable">$hcaptcha_secret_key</span>,</span><br><span class="line">        <span class="string">&#x27;response&#x27;</span> =&gt; <span class="variable">$hcaptcha_response</span> )));</span><br><span class="line"><span class="variable">$response_body</span> = <span class="title function_ invoke__">json_decode</span>(<span class="title function_ invoke__">wp_remote_retrieve_body</span>(<span class="variable">$response</span>));</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$response_body</span>-&gt;success) &#123;</span><br><span class="line">    <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from boy&quot;</span>);</span><br><span class="line">    <span class="variable">$num_boys</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line">    <span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from girl&quot;</span>);</span><br><span class="line">    <span class="variable">$num_girls</span> = <span class="variable">$wpdb</span>-&gt;num_rows;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">echo</span> <span class="string">&quot;验证码输入错误，请重新输入！&lt;br&gt;&quot;</span>;</span><br><span class="line">&#125;&#125;<span class="meta">?&gt;</span></span><br><span class="line"><span class="meta">&lt;?php</span> <span class="keyword">if</span> (<span class="variable">$num_boys</span> == <span class="number">0</span>) : <span class="comment">// 当$num_boys等于0时，显示 hCaptcha 验证码的部分 ?&gt;</span></span><br><span class="line">&lt;form method=<span class="string">&quot;post&quot;</span>&gt;</span><br><span class="line">    &lt;div <span class="class"><span class="keyword">class</span>=&quot;<span class="title">h</span>-<span class="title">captcha</span>&quot; <span class="title">data</span>-<span class="title">sitekey</span>=&quot;<span class="title">a784c10d</span>-6304-4<span class="title">d2e</span>-8<span class="title">d7c</span>-7<span class="title">b5bdf2382f7</span>&quot;&gt;&lt;/<span class="title">div</span>&gt; &lt;!-- 替换成你的<span class="title">hCaptcha</span>站点密钥 --&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">input</span> <span class="title">type</span>=&quot;<span class="title">submit</span>&quot; <span class="title">name</span>=&quot;<span class="title">submit</span>&quot; <span class="title">value</span>=&quot;提交&quot;&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">form</span>&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">script</span> <span class="title">src</span>=&quot;<span class="title">https</span>://<span class="title">hcaptcha</span>.<span class="title">com</span>/1/<span class="title">api</span>.<span class="title">js</span>&quot; <span class="title">async</span> <span class="title">defer</span>&gt;&lt;/<span class="title">script</span>&gt;</span></span><br><span class="line"><span class="class">&lt;?<span class="title">php</span> <span class="title">endif</span>; ?&gt;</span></span><br><span class="line"><span class="class">&lt;?<span class="title">php</span> <span class="title">if</span> ($<span class="title">num_boys</span> &gt; 0) : // 当$<span class="title">num_boys</span>大于0时，显示男生投递的人数 ?&gt;</span></span><br><span class="line"><span class="class">&lt;<span class="title">div</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;?<span class="title">php</span></span></span><br><span class="line"><span class="class">    <span class="title">echo</span> &quot;&lt;<span class="title">br</span>&gt;&lt;<span class="title">br</span>&gt;男生投递的人数: &quot; . $<span class="title">num_boys</span> . &quot;&lt;<span class="title">br</span>&gt;&lt;<span class="title">br</span>&gt;&quot;;</span></span><br><span class="line"><span class="class">    <span class="title">echo</span> &quot;女生投递的人数: &quot; . $<span class="title">num_girls</span> . &quot;&lt;<span class="title">br</span>&gt;&quot;;</span></span><br><span class="line"><span class="class">    ?&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">div</span>&gt;</span></span><br><span class="line"><span class="class">&lt;?<span class="title">php</span> <span class="title">endif</span>; ?&gt;</span></span><br><span class="line"><span class="class">&lt;?<span class="title">php</span></span></span><br><span class="line"><span class="class"><span class="title">endif</span>;?&gt;</span></span><br><span class="line"><span class="class"></span></span><br></pre></td></tr></table></figure><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230418111716778.png" alt="image-20230418111716778" style="zoom:50%;" /><h3 id="对每行代码的分析"><a href="#对每行代码的分析" class="headerlink" title="对每行代码的分析"></a>对每行代码的分析</h3><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?php</span> : 这是PHP代码的开始标记。</span><br><span class="line"><span class="comment">/* : 这是多行注释的开始。</span></span><br><span class="line"><span class="comment">Template Name: Book view : 这是WordPress特有的注释，指定该页面模板的名称。</span></span><br><span class="line"><span class="comment">*/</span> : 多行注释的结束标记。</span><br><span class="line"><span class="title function_ invoke__">get_header</span>() : 这个函数会调用header.php文件，显示网站的标题、导航菜单等内容。</span><br><span class="line"><span class="keyword">if</span> (True === <span class="title function_ invoke__">apply_filters</span>(<span class="string">&#x27;graduate_filter_frontpage_content_enable&#x27;</span>, <span class="literal">true</span>)) : 这是一个条件语句，如果满足条件则执行后面的代码。</span><br><span class="line"><span class="keyword">global</span> <span class="variable">$wpdb</span> : 这个语句将数据库连接对象（<span class="variable">$wpdb</span>）设置为全局变量，从而可以在函数外部使用该变量。</span><br><span class="line"><span class="variable">$boy</span> = <span class="variable">$wpdb</span>-&gt;<span class="title function_ invoke__">get_results</span>(<span class="string">&quot;select * from boy&quot;</span>) : 这个语句使用wpdb对象执行一条SQL查询语句，从boy表中获取所有的记录，并将结果存储在<span class="variable">$boy</span>变量中。</span><br><span class="line"><span class="variable">$num_boys</span> = <span class="variable">$wpdb</span>-&gt;num_rows : 这行代码获取男生投递的结果集行数，并将结果存储在<span class="variable">$num_boys</span>变量中。</span><br><span class="line"><span class="keyword">echo</span> <span class="string">&quot;男生投递的人数: &quot;</span> . <span class="variable">$num_boys</span> . <span class="string">&quot;&lt;br&gt;&quot;</span> : 这行代码会在网页上输出男孩投递的人数。</span><br><span class="line"><span class="keyword">endif</span>; : 这是条件语句的结束标记。</span><br><span class="line"><span class="meta">?&gt;</span> : 这是PHP代码的结束标记。</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PHP HTML</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>笔记本电脑配置环境</title>
    <link href="/2023/11/08/%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/"/>
    <url>/2023/11/08/%E7%94%B5%E8%84%91%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83/%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<h1 id="笔记本电脑配置环境">笔记本电脑配置环境</h1><h2 id="教程">教程：</h2><p><ahref="https://blog.csdn.net/sjjsbsbbs/article/details/123556348">3050显卡驱动安装+配置pytorch的cuda环境_3050驱动_血狼傲骨的博客-CSDN博客</a></p><p>相关型号：GeForce RTX 3050 Laptop GPU</p><p>文件信息：</p><ol type="1"><li>cuda_11.6.1_511.65_windows.exe</li><li>536.23-notebook-win10-win11-64bit-international-dch-whql.exe</li><li>cudnn-windows-x86_64-8.8.1.3_cuda11-archive.zip</li></ol><h2 id="添加镜像源">添加镜像源：</h2><p>conda config --add channelshttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free conda config--add channelshttps://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</p><h2 id="相关指令">相关指令：</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">conda create -n torch_chen2 python=<span class="hljs-number">3.8</span><br>conda activate torch_chen2<br>pip3 install torch==<span class="hljs-number">1.11</span><span class="hljs-number">.0</span>+cu113 torchvision==<span class="hljs-number">0.12</span><span class="hljs-number">.0</span>+cu113 torchaudio===<span class="hljs-number">0.11</span><span class="hljs-number">.0</span>+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html<br><br>python<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-built_in">print</span>(torch.cuda.is_available())<br><span class="hljs-literal">True</span> <span class="hljs-comment"># 测试成功</span><br><span class="hljs-comment"># 在终端输入命令：</span><br>pip install tensorboard<br></code></pre></td></tr></table></figure><p>pip3 install torch==1.10.0+cu113 torchvision==0.11.1+cu113 -fhttps://download.pytorch.org/whl/cu113/torch_stable.html -ihttps://pypi.douban.com/simple pip install xlrd==1.2.0 pip installxlrd==4.64.1</p><p>cudnn-windows-x86_64-8.8.0.121_cuda12-archive.zipcuda_12.0.0_527.41_windows.exe</p><p>pip install matplotlib==3.2.0 -i https://pypi.douban.com/simple/</p>]]></content>
    
    
    <categories>
      
      <category>配置环境</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>土堆代码</title>
    <link href="/2023/11/08/%E5%9C%9F%E5%A0%86/%E5%9C%9F%E5%A0%86%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/08/%E5%9C%9F%E5%A0%86/%E5%9C%9F%E5%A0%86%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="土堆代码"><a href="#土堆代码" class="headerlink" title="土堆代码"></a>土堆代码</h1><h2 id="代码1-Sequential"><a href="#代码1-Sequential" class="headerlink" title="代码1 Sequential"></a>代码1 Sequential</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 作者：小土堆</span></span><br><span class="line"><span class="comment"># 公众号：土堆碎念</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Tudui</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Tudui, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">tudui = Tudui()</span><br><span class="line"><span class="built_in">print</span>(tudui)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">output = tudui(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs1&quot;</span>)</span><br><span class="line">writer.add_graph(tudui, <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RCWA 程序</title>
    <link href="/2023/11/08/RCWA/RCWA%E7%A8%8B%E5%BA%8F/"/>
    <url>/2023/11/08/RCWA/RCWA%E7%A8%8B%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="RCWA程序"><a href="#RCWA程序" class="headerlink" title="RCWA程序"></a>RCWA程序</h1><h2 id="RCWA-一维程序"><a href="#RCWA-一维程序" class="headerlink" title="RCWA 一维程序"></a>RCWA 一维程序</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 不同厚度仿真 exemple2_1D</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clc;clear;close all;</span><br><span class="line">addpath(<span class="string">&#x27;reticolo_allege_v9&#x27;</span>); addpath(<span class="string">&#x27;shuju&#x27;</span>);addpath(<span class="string">&#x27;script&#x27;</span>);addpath(<span class="string">&#x27;RCWA&#x27;</span>);</span><br><span class="line">t1 = clock;</span><br><span class="line">incident_angle = <span class="number">0</span>;</span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.4</span>:<span class="number">0.001</span>:<span class="number">2</span>; <span class="comment">% 波长范围</span></span><br><span class="line"></span><br><span class="line">grating_period = <span class="number">1</span>; <span class="comment">% 光栅周期</span></span><br><span class="line">incident_refractive_index = <span class="number">1</span>; <span class="comment">% 入射介质的折射率</span></span><br><span class="line">k_parallel = incident_refractive_index * <span class="built_in">sin</span>(incident_angle * <span class="built_in">pi</span> / <span class="number">180</span>); <span class="comment">% 入射角的相位角</span></span><br><span class="line">polarization = <span class="number">-1</span>; <span class="comment">% -1:TM   1:TE   </span></span><br><span class="line">parm = res0(polarization); parm.not_io = <span class="number">1</span>; <span class="comment">% 初始化参数</span></span><br><span class="line"><span class="comment">% parm.sym.x = 1; % 利用对称性</span></span><br><span class="line">fourier_series_M = <span class="number">41</span>; <span class="comment">% Fourier series</span></span><br><span class="line">fourier_series = <span class="number">20</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">% 1  MgF2     % 11 W       % 21 VO2-hot</span></span><br><span class="line"><span class="comment">% 2  SiO2     % 12 Ti      % 22 VO2-cool</span></span><br><span class="line"><span class="comment">% 3  Al2O3    % 13 Fe      % 23 VO2-hot</span></span><br><span class="line"><span class="comment">% 4  Si3N4    % 14 Cr      % 24 DAST-Voltage</span></span><br><span class="line"><span class="comment">% 5  Si3N41直 % 15 Mo*     % 25 ALON</span></span><br><span class="line"><span class="comment">% 6  TiO2     % 16 Au      % 26 ITO</span></span><br><span class="line"><span class="comment">% 7  SiN      % 17 Cu      % 27 Ag*</span></span><br><span class="line"><span class="comment">% 8  Ge       % 18 Al</span></span><br><span class="line"><span class="comment">% 9  PMMA     % 19 Ag </span></span><br><span class="line"><span class="comment">% 10 SiO2     % 20 VO2-cool</span></span><br><span class="line">nk_Martix = <span class="built_in">conj</span>(nk_data(wavelength_range*<span class="number">1000</span>));</span><br><span class="line"><span class="comment">%% 结构尺寸和折射率</span></span><br><span class="line">struct.period = <span class="number">1</span>; </span><br><span class="line">struct.height(:,<span class="number">1</span>) =  [<span class="number">1.00</span>   <span class="number">1.00</span>   <span class="number">1</span>]; <span class="comment">% h1 h2 ...</span></span><br><span class="line">struct.width(:,<span class="number">1</span>) =  [<span class="number">0.4</span>    <span class="number">0.6</span>    <span class="number">0.8</span>];   <span class="comment">% w1 w2 ...</span></span><br><span class="line">struct.nkindex(:,<span class="number">1</span>) = [<span class="number">19</span>   <span class="number">12</span>      <span class="number">19</span>];</span><br><span class="line"><span class="comment">% FDTD</span></span><br><span class="line">struct.unit = <span class="number">1e-6</span>; <span class="comment">% 1e-6 μm; 1e-9 nm</span></span><br><span class="line">struct.mesh = <span class="number">0.02</span>; <span class="comment">% mesh </span></span><br><span class="line">struct.mesh_M = <span class="number">0.01</span>;</span><br><span class="line">struct.wave_start = <span class="built_in">min</span>(wavelength_range);</span><br><span class="line">struct.wave_stop = <span class="built_in">max</span>(wavelength_range);</span><br><span class="line">struct.wave_step = wavelength_range(<span class="number">2</span>,<span class="number">1</span>)-wavelength_range(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 结构纹理 textures</span></span><br><span class="line">x_bloack = <span class="number">51</span>;</span><br><span class="line"><span class="keyword">for</span> iz = <span class="number">1</span>:<span class="built_in">length</span>(struct.height)</span><br><span class="line">    textures&#123;iz&#125;(<span class="number">1</span>) = &#123;[-struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>,struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>]&#125;; <span class="comment">% 设置结构宽度</span></span><br><span class="line">    struct.nk(:,iz) = nk_Martix(:,struct.nkindex(iz,<span class="number">1</span>)); <span class="comment">% 设置结构折射率</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">scale_one = grating_period / x_bloack;</span><br><span class="line"><span class="keyword">for</span> io = <span class="number">1</span>:x_bloack</span><br><span class="line">    x_coordinate(io) = scale_one * (io - <span class="number">1</span>) - grating_period/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">textures&#123;<span class="number">3</span>&#125;(<span class="number">1</span>) = &#123;x_coordinate&#125;;</span><br><span class="line">textures&#123;iz+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> method = <span class="number">1</span>:<span class="number">1</span>  <span class="comment">% 1: RCWA 2:FDTD</span></span><br><span class="line"><span class="keyword">switch</span> method</span><br><span class="line">    <span class="comment">%% 1 RCWA</span></span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(fourier_series_M)</span><br><span class="line">            fourier_series = fourier_series_M(ix);</span><br><span class="line">            R = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>); T = R; A = R; </span><br><span class="line">            textures_local = textures; aa_save = &#123;&#125;; profil_save = &#123;&#125;; textures_save = &#123;<span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)&#125;;</span><br><span class="line">            <span class="keyword">parfor</span> wave_num = <span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)                 </span><br><span class="line">                textures = textures_local;</span><br><span class="line">                <span class="keyword">for</span> izz = <span class="number">1</span>:iz;textures&#123;izz&#125;(<span class="number">2</span>) = &#123;[<span class="number">1</span>, struct.nk(wave_num,izz)]&#125;;<span class="keyword">end</span>;</span><br><span class="line">                b_ix = <span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;));</span><br><span class="line">                <span class="keyword">for</span> ia = <span class="number">1</span>:<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;)</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">rem</span>(ia, <span class="number">2</span>) == <span class="number">0</span></span><br><span class="line">                        b_ix(ia) = <span class="number">2</span>;</span><br><span class="line">                    <span class="keyword">end</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">                textures&#123;<span class="number">3</span>&#125;(<span class="number">2</span>) = &#123;b_ix&#125;;</span><br><span class="line"></span><br><span class="line">                aa = res1(wavelength_range(wave_num), struct.period, textures, fourier_series, k_parallel, parm);</span><br><span class="line">                profile = &#123;[<span class="number">0</span>,  struct.height&#x27;, <span class="number">0</span>], [<span class="built_in">length</span>(textures), <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-1</span>), <span class="built_in">length</span>(textures)]&#125;;</span><br><span class="line">                <span class="comment">% 计算</span></span><br><span class="line">                ef = res2(aa, profile);</span><br><span class="line">                R(wave_num,<span class="number">1</span>) = sum(ef.inc_top_reflected.efficiency);</span><br><span class="line">                T(wave_num,<span class="number">1</span>) = sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                A(wave_num,<span class="number">1</span>) = <span class="number">1</span> - sum(ef.inc_top_reflected.efficiency) - sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                textures_save&#123;wave_num&#125; = textures; aa_save&#123;wave_num&#125; = aa; profil_save&#123;wave_num&#125; = profile;</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            RCWA.R(:,ix) = R; RCWA.T(:,ix) = T; RCWA.A(:,ix) = A;</span><br><span class="line">            t2 = clock; tc(t2,t1);</span><br><span class="line">            RCWA.T_matrix(:,ix) = T;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        RCWA.RTA = [R T A]; RCWA.R = R; RCWA.T = T; RCWA.A = A; </span><br><span class="line"></span><br><span class="line">        textures = textures_save&#123;<span class="number">1</span>&#125;; aa = aa_save&#123;<span class="number">1</span>&#125;;</span><br><span class="line">        profile = profil_save&#123;<span class="number">1</span>&#125;; profile&#123;<span class="number">1</span>&#125;(<span class="number">1</span>) = <span class="number">2</span>; profile&#123;<span class="number">1</span>&#125;(<span class="keyword">end</span>) = <span class="number">2</span>;</span><br><span class="line">        x = <span class="built_in">linspace</span>(-struct.period/<span class="number">2</span>, struct.period/<span class="number">2</span>, <span class="built_in">max</span>(x_bloack*<span class="number">2</span>, <span class="number">100</span>));</span><br><span class="line">        [tab1, z, o] = res3(x, aa, profile, <span class="number">1</span>, parm);         </span><br><span class="line">        plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span>],x,z,<span class="built_in">real</span>(o),<span class="number">25</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">900</span>,<span class="number">400</span>,<span class="string">&#x27;X label range (μm)&#x27;</span>,<span class="string">&#x27;Z label (μm)&#x27;</span>,<span class="string">&#x27;截面折射率&#x27;</span>);      </span><br><span class="line">        <span class="comment">%% 绘制透射谱</span></span><br><span class="line">        plot_func(<span class="number">2</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>],wavelength_range,RCWA.T_matrix,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;Transmission&#x27;</span>,<span class="string">&#x27;RCWA 透射&#x27;</span>);</span><br><span class="line">        t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br><span class="line">    <span class="comment">%% 2 FDTD</span></span><br><span class="line">    <span class="keyword">case</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> mesh_num = <span class="number">1</span>:<span class="built_in">length</span>(struct.mesh_M)</span><br><span class="line">            struct.mesh = struct.mesh_M(mesh_num)</span><br><span class="line">            FDTD = fun_1D(struct); <span class="comment">% main function</span></span><br><span class="line">            t2 = clock; tc(t2,t1);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        plot_func(<span class="number">2</span>, <span class="number">0</span>,FDTD.wave,FDTD.T,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;FDTD 透射&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span>;<span class="keyword">end</span></span><br><span class="line"><span class="comment">%% 绘制折射率</span></span><br><span class="line"><span class="comment">% plot_func(2,wavelength_range,RTA.T,  0,25,1.5,  500,500,500,400,&#x27;Wavelength (μm)&#x27;,&#x27;Transmission&#x27;,&#x27;透射率与阶数的关系&#x27;);</span></span><br><span class="line"><span class="comment">% plot_func(2,wavelength_range,RTA.R,  0,25,1.5,  1000,500,500,400,&#x27;Wavelength (μm)&#x27;,&#x27;Transmission&#x27;,&#x27;透射率与阶数的关系&#x27;);</span></span><br><span class="line"><span class="comment">% plot_func(2, FDTD.wave,[RCWA.T FDTD.T],0, 25,1.5,  -500,500,500,400,&#x27;Wavelength (μm)&#x27;,&#x27;R/T/A&#x27;,&#x27;RCWA/FDTD 透射&#x27;);</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="RCWA-二维程序"><a href="#RCWA-二维程序" class="headerlink" title="RCWA 二维程序"></a>RCWA 二维程序</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%   2  D    exemple_general_2Dres0</span></span><br><span class="line"><span class="comment">% 所有长度必须以与波长角以度为单位的相同单位表示</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">clc; clear; close all;</span><br><span class="line">addpath(<span class="string">&#x27;reticolo_allege_v9&#x27;</span>); addpath(<span class="string">&#x27;shuju&#x27;</span>);addpath(<span class="string">&#x27;script&#x27;</span>);addpath(<span class="string">&#x27;RCWA&#x27;</span>);</span><br><span class="line">t1 = clock;</span><br><span class="line"><span class="comment">% 常规设置 % 技术参数</span></span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.41</span>:<span class="number">0.05</span>:<span class="number">2.5</span>; <span class="comment">% 波长范围</span></span><br><span class="line">incident_wavelength = <span class="number">2</span>;</span><br><span class="line">incident_angle = <span class="number">0</span>;</span><br><span class="line">incident_refractive_index = <span class="number">1</span>; <span class="comment">% 入射介质的折射率</span></span><br><span class="line">k_parallel = incident_refractive_index * <span class="built_in">sin</span>(incident_angle * <span class="built_in">pi</span> / <span class="number">180</span>);</span><br><span class="line">angle_delta = <span class="number">0</span>; <span class="comment">%  射平面的角度</span></span><br><span class="line">fourier_series_M = <span class="number">20</span>;</span><br><span class="line">fourier_series = [<span class="number">20</span>, <span class="number">20</span>]; <span class="comment">% fourier ordres</span></span><br><span class="line"></span><br><span class="line"><span class="comment">% 纹理描述，包括基材和上层以及均质介质</span></span><br><span class="line"><span class="comment">%% 结构尺寸和折射率</span></span><br><span class="line">struct.period_x = <span class="number">2</span>;</span><br><span class="line">struct.period_y = <span class="number">2</span>; </span><br><span class="line">period = [struct.period_x struct.period_y];</span><br><span class="line">struct.height(:,<span class="number">1</span>) =  [<span class="number">0.6</span>  <span class="number">0.0</span>     <span class="number">0</span>]; <span class="comment">% h1 h2 ...</span></span><br><span class="line">struct.width(:,<span class="number">1</span>) =  [<span class="number">1</span>     <span class="number">0</span>     <span class="number">0</span>];   <span class="comment">% w1 w2 ...</span></span><br><span class="line">struct.nkindex(:,<span class="number">1</span>) = [<span class="number">19</span>   <span class="number">13</span>      <span class="number">11</span>];</span><br><span class="line"><span class="comment">% FDTD</span></span><br><span class="line">struct.unit = <span class="number">1e-6</span>; <span class="comment">% 1e-6 μm; 1e-9 nm</span></span><br><span class="line">struct.mesh_xy = <span class="number">0.05</span>; <span class="comment">% mesh </span></span><br><span class="line">struct.mesh_z = <span class="number">0.1</span>;</span><br><span class="line">struct.wave_start = <span class="built_in">min</span>(wavelength_range);</span><br><span class="line">struct.wave_stop = <span class="built_in">max</span>(wavelength_range);</span><br><span class="line">struct.wave_step = wavelength_range(<span class="number">2</span>,<span class="number">1</span>)-wavelength_range(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% 1  MgF2     % 11 W       % 21 VO2-hot</span></span><br><span class="line"><span class="comment">% 2  SiO2     % 12 Ti      % 22 VO2-cool</span></span><br><span class="line"><span class="comment">% 3  Al2O3    % 13 Fe      % 23 VO2-hot</span></span><br><span class="line"><span class="comment">% 4  Si3N4    % 14 Cr      % 24 DAST-Voltage</span></span><br><span class="line"><span class="comment">% 5  Si3N41直 % 15 Mo*     % 25 ALON</span></span><br><span class="line"><span class="comment">% 6  TiO2     % 16 Au      % 26 ITO</span></span><br><span class="line"><span class="comment">% 7  SiN      % 17 Cu      % 27 Ag*</span></span><br><span class="line"><span class="comment">% 8  Ge       % 18 Al</span></span><br><span class="line"><span class="comment">% 9  PMMA     % 19 Ag </span></span><br><span class="line"><span class="comment">% 10 SiO2     % 20 VO2-cool</span></span><br><span class="line">nk_Martix = <span class="built_in">conj</span>(nk_data(wavelength_range*<span class="number">1000</span>));</span><br><span class="line"></span><br><span class="line">parm = res0; parm.not_io = <span class="number">1</span>; <span class="comment">% 初始化默认参数</span></span><br><span class="line">parm.sym.x = <span class="number">0</span>; <span class="comment">% x=x0 :plan de symetrie seulement si beta0(1)=0    par defaut parm.sym.x=[]  pas de symetrie en x</span></span><br><span class="line">parm.sym.y = <span class="number">0</span>; <span class="comment">% y=y0 :plan de symetrie seulement si beta0(2)=0   par defaut parm.sym.y=[]  pas de symetrie en y</span></span><br><span class="line">parm.sym.pol = <span class="number">-1</span>; <span class="comment">% 1 TE  -1:TM </span></span><br><span class="line">parm.res1.trace = <span class="number">0</span>; <span class="comment">% 绘制纹理 –period/2 to period/2</span></span><br><span class="line">parm.res1.champ = <span class="number">1</span>; <span class="comment">% 精确计算电磁场</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> method = <span class="number">1</span>:<span class="number">2</span>  <span class="comment">% 1: RCWA 2:FDTD</span></span><br><span class="line">    <span class="keyword">switch</span> method</span><br><span class="line">        <span class="comment">%% 1 RCWA</span></span><br><span class="line">        <span class="keyword">case</span> <span class="number">1</span></span><br><span class="line">            <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(fourier_series_M)</span><br><span class="line">                fourier_series = [<span class="number">1</span> <span class="number">1</span>] * fourier_series_M(ix);</span><br><span class="line"></span><br><span class="line">                R = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>); T = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>); A = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>);</span><br><span class="line">                parm_local = parm; struct_local = struct;</span><br><span class="line">                <span class="keyword">for</span> wave_num = <span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)</span><br><span class="line">                    parm = parm_local;  struct = struct_local; textures=[];</span><br><span class="line">                    incident_wavelength = wavelength_range(wave_num);</span><br><span class="line">                    <span class="comment">%%</span></span><br><span class="line">                    <span class="keyword">for</span> iz = <span class="number">1</span>:<span class="built_in">length</span>(struct.height)</span><br><span class="line">                        struct.nk(:,iz) = nk_Martix(:,struct.nkindex(iz,<span class="number">1</span>)); <span class="comment">% 设置结构折射率</span></span><br><span class="line">                        textures&#123;iz&#125; = &#123;<span class="number">1</span>, [<span class="number">0</span>, <span class="number">0</span>, struct.width(iz,<span class="number">1</span>), struct.width(iz,<span class="number">1</span>), struct.nk(wave_num,iz), <span class="number">1</span>]&#125;;</span><br><span class="line">                    <span class="keyword">end</span></span><br><span class="line">                    textures&#123;iz+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                    profile = &#123;[<span class="number">1</span>, struct.height&#x27;, <span class="number">1</span>], [<span class="built_in">length</span>(textures), <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-1</span>), <span class="built_in">length</span>(textures)]&#125;; <span class="comment">% 厚度 / 折射率索引</span></span><br><span class="line">                    [aa, nef] = res1(incident_wavelength, period, textures, fourier_series, k_parallel, angle_delta, parm);</span><br><span class="line">                    ef = res2(aa, profile);</span><br><span class="line">                    R(wave_num,<span class="number">1</span>) = sum(ef.TMinc_top_reflected.efficiency);</span><br><span class="line">                    T(wave_num,<span class="number">1</span>) = sum(ef.TMinc_bottom_transmitted.efficiency);</span><br><span class="line">                    A(wave_num,<span class="number">1</span>) = <span class="number">1</span> - sum(ef.TMinc_top_reflected.efficiency) - sum(ef.TMinc_bottom_transmitted.efficiency);</span><br><span class="line">                    t2 = clock; tc(t2,t1);</span><br><span class="line">                <span class="keyword">end</span> <span class="comment">%  wavelength_range</span></span><br><span class="line"></span><br><span class="line">                RCWA.R(:,ix) = R; RCWA.T(:,ix) = T; RCWA.A(:,ix) = A; RCWA.T_matrix(:,ix) = T;</span><br><span class="line">                t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            RCWA.RTA = [R T A]; RCWA.R = R; RCWA.T = T; RCWA.A = A; </span><br><span class="line">            plot_func(<span class="number">2</span>,<span class="number">0</span>, wavelength_range,RCWA.T,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;RCWA 透射&#x27;</span>);</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">case</span> <span class="number">2</span></span><br><span class="line">            FDTD = fun_2D(struct);</span><br><span class="line">            plot_func(<span class="number">2</span>,<span class="number">0</span>, FDTD.wave,[RCWA.T FDTD.T],<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;FDTD 透射&#x27;</span>);</span><br><span class="line">            t2 = clock; tc(t2,t1);</span><br><span class="line">    <span class="keyword">end</span>;<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">t2 = clock; tc(t2,t1);</span><br><span class="line">plot_func(<span class="number">2</span>,<span class="number">0</span>, wavelength_range,RCWA.T_matrix  ,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;RCWA 透射&#x27;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 绘制 XY 面纹理</span></span><br><span class="line"><span class="keyword">for</span> iz = <span class="number">1</span>:<span class="built_in">length</span>(struct.height)</span><br><span class="line">    struct.nk(:,iz) = nk_Martix(:,struct.nkindex(iz,<span class="number">1</span>)); <span class="comment">% 设置结构折射率</span></span><br><span class="line">    textures&#123;iz&#125; = &#123;<span class="number">1</span>, [<span class="number">0</span>, <span class="number">0</span>, struct.width(iz,<span class="number">1</span>), struct.width(iz,<span class="number">1</span>), struct.nk(<span class="number">1</span>,iz), <span class="number">1</span>]&#125;;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">textures&#123;iz+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line">parm.res1.trace = <span class="number">1</span>; <span class="comment">% 绘制纹理</span></span><br><span class="line">[aa, nef] = res1(incident_wavelength, period, textures, fourier_series, k_parallel, angle_delta, parm); axis tight;</span><br><span class="line"><span class="comment">%% 绘制XZ面纹理</span></span><br><span class="line">parm.res3.trace = <span class="number">1</span>;</span><br><span class="line">x = <span class="built_in">linspace</span>(-period(<span class="number">1</span>) / <span class="number">2</span>, period(<span class="number">1</span>) / <span class="number">2</span>, <span class="number">51</span>); y = <span class="number">0</span>;</span><br><span class="line">[tab1, z, o] = res3(x, y, aa, profile, [<span class="number">1</span>, <span class="number">1</span>], parm); <span class="comment">% profil1</span></span><br><span class="line"><span class="comment">%% 绘制YZ面纹理</span></span><br><span class="line">parm.res3.trace = <span class="number">1</span>;</span><br><span class="line">y = <span class="built_in">linspace</span>(-period(<span class="number">1</span>) / <span class="number">2</span>, period(<span class="number">1</span>) / <span class="number">2</span>, <span class="number">51</span>); x = <span class="number">0</span>;</span><br><span class="line">[tab1, z, o] = res3(x, y, aa, profile, [<span class="number">1</span>, <span class="number">1</span>], parm); <span class="comment">% profil1</span></span><br><span class="line"><span class="comment">%% 绘制 Z = 固定值 XY面场</span></span><br><span class="line"><span class="comment">%&#123; 1</span></span><br><span class="line">x = <span class="built_in">linspace</span>(-period(<span class="number">1</span>) / <span class="number">2</span>, period(<span class="number">1</span>) / <span class="number">2</span>, <span class="number">51</span>);</span><br><span class="line">y = <span class="built_in">linspace</span>(-period(<span class="number">2</span>) / <span class="number">2</span>, period(<span class="number">2</span>) / <span class="number">2</span>, <span class="number">51</span>); z0 = <span class="number">1.5</span>;</span><br><span class="line">parm.res3.npts = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]; <span class="comment">% 每片的点数</span></span><br><span class="line">parm.res3.champs = [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]; <span class="comment">% 带有对象轮廓的 Ex Hx 自动追踪</span></span><br><span class="line">[e, z, o] = res3(x, y, aa, profile, [<span class="number">1</span>, <span class="number">1</span>], parm);</span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 计算 研究光栅入射的平面波的衍射</span></span><br><span class="line"><span class="comment">% ef = res2(aa, profil1);</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">%&#123; </span></span><br><span class="line"><span class="comment">enerh = sum(ef.TEinc_top_reflected.efficiency); enerb = sum(ef.TEinc_top_transmitted.efficiency);</span></span><br><span class="line"><span class="comment">disp([&#x27;TE incident du haut : energie en haut  &#x27;, num2str(enerh), &#x27; energie en bas &#x27;, num2str(enerb), &#x27; pertes &#x27;, num2str(1 - enerh - enerb)]);</span></span><br><span class="line"><span class="comment">enerh = sum(ef.TEinc_bottom_reflected.efficiency); enerb = sum(ef.TEinc_bottom_transmitted.efficiency);</span></span><br><span class="line"><span class="comment">disp([&#x27;TE incident du bas : energie en haut  &#x27;, num2str(enerh), &#x27; energie en bas &#x27;, num2str(enerb), &#x27; pertes &#x27;, num2str(1 - enerh - enerb)]);</span></span><br><span class="line"><span class="comment">enerh = sum(ef.TMinc_top_reflected.efficiency); enerb = sum(ef.TMinc_top_transmitted.efficiency);</span></span><br><span class="line"><span class="comment">disp([&#x27;TM incident du haut : energie en haut  &#x27;, num2str(enerh), &#x27; energie en bas &#x27;, num2str(enerb), &#x27; pertes &#x27;, num2str(1 - enerh - enerb)]);</span></span><br><span class="line"><span class="comment">enerh = sum(ef.TMinc_bottom_reflected.efficiency); enerb = sum(ef.TMinc_bottom_transmitted.efficiency);</span></span><br><span class="line"><span class="comment">disp([&#x27;TM incident du bas : energie en haut  &#x27;, num2str(enerh), &#x27; energie en bas &#x27;, num2str(enerb), &#x27; pertes &#x27;, num2str(1 - enerh - enerb)]);</span></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">% 绘制 Y = 固定值 XZ面场</span></span><br><span class="line"><span class="comment">%&#123; </span></span><br><span class="line"><span class="comment">x = linspace(-period(1) / 2, period(1) / 2, 51); y = 0; % 网格的x,y坐标在x和y中（z中的坐标由计算确定）</span></span><br><span class="line"><span class="comment">einc = [1, 1]; %  u v 框架中入射 e 场的分量默认情况下入射场来自顶部</span></span><br><span class="line"><span class="comment">parm = res0; parm.not_io = 1; % 默认设置</span></span><br><span class="line"><span class="comment">parm.res3.trace = 1; % 绘制图形</span></span><br><span class="line"><span class="comment">[e, z, o] = res3(x, y, aa, profil1, einc, parm);</span></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">%% 绘制 X = 固定值 XZ面场</span></span><br><span class="line"><span class="comment">%&#123; </span></span><br><span class="line"><span class="comment">x = 0; y = linspace(-period(2) / 2, period(2) / 2, 51); einc = [1, 1];</span></span><br><span class="line"><span class="comment">parm = res0; parm.not_io = 1; %parametres par defaut</span></span><br><span class="line"><span class="comment">parm.res3.npts = 5; % nombre de points par tranche</span></span><br><span class="line"><span class="comment">parm.res3.sens = 0; % champ incident de dessous</span></span><br><span class="line"><span class="comment">parm.res3.trace = 1; % 自动绘图</span></span><br><span class="line"><span class="comment">parm.res3.champs = [1, 1, i];</span></span><br><span class="line"><span class="comment">[e, z, o] = res3(x, y, aa, profil1, einc, parm);</span></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line">t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="画图程序"><a href="#画图程序" class="headerlink" title="画图程序"></a>画图程序</h2><p>使用：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_func(<span class="number">2</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>],wavelength_range,RCWA.T_matrix,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;Transmission&#x27;</span>,<span class="string">&#x27;RCWA 透射&#x27;</span>);</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Y</span> = <span class="title">plot_func</span><span class="params">(dimension,matrix,x, y, z,  fontsize, linewidth, x_dis, y_dis, width, height, x_label, y_label, title1)</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 绘制单个图形</span></span><br><span class="line"><span class="keyword">if</span> matrix(<span class="number">1</span>) == <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">2</span></span><br><span class="line">        <span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>], <span class="string">&#x27;position&#x27;</span>, [x_dis, y_dis, width, height]); <span class="comment">% [位置横纵 宽 高]</span></span><br><span class="line">        <span class="built_in">plot</span>([<span class="number">0</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">0</span>],<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.5</span>);<span class="built_in">hold</span> on;</span><br><span class="line">        set(gca,<span class="string">&#x27;FontSize&#x27;</span>,fontsize,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">        xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        axis tight;</span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(y(<span class="number">1</span>,:))</span><br><span class="line">            <span class="built_in">plot</span>(x, y(:,ix),  <span class="string">&#x27;Color&#x27;</span>, <span class="built_in">rand</span>(<span class="number">1</span>,<span class="number">3</span>), <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);<span class="built_in">hold</span> on;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        xlim([<span class="built_in">min</span>(x), <span class="built_in">max</span>(x)]);</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">3</span></span><br><span class="line">        <span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>], <span class="string">&#x27;position&#x27;</span>, [x_dis, y_dis, width, height]); <span class="comment">% [位置横纵 宽 高]</span></span><br><span class="line">        h = pcolor(x, y, z); <span class="comment">% 绘制图像，并返回句柄</span></span><br><span class="line">        set(h, <span class="string">&#x27;EdgeColor&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">        axis tight; <span class="comment">% 自动调整坐标轴的范围，使其紧贴着数据的最小值和最大值</span></span><br><span class="line">        colorbar;colormap jet;</span><br><span class="line">        set(gca, <span class="string">&#x27;TickDir&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;Box&#x27;</span>, <span class="string">&#x27;off&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">        set(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize); <span class="comment">% Times New Roman</span></span><br><span class="line">        xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 一图绘制多个图形</span></span><br><span class="line"><span class="keyword">if</span> matrix(<span class="number">1</span>) ~= <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> matrix(<span class="number">4</span>) == <span class="number">1</span></span><br><span class="line">        <span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>], <span class="string">&#x27;position&#x27;</span>, [x_dis, y_dis, width, height]);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">2</span></span><br><span class="line">    subplot(matrix(<span class="number">1</span>),matrix(<span class="number">2</span>),matrix(<span class="number">3</span>));</span><br><span class="line">        <span class="built_in">plot</span>([<span class="number">0</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">0</span>],<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.5</span>);<span class="built_in">hold</span> on;</span><br><span class="line">        set(gca,<span class="string">&#x27;FontSize&#x27;</span>,fontsize,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">        xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        axis tight;</span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(y(<span class="number">1</span>,:))</span><br><span class="line">            <span class="built_in">plot</span>(x, y(:,ix),  <span class="string">&#x27;Color&#x27;</span>, <span class="built_in">rand</span>(<span class="number">1</span>,<span class="number">3</span>), <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);<span class="built_in">hold</span> on;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        xlim([<span class="built_in">min</span>(x), <span class="built_in">max</span>(x)]);<span class="built_in">hold</span> on;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">3</span></span><br><span class="line">        subplot(matrix(<span class="number">1</span>),matrix(<span class="number">2</span>),matrix(<span class="number">3</span>));</span><br><span class="line"><span class="comment">%     figure(&#x27;color&#x27;,[1 1 1], &#x27;position&#x27;, [x_dis, y_dis, width, height]); % [位置横纵 宽 高]</span></span><br><span class="line">    h = pcolor(x, y, z); <span class="comment">% 绘制图像，并返回句柄</span></span><br><span class="line">    set(h, <span class="string">&#x27;EdgeColor&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">    axis tight; <span class="comment">% 自动调整坐标轴的范围，使其紧贴着数据的最小值和最大值</span></span><br><span class="line">    colorbar;colormap jet;</span><br><span class="line">    set(gca, <span class="string">&#x27;TickDir&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;Box&#x27;</span>, <span class="string">&#x27;off&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">    set(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize); <span class="comment">% Times New Roman</span></span><br><span class="line">    xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">    ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">    title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="带各种材料折射率"><a href="#带各种材料折射率" class="headerlink" title="带各种材料折射率"></a>带各种材料折射率</h2><p>···python</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 不同厚度仿真 exemple2_1D</span></span><br><span class="line">clc;clear;close all;</span><br><span class="line">addpath(<span class="string">&#x27;reticolo_allege_v9&#x27;</span>); addpath(<span class="string">&#x27;shuju&#x27;</span>);addpath(<span class="string">&#x27;script&#x27;</span>);addpath(<span class="string">&#x27;RCWA&#x27;</span>);</span><br><span class="line">t1 = clock;</span><br><span class="line">incident_angle = <span class="number">0</span>;</span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.4</span>:<span class="number">0.001</span>:<span class="number">4</span>; <span class="comment">% 波长范围</span></span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.4</span>; <span class="comment">% 波长范围</span></span><br><span class="line"></span><br><span class="line">grating_period = <span class="number">1</span>; <span class="comment">% 光栅周期</span></span><br><span class="line">incident_refractive_index = <span class="number">1</span>; <span class="comment">% 入射介质的折射率</span></span><br><span class="line">k_parallel = incident_refractive_index * <span class="built_in">sin</span>(incident_angle * <span class="built_in">pi</span> / <span class="number">180</span>); <span class="comment">% 入射角的相位角</span></span><br><span class="line">polarization = <span class="number">1</span>; <span class="comment">% -1:TM   1:TE   </span></span><br><span class="line">parm = res0(polarization); parm.not_io = <span class="number">1</span>; <span class="comment">% 初始化参数</span></span><br><span class="line"><span class="comment">% parm.sym.x = 1; % 利用对称性</span></span><br><span class="line">fourier_series_M = <span class="number">20</span>; <span class="comment">% Fourier series</span></span><br><span class="line">fourier_series = <span class="number">20</span>; </span><br><span class="line"><span class="comment">% nk = sqrt(3);</span></span><br><span class="line"><span class="comment">% 1  MgF2     % 11 W       % 21 VO2-hot</span></span><br><span class="line"><span class="comment">% 2  SiO2     % 12 Ti      % 22 VO2-cool</span></span><br><span class="line"><span class="comment">% 3  Al2O3    % 13 Fe      % 23 VO2-hot</span></span><br><span class="line"><span class="comment">% 4  Si3N4    % 14 Cr      % 24 DAST-Voltage</span></span><br><span class="line"><span class="comment">% 5  Si3N41直 % 15 Mo*     % 25 ALON</span></span><br><span class="line"><span class="comment">% 6  TiO2     % 16 Au      % 26 ITO</span></span><br><span class="line"><span class="comment">% 7  SiN      % 17 Cu      % 27 Ag*</span></span><br><span class="line"><span class="comment">% 8  Ge       % 18 Al</span></span><br><span class="line"><span class="comment">% 9  PMMA     % 19 Ag </span></span><br><span class="line"><span class="comment">% 10 SiO2     % 20 VO2-cool</span></span><br><span class="line">nk_Martix = <span class="built_in">conj</span>(nk_data(wavelength_range*<span class="number">1000</span>));</span><br><span class="line"><span class="comment">%% 结构尺寸和折射率</span></span><br><span class="line">struct.period = grating_period; </span><br><span class="line">struct.height(:,<span class="number">1</span>) =  [<span class="number">3</span>   <span class="number">3</span>   <span class="number">1</span>]; <span class="comment">% h1 h2 ...</span></span><br><span class="line">struct.width(:,<span class="number">1</span>) =  [<span class="number">0.4</span>    <span class="number">0.6</span>    <span class="number">0.8</span>];   <span class="comment">% w1 w2 ...</span></span><br><span class="line">struct.nkindex(:,<span class="number">1</span>) = [<span class="number">19</span>   <span class="number">19</span>      <span class="number">19</span>];</span><br><span class="line"><span class="comment">% FDTD</span></span><br><span class="line">struct.unit = <span class="number">1e-6</span>; <span class="comment">% 1e-6 μm; 1e-9 nm</span></span><br><span class="line">struct.mesh = <span class="number">0.02</span>; <span class="comment">% mesh </span></span><br><span class="line">struct.mesh_M = <span class="number">0.01</span>;</span><br><span class="line">struct.wave_start = <span class="built_in">min</span>(wavelength_range);</span><br><span class="line">struct.wave_stop = <span class="built_in">max</span>(wavelength_range);</span><br><span class="line">struct.wave_step = wavelength_range(<span class="number">2</span>,<span class="number">1</span>)-wavelength_range(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 结构纹理 textures</span></span><br><span class="line">area(:,<span class="number">1</span>) = [<span class="number">25</span> <span class="number">7</span> <span class="number">6</span> <span class="number">34</span> <span class="number">19</span> <span class="number">37</span> <span class="number">10</span> <span class="number">26</span> <span class="number">16</span> <span class="number">19</span> <span class="number">1</span>]/struct.period; <span class="comment">% 透镜纹理</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_bloack = <span class="number">11</span>;</span><br><span class="line"><span class="keyword">for</span> iz = <span class="number">1</span>:<span class="built_in">length</span>(struct.height)</span><br><span class="line">    textures&#123;iz&#125;(<span class="number">1</span>) = &#123;[-struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>,struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>]&#125;; <span class="comment">% 设置结构宽度</span></span><br><span class="line">    struct.nk(:,iz) = nk_Martix(:,struct.nkindex(iz,<span class="number">1</span>)); <span class="comment">% 设置结构折射率</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">scale_one = grating_period / x_bloack;</span><br><span class="line"><span class="keyword">for</span> io = <span class="number">1</span>:x_bloack</span><br><span class="line">    x_coordinate(io) = scale_one * (io - <span class="number">1</span>) - grating_period/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">textures&#123;<span class="number">3</span>&#125;(<span class="number">1</span>) = &#123;x_coordinate&#125;;</span><br><span class="line">textures&#123;iz+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> method = <span class="number">1</span>:<span class="number">1</span>  <span class="comment">% 1: RCWA 2:FDTD</span></span><br><span class="line"><span class="keyword">switch</span> method    </span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span> <span class="comment">%% 1 RCWA</span></span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(fourier_series_M)</span><br><span class="line">            fourier_series = fourier_series_M(ix);</span><br><span class="line">            R = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>); T = R; A = R; </span><br><span class="line">            textures_local = textures; aa_save = &#123;&#125;; profil_save = &#123;&#125;; textures_save = &#123;<span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)&#125;;</span><br><span class="line">            <span class="keyword">parfor</span> wave_num = <span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)                 </span><br><span class="line">                textures = textures_local;</span><br><span class="line">                <span class="keyword">for</span> izz = <span class="number">1</span>:iz;textures&#123;izz&#125;(<span class="number">2</span>) = &#123;[<span class="number">1</span>, struct.nk(wave_num,izz)]&#125;;<span class="keyword">end</span>;</span><br><span class="line">                b_ix = <span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;));</span><br><span class="line">                <span class="keyword">for</span> ia = <span class="number">1</span>:<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;)</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">rem</span>(ia, <span class="number">2</span>) == <span class="number">0</span></span><br><span class="line">                        b_ix(ia) = <span class="number">2</span>;</span><br><span class="line">                    <span class="keyword">end</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">                textures&#123;<span class="number">3</span>&#125;(<span class="number">2</span>) = &#123;b_ix&#125;;</span><br><span class="line"></span><br><span class="line">                aa = res1(wavelength_range(wave_num), struct.period, textures, fourier_series, k_parallel, parm);</span><br><span class="line">                profile = &#123;[<span class="number">0</span>,  struct.height&#x27;, <span class="number">0</span>], [<span class="built_in">length</span>(textures), <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-1</span>), <span class="built_in">length</span>(textures)]&#125;;</span><br><span class="line">                <span class="comment">% 计算</span></span><br><span class="line">                ef = res2(aa, profile);</span><br><span class="line">                R(wave_num,<span class="number">1</span>) = sum(ef.inc_top_reflected.efficiency);</span><br><span class="line">                T(wave_num,<span class="number">1</span>) = sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                A(wave_num,<span class="number">1</span>) = <span class="number">1</span> - sum(ef.inc_top_reflected.efficiency) - sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                textures_save&#123;wave_num&#125; = textures; aa_save&#123;wave_num&#125; = aa; profil_save&#123;wave_num&#125; = profile;</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            RCWA.R(:,ix) = R; RCWA.T(:,ix) = T; RCWA.A(:,ix) = A;</span><br><span class="line">            t2 = clock; tc(t2,t1);</span><br><span class="line">            RCWA.T_matrix(:,ix) = T;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        RCWA.RTA = [R T A]; RCWA.R = R; RCWA.T = T; RCWA.A = A; </span><br><span class="line"></span><br><span class="line">        textures = textures_save&#123;<span class="number">1</span>&#125;; aa = aa_save&#123;<span class="number">1</span>&#125;;</span><br><span class="line">        profile = profil_save&#123;<span class="number">1</span>&#125;; profile&#123;<span class="number">1</span>&#125;(<span class="number">1</span>) = <span class="number">2</span>; profile&#123;<span class="number">1</span>&#125;(<span class="keyword">end</span>) = <span class="number">2</span>;</span><br><span class="line">        x = <span class="built_in">linspace</span>(-struct.period/<span class="number">2</span>, struct.period/<span class="number">2</span>, x_bloack*<span class="number">3</span>);</span><br><span class="line">        [e, z, o] = res3(x, aa, profile, <span class="number">1</span>, parm);         </span><br><span class="line">        plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">1</span>],x,z,<span class="built_in">real</span>(o),<span class="number">15</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">900</span>,<span class="number">400</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>,<span class="string">&#x27;截面折射率&#x27;</span>);      </span><br><span class="line">        <span class="comment">%% 绘制透射谱</span></span><br><span class="line"><span class="comment">%         plot_func(2,[1 3 2 0],wavelength_range,RCWA.T_matrix,0, 15,1.5,  -500,500,500,400,&#x27;Wavelength&#x27;,&#x27;T&#x27;,&#x27;RCWA 透射&#x27;);</span></span><br><span class="line">        plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>],x,z,e(:,:,<span class="number">1</span>).*<span class="built_in">conj</span>(e(:,:,<span class="number">1</span>)),<span class="number">15</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">900</span>,<span class="number">400</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>,<span class="string">&#x27;(E)^2&#x27;</span>);      </span><br><span class="line">        </span><br><span class="line">        t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br><span class="line">    <span class="comment">%% 2 FDTD</span></span><br><span class="line">    <span class="keyword">case</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> mesh_num = <span class="number">1</span>:<span class="built_in">length</span>(struct.mesh_M)</span><br><span class="line">            struct.mesh = struct.mesh_M(mesh_num); FDTD = fun_1D(struct); t2 = clock; tc(t2,t1);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        plot_func(<span class="number">2</span>, <span class="number">0</span>,FDTD.wave,FDTD.T,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;FDTD 透射&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span>;<span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCWA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RCWA 相关1</title>
    <link href="/2023/11/08/RCWA/RCWA%E7%9B%B8%E5%85%B3/"/>
    <url>/2023/11/08/RCWA/RCWA%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<h1 id="RCWA1"><a href="#RCWA1" class="headerlink" title="RCWA1"></a>RCWA1</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>$\boldsymbol{E}<em>{top}^{inc}exp\left(i\big(k_x^{inc}x+k</em>{z~top}^{inc}(z-h)\big)\right)$</p><p>$a&#x3D;a+b$</p><p>RCWA（Rigorous Coupled Wave Analysis）全名是<code>严格耦合波分析</code>，是一种用于设计、分析及优化周期性结构的数值计算方法。它可以用来模拟各种周期性结构，比如光学元器件中的光栅、光纤光栅、光子晶体等，也可以用于模拟电磁结构中的电磁波导、电磁障碍物、互联线等。</p><p>RCWA方法利用<code>傅里叶变换</code>将<strong>周期相干场</strong>分解为<strong>傅里叶变换</strong>的模式，然后利用模式的耦合关系求解出这些模式的反射、透射、散射等物理量。由于RCWA是一种严格的全波方法，因此它可以考虑各种效应，比如多次反射、全息效应等，对于对场分布有精细要求的问题有很好的解决方案。</p><p>RCWA具有高精度、高效能、灵活性等特点，因此它已经成为现代光学和电磁学中一种常用的设计和分析周期性结构的工具。</p><hr><h1 id="RETICOLO-网状的"><a href="#RETICOLO-网状的" class="headerlink" title="RETICOLO 网状的"></a>RETICOLO 网状的</h1><p>Authors: J.P. Hugonin and P. Lalanne</p><p>• Reticolo 1D代码用于分析传统安装中的1D光栅。</p><p>arXiv: 2101:00901</p><p>• Reticolo 1D-conical代码用于分析传统和锥形安装中的1D光栅。</p><p>• Reticolo 2D代码用于分析2D交叉光栅。</p><p>分析二维交叉光栅。</p><p>它们是在Matlab下运行的免费软件。要安装它们，请复制附带的文件夹“reticolo_allege”，并将文件夹添加到Matlab路径中。软件可以在此处下载。</p><h3 id="This-technical-note-is-composed-of-three-parts"><a href="#This-technical-note-is-composed-of-three-parts" class="headerlink" title="This technical note is composed of three parts:"></a>This technical note is composed of three parts:</h3><p>本技术说明由三部分组成:</p><ol><li>Reticolo code 1D for analyzing 1D gratings in classical mountings Reticolo 代码1D用于分析经典安装中的一维光栅</li><li>Reticolo code 1D-conical for analyzing 1D gratings in classical and conical mountings 用于分析经典和锥形装置中的一维光栅的 Reticolo 程序1D锥形</li><li>Reticolo code 2D for analyzing 2D crossed grating Reticolo 代码2D用于分析二维交叉光栅</li></ol><p>They are free software that operate under Matlab. To install them, copy the companion folder “reticolo_allege” and add the folder in the Matlab path. The software can be downloaded here.</p><p>它们是在 Matlab 下运行的自由软件。要安装它们，复制相关文件夹“ reticolo _ allege”，并将该文件夹添加到 Matlab 路径中。软件可以在这里下载</p><p>The version V9 launched in 01&#x2F;2021 features a few novelties:</p><p>2021年1月发布的 v9版本有一些新特性:</p><p>ü it includes a treatment of stacks of arbitrarily anisotropic multilayered thin-films.1 Be aware that the substrate and superstrate cannot be anisotropic. This part is documented in Reticolo codes 1D-conical (or identically 2D).</p><p>它包括对任意各向异性的多层薄膜堆叠的处理，1 Be 意识到衬底和上层不能是各向异性的。这部分记录在 Reticolo 代码1d-锥形(或同样的2d)中。</p><p>ü It features an option to visualize the Bloch modes.</p><p>它提供了一个可视化 Bloch 模式的选项。</p><p>ü Diagonal anisotropy (𝜺𝒙𝒙 ≠ 𝜺𝒚𝒚 ≠ 𝜺𝒛𝒛) can be incorporated in structured grating layers and gratings with uniform layers having arbitrary anisotropy (𝜺𝒙𝒚 ≠ 𝟎 …) can also be handled)</p><p>对角各向异性(εxx ≠ εy≠ εzz)可以被引入到结构光栅层中，具有任意各向异性的均匀层光栅(εxy ≠0…)也可以被处理</p><p>ü It is fully compatible with earlier versions.</p><p>它与早期版本完全兼容。</p><p>2021年1月发布的V9版本具有一些新功能： 它包括对任意各向异性多层薄膜堆的处理。请注意，基板和上置基底不能是各向异性的。本部分在Reticolo代码1D-conical（或2D相同）中有文档记录。 它具有可视化布洛赫模的选项。 对于具有对角各向异性（≠≠）的结构性光栅层以及具有任意各向异性（≠ …）的均匀光栅层的光栅也可以处理。 它与早期版本完全兼容。</p><p>2021年1月发展的 v9版本有一些新功能: 它包括它包括它对任意角层的光栅的意义，基础板和上基底性不能够是各向性的分部分别在 reticolo 码1d-锥形(或2d 相对)中有文档记录。它以及具有可视化布洛赫的选项对于有具体项目具有可视化布洛赫的选项。</p><p>This is simply achieved by retaining a single Fourier harmonics coefficient in the expansion (nn&#x3D;0). The extension is not optimal from numerical-efficiency perspectives, but has been provided on demand of several users who additionally complained of mistakes in available freeware packages on thin films.</p><p>这只是通过在展开式中保留一个单一的傅里叶谐波系数(nn &#x3D; 0)来实现。从数值效率的角度来看，这种扩展并不是最佳的，但它是根据一些用户的要求提供的，这些用户还抱怨可用的薄膜免费软件包中存在错误。</p><p>Note also that we have launched in 2013 the RETICOLOfilm-stack program, a freeware that computes the reflection and transmission of arbitrary stacks of anisotropic thin films. RETICOLOfilm-stack is vectorialized and thus treats several wavelengths and incidences in a single instruction (see <a href="https://zenodo.org/record/7512710">https://zenodo.org/record/7512710</a>).</p><p>请注意，我们在2013年发布了 RETICOLOfilm-stack 程序，这是一个计算任意堆叠各向异性薄膜的反射和透射的免费软件。RETICOLOfilm-stack 是矢量化的，因此在一条指令中处理多个波长和入射(见 <a href="https://zenodo.org/record/7512710)%E3%80%82">https://zenodo.org/record/7512710)。</a></p><p>通过在展开式中保留单个傅里叶谐波系数（nn&#x3D;0）即可轻松实现该目标。从计算效率的角度来看，扩展不是最优的，但是由于多个用户要求并提到了现有免费软件程序中的错误，因此我们提供了这个扩展。 此外，请注意，2013年我们推出了RETICOLOfilm-stack程序，它是一个免费软件，用于计算各向异性薄膜的任意堆栈的反射和透射。RETICOLOfilm-stack是矢量化的，因此可以在单个指令中处理多个波长和入射角度（请参见<a href="https://zenodo.org/record/7512710%EF%BC%89%E3%80%82">https://zenodo.org/record/7512710）。</a></p><p>通过在此我们提出了 reticolofilm-stack，它是一个免费软件即可计算堆长和在各种轻向异射膜系统中的反射透射度角的设计</p><h1 id="RETICOLO-CODE-1D"><a href="#RETICOLO-CODE-1D" class="headerlink" title="RETICOLO CODE 1D"></a>RETICOLO CODE 1D</h1><p>for the diffraction by stacks of lamellar 1D gratings (classical diffraction) 用于分析分层1D光栅的衍射 （经典衍射）</p><p>对于层状一维光栅的衍射(经典衍射) ，用于分析层状一维光栅的衍射(经典衍射)</p><p>Reticolo code 1D is a free software for analyzing 1D gratings in classical mountings. It operates under Matlab. To install it, copy the companion folder “reticolo_allege” and add the folder in the Matlab path. Reticolo code 1D  是一款免费软件，用于分析经典安装的一维光栅。它在 Matlab 下运行。要安装它，复制伴随文件夹“ reticolo _ allege”，并将该文件夹添加到 Matlab 路径中。</p><h2 id="1-Generality-概述"><a href="#1-Generality-概述" class="headerlink" title="1. Generality 概述"></a>1. Generality 概述</h2><p>它可以计算由层状结构组成的光栅的衍射效率和衍射幅度。它包含用于计算和可视化光栅内部和外部的电磁场的例程。在此版本中，无法分析二维周期性的（交叉的）光栅。</p><p>RETICOLO is a code written in the language MATLAB 9.0. It computes the diffraction efficiencies and the diffracted amplitudes of gratings composed of stacks of lamellar structures. It incorporates routines for the calculation and visualisation of the electromagnetic fields inside and outside the grating. With this version, 2D periodic (crossed) gratings cannot be analysed.</p><p>RETICOLO是用MATLAB 9.0编写的代码。它计算由层状结构组成的光栅的衍射效率和衍射振幅。它包括计算和可视化光栅内外电磁场的例程。这个版本中，无法分析二维周期性（交叉）光栅。</p><p>As free alternative to MATLAB, RETICOLO can also be run in GNU Octave with minimal code changes. For further information, please contact <a href="mailto:&#116;&#105;&#110;&#97;&#x2e;&#x6d;&#105;&#116;&#x74;&#101;&#x72;&#x61;&#109;&#115;&#x6b;&#111;&#103;&#108;&#101;&#114;&#x40;&#112;&#x72;&#x6f;&#102;&#97;&#x63;&#116;&#111;&#x72;&#x2e;&#x61;&#x74;">&#116;&#105;&#110;&#97;&#x2e;&#x6d;&#105;&#116;&#x74;&#101;&#x72;&#x61;&#109;&#115;&#x6b;&#111;&#103;&#108;&#101;&#114;&#x40;&#112;&#x72;&#x6f;&#102;&#97;&#x63;&#116;&#111;&#x72;&#x2e;&#x61;&#x74;</a>.</p><p>作为MATLAB的免费替代品，RETICOLO也可以在GNU Octave中运行，只需进行最小程度的代码更改。欲了解更多信息，请联系<a href="mailto:&#x74;&#x69;&#110;&#x61;&#46;&#109;&#105;&#x74;&#x74;&#x65;&#114;&#x61;&#x6d;&#x73;&#107;&#x6f;&#103;&#108;&#x65;&#114;&#64;&#x70;&#114;&#111;&#102;&#97;&#x63;&#116;&#111;&#x72;&#x2e;&#x61;&#116;">&#x74;&#x69;&#110;&#x61;&#46;&#109;&#105;&#x74;&#x74;&#x65;&#114;&#x61;&#x6d;&#x73;&#107;&#x6f;&#103;&#108;&#x65;&#114;&#64;&#x70;&#114;&#111;&#102;&#97;&#x63;&#116;&#111;&#x72;&#x2e;&#x61;&#116;</a>。</p><p>In brief, RETICOLO implements a frequency-domain modal method (known as the Rigorous Coupled wave Analysis&#x2F;RCWA). To get an overview of the RCWA, the interested readers may refer to the following articles:</p><p>简而言之，RETICOLO 实现了一种频域模态方法(称为严格耦合波分析&#x2F;RCWA)。为了得到 RCWA 的概述，感兴趣的读者可以参考以下文章:</p><p><code>1D-classical and conical diffraction</code> 1d-经典和圆锥衍射</p><ol><li><p>M.G. Moharam et al., JOSAA <strong>12</strong>, 1068 (1995),</p></li><li><p>M.G. Moharam et al, JOSAA <strong>12</strong>, 1077 (1995),</p></li><li><p>P. Lalanne and G.M. Morris, JOSAA <strong>13</strong>, 779 (1996),</p></li><li><p>G. Granet and B. Guizal, JOSAA <strong>13</strong>, 1019 (1996),</p></li><li><p>L. Li, JOSAA <strong>13</strong>, 1870 (1996), see also C. Sauvan et al., Opt. Quantum Electronics <strong>36</strong>, 271-284 (2004) which simply explains the raison of the convergence-rate improvement of the Fourier-Factorization rules without requiring advanced mathematics on Fourier series and generalizes to other kinds of expansions. 具体而言，关于傅里叶分解规则的收敛速率优化原因，可以参考李灵宏在1996年发表在JOSAA期刊上的文章“Efficient computation of diffraction in the Rayleigh-Sommerfeld region by exact use of the scalar wave equation”以及C. Sauvan等人在2004年出版的文章“Theory of the Fabry-Pérot resonator: A review”（Opt. Quantum Electronics 36, 271-284），两篇文章均不需要关于傅里叶级数和其他扩展方法的高级数学知识，可以简单地解释傅里叶分解规则的收敛速率优化原因，并推广至其他类型的展开方法。</p></li></ol><p><code>2D-crossed gratings</code> 2d 交叉光栅</p><ol><li>L. Li, JOSAA <strong>14</strong>, 2758-2767 (1997),</li><li>E. Popov and M. Nevière, JOSAA <strong>17</strong>, 1773 (2000)</li></ol><p>which describe the up-to-date formulation of the approach used in RETICOLO. Note that the formulation used in the last article (which proposes an improvement for analysing metallic gratings with continuous profiles like sinusoidal gratings) is not available in the RETICOLO version of the web. The RCWA relies on the computation of the eigenmodes in all the layers of the grating structure in a Fourier basis (plane-wave basis) and on a scattering matrix approach to recursively relate the mode amplitudes in the different layers.</p><p>描述了 RETICOLO 中使用的方法的最新公式。请注意，上一篇文章中使用的公式(其中提出了一种改进方案，用于分析具有连续剖面的金属光栅，如正弦光栅)在 RETICOLO 版本的 web 中是不可用的。RCWA 依赖于在傅里叶基(平面波基)上计算光栅结构各层的本征模，并利用散射矩阵方法将不同层的模振幅递推关联起来。</p><p><code>Eigenmode solver</code> For conical diffraction analysis of 1D gratings, the Bloch eigenmode solver used in Reticolo is based on the article “P. Lalanne and G.M. Morris, JOSAA <strong>13</strong>, 779 (1996)”.</p><p>本征模式求解器: 对于一维光栅的圆锥衍射分析，Reticolo 中使用的 Bloch 本征模式求解器是基于“ p. Lalanne 和 g.m. Morris，JOSAA 13,779(1996)”一文</p><p><code>Scattering matrix approach</code> The code incorporates many refinements that we have not published and that we do not plan to publish. For instance, although it is generally admitted that the S-matrix is inconditionnally stable, it is not always the case. We have developed an in-house transfer matrix method which is more stable and accurate. The new transfer matrix approach is also more general and can handle perfect metals. The essence of the method has been rapidly published in “J.-P. Hugonin, M. Besbes and P. Lalanne, Op. Lett. <strong>33</strong>, 1590 (2008)”.</p><p>散射矩阵方法: 该代码包含了许多我们没有发表过也不打算发表的改进。例如，尽管人们普遍承认 s 矩阵是无条件稳定的，但事实并非总是如此。我们开发了一种更稳定和准确的内部转移矩阵方法。新的转移矩阵方法也更加通用，可以处理完美的金属。这种方法的精髓已经在《日报》上迅速发表。作者: Hugonin，m. Besbes and p。莱特。33,1590(2008)”。</p><p><code>Field calculation</code> The calculation of the near-field electromagnetic fields everywhere in the grating is performed according to the method described in “P. Lalanne, M.P. Jurek, JMO <strong>45</strong>, 1357 (1998)” and to its generalization to crossed gratings (unpublished). Basically, no Gibbs phenomenon will be visible in the plots of the discontinuous electromagnetic quantities, but field singularities at corners will be correctly handled.</p><p><strong>场计算: 根据“ P.Lalanne，m.p. Jurek，JMO 45,1357(1998)”中描述的方法及其对交叉光栅的推广(未发表) ，计算了光栅内各处的近场电磁场。基本上，在不连续电磁量的图中不会看到吉布斯现象，但是在角落处的场奇异性将被正确处理。</strong></p><p><code>Acknowledging the use of RETICOLO</code> In publications and reports, acknowledgments have to be provided by referencing to J.P. Hugonin and P. Lalanne, RETICOLO software for grating analysis, Institut d’Optique, Orsay, France (2005), arXiv:2101:00901.</p><p>使用RETICOLO声明: 在出版物和报告中，承认必须参考 j.p. Hugonin 和 p. Lalanne，RETICOLO 光栅分析软件，法国 Orsay 光学研究所，arXiv: 2101:00901</p><p><strong>In addition, one may fairly quote the following references in journal publications</strong>:</p><p>此外，人们可以在期刊出版物中公正地引用以下参考文献:</p><p>-M.G. Moharam, E.B. Grann, D.A. Pommet and T.K. Gaylord, “Formulation for stable and efficient implementation of the rigorous coupled-wave analysis of binary gratings”, J. Opt. Soc. Am. A <strong>12</strong>, 1068-1076 (1995), if TE-polarization efficiency calculations are provided -P. Lalanne and G.M. Morris, “Highly improved convergence of the coupled-wave method for TM polarization”,</p><p>- m.g. Moharam，e.b. Grann，d.a. Pommet 和 t.k. Gaylord，“稳定和有效地实施严格的二元光栅耦合波分析的公式”，J.Opt。译注:。译注:。A 12,1068-1076(1995) ，如果提供 te 偏振效率的计算-p. Lalanne 和 gm. Morris，“极大地改进了 TM 偏振耦合波方法的收敛性”,</p><p>J. Opt. Soc. Am. A <strong>13</strong>, 779-789 (1996) and G. Granet and B. Guizal, “Efficient implementation of the coupled- wave method for metallic lamellar gratings in TM polarization”, J. Opt. Soc. Am. A <strong>13</strong>, 1019-1023 (1996), if TM- polarization efficiency calculations are provided, -P. Lalanne and M.P. Jurek, “Computation of the near-field pattern with the coupled-wave method for TM polarization”, J. Mod. Opt.45, 1357-1374 (1998), if near-field electromagnetic-field distributions are shown.</p><h2 id="2-The-diffraction-problem-considered"><a href="#2-The-diffraction-problem-considered" class="headerlink" title="2 The diffraction problem considered"></a>2 The diffraction problem considered</h2><p>颜色问题的考虑</p><p>In general terms, the code solves the diffraction problem by a grating defined by a stack of layers (in the z- direction) which have all identical periods in the x-direction and are invariant in the y direction, see Fig. 1. In the following, the (x,y) plane and the z-direction will be referred to as the transverse plane and the longitudinal direction, respectively. To define the grating structure, first we have to define a top and a bottom. This is rather arbitrary since the top or the bottom can be the substrate or the cover of a real structure. It is up to the user. Once the top and the bottom of the grating have been defined, the user can choose to illuminate the structure from the top or from the bottom. The z-axis is oriented from bottom to top.</p><p>通常情况下，该代码通过在z方向上具有相同周期的层数组成的光栅来求解衍射问题，该光栅在x方向上具有相同的周期并在y方向上不变，见图1。接下来，（x，y）平面和z方向将分别称为横向平面和纵向方向。为了定义光栅结构，首先我们需要定义其顶部和底部。这相当任意，因为顶部或底部可以是真实结构的衬底或覆盖层，根据用户的设定来选择。在定义了光栅的顶部和底部后，用户可以从顶部或底部照射光结构。z轴从下向上定向。</p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403113229636.png" alt="image-20230403113229636" style="zoom: 67%;" /><p> 图1. 衍射场的瑞利展开。 第m阶具有平行动量等于𝑘𝑥𝑖𝑛𝑐+ 𝑚𝐾𝑥。我们定义两个点Otop &#x3D; (0,0, h)在光栅顶部以及Obottom &#x3D; (0,0,0)在光栅底部。</p><p>RETICOLO is written with the convention for the complex notation of the fields. So, if the materials are absorbant, one expects that all indices have a positive imaginary part. The Maxwell’s equations are of the form<br>RETICOLO 是用约定书写的，用于字段的复杂符号。因此，如果材料是吸收性的，人们期望所有的指数都有一个正虚部分。麦克斯韦方程组是这种形式</p><p>其中，𝜀&#x3D; 𝑛2 是相对介电常数，为一个复数，𝜆是真空中的波长。</p><p>接下来，考虑了两种情况： </p><ol><li>TE极化：电场E与Oy平行； </li><li>TM极化：磁场H与Oy平行。</li></ol><p>RETICOLO returns the diffraction efficiencies of the transmitted and reflected orders for a plane wave incident from the top and from the bottom with the same calculation. Of course, these two incident plane waves must have identical x-component of the parallel wave vector: $k_{x}^{inc}$. This possibility which is not mentioned in the literature to our knowledge is important in practice since the user may get, with the same computational loads, the diffraction efficiencies of the grating component illuminated from the substrate or from the cover.</p><p>RETICOLO可以返回从顶部和底部入射的平面波的衍射效率的透射和反射阶数，并采用相同的计算。当然，这两个入射平面波的平行波矢量的x分量必须相同：$k_{x}^{inc}$。在我们所知的文献中未提到这一可能性，但在实践中非常重要，因为用户可以在同样的计算负载下获取从衬底或覆盖层照明的光栅组件的衍射效率。</p><p> RETICOLO-1D calculates the electric and magnetic fields diffracted by the grating for the following incident plane wave:</p><p>RETICOLO-1D 计算了以下入射平面波的光栅衍射的电场和磁场:</p><p>$\boldsymbol{E}<em>{top}^{inc}exp\left(i\big(k_x^{inc}x+k</em>{z~top}^{inc}(z-h)\big)\right)$</p><p>$\textbf{H}^{inc}<em>{top}\textit{exp}\left(i\left(k^{inc}</em>{x}x+k^{inc}_{ztop}(z-h)\right)\right)$ 如果从顶部层入射，</p><p>where $<del>k^{inc}_{z</del>top}&#x3D;-\sqrt{\left(2\pi n_{top}&#x2F;\lambda\right)^2-(k^{inc}_x)^2}$</p><p>$\boldsymbol{E}<em>{bottom}^{inc}exp\left(i\big(k_x^{inc}x+k</em>{z\text{bottom}}^{inc}(z-h)\big)\right)$</p><p>$\textbf{H}<em>{bottom}^{inc}exp\left(i\big(k_x^{inc}x+k</em>{z\textit{bottom}}^{inc}(z-h)\big)\right)$, 如果从底部层入射，</p><p>where $k_{Z\textit{bottom}}^{inc}&#x3D;\sqrt{(2\pi n_{bottom}&#x2F;\lambda)^2-(k_x^{inc})^2}$.</p><p>The z-component of the Poynting vector of the incident plane wave is ±0.5.</p><p>入射平面波的波矢量的z分量为±0.5。</p><p>The Rayleigh-expansion of the diffracted electric fields are shown in the following figure. </p><p>下图显示了衍射电场的瑞利展开结果：</p><p> $\boldsymbol{E}^{diff}<em>{top}&#x3D;\sum_m\boldsymbol{E}^{m}</em>{top}\exp\left[i((k^{inc}<em>x+mK_x)x+k^{m}</em>{z\text{top}}(z-h)\right]$</p><p>$\boldsymbol{H}<em>{top}^{d i f}&#x3D;\sum_m\boldsymbol{H}^{m}</em>{top}\exp\left[i((k^{inc}<em>x+mK_x)x+k^{m}</em>{ztop}(z-h)\right]$</p><p>where $k^m_{z~top}&#x3D;\sqrt{\left(2\pi n_{top}&#x2F;\lambda\right)^2-(k^inc_x+m K_x)^2}$</p><p>$\begin{array}{rcl}\boldsymbol{E}^{diff}<em>{bottom}&amp;&#x3D;\sum_m\boldsymbol{E}^{m}</em>{bottom}exp\left[i((k_x^{inc}+mK_x)x+k^{m}_{\text{z bottom}}z\right]\end{array}$</p><p>$\begin{array}{r l}\boldsymbol H_{bottom}^{diff}&amp;&#x3D;\sum_m\boldsymbol H_{bottom}^m exp[i((k_x^{inc}+mK_x)x+k_{z\text{bottom}}^m z]\end{array}$</p><p>where $k^m_z\text{bottom}&#x3D;\sqrt{(2\pi n_{bottom}&#x2F;\lambda)^2-(k^inc_x+mK_x)^2}$</p><p>They are shown in the following figure. 它们如图1所示。</p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403113229636.png" alt="image-20230403113229636" style="zoom: 67%;" /><p>Fig. 1. Rayleigh expansion for the diffracted fields. $K_x&#x3D;(2\pi)&#x2F;period$. The $m^{\text{th}}$ order has a parallel momentum equal to $\quad k_{x}^{inc}+m K_{x}$. We define two points $\text{O}<em>{\text{top}}&#x3D;(0,0,\text{h})$ at the top of the grating, and $\text{O}</em>{\text{bottom}}&#x3D;(0,0,0)$ at the bottom of the grating .</p><p> 图1. 衍射场的瑞利展开。 𝐾𝑥&#x3D;(2𝜋)&#x2F;𝑝𝑒𝑟𝑖𝑜𝑑。第m阶具有平行动量等于𝑘𝑥𝑖𝑛𝑐+ 𝑚𝐾𝑥。我们定义两个点Otop &#x3D; (0,0, h)在光栅顶部以及Obottom &#x3D; (0,0,0)在光栅底部。</p><p>The following is organized so that one can straightforwardly write a code using the software 以下内容旨在帮助用户直接使用该软件编写代码.</p><h2 id="Preliminary-input-parameters-初步输入参数"><a href="#Preliminary-input-parameters-初步输入参数" class="headerlink" title="Preliminary input parameters 初步输入参数"></a>Preliminary input parameters 初步输入参数</h2><p>The name of the following parameters are given as examples. The user may define his own parameter vocabulary. 下列参数的名称作为示例给出。用户可以定义自己的参数词汇表。</p><p><strong>wavelength &#x3D; 3</strong>; % wavelength (l) in a vacuum. It might be 3 nm or 3 µm. You do not need to specify the unit but all other dimensions are of course in the same unit as the wavelength.</p><p>在真空中，wavelength &#x3D; 3;% wavelength ()。它可能是3 nm 或3 μm。你不需要指定单位，但所有其他维度当然是在同一个单位作为波长。</p><p>period &#x3D; in the x-direction.  周期 &#x3D; 在 x 方向</p><p><code>nn = 20</code>; % this define the set of Fourier harmonics retained for the computation. More specifically, 2´nn+1 represent the number of Fourier harmonics retained from –nn to nn. This is a very important parameter ; for large n values, a high accuracy for the calculated data is achieved, but the computational time and memory is also large. If all the textures are homogeneous (case of a thin-film stack), we may set nn&#x3D;1 and the period may be arbitrarily set to any value, 1 for example. NB: Because of our normalization (Poynting vector equal to 1), the computed reflected and transmitted amplitude coefficients are not identical to those provided by the classical Fresnel formulas found in textbooks.</p><p><code>nn = 20</code>  ％这定义了计算中保留的傅里叶谐波集合。更具体地说，2×nn+1代表从-nn到nn保留的傅里叶谐波数量。这是一个非常重要的参数；对于大的n值，可以实现计算数据的高精度，但计算时间和内存也很大。如果所有的纹理都是均匀的（如薄膜堆），我们可以将nn设置为1，周期可以任意设置为任何值，例如1。注意：由于我们的归一化（泊松矢量等于1），计算得到的反射和透射幅度系数与教科书中的经典Fresnel公式提供的系数不同。</p><p><code>parm = res0(1)</code> for TE polarization;  对于 TE 极化，parm &#x3D; res0(1) ;</p><p><code>parm = res0(-1)</code> for TM polarization; 对于 TM 极化，parm &#x3D; res0(- 1) ;</p><p>% res0.m is a function that set default values to all parameters used by the code and determine the polarisation. res0.m是一个函数，它为代码使用的所有参数设置默认值，并确定极化。</p><p><code>k_parallel</code> &#x3D;$\boldsymbol{k_x^{inc}}$(𝟐𝝅&#x2F;𝝀) is the normalised parallel momentum of the incident plane wave. 入射平面波的归一化平行动量. </p><p>If the grating is illuminated from the top region (or from the bottom region) under an incident angle θ, one has: 如果光栅在入射角为θ的情况下从顶部区域（或底部区域）照射，则有：</p><p><code>k_parallel=n_inc\*sin(θ)</code></p><p><code>K _ parallel = n _ inc \* sin (θ) </code></p><p>where n_inc is the refractive index of the top (or bottom) layer. One expects that it is a positive real number and that the texture (see Section 4.1) associated to the top (or the bottom) layer has a background with a uniform refractive index “n_inc”.</p><p>其中，n_inc是顶部（或底部）层的折射率。人们期望它是一个正实数，并且与顶部（或底部）层相关联的纹理（见第4.1节）具有具有均匀折射率“n_inc”的背景。 </p><p>(Note that the “k_parallel” variable is defined <strong>without</strong> the factor 𝟐𝝅&#x2F;𝝀.)  </p><p>（请注意，“k_parallel”变量的定义没有因子2π&#x2F;λ。）</p><p> It is very important to keep in mind that wether one defines the incident plane wave in the top layer or in the bottom layer, the calculation will be done for both an incident wave from the top and an incident wave from the bottom, with an identical parallel momentum k_parallel. </p><p>需要牢记的是，不管是在顶部层还是底部层中定义入射平面波，计算都将针对从顶部入射的波和从底部入射的波进行，并具有相同的平行动量k_parallel。</p><p>These 5 parameters (“wavelength, nn, parm and k_parallel) are required by the code. Some other parameters can additionally be defined. For example, the default parameters do not take the symmetry of the problem into account. So if one wants to use symmetries, a new parameter has to be defined: “parm.sym.x”, (see section 7). If one wants to calculate accurately the electromagnetics fields, one has to define: ” parm.res1.champ&#x3D;1”, but this increases the calculation time and memory loads (see section 8)</p><p>这5个参数（“波长、nn、parm和k_parallel)”是代码所需的。还可以定义其他一些参数。例如，缺省参数没有考虑问题的对称性。因此，如果想要使用对称性，需要定义一个新的参数：“parm.sym.x”（参见第7节）。如果想要精确计算电磁场，则必须定义：“parm.res1.champ&#x3D;1”，但这将增加计算时间和内存负载（请参见第8节）。</p><h2 id="Structure-definition-grating-parameters"><a href="#Structure-definition-grating-parameters" class="headerlink" title="Structure definition (grating parameters)"></a>Structure definition (grating parameters)</h2><p>结构定义（光栅参数）</p><p>The grating encompasses a uniform upperstrate, called the top in the following, a uniform substrate, called the bottom in the following, and many layers which define the grating, which is defined by a stack of layers. Every layer is defined by a “texture” and by its thickness. Two different layers may be identical (identical texture and thickness), may have different thicknesses with identical texture, may have different thicknesses and textures. To define the diffraction geometry, we need to define the different textures and then the different layers.</p><p>光栅包括一个统一的上层基板，以下称为顶部，在以下称为底部的统一基板上，以及定义光栅的许多层，它由一组层定义。每层由一个“纹理”和它的厚度来定义。两个不同的层可以相同（相同的纹理和厚度），可以具有不同厚度相同的纹理，也可以具有不同厚度和纹理。为了定义衍射几何，我们需要定义不同的纹理，然后是不同的层。</p><h3 id="How-to-define-a-texture"><a href="#How-to-define-a-texture" class="headerlink" title="How to define a texture?"></a>How to define a texture?</h3><p>如何定义纹理？</p><p> Every texture is defined by a cell-array composed of two line-vectors of identical length. The first vector, let us say [x1 x2 … xp …xN], contains all the x-values of the discontinuities. One <em>must</em> have :</p><p>每个纹理都由一个包含两个相同长度的行向量的单元数组定义。第一个向量，我们称之为 [x1 x2 … xp …xN]，包含所有不连续点的x值。必须满足以下条件：</p><ol><li>N&gt;1</li><li>$x_p&lt;x_{p+1}$ for any p</li><li>$x_N-x_1\leq\text{period}$.</li></ol><p>The second line-vector [n1 n2 … np … nN] contains the refractive indices of the material between the discontinuities. More explicitly, we have a refractive index np for xp-1&lt;x&lt;xp. Because of periodicity, note that the refractive index for xN&lt;x&lt;x1+period is equal to n1.</p><p>第二条线向量[ n1 n2… np… nN ]包含介于不连续面之间的材料的折射率。更明确地说，我们对 xp-1 &lt; x &lt; xp 有折射率 np。由于周期性，请注意 xN &lt; x &lt; x1 + 周期的折射率等于 n1。</p><p>The specific case of a uniform texture with a refractive index n is easily defined by texture{1}&#x3D;{n}. In that specific case, no need of a second vector since there is no discontinuity.</p><p>具有折射率 n 的均匀织构的特殊情况很容易由织构{1} &#x3D; { n }来定义。在这种情况下，不需要第二个矢量，因为没有不连续性。</p><p> The textures have all to be to be packed together in a cell array textures&#x3D;{textures{1}, textures{2}, textures{3}} prior calling subroutine <strong>res1.m.</strong></p><p>这些纹理必须在调用子例程 res1.m 之前被打包在一个单元格阵列纹理 &#x3D; {纹理{1} ，纹理{2} ，纹理{3}中。</p><p> Example : 例子:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">period=<span class="number">17</span>; # 周期 = <span class="number">17</span>; </span><br><span class="line">textures =cell(<span class="number">1</span>,<span class="number">2</span>); # 纹理 = 单元格(<span class="number">1</span>,<span class="number">2</span>) ;</span><br><span class="line">textures&#123;<span class="number">1</span>&#125;=&#123;<span class="number">1.5</span>&#125;; <span class="comment">%uniform texture # 纹理&#123;1&#125; = &#123;1.5&#125; ;% 均匀纹理</span></span><br><span class="line">textures&#123;<span class="number">2</span>&#125;=&#123;[<span class="number">-5</span>,<span class="number">-3</span>,<span class="number">1</span>,<span class="number">6</span>],[<span class="number">2</span>,<span class="number">1.3</span>,<span class="number">1.5</span>,<span class="number">3</span>]&#125;; <span class="comment">%texture composed of 4 different refractive indices ％由四个不同折射率组成的纹理</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>The following figure shows the refractive indices of the two textures.以下图显示了这两个纹理的折射率。</p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403163538201.png" alt="image-20230403163538201" style="zoom: 50%;" /><p>Fig. 2. Textures{1} and {2}.  图2. 纹理{1}和{2}。</p><p><code>Slits in perfectly-conducting metallic textures</code>: 完美导体金属纹理中的缝隙: </p><p>Mixing perfectly-conducting metallic textures and dielectric textures in the same grating structure is possible. We have first to define a background by its refractive index “inf” (for infinity). In this uniform background, we can incorporate strip inclusions with a complex or real refractive index “ninclusion” defined by the position c of its center and its x-width L. The inclusions cannot overlap.</p><p>在同一光栅结构中混合完美导体金属纹理和介质纹理是可能的。首先，我们需要通过其折射率“inf”（表示无穷大）来定义一个背景。在这个统一的背景中，我们可以插入带有复杂或实折射率“ninclusion”的条形包含物，该包含物由其中心位置c和x宽度L来定义。这些包含物不能重叠。</p><p>For example: 例如:</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">textures &#123;3&#125;= &#123;inf, [c1,L1,ninclusion1],[c2,L2, ninclusion2]&#125;</span><br><span class="line"># 纹理&#123;3&#125; = &#123; inf，[ c1，L1，ninclusion 1] ，[ c2，L2，ninclusion 2]</span><br></pre></td></tr></table></figure><p><code>Anisotropic layers:</code> 各向异性层:</p><p>Grating layers (not the substrate nor the superstrate) can be anisotropic with diagonal tensors (𝜀𝑥𝑦 &#x3D; 𝜀𝑥𝑧 … &#x3D; 0). 光栅层(不是衬底也不是上层)可以是各向异性的对角张量(εxy &#x3D; εxz… &#x3D; 0)。</p><p>To implement diagonal anisotropy 实现对角各向异性</p><p>parm.res1.change_index&#x3D;${\left[n_{\text{prov}}^1,n_{x}^1,n_{y}^1,n_{z}^1\right],\left[n_{\text{prov}}^2,n_{x}^2,n_{y}^2,n_{z}^2\right]}$; % $\mathbf{n}<em>{\text{prov}}^1\neq\mathbf{n}</em>{\text{prov}}^2$</p><p>The refractive index nprov1 is then replaced <strong>in all textures</strong> by epsilon&#x3D;diag([(n 1)2, (n 1 )2, (nz1 )2]). Beware if the superstate (or substrate) has a refractive index nprov1, it will also be replaced and this is not allowed. Thus we recommend using an unusual value for nprov1 (e.g. 89.99999 or rand(1)).</p><p>然后，折射率 nprov1在所有纹理中被 epsilon &#x3D; diag ([(n1)2，(n1)2，(nz1)2])取代。当心，如果超态(或衬底)具有折射率 nprov1，它也将被替换，这是不允许的。因此，我们建议使用 nprov1的不寻常值(例如89.99999或兰特(1))。</p><p>The user may also diagonal permeability tensors 用户也可以使用对角渗透张量</p><p>parm.res1.change_index&#x3D;</p><p> ${<del>\left{\left[n_{\text{prov}}^1,</del>n_x^1,n_y^1,n_z^1,m_x^1,m_y^1,m_z^1\right],\left[n_{\text{prov}}^2,~n_x^2,n_y^2,n_z^2\right]\right}$;</p><p>​    </p><p>Parm.res1.change _ index &#x3D; {[ nprov1，n1，n1，nz1，m1，m1] ，[ nprov2，n2，n2，nz2] ;</p><p>The     refractive     index     nprov1  is   then   replaced   <strong>in   all   textures</strong>   by $\text{epsilon&#x3D;diag}([(n_x^1)^2,(n_y^1)^2,(n_z^1)^2]),\text{mu&#x3D;diag}([(m_x^1)^2,(m_y^1)^2,(m_z^1)^2]).$</p><p>在所有结构中，折射率 nprov1由 ε &#x3D; diag ([(n1)2，(n1)2，(n1)2]) ，mu &#x3D; diag ([(m1)2，(m1)2，(m1)2])取代。</p><p>For slits in perfectly-conducting metallic textures, anisotropy cannot be implemented. 对于完全导电金属织构中的缝隙，各向异性是不能实现的。</p><p> In order to check if the set of textures is correctly set up, the user can set the variable parm.res1.trace equal to 1: “parm.res1.trace &#x3D; 1;”. </p><p>Then a Matlab figure will show up the refractive-index distribution of all textures. Each</p><p>texture is represented with the coordinate x varying from –period&#x2F;2 to period&#x2F;2</p><p> 为了检查纹理集是否正确设置，用户可以将变量parm.res1.trace设置为1：“parm.res1.trace &#x3D; 1;”。然后，一个Matlab图将显示出所有纹理的折射率分布。每个纹理都用坐标x表示，其变化范围为-period&#x2F;2到period&#x2F;2。</p><h3 id="How-to-define-the-layers-如何定义图层？"><a href="#How-to-define-the-layers-如何定义图层？" class="headerlink" title="How to define the layers? 如何定义图层？"></a>How to define the layers? 如何定义图层？</h3><p>This is performed by defining the “Profile” variable which contains, starting from the top layer and finishing by the bottom layer, the successive information (thickness and texture-label) relative to every layer. Here is an example that illustrates how to set up the “Profile” variable:</p><p>这是通过定义“Profile”变量来实习的，该变量从顶部层开始，以底部层结束，相对于每个层，顺序包含连续的信息（厚度和纹理标签）。以下是一个示例，演示如何设置“Profile”变量：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Profile = &#123;[<span class="number">0</span>,<span class="number">1</span>,<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">1</span>,<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">2</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">2</span>]&#125;; </span><br></pre></td></tr></table></figure><p>It means that from the top to the bottom we have: the top layer is formed by a thickness 0 of texture 1, then we have twice textures 3, 2 and 4 with depth 1, 0.5 and 0.5 respectively, texture 6 with depth 2, and finally the bottom layer (formed by texture 2) with null thickness. Since textures 1 and 2 correspond to the top and bottom layers, they must be uniform. In this example, the top and bottom layers have a null thickness. However, one may set an arbitrary thickness. Especially, if one needs to plot the electromagnetic fields in the bottom and top layers, the thicknesses hb and hh (see Fig. 4) over which the fields have to be visualized has to be specified. For hb&#x3D;hh&#x3D;0, the Rayleigh expansions of the fields in the top and bottom layers are not plotted.  </p><p>这意味着从顶部到底部，我们有：顶部层由纹理1的厚度为0组成，然后我们有两次深度分别为1、0.5和0.5的纹理3、2和4，深度为2的纹理6，最后是由纹理2形成的底部层，厚度为零。由于纹理1和2对应于顶部和底部层，它们必须是均匀的。在这个例子中，顶部和底部层的厚度都为零。然而，可以设置任意厚度。特别地，如果需要绘制底部和顶部层中的电磁场，则必须指定要可视化场的厚度hb和hh（见图4）。对于hb&#x3D;hh&#x3D;0，不绘制顶部和底部层中场的Rayleigh展开。</p><p>In this particular Profile, the structure formed by texture 3 with thickness 1, texture 2 with thickness 0.5 and texture 4 with thickness 0.5 is repeated twice. It is possible to simplify the instruction defining the “Profile” variable in order to take into account the repetitions:  </p><p>在这个特定的“Profile”中，由纹理3（厚度为1）、纹理2（厚度为0.5）和纹理4（厚度为0.5）形成的结构重复了两次。可以简化定义“Profile”变量的指令，因为计算会考虑到重复性：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Profile = &#123;&#123;<span class="number">0</span>,<span class="number">1</span>&#125;,&#123;[<span class="number">1</span>,<span class="number">0.5</span>,<span class="number">0.5</span>], [<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>], <span class="number">2</span>&#125;,&#123;[<span class="number">2</span>,<span class="number">0</span>],[<span class="number">6</span>,<span class="number">2</span>]&#125;&#125;;  </span><br></pre></td></tr></table></figure><p> If a structure is repeated many times, the above “factorized” instruction of Eq. 2 is better than the “expanded” one of Eq. 1, in terms off computational speed, because the calculation will take into account the repetitions.</p><p>The profile is shown below.  如果一个结构需要多次重复，那么上述式子2的“因式分解”指令比式子1的“展开”指令在计算速度上更好，因为计算将考虑到这些重复。</p><p> The profile is shown below. 以下是一个示例变量“Profile”的具体情况。</p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403164752176.png" alt="image-20230403164752176" style="zoom:50%;" /><p> Fig. 3. Texture stacks. The example corresponds to a profile defined by Profile &#x3D;  {[hh,1,0.5,0.5,1,0.5,0.5,2, hb],[1,3,2,4,3,2,4,6,2]}; . The top and bottom layers have uniform textures.  </p><p>图3. 纹理堆栈。该示例对应于一个由Profile &#x3D; {[hh,1,0.5,0.5,1,0.5,0.5,2, hb],[1,3,2,4,3,2,4,6,2]}定义的配置文件。顶部和底部层具有均匀的纹理。</p><h3 id="Solving-the-eigenmode-problem-for-every-texture"><a href="#Solving-the-eigenmode-problem-for-every-texture" class="headerlink" title="Solving the eigenmode problem for every texture"></a>Solving the eigenmode problem for every texture</h3><p>求解每个纹理的特征模态问题</p><p>The first computation with the RCWA consists in calculating the eigenmodes associated to all textures. This is done by the subroutine “res1.m”, following the instruction:</p><p>RCWA 的第一个计算包括计算与所有纹理相关的特征模式。这是由子程序“ res1.m”按照指令完成的:</p><h3 id="res1程序"><a href="#res1程序" class="headerlink" title="res1程序"></a>res1程序</h3><p><code>计算纹理</code></p><p> aa &#x3D; res1(wavelength,period,textures,nn,k_parallel,parm);  </p><p>This subroutine has 6 input arguments: the wavelength “<strong>wavelength</strong>”, the period of the grating “<strong>period</strong>”, the “<strong>textures</strong>” variable, the number of Fourier harmonics “<strong>nn</strong>”, the normalized parallel incident wave vector “<strong>k_parallel</strong>, and the “<strong>parm</strong>” variable containing the values of all parameters used by the code and the selected the polarisation. If one has to study the diffraction by different gratings composed of the same textures, one needs to compute only once the eigenmodes. It is possible to save the “aa” variable in a “.mat” file and to reload it for the computation of the diffracted waves, see an example in Annex 10.3.</p><p>这个子程序有6个输入参数：</p><ol><li>波长“wavelength”，</li><li>光栅周期“period”，</li><li>“textures”变量，</li><li>傅里叶谐波的数量“nn”，</li><li>归一化的平行入射波矢“k_parallel”，</li><li>以及包含代码使用的所有参数值和所选偏振的“parm”变量。</li></ol><p>如果需要研究由同一纹理组成的不同光栅的衍射，则只需计算一次特征模式。可以将“aa”变量保存在一个“.mat”文件中，并重新加载以计算衍射波，见附录10.3中的示例。</p><h2 id="Computing-the-diffracted-waves"><a href="#Computing-the-diffracted-waves" class="headerlink" title="Computing the diffracted waves"></a>Computing the diffracted waves</h2><h3 id="res2程序"><a href="#res2程序" class="headerlink" title="res2程序"></a>res2程序</h3><p><code>计算衍射波</code> </p><p>This is the second step of the computation. This is done by the subroutine “res2.m”, following the instruction:</p><p>这是计算的第二步。这是通过子程序“res2.m”完成的，按照以下指示进行：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result = res2(aa, Profile);</span><br></pre></td></tr></table></figure><p>This subroutine has 2 input arguments: the output “<strong>aa</strong>” of the subroutine “res1.m” and the “<strong>Profile</strong>” variable. The output argument “<strong>result</strong>” contains all the information on the diffracted fields. “<strong>result</strong>” is an object of class ‘reticolo’ that can be indexed as an usual structure with parentheses, or with the labels of the considered orders between curly braces. Examples will be given in the following.</p><p>这个子程序有两个<code>输入</code>参数：</p><ol><li>子程序“res1.m”的输出“aa”</li><li>“Profile”变量。</li></ol><p>输出参数“result”包含所有关于衍射场的信息。“result”是一个‘reticolo’类的对象，可以像普通结构体一样用括号进行索引，或使用大括号中的考虑阶级别的标签进行索引。示例将在接下来给出。</p><p>This information is divided into the following sub-structures fields :</p><p>这些信息分为以下子程序结构<code>输出</code>6个字段:</p><p>从<code>上方</code>入射</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- “result. inc_top”</span><br><span class="line">- “result. inc_top_reflected”</span><br><span class="line">- “result. inc_top_transmitted”</span><br></pre></td></tr></table></figure><p>从<code>下方</code>入射</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- “result. inc_bottom”</span><br><span class="line">- “result.inc_bottom_reflected”</span><br><span class="line">- “result. inc_bottom_transmitted”</span><br></pre></td></tr></table></figure><p>The sub-structure “<strong>result.inc_top_reflected</strong>” contains all the information concerning the propagative <em>reflected</em> waves <em>for an incident wave from the top layer</em> of the grating. The incident wave is described in the sub-structure “<strong>result.inc_top”</strong>.</p><p>子结构“result.inc_top_reflected”包含有关来自光栅顶层的入射波的传播反射波的所有信息。 入射波在子结构“result.inc_top”中描述。</p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403165245428.png" alt="image-20230403165245428" style="zoom:50%;" /><p>Fig. 4. The two obtained solutions.   图4. 获得的两个解决方案。</p><p>Each sub-structure of result is composed of the several fields. Each field is a Matlab column vector or matrix having the same number N of lines. N is the number of propagative orders considered and can be 0.  </p><p>result的每个子结构由多个字段组成。每个字段都是一个Matlab列向量或矩阵，具有相同的行数N。 N是考虑的传播阶数，可以为0。</p><table><thead><tr><th>Field name   字段名</th><th>Signification   意义</th><th>size</th></tr></thead><tbody><tr><td>order  阶数</td><td>orders of the diffracted  propagative plane waves   衍射传播平面波的阶</td><td>N, 1</td></tr><tr><td>theta   Θ</td><td>angle $\theta$m of each diffracted order   每个衍射阶数的角 m</td><td>N, 1</td></tr><tr><td><strong>K</strong></td><td>normalised wave vector   归一化波矢</td><td>N, 3</td></tr><tr><td>efficiency效率</td><td>efficiency of each diffracted  order   每个衍射级数的效率</td><td>N, 1</td></tr><tr><td>amplitude   振幅</td><td>complexe amplitude in TE  polarization of every order   各阶 TE 极化中的复振幅</td><td>N, 1</td></tr><tr><td><strong>E</strong></td><td>electric field (Ex, Ey, Ez) of the diffracted orders  at O_top or O_bottom when the amplitude of the incident plane wave is one.   当入射平面波的振幅为1时，在 O _ 顶或 O _ 底的衍射级数的电场(Ex，Ey，Ez)</td><td>N, 3</td></tr><tr><td><strong>H</strong></td><td>magnetic field (Hx, Hy, Hz) of the diffracted orders  at O_top or O_bottom when the amplitude of the incident plane wave is one.   当入射平面波振幅为1时，在 o _ 顶或 o _ 底的衍射级磁场(Hx，Hy，Hz)。</td><td>N, 3</td></tr><tr><td>PlaneWave_E</td><td>E-vector  components of the $\overrightarrow{\text{PW}}$ ’s (in the Oxyz basis) <br /> PW 的 e 向量分量(在 Oxyz 基础上)</td><td>N, 3</td></tr><tr><td>PlaneWave_H</td><td>H-vector  components of the $\overrightarrow{\text{PW}}$ ’s (in the Oxyz basis)  <br />PW 的 h 向量分量(在 Oxyz 基础上)</td><td>N, 3</td></tr></tbody></table><p> (To use the same notations as in the conical code or in the crossed-grating code, set parm.res1.result&#x3D;-1 before calling res1.m).</p><p>(要使用与锥形代码或交叉光栅代码相同的符号，在调用 res1.m 之前设置 parm.res1.result &#x3D;-1)。</p><h3 id="Efficiencies-效率"><a href="#Efficiencies-效率" class="headerlink" title="Efficiencies 效率"></a>Efficiencies 效率</h3><p>For a given diffraction order n, the diffraction efficiency is defined as the ratio between the flux of the diffracted Poynting vector and the flux of the incident Poynting vector (flux through a period of the grating).</p><p>对于给定的衍射阶数n，衍射效率定义为衍射Poynting矢量通量和入射Poynting矢量通量（通过光栅一个周期的通量）之比。</p><p> The efficiencies of all propagative reflected and transmitted waves for an incident wave from the top of the grating are given by the two vectors “<strong>result.inc_top_reflected.efficiency</strong>” and “<strong>result.inc_top_transmitted.efficiency</strong>”. If all refractive indices are real, the sum of all elements of these two vectors is equal to one because of the energy conservation. The labels n of the corresponding orders are in “<strong>result.inc_top_reflected.order</strong>” (see below for a description of the other fields of this sub_structure).</p><p>对于来自光栅顶部的入射波的所有传播反射和透射波的效率分别由两个向量“result.inc_top_reflected.efficiency”和“result.inc_top_transmitted.efficiency”给出。 如果所有折射率都是实数，则这两个向量的所有元素之和等于1，因为能量守恒。 相应阶级别的标签n在“result.inc_top_reflected.order”中（有关此子结构的其他字段的描述，请参见下文）</p><p> <code>Some examples</code> 一些例子</p><ol><li>The efficiency of the reflected order -2 ($\quad\text{k}_{&#x2F;&#x2F;}\text{&#x3D;}\frac{\text{inc}}{\text{x}}-2\text{K}<em>X\quad$) when the grating is illuminated from the top is equal to result. inc_top_reflected.efficency{-2}. If this order is evanescent, the efficiency is 0.当光栅从顶部照射时，反射级$\quad\text{k}</em>{&#x2F;&#x2F;}\text{&#x3D;}\frac{\text{inc}}{\text{x}}-2\text{K}_X\quad$的效率等于结果。表面反射。效率{-2}。如果这个顺序是消失的，那么效率是0。</li></ol><p>It is important to have in mind the difference between : </p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">result.inc_top_reflected.efficiency&#123;<span class="number">-2</span>&#125; : efficiency of order <span class="number">2</span></span><br><span class="line">result.inc_top_reflected.efficiency(<span class="number">-2</span>) : gives an error !</span><br><span class="line">result.inc_top_reflected.efficiency&#123;<span class="number">2</span>&#125; : efficiency of order <span class="number">2</span></span><br><span class="line">result.inc_top_reflected.efficiency(<span class="number">2</span>) : efficiency in order result. inc_top_reflected.order(<span class="number">2</span>);</span><br></pre></td></tr></table></figure><ol><li>The orders of all the transmitted-propagative plane waves for an incident wave from the top of the grating are given by the vector “<strong>result.inc_top_transmitted.order</strong>”.</li></ol><p>来自光栅顶部的入射波的所有传播透射平面波的级别可以在向量“result.inc_top_transmitted.order”中找到。</p><ol><li>The efficiencies of all propagative reflected waves for an incident wave from the bottom in TM polarization are given by the vector “<strong>result.inc_bottom_reflected.efficiency</strong>”.</li></ol><p>对于在TM偏振下从底部入射的入射波，所有传播反射波的效率由向量“result.inc_bottom_ reflected.efficiency”给出。</p><h3 id="Rayleigh-expansion-for-propagatives-modes"><a href="#Rayleigh-expansion-for-propagatives-modes" class="headerlink" title="Rayleigh expansion for propagatives modes"></a>Rayleigh expansion for propagatives modes</h3><p>传播模式的瑞利展开</p><p>The coefficients of the Rayleigh expansion of Fig. 1 can be obtained from the structure <strong>result</strong>. For instance, when the grating is illuminated from the bottom with a TE polarised mode, we have :</p><p>图1的瑞利展开系数可由结构计算结果得到。例如，当光栅从底部用 TE 偏振模式照明时，我们有:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Ebottom =result.inc_bottom_reflected.E&#123;m&#125; (<span class="number">3</span> components in Oxyz)</span><br><span class="line">m</span><br><span class="line">Hbottom =result inc_bottom_reflected.H&#123;m&#125; (<span class="number">3</span> components in Oxyz)</span><br><span class="line">m</span><br><span class="line">Etop =result.inc_bottom_transmitted.E&#123;m&#125; (<span class="number">3</span> components in Oxyz)</span><br><span class="line">m</span><br><span class="line">Htop =result.inc_bottom_ transmitted.H&#123;m&#125; (<span class="number">3</span> components in Oxyz)</span><br></pre></td></tr></table></figure><p>and the incident plane wave defined in page 4 is given by :</p><p>第4页中定义的入射平面波由以下人员给出:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Ebottom =result inc_bottom.E (<span class="number">3</span> components in Oxyz)</span><br><span class="line">inc</span><br><span class="line">Hbottom =result.inc_bottom.H (<span class="number">3</span> components in Oxyz).</span><br></pre></td></tr></table></figure><h3 id="Amplitude-of-diffracted-propagative-waves"><a href="#Amplitude-of-diffracted-propagative-waves" class="headerlink" title="Amplitude of diffracted propagative waves"></a>Amplitude of diffracted propagative waves</h3><p>衍射传播波的振幅</p><h4 id="入射角度-Angle-theta-m"><a href="#入射角度-Angle-theta-m" class="headerlink" title="入射角度 Angle $\theta_m$"></a>入射角度 Angle $\theta_m$</h4><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403170721968.png" alt="image-20230403170721968" style="zoom:50%;" /><p>Fig. 5 qm angles. 图5m 角。</p><p>The angle qm related to order m is varying between –90 and 90. It is oriented in such a way that the k-parallel momentum of the corresponding wave vector (incident or diffracted) is</p><p>与阶数m相关的角度θm在-90度至90度之间变化。它的方向安排是这样的，使得相应波矢（入射或衍射）的k-parallel动量为：</p><p>$\text{k_x}^{\text{inc}}+\text{mk_x}&#x3D;(2\pi&#x2F;\lambda)\text{n_top}\sin(\Theta_\text{m})\text or (2\pi&#x2F;\lambda)\text{n_bottom_}\sin(\Theta_\text{m})$ 有点错误</p><p>$$</p><p>&#x3D; (2π&#x2F;λ) n_top sin(qm) or (2π&#x2F;λ) n_bottom_sin(qm).</p><h3 id="O-top-and-O-bottom-points-最高点和最低点"><a href="#O-top-and-O-bottom-points-最高点和最低点" class="headerlink" title="$O_{top}$ and $O_{bottom}$ points 最高点和最低点"></a>$O_{top}$ and $O_{bottom}$ points 最高点和最低点</h3><p>Otop and Obottom are 2 important points (see Fig. 1). In the Cartesian coordinates system Oxyz , they are defined by: Otop&#x3D;(0,0,h) at the top of the grating, and Obottom&#x3D;(0,0,0) at the bottom of the grating.</p><p>Otop和Obottom是两个重要点（见图1）。 在笛卡尔坐标系Oxyz中，它们分别定义为：</p><p>Otop &#x3D;（0,0，h）在光栅顶部， Obottom &#x3D;（0,0,0）在光栅底部。</p><p>In addition, let us consider an arbitrary point M&#x3D;(x,y,z) in the 3D space in Oxyz. Associated to this point, we define the two vectors :</p><p>另外，让我们考虑Oxyz中三维空间中的任意点M &#x3D;（x，y，z）。 与此点相关联，我们定义两个向量：</p><p>$\quad\mathbf{r}<em>{\text{top}&#x3D;}\overline{\mathrm{O}</em>{\text{top}}{\text{M}}}$, and</p><p>$\quad\mathbf{r}<em>{\text{bottom}&#x3D;}\overline{\mathrm{O}</em>{\text{bottom}}{\text{M}}}$.</p><h3 id="Jones’-coefficient-琼斯系数"><a href="#Jones’-coefficient-琼斯系数" class="headerlink" title="Jones’ coefficient 琼斯系数"></a>Jones’ coefficient 琼斯系数</h3><p>Let us assume that the grating is illuminated from the top layer and let us consider a diffracted order m in the bottom layer. Any other diffraction situation is straighforwardly deduced.</p><p>让我们假设光栅是从顶层照明，让我们考虑一个衍射阶数 m 在底层。任何其他衍射情况都是直接推导出来的。</p><p>Let α be a given complex number. The incident electromagnetic field (6 components of <strong>E</strong> and <strong>H</strong> in every points of the 3D space) can be written :</p><p>设 α 是给定的复数。入射电磁场(三维空间中每个点上的 e 和 h 的6个分量)可以写成:</p><p>$\mathbf{W}^{\text{inc}}&#x3D;\alpha\overrightarrow{\mathbf{PW}}$</p><p>where PW is a plane wave defined in every point by PW&#x3D;A exp(ikinc top rtop), A being the electromagnetic fields (6 components) of the plane wave at M&#x3D;Otop, and kinc top is the incident wave vector. A and K&#x3D;kinc top &#x2F; kinc top are given by the structure “result“ as will be defined later.</p><p>Similarly, the diffracted electromagnetic field in the m bottom order can be written :</p><p>其中，PW是由PW &#x3D; A exp（ikinc top rtop）在每个点定义的平面波，其中A是平面波在M &#x3D; Otop处的电磁场（6个分量），而kinc top是入射波矢量。向量A和K &#x3D; kinc top &#x2F; kinc top由结构“result”给出，稍后将进行定义。</p><p>同样地，m级别的衍射电磁场可以写成：</p><p>$\mathbf{W}_\mathrm{m}^{\mathrm{dif}}&#x3D;\gamma\overline{\mathbf{PW^m}}$</p><p>where $\gamma$ is a complex number, PWm is a plane wave defined in every point by PWm&#x3D;Am exp (ikm bottom rbottom ), Am is the electromagnetic fields (6 components) of the plane wave at M&#x3D;Obottom, and km bottom is the wave vector of the mth transmitted order. Am and, Km&#x3D;kmbottom &#x2F; kmbottom are given by the structure “result“ as will be defined later.</p><p>We define the Jones’coefficient J, associated to the order m by</p><p>其中，γ是一个复数，PWm是由PWm &#x3D; Am exp（ikm bottom rbottom）在每个点定义的平面波，其中Am是平面波在M &#x3D; Obottom处的电磁场（6个分量），而km bottom是第m个透射级别的波矢量。向量Am和Km &#x3D; kmbottom &#x2F; kmbottom由结构“result”给出，稍后将进行定义。</p><p>我们通过定义与阶数m相关联的Jones系数J来完成：</p><p>待添加</p><p>​                 </p><h2 id="Using-symmetries-to-accelerate-the-computational-speed"><a href="#Using-symmetries-to-accelerate-the-computational-speed" class="headerlink" title="Using symmetries to accelerate the computational speed"></a>Using symmetries to accelerate the computational speed</h2><p><code>使用对称性来加快计算速度</code></p><p>When the grating possesses some mirror symmetry for the plane x&#x3D;x0, one may define “parm.sym.x&#x3D; x0. Then</p><p>when k_parallel &#x3D;0, the code will use the symmetry property for speeding up the calculation.</p><p>当光栅在x &#x3D; x0平面处具有某些镜像对称性时，可以定义“parm.sym.x &#x3D; x0”。然后，当k_parallel &#x3D; 0时，代码将使用对称性属性加快计算速度。</p><p>Note that the code does not verify if the symmetries of the grating defined by the user are in agreement with the “textures” parameters. It is up to the user to define carefully the parameters parm.sym.x. All textures used in the calculation must possess the same symmetry.</p><p>请注意，代码不验证用户定义的光栅的对称性是否与“textures”参数一致。用户必须仔细定义参数parm.sym.x。计算中使用的所有纹理必须具有相同的对称性。</p><h2 id="Plotting-the-electromagnetic-field-and-calculating-the-absorption-loss"><a href="#Plotting-the-electromagnetic-field-and-calculating-the-absorption-loss" class="headerlink" title="Plotting the electromagnetic field and calculating the absorption loss"></a>Plotting the electromagnetic field and calculating the absorption loss</h2><h3 id="res3程序"><a href="#res3程序" class="headerlink" title="res3程序"></a>res3程序</h3><p><code>绘制电磁场并计算吸收损耗</code></p><p>Computation of the electromagnetic fields 计算电磁场</p><p>Once the eigenmodes associated to all textures are known, the calculation of the electromagnetic fields everywhere in the grating can be performed. This calculation is done by the function “<strong>res3.m</strong>”, following the instruction:</p><p>一旦知道了所有纹理的本征模式，就可以计算光栅中各处的电磁场。这个计算是由函数“ res3.m”按照指令完成的:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[e,z,index] = res3(x,aa,Profile, inc,parm);</span><br></pre></td></tr></table></figure><p>The function“res3.m” can be called without calling “res2.m”. This subroutine has 5 input arguments:<br>-the “x” variable is a vector containing the locations where the fields will be calculated in the x-direction [for<br>instance we may set x &#x3D; linspace(-period_x&#x2F;2, period_x&#x2F;2, 51); for allocating 51 sampling points in the xdirection],<br>the “aa” variable contains all the information on the eigenmodes of all textures and is computed by the subroutine<br>res1.m,<br>-the variable “Profile” is defined in Section 4.2; note that it can be redefined,<br>-the variable “inc” defines the y component of the complex amplitude of the incident electric (in TE polarisation)<br>or magnetic field (in TM polarisation) field at O_top or O_bottom .<br>For illuminating the grating exactly by the TE-polarized incident PW defined above, one should set:<br>einc&#x3D; result.inc_top PlaneWave_E(2) for TE polarisation; einc&#x3D; result.inc_top PlaneWave_H(2) for TM<br>polarisation.<br>-the “parm” variable, already mentioned is discussed in the following.<br>There are three possible output arguments for the subroutine “res3.m”. The variable “e” contains all the<br>electromagnetic field quantities:  </p><p>函数“res3.m”可以在不调用“res2.m”的情况下调用。该子程序具有<code>5个输入</code>参数： </p><ol><li><p>“x”变量是一个向量，其中包含在x方向上计算场的位置[例如，我们可以将x &#x3D; linspace（- period_x &#x2F; 2，period_x &#x2F; 2，51）;分配51个采样点以在x方向进行采样]，</p></li><li><p>“aa”变量包含所有纹理的特征模式信息，并由子程序res1.m计算</p></li><li><p>变量“Profile”在第4.2节中定义。请注意，它可以重新定义</p></li><li><p>变量“inc”定义入射电场的复振幅的y分量（在TE偏振中）或磁场（在TM偏振中）在O_top或O_bottom处。 为了精确地用上述TE偏振入射PW照明光栅，应设置： 对于TE偏振，einc &#x3D; result.inc_top PlaneWave_E（2）;对于TM偏振，einc &#x3D; result.inc_top PlaneWave_H（2）。 </p></li><li><p>“parm”变量是已经提到的，在下面进行了讨论。</p></li></ol><p>子程序“res3.m”有<code>三个</code>输出变量。</p><ul><li>“e”变量包含所有电磁场量：</li></ul><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ey=e(:,:,<span class="number">1</span>); Hx=e(:,:,<span class="number">2</span>); Hz=e(:,:,<span class="number">3</span>); in TE polarization.</span><br><span class="line">Hy=e(:,:,<span class="number">1</span>); Ex=e(:,:,<span class="number">2</span>); Ez=e(:,:,<span class="number">3</span>); in TM polarization.</span><br></pre></td></tr></table></figure><p>The second variable “z” is the vector containing the z-coordinate of the sampling points. Note that in the matrix Ex&#x3D;e(:,:,1), the first index refer to the z coordinate, and the second to the x-coordinate. Thus Ex(i,j) is the Ex field component at the location {z(i), x(j)}. The third variable “index” is the complex refractive index of the considered grating. index(i,j) is the refractive index at the location {z(i), x(j)}. It can be useful to test the profile of the grating.</p><ul><li>第二个变量“z”是包含采样点z坐标的向量。请注意，在矩阵Ex &#x3D; e（：，：，1）中，第一个索引是z坐标，第二个是x坐标。 因此，Ex（i，j）是位于{z（i），x（j）}位置处的Ex场分量。第三个变量“index”是所考虑光栅的复折射率。 index（i，j）是在{z（i），x（j）}位置处的折射率。它可以用于测试光栅的轮廓。</li></ul><p>Some <strong>important</strong> comments on the <strong>parm</strong>” variable : 关于“parm”变量的一些重要注释：</p><ol><li>For calculating precisely the electromagnetics fields, one has to set : ”<strong>parm.res1.champ&#x3D;1”</strong> before calling <strong>res1.m.</strong> This increases the calculation time and memory load, but it is highly recommended. If not, the computation of the field will be correct only in homogenous textures (for example in the top layer and in the bottom layer). 1.为了精确计算电磁场，必须在调用res1.m之前设置：“parm.res1.champ&#x3D;1”。这会增加计算时间和内存负荷，但强烈建议这样做。否则，在均匀纹理（例如在顶层和底层）中才能正确计算场。</li><li>Illuminating the grating from the top or the bottom layer : As mentioned earlier, the code compute the diffraction efficiencies of the transmitted and reflected orders for an incident plane wave from the top and for an incident plane wave from the bottom at the same time. When plotting the field, the user must specify the direction of the incident plane wave. This is specified with variable <strong>parm.res3.sens</strong>. For <strong>parm.res3.sens&#x3D;1</strong>, the grating is illuminated from the top and for <strong>parm.res3.sens&#x3D;-1</strong>, the grating is illuminated from the bottom (default is <strong>parm.res3.sens&#x3D;1)</strong>. 2.从顶层或底层照射光栅：如前所述，该代码同时计算从顶部和从底部入射平面波的透射和反射阶数的衍射效率。在绘制场时，用户必须指定入射平面波的方向。这是使用变量parm.res3.sens指定的。对于parm.res3.sens &#x3D; 1，从顶部照亮光栅，而parm.res3.sens &#x3D; -1则从底部照亮光栅（默认值为parm.res3.sens &#x3D; 1）。</li><li>Specifying the z locations of the computed fields: This is provided by the variable <strong>parm.res3.npts</strong>. <strong>parm.res3.npts</strong> is a vector whose length is equal to the number of layers. For instance let us imagine, a grating defined by <strong>Profile</strong> &#x3D; {[0.5,1,2,0.6],[1,2,3,4]}. Setting <strong>parm.res3.npts&#x3D;[2,3,4,5]</strong> implies that the field will be computed in two z&#x3D;constant plans in the top layer, in three z&#x3D;constant plans in the first layer (texture 2), in four z&#x3D;constant plans in the second layer (texture 3), and in five z&#x3D;constant plans in the bottom layer. Default for <strong>parm.res3.npts</strong> is 10 z&#x3D;constant plans per layer. 指定计算场的z位置：这由变量parm.res3.npts提供。parm.res3.npts是一个向量，其长度等于层数。例如，假设存在一个由Profile &#x3D; {[0.5,1,2,0.6],[1,2,3,4]}定义的光栅。设置parm.res3.npts&#x3D;[2,3,4,5]意味着将在顶层的两个z &#x3D; constant平面中计算场，在第一层（纹理2）中的三个z &#x3D; constant平面中计算场，在第二层（纹理3）中的四个z &#x3D; constant平面中计算场，并在底层的五个z &#x3D; constant平面中计算场。parm.res3.npts的默认值是每层10个z &#x3D; constant平面。</li></ol><p><code>VERY IMPORTANT</code> 非常重要</p><p>where is the z&#x3D;0 plan and what are the z-coordinates of the z&#x3D;constant plan? The z&#x3D;0 plan is defined at the bottom of the bottom layer. Thus, the field calculation is performed only for z&gt;0 values. For the example <strong>Profile</strong> &#x3D; {[0.5,1,2,0.6],[1,2,3,4]}, and if we refer to texture 4 as the substrate, the z&#x3D;0 plan is located in the substrate at a distance 0.6 under the grating. The z&#x3D;constant plans are located by an equidistant sampling in every layer. Always referring to the previous example, it implies that the five z&#x3D;constant plans in the substrate are located at coordinate z&#x3D;(p-0.5) 0.6&#x2F;5, where p&#x3D;1,2,…5. Note that the z coordinates for the z&#x3D;constant plans are always given by the second output variable of res3.m.</p><p>z&#x3D;0平面在底层底部定义。因此，场计算仅在z&gt; 0值时执行。对于示例Profile &#x3D; {[0.5,1,2,0.6]，[1,2,3,4]}，如果将纹理4称为基板，则z &#x3D; 0平面位于光栅下0.6的距离处的基板上。 z &#x3D; constant平面是在每个层中通过等距采样来定位的。始终参考之前的例子，意味着底层中的五个z &#x3D; constant平面位于z &#x3D;（p-0.5）0.6&#x2F;5的坐标处，其中p &#x3D; 1,2，… 5。请注意，z &#x3D; constant平面的z坐标始终由res3.m的第二个输出变量给出。</p><ol start="4"><li><p>How can one specify a given z&#x3D;constant plan? First, one has to redefine the variable <strong>Profile</strong>. For the grating example with the two layers discussed above, let us imagine that one wants to plot the field at z&#x3D;z0+0.6+0.2 in layer 2. Then one has to set: <strong>Profile</strong> &#x3D; {[0.5,1-z0,0,z0,0.2,0.6],[1,2,2,2,3,4]} and set <strong>parm.res3.npts&#x3D;[0,0,1,0,0,0]</strong>. Note that it is not necessary to redefine the variable <strong>Profile</strong> at the beginning of the program. One just needs to redefine this variable before calling subroutine res3.m. 如何指定给定的z &#x3D; constant平面？首先，必须重新定义变量Profile。对于上面讨论的两个层的光栅示例，假设想要在第2层的z &#x3D; z0 + 0.6 + 0.2处绘制场。然后，必须设置：Profile &#x3D; {[0.5,1-z0,0,z0,0.2,0.6]，[1,2,2,2,3,4]}，并设置parm.res3.npts &#x3D; [0,0,1,0,0,0]。请注意，在程序开头重新定义变量Profile是不必要的。只需要在调用子程序res3.m之前重新定义此变量即可。</p></li><li><p>Automatic plots: an automatic plot (showing all the components of the electromagnetic fields and the grating refractive index distribution) is provided by setting <strong>parm.res3.trace</strong>&#x3D;1. If one wants to plot only some components of the fields, one can set for instance in TE polarization: <strong>parm.res3.champs</strong>&#x3D;[1,0] to plot Ey and the objet, <strong>parm.res3.champs</strong>&#x3D;[2] to plot only Hx. 自动绘图：通过设置parm.res3.trace &#x3D; 1，可以提供自动绘图（显示电磁场和光栅折射率分布的所有组件）。如果只想绘制场的某些组件，则可以在TE偏振中设置例如parm.res3.champs &#x3D; [1,0]绘制Ey和物体，parm.res3.champs &#x3D; [2]只绘制Hx。</p></li></ol><h3 id="Computation-of-the-absorption-loss"><a href="#Computation-of-the-absorption-loss" class="headerlink" title="Computation of the absorption loss"></a>Computation of the absorption loss</h3><p>吸收损失的计算</p><p>Loss computation is performed with the subroutine “<strong>res3.m</strong>”.</p><p>损耗计算使用子程序“ res3.m”执行。</p><p>First approach based on integrals (not valid for homogeneous layers with non-diagonal anisotropy): The absorption loss in a surface 𝑆 is given by:</p><p>第一种基于积分的方法（不适用于具有非对角各向同性的均匀层）：</p><p>表面𝑆的吸收损耗由以下公式给出：</p><p> 𝐿 &#x3D; 𝜋 ∫ 𝐼𝑚 𝜀(𝑀) |𝐸 (𝑀)|2 𝑑𝑆 for TE polarization.</p><p>𝐿 &#x3D; 𝜋 ∫ 𝐼𝑚 (𝜀𝑋𝑋(𝑀)|𝐸𝑋(𝑀)|2 + 𝜀𝑍𝑍(𝑀)|𝐸𝑧(𝑀)|2) 𝑑𝑆 for TM polarization.</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[e, Z, index, wZ, loss_per_layer, loss_of_Z, loss_of_Z_X, X, wX] = res3(x,aa,Profile,einc,parm);</span><br></pre></td></tr></table></figure><p>The important ouput arguments are: 重要的输出参数是:</p><p><strong>loss_per_layer</strong>: the loss in every layer defined by <strong>Profile</strong>, <strong>loss_per_layer</strong>(1) is the loss in the top layer, loss_per_layer(2) is the loss in layer 2, … and loss_per_layer(end) is the loss in the bottom layer </p><p>loss_of_Z: the absorption loss density (integrated over X) as a function of Z (like for X, the sampling points Z are not equidistant. You may plot this loss density as follows: plot(Z, loss_of_Z), xlabel(‘Z’), ylabel(‘absorption’) </p><p>loss_of_Z_X(Z,X) &#x3D; π&#x2F;λ Im(index(Z,X).^2) |e(Z,X,1)|2 in TE polarization </p><p>loss_of_Z_X(Z,X) &#x3D; π&#x2F;λ Im(index(Z,X).^2) ( e(Z,X,2)|2+|e(Z,X,3)|2) in TM polarization </p><p>index: index(i,j) is the complex refractive index at the location {z(i), x(j)}.</p><p>每层损耗: 由 Profile 定义的每层损耗，每层损耗(1)是顶层损耗，每层损耗(2)是第2层损耗，… 每层损耗(末端)是底层损耗(z) : 吸收损耗密度(在 x 上积分)与 z 的函数关系(如 x，取样点 z 不等距)。您可以将这个损失密度绘制如下: 绘图(z，_ z 的损失) ，xlabel (‘ z’) ，ylabel (‘吸收’) _ z _ x (z，x)的损失 _ &#x3D; π&#x2F;λim (指数(z，x)。_ z _ x (z，x) &#x3D; π&#x2F;λim (index (z，x)的 TE 偏振损耗 _ 中的 ^ 2) | e (z，x，1) | 2。TM 偏振指数中的 ^ 2)(e (z，x，2) | 2 + | e (z，x，3) | 2) : 指数(i，j)是{ z (i) ，x (j)}处的复折射率。</p><p>Second approach based on Poynting theorem (always valid, even for homogeneous layers with non-diagonal anisotropy):</p><p>基于 Poynting 定理的第二种方法(总是有效的，即使对于非对角各向异性的均匀层) :</p><p>An alternative approach to compute the losses in the layers consists in calculating the difference in the flux of the incoming and outgoing Poynting vectors. This approach is faster, but in some cases, the computation of the integral can be more accurate. In homogeneous layers with non-diagonal anisotropy, only this approach is possible.</p><p>另一种计算各层损耗的方法是计算输入和输出 Poynting 向量的通量差。这种方法更快，但在某些情况下，积分的计算可以更精确。在非对角各向异性的均匀层中，只有这种方法是可行的。</p><p>To specify which approach used per layer, we define a vector parm.res3.pertes_poynting &#x3D; [0,0,0,1,0]; % for instance for a 5-layer grating with “0”, the integral approach is used (default option) and with “1”, the Poynting approach is used. The length of parm.res3.pertes_poynting is equal to the number of layers. We may set parm.res3.pertes_poynting &#x3D; 0 or 1; the scalar is then repeated for all layers.</p><p>为了指定每层使用的方法，我们定义了一个向量 parm.res3.pertes _ Poynting &#x3D; [0,0,0,1,0] ; 例如，对于5层光栅，使用“0”，使用积分方法(默认选项) ，对于“1”，使用 Poynting 方法。Parm.res3.pertes _ poynting 的长度等于层数。我们可以设置 parm.res3.pertes _ poynting &#x3D; 0或1; 然后对所有层重复标量。</p><p>We may then compute the flux of the Poynting vector in the layer-boundary planes [e, Z, index, wZ,loss_per_layer,loss_of_Z,loss_of_Z_X,X,wX,Flux_Poynting] &#x3D; res3(x,aa,Profile,einc,parm);</p><p>然后我们可以计算 Poynting 向量在层边界面[ e，z，index，wz，loss _ per _ layer，loss _ z，loss _ of _ zx，x，wx，flux _ Poynting ] &#x3D; res3(x，aa，Profile，einc，parm)中的通量;</p><p><strong>Flux_Poynting</strong> is a vector. <strong>Flux_Poynting(1)</strong> corresponds to the upper interface of the top layer. The flux is computed for a normal vector equal to the 𝐳̂vector. If <strong>Flux_Poynting(p)</strong> &gt; 0, the energy flows toward the top and if it is negative, the energy flows toward the bottom.</p><p><strong>Flux _ poynting 是一个矢量。Flux _ poynting (1)对应于顶层的上层界面。通量是针对一个等于 something 矢量的法向量计算的。如果 Flux _ poynting (p) &gt; 0，能量流向顶部，如果它是负的，能量流向底部。</strong></p><p>For an illumination from the top and a lossy substrate, the substrate absorption is **-**<strong>Flux_Poynting (end)&#x2F;(0.5*period)</strong>. For an illumination from the bottom and a lossy superstrate, the superstrate absorption is <strong>Flux_Poynting (1)&#x2F;(0.5*period)</strong>.</p><p>对于来自顶部和有耗基板的照明，基板的吸收是 Flux _ poynting (end)&#x2F;(0.5 * period)。对于来自底部和有耗上层的照明，上层吸收是 Flux _ poynting (1)&#x2F;(0.5 * period)。</p><p><code>Note on the computation accuracy of the integral approach</code> 关于积分法计算精度的注意事项</p><p>To compute integrals like the loss or the electromagnetic energy, RETICOLO uses a Gauss-Legendre integration method. This method, which is very powerful for ‘regular’ functions, becomes inaccurate for discontinuous functions. Thus, the integration domain should be divided into subdomains where the electric field <strong>E</strong> is continuous. For the integration in <strong>X</strong>, this difficult task is performed by the program, so that the user should only define the limits of integration: the input “<strong>x</strong>” argument is now a vector of length 2, which represent the limits of the x interval (to compute the loss over the entire period, we may take <strong>x</strong>(2)&#x3D;<strong>x</strong>(1)+<strong>period</strong>. The integration domain is then divided into subintervals where the permittivity is continuous, each subinterval having a length less than l&#x2F;(2p). For every subinterval, a Gauss-Legendre integration method of degree 10 is used. This default value can be changed by setting <strong>parm.res3.gauss_x</strong>&#x3D;. The actual points of computation of the field are returned in the output argument</p><p>为了计算像损耗或电磁能这样的积分，RETICOLO 使用了 Gauss-Legendre 积分法。这种方法对于“正则”函数非常有效，但是对于不连续的函数就不准确了。因此，积分域应该被划分为电场 e 是连续的子域。对于 x 中的积分，这个困难的任务是由程序执行的，因此用户只需要定义积分的极限: 输入“ x”参数现在是一个长度为2的向量，它表示 x 区间的极限(为了计算整个周期的损失，我们可以采用 x (2) &#x3D; x (1) + 周期)。然后将积分域划分为介电常数连续的子区间，每个子区间的长度小于&#x2F;(2)。对于每个子区间，使用10度的 Gauss-Legendre 积分方法。这个默认值可以通过设置 parm.res3.gauss _ x &#x3D; 来改变。字段的实际计算点在输出参数中返回X.</p><p>For the z integration, the discontinuity points are more easily determined by the variable ‘Profile’. The user</p><p>may choose the number of subintervals and the degree in every layer using the parameter parm.res3.npts, which is now an array with two lines (in subsection 8.1 this variable is a line vector): the first line defines the degree and the second line the numbers of subintervals of every layer. For example: parm.res3.npts &#x3D; [ [10,0,12] ; [3,1,5] ]; means that 3 subintervals with 10-degree points are used in the first layer, 1 subintervals with 0 point in the second layer, 5 subintervals with 12degree points in the third layer.</p><p>对于z积分，不连续点可以更轻松地通过变量“Profile”确定。用户可以使用参数parm.res3.npts选择每个层中的子区间数和度数，该参数现在是一个带有两行的数组（在第8.1小节中，此变量是线向量）：第一行定义度数，第二行定义每个层的子区间数。例如：parm.res3.npts &#x3D;[ [10,0,12];[3,1,5]]; 表示在第一层中使用3个子区间和10度点，第二层中使用1个子区间和0点，第三层中使用5个子区间和12度点。</p><p>The actual z-points of computation of the field are returned in the output variable <strong>Z</strong>, and the vector <strong>wZ</strong> represents the weights and we have sum(<strong>loss_of_Z</strong>.*<strong>wZ</strong>)&#x3D;sum(<strong>loss_per_layer</strong>). Although the maximum degree that can be handled by reticolo is 1000, it is recommended to limit the degree values to modest numbers (10-30 maximum) and to increase the number of subintervals (the larger the degree, the denser the sampling points in the vicinity of the subinterval boundaries).</p><p>字段计算的实际 z 点在输出变量 z 中返回，向量 wZ 表示权重，我们有 _ z 的总和(损失 _)。wZ) &#x3D; 总和(每层损失)。尽管 reticolo 可以处理的最大程度是1000，但建议将程度值限制为适度数(最大10-30) ，并增加子区间的数目(程度越大，子区间边界附近的采样点越密集)。</p><p>Note that if <strong>einc</strong>&#x3D; <strong>result. inc_top PlaneWave_E(2)</strong>, in TE ploarization, or <strong>einc</strong>&#x3D; <strong>result. inc_top PlaneWave_H(2)</strong>, in TE ploarization <strong>,</strong> the energie conservation test for an incident plane wave from the top is sum(result. inc_top_reflected.efficiency)+ sum(result. inc_top_transmitted.efficiency)+ sum(loss_per_layer) &#x2F; (.5*period) &#x3D; 1.</p><p>注意，如果 einc &#x3D; result。Inc _ top PlaneWave _ e (2) ，TE 极化，或 einc &#x3D; result。在 TE 极化条件下，从顶部入射的平面波的能量守恒实验是求和(结果)。反射。效率) + 总和(结果)。传输。效率) + 总和(每层损失)&#x2F;(. 5周期) &#x3D; 1。</p><p>Usually, this equality is achieved with an absolute error of &lt;10-5.</p><p>通常，这种等式是在绝对误差 &lt; 105时实现的。</p><p><code> For specialists: 对于专家</code>:</p><ol><li>-loss_of_Z_X &#x3D;pi&#x2F; wavelength<em>imag(index.^2).</em> abs(e(:,:,1)).^2; in TE polarization</li><li>-loss_of_Z_X &#x3D;pi&#x2F; wavelength*imag(index.^2).*sum(abs(e(:,:,2:3)).^2,3); in TM polarization</li><li>-loss_of_Z &#x3D;(loss_of_Z_X*wX(:)).’;</li><li>-by setting index(index ~&#x3D; index_chosen)&#x3D;0 in the previous formulas, one may calculate the absorption loss in the medium of refractive index index_chosen.</li></ol><p>通过在先前的公式中设置index（index〜&#x3D;index_chosen）&#x3D; 0，可以计算折射率为index_chosen的介质中的吸收损耗。</p><h2 id="Bloch-mode-effective-indices"><a href="#Bloch-mode-effective-indices" class="headerlink" title="Bloch-mode effective indices"></a>Bloch-mode effective indices</h2><p><code>Bloch模式有效指数</code></p><p>RETICOLO gives access to another output: the Bloch mode associated to all textures. The Bloch mode k of the</p><p>texture l can be written</p><p>RETICOLO提供了另一种输出：与所有纹理相关联的布洛赫模。纹理l的布洛赫模k可以写成：</p><p>$\left|\Phi_k{}^l\right\rangle&#x3D;\sum_m a_m^{k,l}exp\left[i(k_x^{inc}+mK_x)x\right]exp\left(i\frac{2\pi}{\lambda}n_{eff}^{k,l}z\right)$,</p><p>where $n_{\textit{eff}}^{k,l}$ is the effective index of the Bloch mode <em>k</em> of the texture <em>l</em>.</p><p>其中，$n_{\textit{eff}}^{k,l}$是纹理l的布洛赫模k的有效指数。</p><p><code>Instruction:</code>说明:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[aa, n_eff] = res1(wavelength,period,textures,nn,kparallel, parm);</span><br></pre></td></tr></table></figure><p>Note that the “n_eff” variable is a Matlab cell array: “n_eff{ii}” is a column vector containing all the Bloch-mode effective indices associated to the texture “textures{ii}”. The element number 5 of this vector, for example, is called by the instruction “n_eff{ii}(5);”. An attenuated Bloch-mode has a complex effective index.</p><p>请注意，“n_eff”变量是Matlab单元数组：“n_eff {ii}”是包含所有与纹理“textures {ii}”相关联的布洛赫模有效指数的列向量。例如，此向量的第5个元素由指令“n_eff {ii}（5）;”调用。衰减的布洛赫模具有复有效指数。</p><p><code>Bloch mode profile visualization</code> Bloch 模式剖面可视化:</p><p>To plot the profile of Bloch mode Num_mode of the texture Num_texture:</p><p>要绘制纹理Num_texture的Bloch模Num_mode的轮廓：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res1(aa, neff, Num_texture, Num_mode);</span><br></pre></td></tr></table></figure><p>To obtain the profile datas in the format given by res3:</p><p>要以res3给出的格式获取轮廓数据：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[e,o,x] = res1(aa, neff, Num_texture, Num_mode); <span class="comment">% by default, |x| &lt; period/2</span></span><br><span class="line">[e,o] = res1(aa, neff, Num_texture, Num_mode, x); <span class="comment">% by specifying the x vector, x=linspace(0, 3*period(1),100)</span></span><br><span class="line"><span class="keyword">for</span> example.</span><br></pre></td></tr></table></figure><h2 id="10-Annex-附件"><a href="#10-Annex-附件" class="headerlink" title="10 Annex 附件"></a>10 Annex 附件</h2><h3 id="10-1-Checking-that-the-textures-are-correctly-set-up"><a href="#10-1-Checking-that-the-textures-are-correctly-set-up" class="headerlink" title="10.1 Checking that the textures are correctly set up"></a>10.1 Checking that the textures are correctly set up</h3><p>检查纹理设置是否正确</p><p>Setting “<strong>parm.res1.trace &#x3D; 1</strong>;” generates a Matlab figure which represents the refractive-index distribution of all the textures.</p><p>设置“ parm.res1.trace &#x3D; 1;”生成一个代表所有纹理折射率分布的 Matlab 图形。</p><h3 id="10-2-The-“retio”-“retefface”-instructions"><a href="#10-2-The-“retio”-“retefface”-instructions" class="headerlink" title="10.2 The “retio” &amp; “retefface” instructions"></a>10.2 The “retio” &amp; “retefface” instructions</h3><p>RETICOLO automatically creates temporary files in order to save memory. These temporary files are of the form “abcd0.mat”, “abcd1.mat” … with abcd are randomly chosen) .They are created in the current directory. In general RETICOLO automatically erases these files when they are no longer needed, but it is recommended to finish all programs by the instruction “retio;”, which erases all temporary files. Also, if a program anormally stopsone may execute the instruction “retio” before restarting the program.</p><p>RETICOLO会自动创建临时文件以节省内存。这些临时文件的格式为“abcd0.mat”，“abcd1.mat”……其中abcd是随机选择的）。它们在当前目录中创建。一般情况下，RETICOLO在不再需要这些文件时会自动删除它们，但建议通过指令“retio;”结束所有程序，该指令将删除所有临时文件。此外，如果程序异常停止，可以在重新启动程序之前执行指令“retio”。</p><p>The “retefface” instruction allows to know all the “abcd0.mat” files and to erase them if wanted.</p><p>“ reteface”指令允许知道所有“ abcd0.mat”文件，并在需要时删除它们。</p><p>If we are not limited by memory (this is often the case with modern computers), we can prevent the writing of intermediate files on the hard disk by the setting</p><p>如果我们不受内存的限制(现代计算机通常就是这种情况) ，我们可以通过设置来防止在硬盘上写入中间文件</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">parm.not_io = <span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>before the call to res1. Then it is no longer necessary to use the retio instruction at the end of the programs to erase the files.</p><p>在调用 res1之前。然后就不再需要在程序结束时使用 retio 指令来删除文件了。</p><p><code>Important</code>: to use parfor loops, it is imperative to take the option parm.not_io &#x3D; 1.</p><p>重要提示: 要使用 parfor 循环，必须使用选项 parm.not _ io &#x3D; 1。</p><h3 id="10-3-How-to-save-and-to-reload-the-“aa”-variable"><a href="#10-3-How-to-save-and-to-reload-the-“aa”-variable" class="headerlink" title="10.3.   How to save and to reload the “aa” variable"></a><strong>10.3.</strong>   How to save and to reload the “aa” variable</h3><p>如何保存和重新加载“ aa”变量</p><p>To save the “<strong>aa</strong>” variable in a “.mat” file, the user has to define a new parameter containing the name of the file he or she wants to create : “<strong>parm.res1.fperm &#x3D; ‘file_name’</strong>;”. field_name is a char string with at least one letter. The program will automatically save “<strong>aa</strong>” in the file “<strong>file_name.mat</strong>”. In a new utilisation it is sufficient to write aa&#x3D;<strong>&#x3D; ‘file_name’</strong>;.</p><p>将“ aa”变量保存到“。在 mat”文件中，用户必须定义一个新参数，其中包含他或她想要创建的文件的名称: “ parm.res1.fperm &#x3D; ‘ file _ name’;”。Field _ name 是一个至少有一个字母的字符串。程序会自动将“ aa”保存到文件“ file _ name”中。马特。在一个新的应用程序中，写 aa &#x3D; &#x3D; ‘ file _ name’就足够了;。</p><p>Example of a program which calculates and saves the “aa” variable […] % Definition of the input parameters, see Section 3 <strong>parm.res1.fperm &#x3D; ‘toto’</strong>;</p><p>计算并保存输入参数的“ aa”变量[ … ]% 定义的程序示例，参见第3节 parm.res1.fperm &#x3D; ‘ toto’;</p><p>[…] % Definition of the textures, see Section 4.1</p><p>[ … ]% 纹理的定义，参见第4.1节</p><p><strong>aa &#x3D; res1(wavelength,period,textures,nn,k_parallel,parm)</strong>;</p><p><strong>Aa &#x3D; res1(波长，周期，纹理，nn，k 平行，parm) ;</strong></p><p>Example of a program which uses the “aa” variable and then calculates the diffracted waves […]  % Definition of the profile, see Section 4.2. Note that the textures used to define the profile argument have to correspond to the textures defined in the program which has previously calculated the “aa” variable. aa&#x3D;’toto’;</p><p>程序使用“ aa”变量，然后计算衍射波[ … ]% 轮廓的定义，参见第4.2节。注意，用于定义配置文件参数的纹理必须与之前计算“ aa”变量的程序中定义的纹理相对应。Aa &#x3D;’toto’;</p><h3 id="10-4-Asymmetry-of-the-Fourier-harmonics-retained-in-the-computation"><a href="#10-4-Asymmetry-of-the-Fourier-harmonics-retained-in-the-computation" class="headerlink" title="10.4.   Asymmetry of the Fourier harmonics retained in the computation"></a><strong>10.4.</strong>   Asymmetry of the Fourier harmonics retained in the computation</h3><p> nn &#x3D; [-15;20]; % this defines the set of non-symmetric Fourier harmonics retained for the computation. In this</p><p>case, the Fourier harmonics from –15 to +20 are retained.</p><p>The instructions “nn &#x3D; 10;” and “nn &#x3D; [-10;10];” are equivalent.</p><p>Take care that the use of symmetry imposes symmetric Fourier harmonics if not the computation will be done</p><p>without any symmetry consideration.</p><p>nn &#x3D; [-15; 20];% 这定义了计算中保留的非对称傅里叶谐波集。在这种情况下，保留从-15到+20的傅里叶谐波。 “nn &#x3D; 10;”和“nn &#x3D; [-10; 10];”指令是等价的。请注意，如果不使用对称性，则使用对称傅里叶谐波进行计算，否则将完全没有考虑对称性。</p><h2 id="11-Summary"><a href="#11-Summary" class="headerlink" title="11  Summary"></a>11  Summary</h2><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230403230539759.png" alt="image-20230403230539759" style="zoom:50%;" /><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">parm = res0( <span class="number">1</span>) <span class="keyword">for</span> TE polarisation;</span><br><span class="line">parm = res0(<span class="number">-1</span>) <span class="keyword">for</span> TM polarisation;</span><br><span class="line">aa = res1(wavelength,period,textures,nn,k_parallel,parm);</span><br><span class="line">result = res2(aa,Profile);</span><br><span class="line">J = result.Jones.inc_top_transmitted &#123;m&#125;</span><br><span class="line">[e,z,o] = res3(x,aa,Profile, inc,parm);</span><br></pre></td></tr></table></figure><h2 id="12-Examples-例子"><a href="#12-Examples-例子" class="headerlink" title="12 Examples  例子"></a>12 Examples  例子</h2><p> The following example can be copied and executed in Matlab ：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%%%%%%%%%%%%%%%%%%%%%%%%%</span></span><br><span class="line"><span class="comment">% EXAMPLE 1D (TE or TM) %</span></span><br><span class="line"><span class="comment">%%%%%%%%%%%%%%%%%%%%%%%%%</span></span><br><span class="line">wavelength=<span class="number">8</span>;</span><br><span class="line">period=<span class="number">10</span>;<span class="comment">% same unit as wavelength</span></span><br><span class="line">n_incident_medium=<span class="number">1</span>;<span class="comment">% refractive index of the top layer</span></span><br><span class="line">n_transmitted_medium=<span class="number">1.5</span>;<span class="comment">% refractive index of the bottom layer</span></span><br><span class="line">angle_theta0=<span class="number">-10</span>;k_parallel=n_incident_medium*<span class="built_in">sin</span>(angle_theta0*<span class="built_in">pi</span>/<span class="number">180</span>);</span><br><span class="line">parm=res0(<span class="number">1</span>);<span class="comment">% TE polarization. For TM : parm=res0(-1)</span></span><br><span class="line">parm.res1.champ=<span class="number">1</span>;<span class="comment">% the electromagnetic field is calculated accurately</span></span><br><span class="line">nn=<span class="number">40</span>;<span class="comment">% Fourier harmonics run from [-40,40]</span></span><br><span class="line"><span class="comment">% textures for all layers including the top and bottom layers</span></span><br><span class="line">texture=cell(<span class="number">1</span>,<span class="number">3</span>);</span><br><span class="line">textures&#123;<span class="number">1</span>&#125;= n_incident_medium; <span class="comment">% uniform texture</span></span><br><span class="line">textures&#123;<span class="number">2</span>&#125;= n_transmitted_medium; <span class="comment">% uniform texture</span></span><br><span class="line">textures&#123;<span class="number">3</span>&#125;=&#123;[<span class="number">-2.5</span>,<span class="number">2.5</span>],[n_incident_medium,n_transmitted_medium] &#125;;</span><br><span class="line"></span><br><span class="line">aa=res1(wavelength,period,textures,nn,k_parallel,parm);</span><br><span class="line">Profile=&#123;[<span class="number">4.1</span>,<span class="number">5.2</span>,<span class="number">4.1</span>],[<span class="number">1</span>,<span class="number">3</span>,<span class="number">2</span>]&#125;;</span><br><span class="line">one_D_TE=res2(aa,Profile)</span><br><span class="line">eff=one_D_TE.inc_top_reflected.efficiency&#123;<span class="number">-1</span>&#125;</span><br><span class="line">J=one_D_TE.Jones.inc_top_reflected&#123;<span class="number">-1</span>&#125;;<span class="comment">% Jones’coefficients</span></span><br><span class="line"><span class="built_in">abs</span>(J)^<span class="number">2</span> <span class="comment">% first order efficiency for an illumination from the top layer</span></span><br><span class="line"><span class="comment">% field calculation</span></span><br><span class="line">x=<span class="built_in">linspace</span>(-period/<span class="number">2</span>,period/<span class="number">2</span>,<span class="number">51</span>);<span class="comment">% x coordinates(z-coordinates are determined by</span></span><br><span class="line">res3.m)</span><br><span class="line">einc=<span class="number">1</span>;</span><br><span class="line">parm.res3.trace=<span class="number">1</span>; <span class="comment">% plotting automatically</span></span><br><span class="line">parm.res3.npts=[<span class="number">50</span>,<span class="number">50</span>,<span class="number">50</span>];</span><br><span class="line">[e,z,index]=res3(x,aa,Profile,einc,parm);</span><br><span class="line"><span class="built_in">figure</span>;pcolor(x,z,<span class="built_in">real</span>(<span class="built_in">squeeze</span>(e(:,:,<span class="number">1</span>)))); <span class="comment">% user plotting</span></span><br><span class="line">shading flat;xlabel(<span class="string">&#x27;x&#x27;</span>);ylabel(<span class="string">&#x27;y&#x27;</span>);axis equal;title(<span class="string">&#x27;Real(Ey)&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">% Loss calculation</span></span><br><span class="line">textures&#123;<span class="number">3</span>&#125;=&#123;[<span class="number">-2.5</span>,<span class="number">2.5</span>],[n_incident_medium,<span class="number">.1</span>+<span class="number">5</span><span class="built_in">i</span>] &#125;;</span><br><span class="line">aa_loss=res1(wavelength,period,textures,nn,k_parallel,parm);</span><br><span class="line">one_D_loss=res2(aa_loss,Profile)</span><br><span class="line">parm.res3.npts=[[<span class="number">0</span>,<span class="number">10</span>,<span class="number">0</span>];[<span class="number">1</span>,<span class="number">3</span>,<span class="number">1</span>]];</span><br><span class="line">einc=one_D_loss.inc_top.PlaneWave_E(<span class="number">2</span>);</span><br><span class="line">[e,z,index,wZ,loss_per_layer,loss_of_Z,loss_of_Z_X,X,wX]=res3([-</span><br><span class="line">period/<span class="number">2</span>,period/<span class="number">2</span>],aa_loss,Profile,einc,parm);</span><br><span class="line">Energie_conservation=sum(one_D_loss.inc_top_reflected.efficiency)+sum(one_D_loss.in</span><br><span class="line">c_top_transmitted.efficiency)+sum(loss_per_layer)/(<span class="number">.5</span>* period)<span class="number">-1</span></span><br><span class="line">retio <span class="comment">% erase temporary files</span></span><br></pre></td></tr></table></figure><h1 id="for-the-analysis-of-the-diffraction-by-stacks-of-lamellar-1D-gratings-conical-diffraction"><a href="#for-the-analysis-of-the-diffraction-by-stacks-of-lamellar-1D-gratings-conical-diffraction" class="headerlink" title="for the analysis of the diffraction by stacks of lamellar 1D gratings (conical diffraction)"></a>for the analysis of the diffraction by stacks of lamellar 1D gratings (conical diffraction)</h1><p><code>用于分析层状一维光栅的衍射(锥形衍射)</code></p><p>Reticolo code 1D-conical is a free software for analyzing 1D gratings in classical and conical mountings. It operates under Matlab. To install it, copy the companion folder “reticolo_allege” and add the folder in the Matlab path. The code may also be used to analyze thin-film stacks with homogeneous and anisotropic materials, see the end of Section 3.1.</p><p>Reticolo 代码1d-锥是一个免费的软件，用于分析一维光栅在经典和锥形安装。它在 Matlab 下运行。要安装它，复制伴随文件夹“ reticolo _ allege”，并将该文件夹添加到 Matlab 路径中。该代码也可用于分析均质和各向异性材料的薄膜堆栈，参见第3.1节的结尾。</p><h2 id="Outline-大纲"><a href="#Outline-大纲" class="headerlink" title="Outline 大纲"></a>Outline 大纲</h2><h2 id="Generality-概括"><a href="#Generality-概括" class="headerlink" title="Generality 概括"></a>Generality 概括</h2><p>RETICOLO is a code written in the language MATLAB 9.0. It computes the diffraction efficiencies and the diffracted amplitudes of gratings composed of stacks of lamellar structures. It incorporates routines for the calculation and visualisation of the electromagnetic fields inside and outside the grating. With this version, 2D periodic (crossed) gratings cannot be analysed.</p><p>RETICOLO 是用 MATLAB 9.0语言编写的代码。它计算由层状结构堆叠组成的光栅的衍射效率和衍射振幅。它包含了用于计算和可视化光栅内外电磁场的例程。有了这个版本，二维周期(交叉)光栅不能被分析。</p><p>As free alternative to MATLAB, RETICOLO can also be run in GNU Octave with minimal code changes. For further information, please contact <a href="mailto:&#x74;&#x69;&#x6e;&#x61;&#x2e;&#x6d;&#x69;&#x74;&#116;&#x65;&#x72;&#x61;&#109;&#115;&#x6b;&#111;&#103;&#108;&#101;&#x72;&#x40;&#112;&#114;&#x6f;&#x66;&#97;&#99;&#116;&#111;&#114;&#46;&#97;&#x74;">&#x74;&#x69;&#x6e;&#x61;&#x2e;&#x6d;&#x69;&#x74;&#116;&#x65;&#x72;&#x61;&#109;&#115;&#x6b;&#111;&#103;&#108;&#101;&#x72;&#x40;&#112;&#114;&#x6f;&#x66;&#97;&#99;&#116;&#111;&#114;&#46;&#97;&#x74;</a>.</p><p>作为 MATLAB 的免费替代品，RETICOLO 也可以在 GNU Octave 中运行，代码变化很小。欲了解更多信息，请联系 <a href="mailto:&#116;&#105;&#x6e;&#x61;&#x2e;&#x6d;&#x69;&#116;&#x74;&#101;&#114;&#x61;&#109;&#x73;&#107;&#111;&#103;&#108;&#x65;&#114;&#x40;&#112;&#x72;&#x6f;&#102;&#97;&#99;&#x74;&#x6f;&#114;&#x2e;&#97;&#x74;">&#116;&#105;&#x6e;&#x61;&#x2e;&#x6d;&#x69;&#116;&#x74;&#101;&#114;&#x61;&#109;&#x73;&#107;&#111;&#103;&#108;&#x65;&#114;&#x40;&#112;&#x72;&#x6f;&#102;&#97;&#99;&#x74;&#x6f;&#114;&#x2e;&#97;&#x74;</a>。</p><p>In brief, RETICOLO implements a frequency-domain modal method (known as the Rigorous Coupled wave Analysis&#x2F;RCWA). To get an overview of the RCWA, the interested readers may refer to the following articles:</p><p>简而言之，RETICOLO 实现了一种频域模态方法(称为严格耦合波分析&#x2F;RCWA)。为了得到 RCWA 的概述，感兴趣的读者可以参考以下文章:</p><p>1D-classical and conical diffraction</p><p>1d-经典和圆锥衍射</p><p><strong>Scattering matrix approach:</strong> The code incorporates many refinements that we have not published and that we do not plan to publish. For instance, although it is generally admitted that the S-matrix is inconditionnally stable, it is not always the case. We have developed an in-house transfer matrix method which is more stable and accurate. The new transfer matrix approach is also more general and can handle perfect metals. The essence of the method has been rapidly published in “J.-P. Hugonin, M. Besbes and P. Lalanne, Op. Lett. <strong>33</strong>, 1590 (2008)”.</p><p><strong>散射矩阵方法: 该代码包含了许多我们没有发表过也不打算发表的改进。例如，尽管人们普遍承认 s 矩阵是无条件稳定的，但事实并非总是如此。我们开发了一种更稳定和准确的内部转移矩阵方法。新的转移矩阵方法也更加通用，可以处理完美的金属。这种方法的精髓已经在《日报》上迅速发表。作者: Hugonin，m. Besbes and p。莱特。33,1590(2008)”。</strong></p><p><strong>Field calculation:</strong> The calculation of the near-field electromagnetic fields everywhere in the grating is performed according to the method described in “P. Lalanne, M.P. Jurek, JMO <strong>45</strong>, 1357 (1998)” and to its generalization to crossed gratings (unpublished). Basically, no Gibbs phenomenon will be visible in the plots of the discontinuous electromagnetic quantities, but field singularities at corners will be correctly handled.</p><p><strong>场计算: 根据“ P.Lalanne，m.p. Jurek，JMO 45,1357(1998)”中描述的方法及其对交叉光栅的推广(未发表) ，计算了光栅内各处的近场电磁场。基本上，在不连续电磁量的图中不会看到吉布斯现象，但是在角落处的场奇异性将被正确处理。</strong></p><p><strong>Acknowledging the use of RETICOLO</strong>: In publications and reports, acknowledgments have to be provided by referencing to J.P. Hugonin and P. Lalanne, RETICOLO software for grating analysis, Institut d’Optique, Orsay, France (2005), arXiv:2101:00901.</p><p><strong>承认 RETICOLO 的使用: 在出版物和报告中，承认必须参考 j.p. Hugonin 和 p. Lalanne，RETICOLO 光栅分析软件，法国 Orsay 光学研究所，arXiv: 2101:00901。</strong></p><p>In journal publications and in addition, one may fairly quote the following references:</p><p>在期刊出版物和另外，人们可以公正地引用下列参考文献:</p><p>-P. Lalanne and G.M. Morris, “Highly improved convergence of the coupled-wave method for TM polarization”, J. Opt. Soc. Am. A <strong>13</strong>, 779-789 (1996).</p><p>拉兰内和莫里斯，“ TM 极化的耦合波方法的高度改进的收敛性”，J.Opt。Soc.译注:。13,779-789(1996).</p><p>-P. Lalanne and M.P. Jurek, “Computation of the near-field pattern with the coupled-wave method for TM polarization”, J. Mod. Opt.<strong>45</strong>, 1357-1374 (1998), if near-field electromagnetic-field distributions are shown.</p><p>- P.Lalanne 和 m.p. Jurek，“用 TM 极化的耦合波方法计算近场模式”，J.Mod。如果显示近场电磁场分布，则为 Opt. 45,1357-1374(1998)。</p><h2 id="The-diffraction-problem-considered"><a href="#The-diffraction-problem-considered" class="headerlink" title="The diffraction problem considered"></a>The diffraction problem considered</h2><p>考虑了衍射问题</p><p>In general terms, the code solves the diffraction problem by a grating defined by a stack of layers which have all identical periods in the x- directions and are invariant in the y direction see the following figure. In the following, the (x,y) plane and the z-direction will be referred to as the transverse plane and the longitudinal direction, respectively. To define the grating structure, first we have to define a top and a bottom. This is rather arbitrary since the top or the bottom can be the substrate or the cover of a real structure. It is up to the user. Once the top</p><p>一般来说，该代码通过一个光栅来解决衍射问题，这个光栅由一堆在 x 方向上具有相同周期且在 y 方向上不变的层所定义，如下图所示。接下来，(x，y)平面和 z 方向分别称为横向平面和纵向平面。为了定义光栅结构，首先我们必须定义一个顶部和一个底部。这是相当武断的，因为顶部或底部可以是一个真实结构的衬底或覆盖物。这取决于用户。一旦登顶</p><p> and the bottom of the grating have been defined, the user can choose to illuminate the structure from the top or from the bottom. The z-axis is oriented from bottom to top.</p><p>光栅的底部已经确定，用户可以选择从顶部或从底部照明结构。Z 轴是从下到上定向的。</p><p>RETICOLO is written with the 𝑒𝑥𝑝(−𝑖𝜔𝑡) convention for the complex notation of the fields. So, if the materials are absorbant, one expects that all indices have a positive imaginary part. The Maxwell’s equations are of the form</p><p>RETICOLO 是用 exp (- iωt)约定书写的，用于字段的复杂符号。因此，如果材料是吸收性的，人们期望所有的指数都有一个正虚部分。麦克斯韦方程组是这种形式</p><p>where 𝜀 &#x3D; 𝑛2 is the relative permittivity, a complex number, and 𝜆 is the wavelength in a vacuum.</p><p>其中 ε &#x3D; n2是相对电容率，一个复数 λ 是真空中的波长。</p><p>RETICOLO-1D returns the diffraction efficiencies of the transmitted and reflected orders for an incident plane wave from the top and for an incident plane wave from the bottom, both for TM and TE polarizations. The four results are obtained by the same calculation (incident TE wave from the top, incident TM wave from the top, incident TE wave from the bottom and incident TM wave from the bottom). Of course, the two incident plane waves must have identical parallel wave vector in the transverse plane [ kinc , kinc ]. This possibility which is not</p><p>RETICOLO-1D 返回了 TM 和 TE 偏振情况下从顶部入射的平面波和从底部入射的平面波的透射和反射阶的衍射效率。四个结果是通过相同的计算(从顶部入射的 TE 波，从顶部入射的 TM 波，从底部入射的 TE 波和从底部入射的 TM 波)得到的。当然，两个入射平面波在横向平面上必须有相同的平行波向量[ kinc，kinc ]。这种可能性不是</p><h2 id="跑的通"><a href="#跑的通" class="headerlink" title="跑的通"></a>跑的通</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">%   1  D    exemple10_1D</span></span><br><span class="line"><span class="comment">% 不同厚度仿真 exemple2_1D</span></span><br><span class="line"><span class="comment">% 不同波长仿真 exemple5_1D</span></span><br><span class="line">clc;clear;close all;</span><br><span class="line">addpath(<span class="string">&#x27;reticolo_allege_v9&#x27;</span>);</span><br><span class="line">t1 = clock;</span><br><span class="line">incident_angle = <span class="number">0</span>;</span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.4</span>:<span class="number">0.010</span>:<span class="number">2</span>; <span class="comment">% 波长范围</span></span><br><span class="line">grating_period = <span class="number">1</span>; <span class="comment">% 光栅周期</span></span><br><span class="line">grating_height = <span class="number">1</span>;</span><br><span class="line">incident_refractive_index = <span class="number">1</span>; <span class="comment">% 入射介质的折射率</span></span><br><span class="line">beta0 = incident_refractive_index * <span class="built_in">sin</span>(incident_angle * <span class="built_in">pi</span> / <span class="number">180</span>); <span class="comment">% 入射角的相位角</span></span><br><span class="line">polarization = <span class="number">-1</span>; <span class="comment">% -1:TM   1:TE   </span></span><br><span class="line">parm = res0(polarization); parm.not_io = <span class="number">1</span>; <span class="comment">% 初始化参数</span></span><br><span class="line">parm.sym.x = <span class="number">0</span>; <span class="comment">% 利用对称性</span></span><br><span class="line">fourier_series = <span class="number">20</span>; <span class="comment">% Fourier series</span></span><br><span class="line"><span class="comment">%% 结构尺寸和折射率</span></span><br><span class="line"><span class="comment">%&#123; </span></span><br><span class="line"><span class="comment">for ii = 1:12 textures&#123;ii&#125; = &#123;[-ii * grating_period / 13, 0], [1, 1.5]&#125;; end</span></span><br><span class="line"><span class="comment">% textures&#123;12&#125; = &#123;[-12 * grating_period / 13, -4,0], [3.2, 1,1.5]&#125;; </span></span><br><span class="line"><span class="comment">textures&#123;13&#125; = 1;textures&#123;14&#125; = 2.5;</span></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment"></span><span class="comment"></span></span><br><span class="line"><span class="comment">%&#123; </span></span><br><span class="line"><span class="comment">ii = 2;</span></span><br><span class="line"><span class="comment">textures&#123;1&#125; = &#123;[0,10,25], [1.5,1.7, 1.9]&#125;; </span></span><br><span class="line"><span class="comment">textures&#123;2&#125; = &#123;[0,10,15,25], [1.3,1.2, 1.4,1.1]&#125;; </span></span><br><span class="line"><span class="comment">textures&#123;ii+1&#125; = 1;</span></span><br><span class="line"><span class="comment">textures&#123;ii+2&#125; = 1.5;</span></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment">%&#123; 1</span></span><br><span class="line">ii = <span class="number">1</span>;</span><br><span class="line">textures&#123;<span class="number">1</span>&#125; = &#123;[<span class="number">0.25</span>,<span class="number">0.75</span>], [<span class="number">1</span>, <span class="number">2</span>]&#125;; </span><br><span class="line"><span class="comment">% textures&#123;2&#125; = &#123;[0,10,15,25], [1+3i,2, 1,2]&#125;; </span></span><br><span class="line">textures&#123;ii+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line">textures&#123;ii+<span class="number">2</span>&#125; = <span class="number">1</span>;</span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%%</span></span><br><span class="line"><span class="comment">%&#123; 1</span></span><br><span class="line"><span class="keyword">for</span> ix = <span class="number">20</span></span><br><span class="line">    fourier_series = ix;</span><br><span class="line">    T = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> wave_num = <span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)</span><br><span class="line">        </span><br><span class="line">        aa = res1(wavelength_range(wave_num), grating_period, textures, fourier_series, beta0, parm);</span><br><span class="line">        profil = &#123;[<span class="number">0</span>,  (grating_height / <span class="number">1</span>), <span class="number">0</span>], [<span class="built_in">numel</span>(textures)<span class="number">-1</span>, <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-2</span>), <span class="built_in">numel</span>(textures)]&#125;;</span><br><span class="line">        ef = res2(aa, profil);</span><br><span class="line">        R(wave_num,<span class="number">1</span>) = sum(ef.inc_top_reflected.efficiency);</span><br><span class="line">        T(wave_num,<span class="number">1</span>) = sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">    Transmission_M(:,ix) = T;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="comment">%&#125;</span></span><br><span class="line"><span class="comment">%% 绘制折射率</span></span><br><span class="line">wave_num = <span class="number">1</span>;</span><br><span class="line">aa = res1(wavelength_range(wave_num), grating_period, textures, fourier_series, beta0, parm);</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>, grating_period, <span class="number">100</span>); <span class="comment">% 绘制的范围 两个周期 </span></span><br><span class="line">parm.res3.cale = []; <span class="comment">% signifie que l&#x27;on ne calcule pas le champ</span></span><br><span class="line">profil = &#123;[<span class="number">2</span>,  grating_height, <span class="number">2</span>], [<span class="built_in">numel</span>(textures)<span class="number">-1</span>, <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-2</span>), <span class="built_in">numel</span>(textures)]&#125;;</span><br><span class="line">[tab1, z, o] = res3(x, aa, profil, <span class="number">1</span>, parm); </span><br><span class="line"></span><br><span class="line"><span class="comment">% plot_func(dimension,x,y,z,fontsize, linewidth, x_dis, y_dis, width, height,xlable, ylable, title)</span></span><br><span class="line">plot_func(<span class="number">3</span>,x,z,<span class="built_in">real</span>(o),<span class="number">25</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;X label range (μm)&#x27;</span>,<span class="string">&#x27;Z label (μm)&#x27;</span>,<span class="string">&#x27;截面折射率&#x27;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">%% 绘制透射谱</span></span><br><span class="line"><span class="comment">% plot_func(dimension,x,y,z,fontsize, linewidth, x_dis, y_dis, width, height,xlable, ylable, title)</span></span><br><span class="line"><span class="keyword">if</span> exist(<span class="string">&#x27;Transmission_M&#x27;</span>) ~= <span class="number">0</span></span><br><span class="line">    plot_func(<span class="number">2</span>,wavelength_range,Transmission_M,  <span class="number">0</span>,<span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;Transmission&#x27;</span>,<span class="string">&#x27;透射率与阶数的关系&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="一维光栅结构-改之前"><a href="#一维光栅结构-改之前" class="headerlink" title="一维光栅结构-改之前"></a>一维光栅结构-改之前</h2><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230419103659141.png" alt="image-20230419103659141" style="zoom:80%;" /><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">% 不同厚度仿真 exemple2_1D</span></span><br><span class="line">clc;clear;close all;</span><br><span class="line">addpath(<span class="string">&#x27;reticolo_allege_v9&#x27;</span>); addpath(<span class="string">&#x27;shuju&#x27;</span>);addpath(<span class="string">&#x27;script&#x27;</span>);addpath(<span class="string">&#x27;RCWA&#x27;</span>);</span><br><span class="line">t1 = clock;</span><br><span class="line">incident_angle = <span class="number">0</span>;</span><br><span class="line">wavelength_range(:,<span class="number">1</span>) = <span class="number">0.4</span>:<span class="number">0.001</span>:<span class="number">4</span>; <span class="comment">% 波长范围</span></span><br><span class="line"></span><br><span class="line">grating_period = <span class="number">1</span>; <span class="comment">% 光栅周期</span></span><br><span class="line">incident_refractive_index = <span class="number">1</span>; <span class="comment">% 入射介质的折射率</span></span><br><span class="line">k_parallel = incident_refractive_index * <span class="built_in">sin</span>(incident_angle * <span class="built_in">pi</span> / <span class="number">180</span>); <span class="comment">% 入射角的相位角</span></span><br><span class="line">polarization = <span class="number">-1</span>; <span class="comment">% -1:TM   1:TE   </span></span><br><span class="line">parm = res0(polarization); parm.not_io = <span class="number">1</span>; <span class="comment">% 初始化参数</span></span><br><span class="line"><span class="comment">% parm.sym.x = 1; % 利用对称性</span></span><br><span class="line">fourier_series_M = <span class="number">20</span>; <span class="comment">% Fourier series</span></span><br><span class="line">fourier_series = <span class="number">20</span>; </span><br><span class="line"></span><br><span class="line"><span class="comment">% 1  MgF2     % 11 W       % 21 VO2-hot</span></span><br><span class="line"><span class="comment">% 2  SiO2     % 12 Ti      % 22 VO2-cool</span></span><br><span class="line"><span class="comment">% 3  Al2O3    % 13 Fe      % 23 VO2-hot</span></span><br><span class="line"><span class="comment">% 4  Si3N4    % 14 Cr      % 24 DAST-Voltage</span></span><br><span class="line"><span class="comment">% 5  Si3N41直 % 15 Mo*     % 25 ALON</span></span><br><span class="line"><span class="comment">% 6  TiO2     % 16 Au      % 26 ITO</span></span><br><span class="line"><span class="comment">% 7  SiN      % 17 Cu      % 27 Ag*</span></span><br><span class="line"><span class="comment">% 8  Ge       % 18 Al</span></span><br><span class="line"><span class="comment">% 9  PMMA     % 19 Ag </span></span><br><span class="line"><span class="comment">% 10 SiO2     % 20 VO2-cool</span></span><br><span class="line">nk_Martix = <span class="built_in">conj</span>(nk_data(wavelength_range*<span class="number">1000</span>));</span><br><span class="line"><span class="comment">%% 结构尺寸和折射率</span></span><br><span class="line">struct.period = <span class="number">1</span>; </span><br><span class="line">struct.height(:,<span class="number">1</span>) =  [<span class="number">1.00</span>   <span class="number">1.00</span>   <span class="number">1</span>]; <span class="comment">% h1 h2 ...</span></span><br><span class="line">struct.width(:,<span class="number">1</span>) =  [<span class="number">0.4</span>    <span class="number">0.6</span>    <span class="number">0.8</span>];   <span class="comment">% w1 w2 ...</span></span><br><span class="line">struct.nkindex(:,<span class="number">1</span>) = [<span class="number">19</span>   <span class="number">19</span>      <span class="number">19</span>];</span><br><span class="line"><span class="comment">% FDTD</span></span><br><span class="line">struct.unit = <span class="number">1e-6</span>; <span class="comment">% 1e-6 μm; 1e-9 nm</span></span><br><span class="line">struct.mesh = <span class="number">0.02</span>; <span class="comment">% mesh </span></span><br><span class="line">struct.mesh_M = <span class="number">0.01</span>;</span><br><span class="line">struct.wave_start = <span class="built_in">min</span>(wavelength_range);</span><br><span class="line">struct.wave_stop = <span class="built_in">max</span>(wavelength_range);</span><br><span class="line">struct.wave_step = wavelength_range(<span class="number">2</span>,<span class="number">1</span>)-wavelength_range(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">%% 结构纹理 textures</span></span><br><span class="line">x_bloack = <span class="number">51</span>;</span><br><span class="line"><span class="keyword">for</span> iz = <span class="number">1</span>:<span class="built_in">length</span>(struct.height)</span><br><span class="line">    textures&#123;iz&#125;(<span class="number">1</span>) = &#123;[-struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>,struct.width(iz,<span class="number">1</span>)/<span class="number">2</span>]&#125;; <span class="comment">% 设置结构宽度</span></span><br><span class="line">    struct.nk(:,iz) = nk_Martix(:,struct.nkindex(iz,<span class="number">1</span>)); <span class="comment">% 设置结构折射率</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">scale_one = grating_period / x_bloack;</span><br><span class="line"><span class="keyword">for</span> io = <span class="number">1</span>:x_bloack</span><br><span class="line">    x_coordinate(io) = scale_one * (io - <span class="number">1</span>) - grating_period/<span class="number">2</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line">textures&#123;<span class="number">3</span>&#125;(<span class="number">1</span>) = &#123;x_coordinate&#125;;</span><br><span class="line">textures&#123;iz+<span class="number">1</span>&#125; = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> method = <span class="number">1</span>:<span class="number">1</span>  <span class="comment">% 1: RCWA 2:FDTD</span></span><br><span class="line"><span class="keyword">switch</span> method    </span><br><span class="line">    <span class="keyword">case</span> <span class="number">1</span> <span class="comment">%% 1 RCWA</span></span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(fourier_series_M)</span><br><span class="line">            fourier_series = fourier_series_M(ix);</span><br><span class="line">            R = <span class="built_in">zeros</span>(<span class="built_in">length</span>(wavelength_range), <span class="number">1</span>); T = R; A = R; </span><br><span class="line">            textures_local = textures; aa_save = &#123;&#125;; profil_save = &#123;&#125;; textures_save = &#123;<span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)&#125;;</span><br><span class="line">            <span class="keyword">parfor</span> wave_num = <span class="number">1</span>:<span class="built_in">length</span>(wavelength_range)                 </span><br><span class="line">                textures = textures_local;</span><br><span class="line">                <span class="keyword">for</span> izz = <span class="number">1</span>:iz;textures&#123;izz&#125;(<span class="number">2</span>) = &#123;[<span class="number">1</span>, struct.nk(wave_num,izz)]&#125;;<span class="keyword">end</span>;</span><br><span class="line">                b_ix = <span class="built_in">ones</span>(<span class="number">1</span>,<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;));</span><br><span class="line">                <span class="keyword">for</span> ia = <span class="number">1</span>:<span class="built_in">length</span>(textures&#123;<span class="number">1</span>, <span class="number">3</span>&#125;&#123;<span class="number">1</span>, <span class="number">1</span>&#125;)</span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">rem</span>(ia, <span class="number">2</span>) == <span class="number">0</span></span><br><span class="line">                        b_ix(ia) = <span class="number">2</span>;</span><br><span class="line">                    <span class="keyword">end</span></span><br><span class="line">                <span class="keyword">end</span></span><br><span class="line">                textures&#123;<span class="number">3</span>&#125;(<span class="number">2</span>) = &#123;b_ix&#125;;</span><br><span class="line"></span><br><span class="line">                aa = res1(wavelength_range(wave_num), struct.period, textures, fourier_series, k_parallel, parm);</span><br><span class="line">                profile = &#123;[<span class="number">0</span>,  struct.height&#x27;, <span class="number">0</span>], [<span class="built_in">length</span>(textures), <span class="number">1</span>:(<span class="built_in">numel</span>(textures)<span class="number">-1</span>), <span class="built_in">length</span>(textures)]&#125;;</span><br><span class="line">                <span class="comment">% 计算</span></span><br><span class="line">                ef = res2(aa, profile);</span><br><span class="line">                R(wave_num,<span class="number">1</span>) = sum(ef.inc_top_reflected.efficiency);</span><br><span class="line">                T(wave_num,<span class="number">1</span>) = sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                A(wave_num,<span class="number">1</span>) = <span class="number">1</span> - sum(ef.inc_top_reflected.efficiency) - sum(ef.inc_top_transmitted.efficiency);</span><br><span class="line">                textures_save&#123;wave_num&#125; = textures; aa_save&#123;wave_num&#125; = aa; profil_save&#123;wave_num&#125; = profile;</span><br><span class="line">            <span class="keyword">end</span></span><br><span class="line">            RCWA.R(:,ix) = R; RCWA.T(:,ix) = T; RCWA.A(:,ix) = A;</span><br><span class="line">            t2 = clock; tc(t2,t1);</span><br><span class="line">            RCWA.T_matrix(:,ix) = T;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        RCWA.RTA = [R T A]; RCWA.R = R; RCWA.T = T; RCWA.A = A; </span><br><span class="line"></span><br><span class="line">        textures = textures_save&#123;<span class="number">1</span>&#125;; aa = aa_save&#123;<span class="number">1</span>&#125;;</span><br><span class="line">        profile = profil_save&#123;<span class="number">1</span>&#125;; profile&#123;<span class="number">1</span>&#125;(<span class="number">1</span>) = <span class="number">2</span>; profile&#123;<span class="number">1</span>&#125;(<span class="keyword">end</span>) = <span class="number">2</span>;</span><br><span class="line">        x = <span class="built_in">linspace</span>(-struct.period/<span class="number">2</span>, struct.period/<span class="number">2</span>, <span class="built_in">max</span>(x_bloack*<span class="number">2</span>, <span class="number">100</span>));</span><br><span class="line">        [e, z, o] = res3(x, aa, profile, <span class="number">1</span>, parm);         </span><br><span class="line">        plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">3</span> <span class="number">1</span> <span class="number">1</span>],x,z,<span class="built_in">real</span>(o),<span class="number">15</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">900</span>,<span class="number">400</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>,<span class="string">&#x27;截面折射率&#x27;</span>);      </span><br><span class="line">        <span class="comment">%% 绘制透射谱</span></span><br><span class="line">        plot_func(<span class="number">2</span>,[<span class="number">1</span> <span class="number">3</span> <span class="number">2</span> <span class="number">0</span>],wavelength_range,RCWA.T_matrix,<span class="number">0</span>, <span class="number">15</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;Transmission&#x27;</span>,<span class="string">&#x27;RCWA 透射&#x27;</span>);</span><br><span class="line">        plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">3</span> <span class="number">3</span> <span class="number">0</span>],x,z,e(:,:,<span class="number">1</span>).*<span class="built_in">conj</span>(e(:,:,<span class="number">1</span>)),<span class="number">15</span>, <span class="number">1.5</span>, <span class="number">-1000</span>,<span class="number">500</span>,<span class="number">900</span>,<span class="number">400</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>,<span class="string">&#x27;abs(E)^2&#x27;</span>);      </span><br><span class="line">        </span><br><span class="line">        t2 = clock; tc(t2,t1);</span><br><span class="line"></span><br><span class="line">    <span class="comment">%% 2 FDTD</span></span><br><span class="line">    <span class="keyword">case</span> <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> mesh_num = <span class="number">1</span>:<span class="built_in">length</span>(struct.mesh_M)</span><br><span class="line">            struct.mesh = struct.mesh_M(mesh_num); FDTD = fun_1D(struct); t2 = clock; tc(t2,t1);</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        plot_func(<span class="number">2</span>, <span class="number">0</span>,FDTD.wave,FDTD.T,<span class="number">0</span>, <span class="number">25</span>,<span class="number">1.5</span>,  <span class="number">-500</span>,<span class="number">500</span>,<span class="number">500</span>,<span class="number">400</span>,<span class="string">&#x27;Wavelength (μm)&#x27;</span>,<span class="string">&#x27;R/T/A&#x27;</span>,<span class="string">&#x27;FDTD 透射&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span>;<span class="keyword">end</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>RCWA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python常用</title>
    <link href="/2023/11/08/Python/Python%E5%B8%B8%E7%94%A8/"/>
    <url>/2023/11/08/Python/Python%E5%B8%B8%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<hr><h2 id="time-cal-py时间计算"><a href="#time-cal-py时间计算" class="headerlink" title="time_cal.py时间计算"></a>time_cal.py时间计算</h2><p>使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> time_cal <span class="keyword">import</span> *  <span class="comment"># 自定义模块，计算代码运行时间</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">time_calculation(start_time, time.time())</span><br></pre></td></tr></table></figure><p>代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">time_calculation</span>(<span class="params">start_time, end_time</span>):</span><br><span class="line">    end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">    <span class="keyword">if</span> end_time - start_time &gt;= <span class="number">3600</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; h&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">3600</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">elif</span> end_time - start_time &gt;= <span class="number">60</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; min&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">60</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; s&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time), <span class="number">1</span>)))</span><br></pre></td></tr></table></figure><h2 id="河北工业大学p10-代码"><a href="#河北工业大学p10-代码" class="headerlink" title="河北工业大学p10 代码"></a>河北工业大学p10 代码</h2><p>利用SummaryWriter，Sequential，看流程图</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> optimizer</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> time_cal <span class="keyword">import</span> *  <span class="comment"># 自定义模块，计算代码运行时间</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># from main_09 import criterion</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line"><span class="comment"># 设置数据预处理方式（将图像数据转换为张量并进行归一化处理）</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])  <span class="comment"># 均值 标准差</span></span><br><span class="line"><span class="comment"># 加载训练数据集和测试数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Relu</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        a = torch.nn.ReLU</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line">        self.model1 = torch.nn.Sequential(</span><br><span class="line">            Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            torch.nn.ReLU(),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)  <span class="comment"># 64</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.pooling(self.conv1(x)))</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.pooling(self.conv2(x)))</span></span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="comment"># x = x.view(batch_size, -1)  # flatten</span></span><br><span class="line">        <span class="comment"># x = self.fc(x)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="comment"># 定义损失函数（交叉熵损失函数）</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 定义优化器（使用随机梯度下降法进行优化，设置学习率和冲量）</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 冲量0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            inputs, target = data</span><br><span class="line">            inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy=&#123;&#125;, [&#123;&#125;/&#123;&#125;],&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:  <span class="comment"># 求余函数</span></span><br><span class="line">            test()</span><br><span class="line">            <span class="comment"># import time</span></span><br><span class="line">            end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">            time_calculation(start_time, time.time())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)).cuda()</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;../logs_seq&quot;</span>)</span><br><span class="line">writer.add_graph(model, <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br><span class="line"><span class="comment">#  conda activate Deep39</span></span><br><span class="line"><span class="comment"># tensorboard --logdir=logs_seq</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="经典代码1"><a href="#经典代码1" class="headerlink" title="经典代码1"></a>经典代码1</h2><h3 id="p10-py"><a href="#p10-py" class="headerlink" title="p10.py"></a>p10.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Flatten, Linear, ReLU</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> optimizer</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> time_cal <span class="keyword">import</span> *  <span class="comment"># 自定义模块，计算代码运行时间</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">run_code = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">start_time = time.time()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置数据预处理方式（将图像数据转换为张量并进行归一化处理）</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])  <span class="comment"># 均值 标准差</span></span><br><span class="line"><span class="comment"># 加载训练数据集和测试数据集</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line">        self.model1 = torch.nn.Sequential(</span><br><span class="line">            <span class="comment"># Conv2d(1, 100, kernel_size=5), MaxPool2d(2), torch.nn.ReLU(),</span></span><br><span class="line">            <span class="comment"># Conv2d(100, 10, kernel_size=5), MaxPool2d(2), torch.nn.ReLU(),</span></span><br><span class="line">            <span class="comment"># Flatten(), Linear(160, 10),</span></span><br><span class="line"></span><br><span class="line">            Conv2d(<span class="number">1</span>, <span class="number">100</span>, kernel_size=<span class="number">3</span>), MaxPool2d(<span class="number">2</span>), ReLU(),</span><br><span class="line">            Conv2d(<span class="number">100</span>, <span class="number">60</span>, kernel_size=<span class="number">3</span>), torch.nn.ReLU(),</span><br><span class="line">            Conv2d(<span class="number">60</span>, <span class="number">40</span>, kernel_size=<span class="number">4</span>), MaxPool2d(<span class="number">2</span>), torch.nn.ReLU(),</span><br><span class="line">            Conv2d(<span class="number">40</span>, <span class="number">20</span>, kernel_size=<span class="number">2</span>), torch.nn.ReLU(),</span><br><span class="line">            Flatten(), Linear(<span class="number">180</span>, <span class="number">10</span>),</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Conv2d(1, 10, kernel_size=5), MaxPool2d(2), torch.nn.ReLU(),</span></span><br><span class="line">            <span class="comment"># Conv2d(10, 20, kernel_size=5), MaxPool2d(2), torch.nn.ReLU(),</span></span><br><span class="line">            <span class="comment"># Flatten(), Linear(320, 10),</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        <span class="comment"># batch_size = x.size(0)  # 64</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.pooling(self.conv1(x)))</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.pooling(self.conv2(x)))</span></span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="comment"># x = x.view(batch_size, -1)  # flatten</span></span><br><span class="line">        <span class="comment"># x = self.fc(x)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model.to(device)</span><br><span class="line"><span class="comment"># 定义损失函数（交叉熵损失函数）</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 定义优化器（使用随机梯度下降法进行优化，设置学习率和冲量）</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 冲量0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            inputs, target = data</span><br><span class="line">            inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy=&#123;&#125;, [&#123;&#125;/&#123;&#125;],&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> run_code == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            train(epoch)</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:  <span class="comment"># 求余函数</span></span><br><span class="line">                test()</span><br><span class="line">                <span class="comment"># import time</span></span><br><span class="line">                end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">                time_calculation(start_time, time.time())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)).cuda()</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># writer tensorboard</span></span><br><span class="line">log_dir = <span class="string">&quot;../logs_p10&quot;</span>;  shutil.rmtree(log_dir, ignore_errors=<span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(log_dir); writer.add_graph(model, <span class="built_in">input</span>);writer.close()</span><br><span class="line"><span class="comment">#  conda activate Deep39    tensorboard --logdir=logs_p10</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="p11-py"><a href="#p11-py" class="headerlink" title="p11.py"></a>p11.py</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, ReLU, Flatten, Linear</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> optimizer</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> time_cal <span class="keyword">import</span> *  <span class="comment"># 自定义模块，计算代码运行时间</span></span><br><span class="line">start_time = time.time()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># device = torch.device(&quot;cpu&quot;)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(device))</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">run_code = <span class="number">0</span>  <span class="comment"># 1:run</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])  <span class="comment"># 均值 标准差</span></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionA</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionA, self).__init__()</span><br><span class="line">        <span class="comment"># 1</span></span><br><span class="line">        self.branch_pool = nn.Conv2d(in_channels, out_channels=<span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 2</span></span><br><span class="line">        self.branch1x1 = nn.Conv2d(in_channels, out_channels=<span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 3</span></span><br><span class="line">        self.branch5x5_1 = nn.Conv2d(in_channels, out_channels=<span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = nn.Conv2d(<span class="number">16</span>, out_channels=<span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 4</span></span><br><span class="line">        self.branch3x3_1 = nn.Conv2d(in_channels, out_channels=<span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_3 = nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.inception_mode = torch.nn.Sequential(</span><br><span class="line"></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># 1</span></span><br><span class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line">        <span class="comment"># 2</span></span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line">        <span class="comment"># 3</span></span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line">        <span class="comment"># 4</span></span><br><span class="line">        branch3x3 = self.branch3x3_1(x)</span><br><span class="line">        branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">        branch3x3 = self.branch3x3_3(branch3x3)</span><br><span class="line">        <span class="comment"># [batch, channel, width, height]</span></span><br><span class="line">        outputs = [branch_pool, branch1x1, branch5x5, branch3x3] <span class="comment"># 24 + 16 + 24 + 24 = 88 channel</span></span><br><span class="line">        <span class="comment"># outputs = [branch1x1, branch5x5, branch3x3, branch_pool]</span></span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)  <span class="comment"># batch, channel(第一个), width, height. dim = -1是沿最后一个元素方向</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.incep1 = InceptionA(in_channels=<span class="number">10</span>)</span><br><span class="line">        self.incep2 = InceptionA(in_channels=<span class="number">20</span>)</span><br><span class="line">        self.mp = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1408</span>, <span class="number">10</span>)</span><br><span class="line">        self.model1 = torch.nn.Sequential(</span><br><span class="line">            Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>), MaxPool2d(<span class="number">2</span>), ReLU(),</span><br><span class="line">            InceptionA(in_channels=<span class="number">10</span>),</span><br><span class="line">            Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>), MaxPool2d(<span class="number">2</span>), ReLU(),</span><br><span class="line">            InceptionA(in_channels=<span class="number">20</span>),</span><br><span class="line">            Flatten(), Linear(<span class="number">1408</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># in_size = x.size(0)</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.mp(self.conv1(x)))</span></span><br><span class="line">        <span class="comment"># x = self.incep1(x)</span></span><br><span class="line">        <span class="comment"># x = F.relu(self.mp(self.conv2(x)))</span></span><br><span class="line">        <span class="comment"># x = self.incep2(x)</span></span><br><span class="line">        <span class="comment"># x = x.view(in_size, -1)</span></span><br><span class="line">        <span class="comment"># x = self.fc(x)</span></span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line"></span><br><span class="line">model.to(device)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 冲量0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            inputs, target = data</span><br><span class="line">            inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: &#123;&#125;%, [&#123;&#125;/&#123;&#125;]&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">if</span> run_code == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            train(epoch)</span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">                test()</span><br><span class="line">                <span class="keyword">import</span> time</span><br><span class="line">                time_calculation(start_time, time.time())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)).cuda()</span><br><span class="line">output = model(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">log_dir = <span class="string">&quot;../logs_11&quot;</span>; shutil.rmtree(log_dir, ignore_errors=<span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(log_dir); writer.add_graph(model, <span class="built_in">input</span>); writer.close()</span><br><span class="line"><span class="comment">#  conda activate Deep39    tensorboard --logdir=logs_11</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>重要</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MATLAB代码</title>
    <link href="/2023/11/08/MATLAB/MATLAB%E4%BB%A3%E7%A0%81/"/>
    <url>/2023/11/08/MATLAB/MATLAB%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<h1 id="MATLAB代码"><a href="#MATLAB代码" class="headerlink" title="MATLAB代码"></a>MATLAB代码</h1><h2 id="MATLAB-绘制-2D-3D-图片"><a href="#MATLAB-绘制-2D-3D-图片" class="headerlink" title="MATLAB 绘制 2D&#x2F;3D 图片"></a>MATLAB 绘制 2D&#x2F;3D 图片</h2><p><code>plot_func(dimension,x, y, z,  fontsize, linewidth, x_dis, y_dis, width, height, x_label, y_label, title1)</code></p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">Y</span> = <span class="title">plot_func</span><span class="params">(dimension,x, y, z,  fontsize, linewidth, x_dis, y_dis, width, height, x_label, y_label, title1)</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">3</span></span><br><span class="line">        <span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>], <span class="string">&#x27;position&#x27;</span>, [x_dis, y_dis, width, height]); <span class="comment">% [位置横纵 宽 高]</span></span><br><span class="line">        h = pcolor(x, y, z); <span class="comment">% 绘制图像，并返回句柄</span></span><br><span class="line">        set(h, <span class="string">&#x27;EdgeColor&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">        axis tight; <span class="comment">% 自动调整坐标轴的范围，使其紧贴着数据的最小值和最大值</span></span><br><span class="line">        colorbar;colormap jet;</span><br><span class="line">        set(gca, <span class="string">&#x27;TickDir&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;Box&#x27;</span>, <span class="string">&#x27;off&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">        set(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize); <span class="comment">% Times New Roman</span></span><br><span class="line">        xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> dimension == <span class="number">2</span></span><br><span class="line">        <span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>], <span class="string">&#x27;position&#x27;</span>, [x_dis, y_dis, width, height]); <span class="comment">% [位置横纵 宽 高]</span></span><br><span class="line">        <span class="built_in">plot</span>([<span class="number">0</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">0</span>],<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.5</span>);<span class="built_in">hold</span> on;</span><br><span class="line">        set(gca,<span class="string">&#x27;FontSize&#x27;</span>,fontsize,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);</span><br><span class="line">        xlabel(x_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        ylabel(y_label,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        title(title1,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,fontsize);</span><br><span class="line">        axis tight;</span><br><span class="line">        <span class="keyword">for</span> ix = <span class="number">1</span>:<span class="built_in">length</span>(y(<span class="number">1</span>,:))</span><br><span class="line">            <span class="built_in">plot</span>(x, y(:,ix),  <span class="string">&#x27;Color&#x27;</span>, <span class="built_in">rand</span>(<span class="number">1</span>,<span class="number">3</span>), <span class="string">&#x27;LineWidth&#x27;</span>, linewidth);<span class="built_in">hold</span> on;</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        xlim([<span class="built_in">min</span>(x), <span class="built_in">max</span>(x)]);</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230405221005646.png" alt="image-20230405221005646" style="zoom:50%;" /><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230405220929573.png" alt="image-20230405220929573" style="zoom:50%;" /><h2 id="Comsol-数据导出成矩阵1"><a href="#Comsol-数据导出成矩阵1" class="headerlink" title="Comsol 数据导出成矩阵1"></a>Comsol 数据导出成矩阵1</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">clear M;</span><br><span class="line">a=<span class="number">0</span>:<span class="number">2</span>:<span class="number">86</span>;</span><br><span class="line">b=<span class="number">486</span>;</span><br><span class="line">M=[];</span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:length(a)</span><br><span class="line">    x=df(((i-<span class="number">1</span>)*b+<span class="number">1</span>:(i-<span class="number">1</span>)*b+<span class="number">486</span>),<span class="number">2</span>);</span><br><span class="line">    M=[M x];</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h2 id="Comsol-数据导出成矩阵2"><a href="#Comsol-数据导出成矩阵2" class="headerlink" title="Comsol 数据导出成矩阵2"></a>Comsol 数据导出成矩阵2</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">wave=<span class="number">400</span>:<span class="number">20</span>:<span class="number">1300</span>;</span><br><span class="line"></span><br><span class="line">a=load(<span class="string">&#x27;C:\Users\Administrator\Desktop\Y.txt&#x27;</span>);</span><br><span class="line">dis=<span class="built_in">round</span>(a(<span class="number">2</span>,<span class="number">1</span>)-a(<span class="number">1</span>,<span class="number">1</span>),<span class="number">0</span>);</span><br><span class="line">x = <span class="built_in">round</span>((a(end,<span class="number">1</span>)-a(<span class="number">1</span>,<span class="number">1</span>))/dis,<span class="number">0</span>)+<span class="number">1</span>;</span><br><span class="line">clear M;</span><br><span class="line">dis=<span class="built_in">round</span>(a(<span class="number">2</span>,<span class="number">1</span>)-a(<span class="number">1</span>,<span class="number">1</span>),<span class="number">0</span>);</span><br><span class="line">x = <span class="built_in">round</span>((a(end,<span class="number">1</span>)-a(<span class="number">1</span>,<span class="number">1</span>))/dis,<span class="number">0</span>)+<span class="number">1</span>;</span><br><span class="line">dis = <span class="number">1</span>;</span><br><span class="line">x = <span class="number">31</span>;</span><br><span class="line"><span class="keyword">for</span> ix =<span class="number">1</span>:length(a(:,<span class="number">1</span>))/x</span><br><span class="line">    M(:,ix) =a((ix-<span class="number">1</span>)*x+<span class="number">1</span>:x*ix,<span class="number">2</span>); </span><br><span class="line">end</span><br><span class="line">plot(wave,M(:,<span class="number">8</span>:<span class="number">14</span>))</span><br><span class="line">plot(wave,M(:,<span class="number">15</span>:<span class="number">21</span>))</span><br><span class="line"></span><br><span class="line">b = reshape(a,<span class="number">217</span>,<span class="number">41</span>)</span><br></pre></td></tr></table></figure><p>MATLAB CRT Ra色坐标</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br><span class="line">819</span><br><span class="line">820</span><br><span class="line">821</span><br><span class="line">822</span><br><span class="line">823</span><br><span class="line">824</span><br><span class="line">825</span><br><span class="line">826</span><br><span class="line">827</span><br><span class="line">828</span><br><span class="line">829</span><br><span class="line">830</span><br><span class="line">831</span><br><span class="line">832</span><br><span class="line">833</span><br><span class="line">834</span><br><span class="line">835</span><br><span class="line">836</span><br><span class="line">837</span><br><span class="line">838</span><br><span class="line">839</span><br><span class="line">840</span><br><span class="line">841</span><br><span class="line">842</span><br><span class="line">843</span><br><span class="line">844</span><br><span class="line">845</span><br><span class="line">846</span><br><span class="line">847</span><br><span class="line">848</span><br><span class="line">849</span><br><span class="line">850</span><br><span class="line">851</span><br><span class="line">852</span><br><span class="line">853</span><br><span class="line">854</span><br><span class="line">855</span><br><span class="line">856</span><br><span class="line">857</span><br><span class="line">858</span><br><span class="line">859</span><br><span class="line">860</span><br><span class="line">861</span><br><span class="line">862</span><br></pre></td><td class="code"><pre><span class="line">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span><br><span class="line">%This script calculates chromaticity coordinates, CCT, CRI, GAI, <span class="keyword">and</span> FSCI</span><br><span class="line">%<span class="keyword">for</span> a <span class="number">2856</span> blackbody source (illuminant A).  To use other sources, just</span><br><span class="line">%replace the spd matrix <span class="keyword">with</span> the values <span class="keyword">for</span> the other source.</span><br><span class="line">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span><br><span class="line"></span><br><span class="line">% Light source SPD</span><br><span class="line">%   The light source spd <span class="keyword">is</span> entered <span class="keyword">in</span> a <span class="number">2</span>-column <span class="built_in">format</span> <span class="keyword">as</span> shown below.</span><br><span class="line">%   [wavelength (nm)    value]</span><br><span class="line">spd =[                 <span class="number">380</span>       <span class="number">0.00132948037347175</span>;...</span><br><span class="line">                       <span class="number">390</span>       <span class="number">0.00164023432576807</span>;...</span><br><span class="line">                       <span class="number">400</span>       <span class="number">0.00199607408541092</span>;...</span><br><span class="line">                       <span class="number">410</span>       <span class="number">0.00239863299576014</span>;...</span><br><span class="line">                       <span class="number">420</span>       <span class="number">0.00284898784428011</span>;...</span><br><span class="line">                       <span class="number">430</span>       <span class="number">0.00334764547822949</span>;...</span><br><span class="line">                       <span class="number">440</span>       <span class="number">0.00389454498476917</span>;...</span><br><span class="line">                       <span class="number">450</span>        <span class="number">0.0044890736644276</span>;...</span><br><span class="line">                       <span class="number">460</span>       <span class="number">0.00513009474369056</span>;...</span><br><span class="line">                       <span class="number">470</span>       <span class="number">0.00581598464137424</span>;...</span><br><span class="line">                       <span class="number">480</span>       <span class="number">0.00654467759688934</span>;...</span><br><span class="line">                       <span class="number">490</span>       <span class="number">0.00731371555834619</span>;...</span><br><span class="line">                       <span class="number">500</span>       <span class="number">0.00812030138807687</span>;...</span><br><span class="line">                       <span class="number">510</span>       <span class="number">0.00896135364886274</span>;...</span><br><span class="line">                       <span class="number">520</span>       <span class="number">0.00983356146587939</span>;...</span><br><span class="line">                       <span class="number">530</span>        <span class="number">0.0107334382008557</span>;...</span><br><span class="line">                       <span class="number">540</span>        <span class="number">0.0116573729136429</span>;...</span><br><span class="line">                       <span class="number">550</span>        <span class="number">0.0126016788131223</span>;...</span><br><span class="line">                       <span class="number">560</span>        <span class="number">0.0135626381078808</span>;...</span><br><span class="line">                       <span class="number">570</span>        <span class="number">0.0145365428535139</span>;...</span><br><span class="line">                       <span class="number">580</span>        <span class="number">0.0155197315558729</span>;...</span><br><span class="line">                       <span class="number">590</span>        <span class="number">0.0165086214276558</span>;...</span><br><span class="line">                       <span class="number">600</span>        <span class="number">0.0174997363101301</span>;...</span><br><span class="line">                       <span class="number">610</span>        <span class="number">0.0184897303639286</span>;...</span><br><span class="line">                       <span class="number">620</span>        <span class="number">0.0194754077047119</span>;...</span><br><span class="line">                       <span class="number">630</span>        <span class="number">0.0204537382132532</span>;...</span><br><span class="line">                       <span class="number">640</span>        <span class="number">0.0214218697874947</span>;...</span><br><span class="line">                       <span class="number">650</span>         <span class="number">0.022377137328638</span>;...</span><br><span class="line">                       <span class="number">660</span>        <span class="number">0.0233170687665763</span>;...</span><br><span class="line">                       <span class="number">670</span>        <span class="number">0.0242393884339735</span>;...</span><br><span class="line">                       <span class="number">680</span>        <span class="number">0.0251420180949075</span>;...</span><br><span class="line">                       <span class="number">690</span>        <span class="number">0.0260230759248419</span>;...</span><br><span class="line">                       <span class="number">700</span>         <span class="number">0.026880873725211</span>;...</span><br><span class="line">                       <span class="number">710</span>        <span class="number">0.0277139126393038</span>;...</span><br><span class="line">                       <span class="number">720</span>        <span class="number">0.0285208776174515</span>;...</span><br><span class="line">                       <span class="number">730</span>        <span class="number">0.0293006308595934</span>;...</span><br><span class="line">                       <span class="number">740</span>        <span class="number">0.0300522044428256</span>;...</span><br><span class="line">                       <span class="number">750</span>        <span class="number">0.0307747923210527</span>;...</span><br><span class="line">                       <span class="number">760</span>        <span class="number">0.0314677418638086</span>;...</span><br><span class="line">                       <span class="number">770</span>        <span class="number">0.0321305450820022</span>;...</span><br><span class="line">                       <span class="number">780</span>        <span class="number">0.0327628296700076</span>];</span><br><span class="line">                   </span><br><span class="line">  wavelength_spd = spd(:,<span class="number">1</span>);</span><br><span class="line">  spd = spd(:,<span class="number">2</span>);</span><br><span class="line">       </span><br><span class="line">% First, obtain reference data values</span><br><span class="line">% The CIE <span class="number">1931</span> <span class="number">2</span> degree Standard Colorimetric Observer</span><br><span class="line">% [wavelength(nm)   xbar    ybar zbar]</span><br><span class="line">CIE31Table = [<span class="number">360</span> <span class="number">0.000130</span> <span class="number">0.000004</span> <span class="number">0.000606</span>;...</span><br><span class="line">            <span class="number">361</span> <span class="number">0.000146</span> <span class="number">0.000004</span> <span class="number">0.000681</span>;...</span><br><span class="line">            <span class="number">362</span> <span class="number">0.000164</span> <span class="number">0.000005</span> <span class="number">0.000765</span>;...</span><br><span class="line">            <span class="number">363</span> <span class="number">0.000184</span> <span class="number">0.000006</span> <span class="number">0.000860</span>;...</span><br><span class="line">            <span class="number">364</span> <span class="number">0.000207</span> <span class="number">0.000006</span> <span class="number">0.000967</span>;...</span><br><span class="line">            <span class="number">365</span> <span class="number">0.000232</span> <span class="number">0.000007</span> <span class="number">0.001086</span>;...</span><br><span class="line">            <span class="number">366</span> <span class="number">0.000261</span> <span class="number">0.000008</span> <span class="number">0.001221</span>;...</span><br><span class="line">            <span class="number">367</span> <span class="number">0.000293</span> <span class="number">0.000009</span> <span class="number">0.001373</span>;...</span><br><span class="line">            <span class="number">368</span> <span class="number">0.000329</span> <span class="number">0.000010</span> <span class="number">0.001544</span>;...</span><br><span class="line">            <span class="number">369</span> <span class="number">0.000370</span> <span class="number">0.000011</span> <span class="number">0.001734</span>;...</span><br><span class="line">            <span class="number">370</span> <span class="number">0.000415</span> <span class="number">0.000012</span> <span class="number">0.001946</span>;...</span><br><span class="line">            <span class="number">371</span> <span class="number">0.000464</span> <span class="number">0.000014</span> <span class="number">0.002178</span>;...</span><br><span class="line">            <span class="number">372</span> <span class="number">0.000519</span> <span class="number">0.000016</span> <span class="number">0.002436</span>;...</span><br><span class="line">            <span class="number">373</span> <span class="number">0.000582</span> <span class="number">0.000017</span> <span class="number">0.002732</span>;...</span><br><span class="line">            <span class="number">374</span> <span class="number">0.000655</span> <span class="number">0.000020</span> <span class="number">0.003078</span>;...</span><br><span class="line">            <span class="number">375</span> <span class="number">0.000742</span> <span class="number">0.000022</span> <span class="number">0.003486</span>;...</span><br><span class="line">            <span class="number">376</span> <span class="number">0.000845</span> <span class="number">0.000025</span> <span class="number">0.003975</span>;...</span><br><span class="line">            <span class="number">377</span> <span class="number">0.000965</span> <span class="number">0.000028</span> <span class="number">0.004541</span>;...</span><br><span class="line">            <span class="number">378</span> <span class="number">0.001095</span> <span class="number">0.000032</span> <span class="number">0.005158</span>;...</span><br><span class="line">            <span class="number">379</span> <span class="number">0.001231</span> <span class="number">0.000035</span> <span class="number">0.005803</span>;...</span><br><span class="line">            <span class="number">380</span> <span class="number">0.001368</span> <span class="number">0.000039</span> <span class="number">0.006450</span>;...</span><br><span class="line">            <span class="number">381</span> <span class="number">0.001502</span> <span class="number">0.000043</span> <span class="number">0.007083</span>;...</span><br><span class="line">            <span class="number">382</span> <span class="number">0.001642</span> <span class="number">0.000047</span> <span class="number">0.007745</span>;...</span><br><span class="line">            <span class="number">383</span> <span class="number">0.001802</span> <span class="number">0.000052</span> <span class="number">0.008501</span>;...</span><br><span class="line">            <span class="number">384</span> <span class="number">0.001996</span> <span class="number">0.000057</span> <span class="number">0.009415</span>;...</span><br><span class="line">            <span class="number">385</span> <span class="number">0.002236</span> <span class="number">0.000064</span> <span class="number">0.010550</span>;...</span><br><span class="line">            <span class="number">386</span> <span class="number">0.002535</span> <span class="number">0.000072</span> <span class="number">0.011966</span>;...</span><br><span class="line">            <span class="number">387</span> <span class="number">0.002893</span> <span class="number">0.000082</span> <span class="number">0.013656</span>;...</span><br><span class="line">            <span class="number">388</span> <span class="number">0.003301</span> <span class="number">0.000094</span> <span class="number">0.015588</span>;...</span><br><span class="line">            <span class="number">389</span> <span class="number">0.003753</span> <span class="number">0.000106</span> <span class="number">0.017730</span>;...</span><br><span class="line">            <span class="number">390</span> <span class="number">0.004243</span> <span class="number">0.000120</span> <span class="number">0.020050</span>;...</span><br><span class="line">            <span class="number">391</span> <span class="number">0.004762</span> <span class="number">0.000135</span> <span class="number">0.022511</span>;...</span><br><span class="line">            <span class="number">392</span> <span class="number">0.005330</span> <span class="number">0.000151</span> <span class="number">0.025203</span>;...</span><br><span class="line">            <span class="number">393</span> <span class="number">0.005979</span> <span class="number">0.000170</span> <span class="number">0.028280</span>;...</span><br><span class="line">            <span class="number">394</span> <span class="number">0.006741</span> <span class="number">0.000192</span> <span class="number">0.031897</span>;...</span><br><span class="line">            <span class="number">395</span> <span class="number">0.007650</span> <span class="number">0.000217</span> <span class="number">0.036210</span>;...</span><br><span class="line">            <span class="number">396</span> <span class="number">0.008751</span> <span class="number">0.000247</span> <span class="number">0.041438</span>;...</span><br><span class="line">            <span class="number">397</span> <span class="number">0.010029</span> <span class="number">0.000281</span> <span class="number">0.047504</span>;...</span><br><span class="line">            <span class="number">398</span> <span class="number">0.011422</span> <span class="number">0.000319</span> <span class="number">0.054120</span>;...</span><br><span class="line">            <span class="number">399</span> <span class="number">0.012869</span> <span class="number">0.000357</span> <span class="number">0.060998</span>;...</span><br><span class="line">            <span class="number">400</span> <span class="number">0.014310</span> <span class="number">0.000396</span> <span class="number">0.067850</span>;...</span><br><span class="line">            <span class="number">401</span> <span class="number">0.015704</span> <span class="number">0.000434</span> <span class="number">0.074486</span>;...</span><br><span class="line">            <span class="number">402</span> <span class="number">0.017147</span> <span class="number">0.000473</span> <span class="number">0.081362</span>;...</span><br><span class="line">            <span class="number">403</span> <span class="number">0.018781</span> <span class="number">0.000518</span> <span class="number">0.089154</span>;...</span><br><span class="line">            <span class="number">404</span> <span class="number">0.020748</span> <span class="number">0.000572</span> <span class="number">0.098540</span>;...</span><br><span class="line">            <span class="number">405</span> <span class="number">0.023190</span> <span class="number">0.000640</span> <span class="number">0.110200</span>;...</span><br><span class="line">            <span class="number">406</span> <span class="number">0.026207</span> <span class="number">0.000725</span> <span class="number">0.124613</span>;...</span><br><span class="line">            <span class="number">407</span> <span class="number">0.029782</span> <span class="number">0.000825</span> <span class="number">0.141702</span>;...</span><br><span class="line">            <span class="number">408</span> <span class="number">0.033881</span> <span class="number">0.000941</span> <span class="number">0.161303</span>;...</span><br><span class="line">            <span class="number">409</span> <span class="number">0.038468</span> <span class="number">0.001070</span> <span class="number">0.183257</span>;...</span><br><span class="line">            <span class="number">410</span> <span class="number">0.043510</span> <span class="number">0.001210</span> <span class="number">0.207400</span>;...</span><br><span class="line">            <span class="number">411</span> <span class="number">0.048996</span> <span class="number">0.001362</span> <span class="number">0.233692</span>;...</span><br><span class="line">            <span class="number">412</span> <span class="number">0.055023</span> <span class="number">0.001531</span> <span class="number">0.262611</span>;...</span><br><span class="line">            <span class="number">413</span> <span class="number">0.061719</span> <span class="number">0.001720</span> <span class="number">0.294775</span>;...</span><br><span class="line">            <span class="number">414</span> <span class="number">0.069212</span> <span class="number">0.001935</span> <span class="number">0.330799</span>;...</span><br><span class="line">            <span class="number">415</span> <span class="number">0.077630</span> <span class="number">0.002180</span> <span class="number">0.371300</span>;...</span><br><span class="line">            <span class="number">416</span> <span class="number">0.086958</span> <span class="number">0.002455</span> <span class="number">0.416209</span>;...</span><br><span class="line">            <span class="number">417</span> <span class="number">0.097177</span> <span class="number">0.002764</span> <span class="number">0.465464</span>;...</span><br><span class="line">            <span class="number">418</span> <span class="number">0.108406</span> <span class="number">0.003118</span> <span class="number">0.519695</span>;...</span><br><span class="line">            <span class="number">419</span> <span class="number">0.120767</span> <span class="number">0.003526</span> <span class="number">0.579530</span>;...</span><br><span class="line">            <span class="number">420</span> <span class="number">0.134380</span> <span class="number">0.004000</span> <span class="number">0.645600</span>;...</span><br><span class="line">            <span class="number">421</span> <span class="number">0.149358</span> <span class="number">0.004546</span> <span class="number">0.718484</span>;...</span><br><span class="line">            <span class="number">422</span> <span class="number">0.165396</span> <span class="number">0.005159</span> <span class="number">0.796713</span>;...</span><br><span class="line">            <span class="number">423</span> <span class="number">0.181983</span> <span class="number">0.005829</span> <span class="number">0.877846</span>;...</span><br><span class="line">            <span class="number">424</span> <span class="number">0.198611</span> <span class="number">0.006546</span> <span class="number">0.959439</span>;...</span><br><span class="line">            <span class="number">425</span> <span class="number">0.214770</span> <span class="number">0.007300</span> <span class="number">1.039050</span>;...</span><br><span class="line">            <span class="number">426</span> <span class="number">0.230187</span> <span class="number">0.008087</span> <span class="number">1.115367</span>;...</span><br><span class="line">            <span class="number">427</span> <span class="number">0.244880</span> <span class="number">0.008909</span> <span class="number">1.188497</span>;...</span><br><span class="line">            <span class="number">428</span> <span class="number">0.258777</span> <span class="number">0.009768</span> <span class="number">1.258123</span>;...</span><br><span class="line">            <span class="number">429</span> <span class="number">0.271808</span> <span class="number">0.010664</span> <span class="number">1.323930</span>;...</span><br><span class="line">            <span class="number">430</span> <span class="number">0.283900</span> <span class="number">0.011600</span> <span class="number">1.385600</span>;...</span><br><span class="line">            <span class="number">431</span> <span class="number">0.294944</span> <span class="number">0.012573</span> <span class="number">1.442635</span>;...</span><br><span class="line">            <span class="number">432</span> <span class="number">0.304897</span> <span class="number">0.013583</span> <span class="number">1.494804</span>;...</span><br><span class="line">            <span class="number">433</span> <span class="number">0.313787</span> <span class="number">0.014630</span> <span class="number">1.542190</span>;...</span><br><span class="line">            <span class="number">434</span> <span class="number">0.321645</span> <span class="number">0.015715</span> <span class="number">1.584881</span>;...</span><br><span class="line">            <span class="number">435</span> <span class="number">0.328500</span> <span class="number">0.016840</span> <span class="number">1.622960</span>;...</span><br><span class="line">            <span class="number">436</span> <span class="number">0.334351</span> <span class="number">0.018007</span> <span class="number">1.656405</span>;...</span><br><span class="line">            <span class="number">437</span> <span class="number">0.339210</span> <span class="number">0.019214</span> <span class="number">1.685296</span>;...</span><br><span class="line">            <span class="number">438</span> <span class="number">0.343121</span> <span class="number">0.020454</span> <span class="number">1.709875</span>;...</span><br><span class="line">            <span class="number">439</span> <span class="number">0.346130</span> <span class="number">0.021718</span> <span class="number">1.730382</span>;...</span><br><span class="line">            <span class="number">440</span> <span class="number">0.348280</span> <span class="number">0.023000</span> <span class="number">1.747060</span>;...</span><br><span class="line">            <span class="number">441</span> <span class="number">0.349600</span> <span class="number">0.024295</span> <span class="number">1.760045</span>;...</span><br><span class="line">            <span class="number">442</span> <span class="number">0.350147</span> <span class="number">0.025610</span> <span class="number">1.769623</span>;...</span><br><span class="line">            <span class="number">443</span> <span class="number">0.350013</span> <span class="number">0.026959</span> <span class="number">1.776264</span>;...</span><br><span class="line">            <span class="number">444</span> <span class="number">0.349287</span> <span class="number">0.028351</span> <span class="number">1.780433</span>;...</span><br><span class="line">            <span class="number">445</span> <span class="number">0.348060</span> <span class="number">0.029800</span> <span class="number">1.782600</span>;...</span><br><span class="line">            <span class="number">446</span> <span class="number">0.346373</span> <span class="number">0.031311</span> <span class="number">1.782968</span>;...</span><br><span class="line">            <span class="number">447</span> <span class="number">0.344262</span> <span class="number">0.032884</span> <span class="number">1.781700</span>;...</span><br><span class="line">            <span class="number">448</span> <span class="number">0.341809</span> <span class="number">0.034521</span> <span class="number">1.779198</span>;...</span><br><span class="line">            <span class="number">449</span> <span class="number">0.339094</span> <span class="number">0.036226</span> <span class="number">1.775867</span>;...</span><br><span class="line">            <span class="number">450</span> <span class="number">0.336200</span> <span class="number">0.038000</span> <span class="number">1.772110</span>;...</span><br><span class="line">            <span class="number">451</span> <span class="number">0.333198</span> <span class="number">0.039847</span> <span class="number">1.768259</span>;...</span><br><span class="line">            <span class="number">452</span> <span class="number">0.330041</span> <span class="number">0.041768</span> <span class="number">1.764039</span>;...</span><br><span class="line">            <span class="number">453</span> <span class="number">0.326636</span> <span class="number">0.043766</span> <span class="number">1.758944</span>;...</span><br><span class="line">            <span class="number">454</span> <span class="number">0.322887</span> <span class="number">0.045843</span> <span class="number">1.752466</span>;...</span><br><span class="line">            <span class="number">455</span> <span class="number">0.318700</span> <span class="number">0.048000</span> <span class="number">1.744100</span>;...</span><br><span class="line">            <span class="number">456</span> <span class="number">0.314025</span> <span class="number">0.050244</span> <span class="number">1.733559</span>;...</span><br><span class="line">            <span class="number">457</span> <span class="number">0.308884</span> <span class="number">0.052573</span> <span class="number">1.720858</span>;...</span><br><span class="line">            <span class="number">458</span> <span class="number">0.303290</span> <span class="number">0.054981</span> <span class="number">1.705937</span>;...</span><br><span class="line">            <span class="number">459</span> <span class="number">0.297258</span> <span class="number">0.057459</span> <span class="number">1.688737</span>;...</span><br><span class="line">            <span class="number">460</span> <span class="number">0.290800</span> <span class="number">0.060000</span> <span class="number">1.669200</span>;...</span><br><span class="line">            <span class="number">461</span> <span class="number">0.283970</span> <span class="number">0.062602</span> <span class="number">1.647529</span>;...</span><br><span class="line">            <span class="number">462</span> <span class="number">0.276721</span> <span class="number">0.065278</span> <span class="number">1.623413</span>;...</span><br><span class="line">            <span class="number">463</span> <span class="number">0.268918</span> <span class="number">0.068042</span> <span class="number">1.596022</span>;...</span><br><span class="line">            <span class="number">464</span> <span class="number">0.260423</span> <span class="number">0.070911</span> <span class="number">1.564528</span>;...</span><br><span class="line">            <span class="number">465</span> <span class="number">0.251100</span> <span class="number">0.073900</span> <span class="number">1.528100</span>;...</span><br><span class="line">            <span class="number">466</span> <span class="number">0.240847</span> <span class="number">0.077016</span> <span class="number">1.486111</span>;...</span><br><span class="line">            <span class="number">467</span> <span class="number">0.229851</span> <span class="number">0.080266</span> <span class="number">1.439521</span>;...</span><br><span class="line">            <span class="number">468</span> <span class="number">0.218407</span> <span class="number">0.083667</span> <span class="number">1.389880</span>;...</span><br><span class="line">            <span class="number">469</span> <span class="number">0.206812</span> <span class="number">0.087233</span> <span class="number">1.338736</span>;...</span><br><span class="line">            <span class="number">470</span> <span class="number">0.195360</span> <span class="number">0.090980</span> <span class="number">1.287640</span>;...</span><br><span class="line">            <span class="number">471</span> <span class="number">0.184214</span> <span class="number">0.094918</span> <span class="number">1.237422</span>;...</span><br><span class="line">            <span class="number">472</span> <span class="number">0.173327</span> <span class="number">0.099046</span> <span class="number">1.187824</span>;...</span><br><span class="line">            <span class="number">473</span> <span class="number">0.162688</span> <span class="number">0.103367</span> <span class="number">1.138761</span>;...</span><br><span class="line">            <span class="number">474</span> <span class="number">0.152283</span> <span class="number">0.107885</span> <span class="number">1.090148</span>;...</span><br><span class="line">            <span class="number">475</span> <span class="number">0.142100</span> <span class="number">0.112600</span> <span class="number">1.041900</span>;...</span><br><span class="line">            <span class="number">476</span> <span class="number">0.132179</span> <span class="number">0.117532</span> <span class="number">0.994198</span>;...</span><br><span class="line">            <span class="number">477</span> <span class="number">0.122570</span> <span class="number">0.122674</span> <span class="number">0.947347</span>;...</span><br><span class="line">            <span class="number">478</span> <span class="number">0.113275</span> <span class="number">0.127993</span> <span class="number">0.901453</span>;...</span><br><span class="line">            <span class="number">479</span> <span class="number">0.104298</span> <span class="number">0.133453</span> <span class="number">0.856619</span>;...</span><br><span class="line">            <span class="number">480</span> <span class="number">0.095640</span> <span class="number">0.139020</span> <span class="number">0.812950</span>;...</span><br><span class="line">            <span class="number">481</span> <span class="number">0.087300</span> <span class="number">0.144676</span> <span class="number">0.770517</span>;...</span><br><span class="line">            <span class="number">482</span> <span class="number">0.079308</span> <span class="number">0.150469</span> <span class="number">0.729445</span>;...</span><br><span class="line">            <span class="number">483</span> <span class="number">0.071718</span> <span class="number">0.156462</span> <span class="number">0.689914</span>;...</span><br><span class="line">            <span class="number">484</span> <span class="number">0.064581</span> <span class="number">0.162718</span> <span class="number">0.652105</span>;...</span><br><span class="line">            <span class="number">485</span> <span class="number">0.057950</span> <span class="number">0.169300</span> <span class="number">0.616200</span>;...</span><br><span class="line">            <span class="number">486</span> <span class="number">0.051862</span> <span class="number">0.176243</span> <span class="number">0.582329</span>;...</span><br><span class="line">            <span class="number">487</span> <span class="number">0.046282</span> <span class="number">0.183558</span> <span class="number">0.550416</span>;...</span><br><span class="line">            <span class="number">488</span> <span class="number">0.041151</span> <span class="number">0.191274</span> <span class="number">0.520338</span>;...</span><br><span class="line">            <span class="number">489</span> <span class="number">0.036413</span> <span class="number">0.199418</span> <span class="number">0.491967</span>;...</span><br><span class="line">            <span class="number">490</span> <span class="number">0.032010</span> <span class="number">0.208020</span> <span class="number">0.465180</span>;...</span><br><span class="line">            <span class="number">491</span> <span class="number">0.027917</span> <span class="number">0.217120</span> <span class="number">0.439925</span>;...</span><br><span class="line">            <span class="number">492</span> <span class="number">0.024144</span> <span class="number">0.226735</span> <span class="number">0.416184</span>;...</span><br><span class="line">            <span class="number">493</span> <span class="number">0.020687</span> <span class="number">0.236857</span> <span class="number">0.393882</span>;...</span><br><span class="line">            <span class="number">494</span> <span class="number">0.017540</span> <span class="number">0.247481</span> <span class="number">0.372946</span>;...</span><br><span class="line">            <span class="number">495</span> <span class="number">0.014700</span> <span class="number">0.258600</span> <span class="number">0.353300</span>;...</span><br><span class="line">            <span class="number">496</span> <span class="number">0.012162</span> <span class="number">0.270185</span> <span class="number">0.334858</span>;...</span><br><span class="line">            <span class="number">497</span> <span class="number">0.009920</span> <span class="number">0.282294</span> <span class="number">0.317552</span>;...</span><br><span class="line">            <span class="number">498</span> <span class="number">0.007967</span> <span class="number">0.295050</span> <span class="number">0.301337</span>;...</span><br><span class="line">            <span class="number">499</span> <span class="number">0.006296</span> <span class="number">0.308578</span> <span class="number">0.286169</span>;...</span><br><span class="line">            <span class="number">500</span> <span class="number">0.004900</span> <span class="number">0.323000</span> <span class="number">0.272000</span>;...</span><br><span class="line">            <span class="number">501</span> <span class="number">0.003777</span> <span class="number">0.338402</span> <span class="number">0.258817</span>;...</span><br><span class="line">            <span class="number">502</span> <span class="number">0.002945</span> <span class="number">0.354686</span> <span class="number">0.246484</span>;...</span><br><span class="line">            <span class="number">503</span> <span class="number">0.002425</span> <span class="number">0.371699</span> <span class="number">0.234772</span>;...</span><br><span class="line">            <span class="number">504</span> <span class="number">0.002236</span> <span class="number">0.389288</span> <span class="number">0.223453</span>;...</span><br><span class="line">            <span class="number">505</span> <span class="number">0.002400</span> <span class="number">0.407300</span> <span class="number">0.212300</span>;...</span><br><span class="line">            <span class="number">506</span> <span class="number">0.002926</span> <span class="number">0.425630</span> <span class="number">0.201169</span>;...</span><br><span class="line">            <span class="number">507</span> <span class="number">0.003837</span> <span class="number">0.444310</span> <span class="number">0.190120</span>;...</span><br><span class="line">            <span class="number">508</span> <span class="number">0.005175</span> <span class="number">0.463394</span> <span class="number">0.179225</span>;...</span><br><span class="line">            <span class="number">509</span> <span class="number">0.006982</span> <span class="number">0.482940</span> <span class="number">0.168561</span>;...</span><br><span class="line">            <span class="number">510</span> <span class="number">0.009300</span> <span class="number">0.503000</span> <span class="number">0.158200</span>;...</span><br><span class="line">            <span class="number">511</span> <span class="number">0.012149</span> <span class="number">0.523569</span> <span class="number">0.148138</span>;...</span><br><span class="line">            <span class="number">512</span> <span class="number">0.015536</span> <span class="number">0.544512</span> <span class="number">0.138376</span>;...</span><br><span class="line">            <span class="number">513</span> <span class="number">0.019478</span> <span class="number">0.565690</span> <span class="number">0.128994</span>;...</span><br><span class="line">            <span class="number">514</span> <span class="number">0.023993</span> <span class="number">0.586965</span> <span class="number">0.120075</span>;...</span><br><span class="line">            <span class="number">515</span> <span class="number">0.029100</span> <span class="number">0.608200</span> <span class="number">0.111700</span>;...</span><br><span class="line">            <span class="number">516</span> <span class="number">0.034815</span> <span class="number">0.629346</span> <span class="number">0.103905</span>;...</span><br><span class="line">            <span class="number">517</span> <span class="number">0.041120</span> <span class="number">0.650307</span> <span class="number">0.096667</span>;...</span><br><span class="line">            <span class="number">518</span> <span class="number">0.047985</span> <span class="number">0.670875</span> <span class="number">0.089983</span>;...</span><br><span class="line">            <span class="number">519</span> <span class="number">0.055379</span> <span class="number">0.690842</span> <span class="number">0.083845</span>;...</span><br><span class="line">            <span class="number">520</span> <span class="number">0.063270</span> <span class="number">0.710000</span> <span class="number">0.078250</span>;...</span><br><span class="line">            <span class="number">521</span> <span class="number">0.071635</span> <span class="number">0.728185</span> <span class="number">0.073209</span>;...</span><br><span class="line">            <span class="number">522</span> <span class="number">0.080462</span> <span class="number">0.745464</span> <span class="number">0.068678</span>;...</span><br><span class="line">            <span class="number">523</span> <span class="number">0.089740</span> <span class="number">0.761969</span> <span class="number">0.064568</span>;...</span><br><span class="line">            <span class="number">524</span> <span class="number">0.099456</span> <span class="number">0.777837</span> <span class="number">0.060788</span>;...</span><br><span class="line">            <span class="number">525</span> <span class="number">0.109600</span> <span class="number">0.793200</span> <span class="number">0.057250</span>;...</span><br><span class="line">            <span class="number">526</span> <span class="number">0.120167</span> <span class="number">0.808110</span> <span class="number">0.053904</span>;...</span><br><span class="line">            <span class="number">527</span> <span class="number">0.131114</span> <span class="number">0.822496</span> <span class="number">0.050747</span>;...</span><br><span class="line">            <span class="number">528</span> <span class="number">0.142368</span> <span class="number">0.836307</span> <span class="number">0.047753</span>;...</span><br><span class="line">            <span class="number">529</span> <span class="number">0.153854</span> <span class="number">0.849492</span> <span class="number">0.044899</span>;...</span><br><span class="line">            <span class="number">530</span> <span class="number">0.165500</span> <span class="number">0.862000</span> <span class="number">0.042160</span>;...</span><br><span class="line">            <span class="number">531</span> <span class="number">0.177257</span> <span class="number">0.873811</span> <span class="number">0.039507</span>;...</span><br><span class="line">            <span class="number">532</span> <span class="number">0.189140</span> <span class="number">0.884962</span> <span class="number">0.036936</span>;...</span><br><span class="line">            <span class="number">533</span> <span class="number">0.201169</span> <span class="number">0.895494</span> <span class="number">0.034458</span>;...</span><br><span class="line">            <span class="number">534</span> <span class="number">0.213366</span> <span class="number">0.905443</span> <span class="number">0.032089</span>;...</span><br><span class="line">            <span class="number">535</span> <span class="number">0.225750</span> <span class="number">0.914850</span> <span class="number">0.029840</span>;...</span><br><span class="line">            <span class="number">536</span> <span class="number">0.238321</span> <span class="number">0.923735</span> <span class="number">0.027712</span>;...</span><br><span class="line">            <span class="number">537</span> <span class="number">0.251067</span> <span class="number">0.932092</span> <span class="number">0.025694</span>;...</span><br><span class="line">            <span class="number">538</span> <span class="number">0.263992</span> <span class="number">0.939923</span> <span class="number">0.023787</span>;...</span><br><span class="line">            <span class="number">539</span> <span class="number">0.277102</span> <span class="number">0.947225</span> <span class="number">0.021989</span>;...</span><br><span class="line">            <span class="number">540</span> <span class="number">0.290400</span> <span class="number">0.954000</span> <span class="number">0.020300</span>;...</span><br><span class="line">            <span class="number">541</span> <span class="number">0.303891</span> <span class="number">0.960256</span> <span class="number">0.018718</span>;...</span><br><span class="line">            <span class="number">542</span> <span class="number">0.317573</span> <span class="number">0.966007</span> <span class="number">0.017240</span>;...</span><br><span class="line">            <span class="number">543</span> <span class="number">0.331438</span> <span class="number">0.971261</span> <span class="number">0.015864</span>;...</span><br><span class="line">            <span class="number">544</span> <span class="number">0.345483</span> <span class="number">0.976023</span> <span class="number">0.014585</span>;...</span><br><span class="line">            <span class="number">545</span> <span class="number">0.359700</span> <span class="number">0.980300</span> <span class="number">0.013400</span>;...</span><br><span class="line">            <span class="number">546</span> <span class="number">0.374084</span> <span class="number">0.984092</span> <span class="number">0.012307</span>;...</span><br><span class="line">            <span class="number">547</span> <span class="number">0.388640</span> <span class="number">0.987418</span> <span class="number">0.011302</span>;...</span><br><span class="line">            <span class="number">548</span> <span class="number">0.403378</span> <span class="number">0.990313</span> <span class="number">0.010378</span>;...</span><br><span class="line">            <span class="number">549</span> <span class="number">0.418312</span> <span class="number">0.992812</span> <span class="number">0.009529</span>;...</span><br><span class="line">            <span class="number">550</span> <span class="number">0.433450</span> <span class="number">0.994950</span> <span class="number">0.008750</span>;...</span><br><span class="line">            <span class="number">551</span> <span class="number">0.448795</span> <span class="number">0.996711</span> <span class="number">0.008035</span>;...</span><br><span class="line">            <span class="number">552</span> <span class="number">0.464336</span> <span class="number">0.998098</span> <span class="number">0.007382</span>;...</span><br><span class="line">            <span class="number">553</span> <span class="number">0.480064</span> <span class="number">0.999112</span> <span class="number">0.006785</span>;...</span><br><span class="line">            <span class="number">554</span> <span class="number">0.495971</span> <span class="number">0.999748</span> <span class="number">0.006243</span>;...</span><br><span class="line">            <span class="number">555</span> <span class="number">0.512050</span> <span class="number">1.000000</span> <span class="number">0.005750</span>;...</span><br><span class="line">            <span class="number">556</span> <span class="number">0.528296</span> <span class="number">0.999857</span> <span class="number">0.005304</span>;...</span><br><span class="line">            <span class="number">557</span> <span class="number">0.544692</span> <span class="number">0.999305</span> <span class="number">0.004900</span>;...</span><br><span class="line">            <span class="number">558</span> <span class="number">0.561209</span> <span class="number">0.998325</span> <span class="number">0.004534</span>;...</span><br><span class="line">            <span class="number">559</span> <span class="number">0.577821</span> <span class="number">0.996899</span> <span class="number">0.004202</span>;...</span><br><span class="line">            <span class="number">560</span> <span class="number">0.594500</span> <span class="number">0.995000</span> <span class="number">0.003900</span>;...</span><br><span class="line">            <span class="number">561</span> <span class="number">0.611221</span> <span class="number">0.992601</span> <span class="number">0.003623</span>;...</span><br><span class="line">            <span class="number">562</span> <span class="number">0.627976</span> <span class="number">0.989743</span> <span class="number">0.003371</span>;...</span><br><span class="line">            <span class="number">563</span> <span class="number">0.644760</span> <span class="number">0.986444</span> <span class="number">0.003141</span>;...</span><br><span class="line">            <span class="number">564</span> <span class="number">0.661570</span> <span class="number">0.982724</span> <span class="number">0.002935</span>;...</span><br><span class="line">            <span class="number">565</span> <span class="number">0.678400</span> <span class="number">0.978600</span> <span class="number">0.002750</span>;...</span><br><span class="line">            <span class="number">566</span> <span class="number">0.695239</span> <span class="number">0.974084</span> <span class="number">0.002585</span>;...</span><br><span class="line">            <span class="number">567</span> <span class="number">0.712059</span> <span class="number">0.969171</span> <span class="number">0.002439</span>;...</span><br><span class="line">            <span class="number">568</span> <span class="number">0.728828</span> <span class="number">0.963857</span> <span class="number">0.002309</span>;...</span><br><span class="line">            <span class="number">569</span> <span class="number">0.745519</span> <span class="number">0.958135</span> <span class="number">0.002197</span>;...</span><br><span class="line">            <span class="number">570</span> <span class="number">0.762100</span> <span class="number">0.952000</span> <span class="number">0.002100</span>;...</span><br><span class="line">            <span class="number">571</span> <span class="number">0.778543</span> <span class="number">0.945450</span> <span class="number">0.002018</span>;...</span><br><span class="line">            <span class="number">572</span> <span class="number">0.794826</span> <span class="number">0.938499</span> <span class="number">0.001948</span>;...</span><br><span class="line">            <span class="number">573</span> <span class="number">0.810926</span> <span class="number">0.931163</span> <span class="number">0.001890</span>;...</span><br><span class="line">            <span class="number">574</span> <span class="number">0.826825</span> <span class="number">0.923458</span> <span class="number">0.001841</span>;...</span><br><span class="line">            <span class="number">575</span> <span class="number">0.842500</span> <span class="number">0.915400</span> <span class="number">0.001800</span>;...</span><br><span class="line">            <span class="number">576</span> <span class="number">0.857932</span> <span class="number">0.907006</span> <span class="number">0.001766</span>;...</span><br><span class="line">            <span class="number">577</span> <span class="number">0.873082</span> <span class="number">0.898277</span> <span class="number">0.001738</span>;...</span><br><span class="line">            <span class="number">578</span> <span class="number">0.887894</span> <span class="number">0.889205</span> <span class="number">0.001711</span>;...</span><br><span class="line">            <span class="number">579</span> <span class="number">0.902318</span> <span class="number">0.879782</span> <span class="number">0.001683</span>;...</span><br><span class="line">            <span class="number">580</span> <span class="number">0.916300</span> <span class="number">0.870000</span> <span class="number">0.001650</span>;...</span><br><span class="line">            <span class="number">581</span> <span class="number">0.929800</span> <span class="number">0.859861</span> <span class="number">0.001610</span>;...</span><br><span class="line">            <span class="number">582</span> <span class="number">0.942798</span> <span class="number">0.849392</span> <span class="number">0.001564</span>;...</span><br><span class="line">            <span class="number">583</span> <span class="number">0.955278</span> <span class="number">0.838622</span> <span class="number">0.001514</span>;...</span><br><span class="line">            <span class="number">584</span> <span class="number">0.967218</span> <span class="number">0.827581</span> <span class="number">0.001459</span>;...</span><br><span class="line">            <span class="number">585</span> <span class="number">0.978600</span> <span class="number">0.816300</span> <span class="number">0.001400</span>;...</span><br><span class="line">            <span class="number">586</span> <span class="number">0.989386</span> <span class="number">0.804795</span> <span class="number">0.001337</span>;...</span><br><span class="line">            <span class="number">587</span> <span class="number">0.999549</span> <span class="number">0.793082</span> <span class="number">0.001270</span>;...</span><br><span class="line">            <span class="number">588</span> <span class="number">1.009089</span> <span class="number">0.781192</span> <span class="number">0.001205</span>;...</span><br><span class="line">            <span class="number">589</span> <span class="number">1.018006</span> <span class="number">0.769155</span> <span class="number">0.001147</span>;...</span><br><span class="line">            <span class="number">590</span> <span class="number">1.026300</span> <span class="number">0.757000</span> <span class="number">0.001100</span>;...</span><br><span class="line">            <span class="number">591</span> <span class="number">1.033983</span> <span class="number">0.744754</span> <span class="number">0.001069</span>;...</span><br><span class="line">            <span class="number">592</span> <span class="number">1.040986</span> <span class="number">0.732422</span> <span class="number">0.001049</span>;...</span><br><span class="line">            <span class="number">593</span> <span class="number">1.047188</span> <span class="number">0.720004</span> <span class="number">0.001036</span>;...</span><br><span class="line">            <span class="number">594</span> <span class="number">1.052467</span> <span class="number">0.707496</span> <span class="number">0.001021</span>;...</span><br><span class="line">            <span class="number">595</span> <span class="number">1.056700</span> <span class="number">0.694900</span> <span class="number">0.001000</span>;...</span><br><span class="line">            <span class="number">596</span> <span class="number">1.059794</span> <span class="number">0.682219</span> <span class="number">0.000969</span>;...</span><br><span class="line">            <span class="number">597</span> <span class="number">1.061799</span> <span class="number">0.669472</span> <span class="number">0.000930</span>;...</span><br><span class="line">            <span class="number">598</span> <span class="number">1.062807</span> <span class="number">0.656674</span> <span class="number">0.000887</span>;...</span><br><span class="line">            <span class="number">599</span> <span class="number">1.062910</span> <span class="number">0.643845</span> <span class="number">0.000843</span>;...</span><br><span class="line">            <span class="number">600</span> <span class="number">1.062200</span> <span class="number">0.631000</span> <span class="number">0.000800</span>;...</span><br><span class="line">            <span class="number">601</span> <span class="number">1.060735</span> <span class="number">0.618155</span> <span class="number">0.000761</span>;...</span><br><span class="line">            <span class="number">602</span> <span class="number">1.058444</span> <span class="number">0.605314</span> <span class="number">0.000724</span>;...</span><br><span class="line">            <span class="number">603</span> <span class="number">1.055224</span> <span class="number">0.592476</span> <span class="number">0.000686</span>;...</span><br><span class="line">            <span class="number">604</span> <span class="number">1.050977</span> <span class="number">0.579638</span> <span class="number">0.000645</span>;...</span><br><span class="line">            <span class="number">605</span> <span class="number">1.045600</span> <span class="number">0.566800</span> <span class="number">0.000600</span>;...</span><br><span class="line">            <span class="number">606</span> <span class="number">1.039037</span> <span class="number">0.553961</span> <span class="number">0.000548</span>;...</span><br><span class="line">            <span class="number">607</span> <span class="number">1.031361</span> <span class="number">0.541137</span> <span class="number">0.000492</span>;...</span><br><span class="line">            <span class="number">608</span> <span class="number">1.022666</span> <span class="number">0.528353</span> <span class="number">0.000435</span>;...</span><br><span class="line">            <span class="number">609</span> <span class="number">1.013048</span> <span class="number">0.515632</span> <span class="number">0.000383</span>;...</span><br><span class="line">            <span class="number">610</span> <span class="number">1.002600</span> <span class="number">0.503000</span> <span class="number">0.000340</span>;...</span><br><span class="line">            <span class="number">611</span> <span class="number">0.991367</span> <span class="number">0.490469</span> <span class="number">0.000307</span>;...</span><br><span class="line">            <span class="number">612</span> <span class="number">0.979331</span> <span class="number">0.478030</span> <span class="number">0.000283</span>;...</span><br><span class="line">            <span class="number">613</span> <span class="number">0.966492</span> <span class="number">0.465678</span> <span class="number">0.000265</span>;...</span><br><span class="line">            <span class="number">614</span> <span class="number">0.952848</span> <span class="number">0.453403</span> <span class="number">0.000252</span>;...</span><br><span class="line">            <span class="number">615</span> <span class="number">0.938400</span> <span class="number">0.441200</span> <span class="number">0.000240</span>;...</span><br><span class="line">            <span class="number">616</span> <span class="number">0.923194</span> <span class="number">0.429080</span> <span class="number">0.000230</span>;...</span><br><span class="line">            <span class="number">617</span> <span class="number">0.907244</span> <span class="number">0.417036</span> <span class="number">0.000221</span>;...</span><br><span class="line">            <span class="number">618</span> <span class="number">0.890502</span> <span class="number">0.405032</span> <span class="number">0.000212</span>;...</span><br><span class="line">            <span class="number">619</span> <span class="number">0.872920</span> <span class="number">0.393032</span> <span class="number">0.000202</span>;...</span><br><span class="line">            <span class="number">620</span> <span class="number">0.854450</span> <span class="number">0.381000</span> <span class="number">0.000190</span>;...</span><br><span class="line">            <span class="number">621</span> <span class="number">0.835084</span> <span class="number">0.368918</span> <span class="number">0.000174</span>;...</span><br><span class="line">            <span class="number">622</span> <span class="number">0.814946</span> <span class="number">0.356827</span> <span class="number">0.000156</span>;...</span><br><span class="line">            <span class="number">623</span> <span class="number">0.794186</span> <span class="number">0.344777</span> <span class="number">0.000136</span>;...</span><br><span class="line">            <span class="number">624</span> <span class="number">0.772954</span> <span class="number">0.332818</span> <span class="number">0.000117</span>;...</span><br><span class="line">            <span class="number">625</span> <span class="number">0.751400</span> <span class="number">0.321000</span> <span class="number">0.000100</span>;...</span><br><span class="line">            <span class="number">626</span> <span class="number">0.729584</span> <span class="number">0.309338</span> <span class="number">0.000086</span>;...</span><br><span class="line">            <span class="number">627</span> <span class="number">0.707589</span> <span class="number">0.297850</span> <span class="number">0.000075</span>;...</span><br><span class="line">            <span class="number">628</span> <span class="number">0.685602</span> <span class="number">0.286594</span> <span class="number">0.000065</span>;...</span><br><span class="line">            <span class="number">629</span> <span class="number">0.663810</span> <span class="number">0.275624</span> <span class="number">0.000057</span>;...</span><br><span class="line">            <span class="number">630</span> <span class="number">0.642400</span> <span class="number">0.265000</span> <span class="number">0.000050</span>;...</span><br><span class="line">            <span class="number">631</span> <span class="number">0.621515</span> <span class="number">0.254763</span> <span class="number">0.000044</span>;...</span><br><span class="line">            <span class="number">632</span> <span class="number">0.601114</span> <span class="number">0.244890</span> <span class="number">0.000039</span>;...</span><br><span class="line">            <span class="number">633</span> <span class="number">0.581105</span> <span class="number">0.235334</span> <span class="number">0.000036</span>;...</span><br><span class="line">            <span class="number">634</span> <span class="number">0.561398</span> <span class="number">0.226053</span> <span class="number">0.000033</span>;...</span><br><span class="line">            <span class="number">635</span> <span class="number">0.541900</span> <span class="number">0.217000</span> <span class="number">0.000030</span>;...</span><br><span class="line">            <span class="number">636</span> <span class="number">0.522599</span> <span class="number">0.208162</span> <span class="number">0.000028</span>;...</span><br><span class="line">            <span class="number">637</span> <span class="number">0.503546</span> <span class="number">0.199549</span> <span class="number">0.000026</span>;...</span><br><span class="line">            <span class="number">638</span> <span class="number">0.484744</span> <span class="number">0.191155</span> <span class="number">0.000024</span>;...</span><br><span class="line">            <span class="number">639</span> <span class="number">0.466194</span> <span class="number">0.182974</span> <span class="number">0.000022</span>;...</span><br><span class="line">            <span class="number">640</span> <span class="number">0.447900</span> <span class="number">0.175000</span> <span class="number">0.000020</span>;...</span><br><span class="line">            <span class="number">641</span> <span class="number">0.429861</span> <span class="number">0.167224</span> <span class="number">0.000018</span>;...</span><br><span class="line">            <span class="number">642</span> <span class="number">0.412098</span> <span class="number">0.159646</span> <span class="number">0.000016</span>;...</span><br><span class="line">            <span class="number">643</span> <span class="number">0.394644</span> <span class="number">0.152278</span> <span class="number">0.000014</span>;...</span><br><span class="line">            <span class="number">644</span> <span class="number">0.377533</span> <span class="number">0.145126</span> <span class="number">0.000012</span>;...</span><br><span class="line">            <span class="number">645</span> <span class="number">0.360800</span> <span class="number">0.138200</span> <span class="number">0.000010</span>;...</span><br><span class="line">            <span class="number">646</span> <span class="number">0.344456</span> <span class="number">0.131500</span> <span class="number">0.000008</span>;...</span><br><span class="line">            <span class="number">647</span> <span class="number">0.328517</span> <span class="number">0.125025</span> <span class="number">0.000005</span>;...</span><br><span class="line">            <span class="number">648</span> <span class="number">0.313019</span> <span class="number">0.118779</span> <span class="number">0.000003</span>;...</span><br><span class="line">            <span class="number">649</span> <span class="number">0.298001</span> <span class="number">0.112769</span> <span class="number">0.000001</span>;...</span><br><span class="line">            <span class="number">650</span> <span class="number">0.283500</span> <span class="number">0.107000</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">651</span> <span class="number">0.269545</span> <span class="number">0.101476</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">652</span> <span class="number">0.256118</span> <span class="number">0.096189</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">653</span> <span class="number">0.243190</span> <span class="number">0.091123</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">654</span> <span class="number">0.230727</span> <span class="number">0.086265</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">655</span> <span class="number">0.218700</span> <span class="number">0.081600</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">656</span> <span class="number">0.207097</span> <span class="number">0.077121</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">657</span> <span class="number">0.195923</span> <span class="number">0.072826</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">658</span> <span class="number">0.185171</span> <span class="number">0.068710</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">659</span> <span class="number">0.174832</span> <span class="number">0.064770</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">660</span> <span class="number">0.164900</span> <span class="number">0.061000</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">661</span> <span class="number">0.155367</span> <span class="number">0.057396</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">662</span> <span class="number">0.146230</span> <span class="number">0.053955</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">663</span> <span class="number">0.137490</span> <span class="number">0.050674</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">664</span> <span class="number">0.129147</span> <span class="number">0.047550</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">665</span> <span class="number">0.121200</span> <span class="number">0.044580</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">666</span> <span class="number">0.113640</span> <span class="number">0.041759</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">667</span> <span class="number">0.106465</span> <span class="number">0.039085</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">668</span> <span class="number">0.099690</span> <span class="number">0.036564</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">669</span> <span class="number">0.093331</span> <span class="number">0.034200</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">670</span> <span class="number">0.087400</span> <span class="number">0.032000</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">671</span> <span class="number">0.081901</span> <span class="number">0.029963</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">672</span> <span class="number">0.076804</span> <span class="number">0.028077</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">673</span> <span class="number">0.072077</span> <span class="number">0.026329</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">674</span> <span class="number">0.067687</span> <span class="number">0.024708</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">675</span> <span class="number">0.063600</span> <span class="number">0.023200</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">676</span> <span class="number">0.059807</span> <span class="number">0.021801</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">677</span> <span class="number">0.056282</span> <span class="number">0.020501</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">678</span> <span class="number">0.052971</span> <span class="number">0.019281</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">679</span> <span class="number">0.049819</span> <span class="number">0.018121</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">680</span> <span class="number">0.046770</span> <span class="number">0.017000</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">681</span> <span class="number">0.043784</span> <span class="number">0.015904</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">682</span> <span class="number">0.040875</span> <span class="number">0.014837</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">683</span> <span class="number">0.038073</span> <span class="number">0.013811</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">684</span> <span class="number">0.035405</span> <span class="number">0.012835</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">685</span> <span class="number">0.032900</span> <span class="number">0.011920</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">686</span> <span class="number">0.030564</span> <span class="number">0.011068</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">687</span> <span class="number">0.028381</span> <span class="number">0.010273</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">688</span> <span class="number">0.026345</span> <span class="number">0.009533</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">689</span> <span class="number">0.024453</span> <span class="number">0.008846</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">690</span> <span class="number">0.022700</span> <span class="number">0.008210</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">691</span> <span class="number">0.021084</span> <span class="number">0.007624</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">692</span> <span class="number">0.019600</span> <span class="number">0.007085</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">693</span> <span class="number">0.018237</span> <span class="number">0.006591</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">694</span> <span class="number">0.016987</span> <span class="number">0.006138</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">695</span> <span class="number">0.015840</span> <span class="number">0.005723</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">696</span> <span class="number">0.014791</span> <span class="number">0.005343</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">697</span> <span class="number">0.013831</span> <span class="number">0.004996</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">698</span> <span class="number">0.012949</span> <span class="number">0.004676</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">699</span> <span class="number">0.012129</span> <span class="number">0.004380</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">700</span> <span class="number">0.011359</span> <span class="number">0.004102</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">701</span> <span class="number">0.010629</span> <span class="number">0.003838</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">702</span> <span class="number">0.009939</span> <span class="number">0.003589</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">703</span> <span class="number">0.009288</span> <span class="number">0.003354</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">704</span> <span class="number">0.008679</span> <span class="number">0.003134</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">705</span> <span class="number">0.008111</span> <span class="number">0.002929</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">706</span> <span class="number">0.007582</span> <span class="number">0.002738</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">707</span> <span class="number">0.007089</span> <span class="number">0.002560</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">708</span> <span class="number">0.006627</span> <span class="number">0.002393</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">709</span> <span class="number">0.006195</span> <span class="number">0.002237</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">710</span> <span class="number">0.005790</span> <span class="number">0.002091</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">711</span> <span class="number">0.005410</span> <span class="number">0.001954</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">712</span> <span class="number">0.005053</span> <span class="number">0.001825</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">713</span> <span class="number">0.004718</span> <span class="number">0.001704</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">714</span> <span class="number">0.004404</span> <span class="number">0.001590</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">715</span> <span class="number">0.004109</span> <span class="number">0.001484</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">716</span> <span class="number">0.003834</span> <span class="number">0.001384</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">717</span> <span class="number">0.003576</span> <span class="number">0.001291</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">718</span> <span class="number">0.003334</span> <span class="number">0.001204</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">719</span> <span class="number">0.003109</span> <span class="number">0.001123</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">720</span> <span class="number">0.002899</span> <span class="number">0.001047</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">721</span> <span class="number">0.002704</span> <span class="number">0.000977</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">722</span> <span class="number">0.002523</span> <span class="number">0.000911</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">723</span> <span class="number">0.002354</span> <span class="number">0.000850</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">724</span> <span class="number">0.002197</span> <span class="number">0.000793</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">725</span> <span class="number">0.002049</span> <span class="number">0.000740</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">726</span> <span class="number">0.001911</span> <span class="number">0.000690</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">727</span> <span class="number">0.001781</span> <span class="number">0.000643</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">728</span> <span class="number">0.001660</span> <span class="number">0.000599</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">729</span> <span class="number">0.001546</span> <span class="number">0.000558</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">730</span> <span class="number">0.001440</span> <span class="number">0.000520</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">731</span> <span class="number">0.001340</span> <span class="number">0.000484</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">732</span> <span class="number">0.001246</span> <span class="number">0.000450</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">733</span> <span class="number">0.001158</span> <span class="number">0.000418</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">734</span> <span class="number">0.001076</span> <span class="number">0.000389</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">735</span> <span class="number">0.001000</span> <span class="number">0.000361</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">736</span> <span class="number">0.000929</span> <span class="number">0.000335</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">737</span> <span class="number">0.000862</span> <span class="number">0.000311</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">738</span> <span class="number">0.000801</span> <span class="number">0.000289</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">739</span> <span class="number">0.000743</span> <span class="number">0.000268</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">740</span> <span class="number">0.000690</span> <span class="number">0.000249</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">741</span> <span class="number">0.000641</span> <span class="number">0.000231</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">742</span> <span class="number">0.000595</span> <span class="number">0.000215</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">743</span> <span class="number">0.000552</span> <span class="number">0.000199</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">744</span> <span class="number">0.000512</span> <span class="number">0.000185</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">745</span> <span class="number">0.000476</span> <span class="number">0.000172</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">746</span> <span class="number">0.000442</span> <span class="number">0.000160</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">747</span> <span class="number">0.000412</span> <span class="number">0.000149</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">748</span> <span class="number">0.000383</span> <span class="number">0.000138</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">749</span> <span class="number">0.000357</span> <span class="number">0.000129</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">750</span> <span class="number">0.000332</span> <span class="number">0.000120</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">751</span> <span class="number">0.000310</span> <span class="number">0.000112</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">752</span> <span class="number">0.000289</span> <span class="number">0.000104</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">753</span> <span class="number">0.000270</span> <span class="number">0.000097</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">754</span> <span class="number">0.000252</span> <span class="number">0.000091</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">755</span> <span class="number">0.000235</span> <span class="number">0.000085</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">756</span> <span class="number">0.000219</span> <span class="number">0.000079</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">757</span> <span class="number">0.000205</span> <span class="number">0.000074</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">758</span> <span class="number">0.000191</span> <span class="number">0.000069</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">759</span> <span class="number">0.000178</span> <span class="number">0.000064</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">760</span> <span class="number">0.000166</span> <span class="number">0.000060</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">761</span> <span class="number">0.000155</span> <span class="number">0.000056</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">762</span> <span class="number">0.000145</span> <span class="number">0.000052</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">763</span> <span class="number">0.000135</span> <span class="number">0.000049</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">764</span> <span class="number">0.000126</span> <span class="number">0.000045</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">765</span> <span class="number">0.000117</span> <span class="number">0.000042</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">766</span> <span class="number">0.000110</span> <span class="number">0.000040</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">767</span> <span class="number">0.000102</span> <span class="number">0.000037</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">768</span> <span class="number">0.000095</span> <span class="number">0.000034</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">769</span> <span class="number">0.000089</span> <span class="number">0.000032</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">770</span> <span class="number">0.000083</span> <span class="number">0.000030</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">771</span> <span class="number">0.000078</span> <span class="number">0.000028</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">772</span> <span class="number">0.000072</span> <span class="number">0.000026</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">773</span> <span class="number">0.000067</span> <span class="number">0.000024</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">774</span> <span class="number">0.000063</span> <span class="number">0.000023</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">775</span> <span class="number">0.000059</span> <span class="number">0.000021</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">776</span> <span class="number">0.000055</span> <span class="number">0.000020</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">777</span> <span class="number">0.000051</span> <span class="number">0.000018</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">778</span> <span class="number">0.000048</span> <span class="number">0.000017</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">779</span> <span class="number">0.000044</span> <span class="number">0.000016</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">780</span> <span class="number">0.000042</span> <span class="number">0.000015</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">781</span> <span class="number">0.000039</span> <span class="number">0.000014</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">782</span> <span class="number">0.000036</span> <span class="number">0.000013</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">783</span> <span class="number">0.000034</span> <span class="number">0.000012</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">784</span> <span class="number">0.000031</span> <span class="number">0.000011</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">785</span> <span class="number">0.000029</span> <span class="number">0.000011</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">786</span> <span class="number">0.000027</span> <span class="number">0.000010</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">787</span> <span class="number">0.000026</span> <span class="number">0.000009</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">788</span> <span class="number">0.000024</span> <span class="number">0.000009</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">789</span> <span class="number">0.000022</span> <span class="number">0.000008</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">790</span> <span class="number">0.000021</span> <span class="number">0.000007</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">791</span> <span class="number">0.000019</span> <span class="number">0.000007</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">792</span> <span class="number">0.000018</span> <span class="number">0.000006</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">793</span> <span class="number">0.000017</span> <span class="number">0.000006</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">794</span> <span class="number">0.000016</span> <span class="number">0.000006</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">795</span> <span class="number">0.000015</span> <span class="number">0.000005</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">796</span> <span class="number">0.000014</span> <span class="number">0.000005</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">797</span> <span class="number">0.000013</span> <span class="number">0.000005</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">798</span> <span class="number">0.000012</span> <span class="number">0.000004</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">799</span> <span class="number">0.000011</span> <span class="number">0.000004</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">800</span> <span class="number">0.000010</span> <span class="number">0.000004</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">801</span> <span class="number">0.000010</span> <span class="number">0.000003</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">802</span> <span class="number">0.000009</span> <span class="number">0.000003</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">803</span> <span class="number">0.000008</span> <span class="number">0.000003</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">804</span> <span class="number">0.000008</span> <span class="number">0.000003</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">805</span> <span class="number">0.000007</span> <span class="number">0.000003</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">806</span> <span class="number">0.000007</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">807</span> <span class="number">0.000006</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">808</span> <span class="number">0.000006</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">809</span> <span class="number">0.000005</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">810</span> <span class="number">0.000005</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">811</span> <span class="number">0.000005</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">812</span> <span class="number">0.000004</span> <span class="number">0.000002</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">813</span> <span class="number">0.000004</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">814</span> <span class="number">0.000004</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">815</span> <span class="number">0.000004</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">816</span> <span class="number">0.000003</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">817</span> <span class="number">0.000003</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">818</span> <span class="number">0.000003</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">819</span> <span class="number">0.000003</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">820</span> <span class="number">0.000003</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">821</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">822</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">823</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">824</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">825</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">826</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">827</span> <span class="number">0.000002</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">828</span> <span class="number">0.000001</span> <span class="number">0.000001</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">829</span> <span class="number">0.000001</span> <span class="number">0.000000</span> <span class="number">0.000000</span>;...</span><br><span class="line">            <span class="number">830</span> <span class="number">0.000001</span> <span class="number">0.000000</span> <span class="number">0.000000</span>];</span><br><span class="line">        wavelength = CIE31Table(:,<span class="number">1</span>);</span><br><span class="line">        xbar = CIE31Table(:,<span class="number">2</span>);</span><br><span class="line">        ybar = CIE31Table(:,<span class="number">3</span>);</span><br><span class="line">        zbar = CIE31Table(:,<span class="number">4</span>);</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">% The spectral reflectance data of <span class="number">14</span> color test samples <span class="keyword">for</span> CRI</span><br><span class="line">% [wavelength (nm) TCS1 TCS2 TCS3 ... TCS14]</span><br><span class="line">TCS =  [<span class="number">360</span> <span class="number">116</span>  <span class="number">53</span>  <span class="number">58</span>  <span class="number">57</span> <span class="number">143</span>  <span class="number">79</span> <span class="number">150</span>  <span class="number">75</span>  <span class="number">69</span>  <span class="number">42</span>  <span class="number">74</span> <span class="number">189</span>  <span class="number">71</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">365</span> <span class="number">136</span>  <span class="number">55</span>  <span class="number">59</span>  <span class="number">59</span> <span class="number">187</span>  <span class="number">81</span> <span class="number">177</span>  <span class="number">78</span>  <span class="number">72</span>  <span class="number">43</span>  <span class="number">79</span> <span class="number">175</span>  <span class="number">76</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">370</span> <span class="number">159</span>  <span class="number">59</span>  <span class="number">61</span>  <span class="number">62</span> <span class="number">233</span>  <span class="number">89</span> <span class="number">218</span>  <span class="number">84</span>  <span class="number">73</span>  <span class="number">45</span>  <span class="number">86</span> <span class="number">158</span>  <span class="number">82</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">375</span> <span class="number">190</span>  <span class="number">64</span>  <span class="number">63</span>  <span class="number">67</span> <span class="number">269</span> <span class="number">113</span> <span class="number">293</span>  <span class="number">90</span>  <span class="number">70</span>  <span class="number">47</span>  <span class="number">98</span> <span class="number">139</span>  <span class="number">90</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">380</span> <span class="number">219</span>  <span class="number">70</span>  <span class="number">65</span>  <span class="number">74</span> <span class="number">295</span> <span class="number">151</span> <span class="number">378</span> <span class="number">104</span>  <span class="number">66</span>  <span class="number">50</span> <span class="number">111</span> <span class="number">120</span> <span class="number">104</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">385</span> <span class="number">239</span>  <span class="number">79</span>  <span class="number">68</span>  <span class="number">83</span> <span class="number">306</span> <span class="number">203</span> <span class="number">459</span> <span class="number">129</span>  <span class="number">62</span>  <span class="number">54</span> <span class="number">121</span> <span class="number">103</span> <span class="number">127</span>  <span class="number">36</span>;...</span><br><span class="line">        <span class="number">390</span> <span class="number">252</span>  <span class="number">89</span>  <span class="number">70</span>  <span class="number">93</span> <span class="number">310</span> <span class="number">265</span> <span class="number">524</span> <span class="number">170</span>  <span class="number">58</span>  <span class="number">59</span> <span class="number">127</span>  <span class="number">90</span> <span class="number">161</span>  <span class="number">37</span>;...</span><br><span class="line">        <span class="number">395</span> <span class="number">256</span> <span class="number">101</span>  <span class="number">72</span> <span class="number">105</span> <span class="number">312</span> <span class="number">339</span> <span class="number">546</span> <span class="number">240</span>  <span class="number">55</span>  <span class="number">63</span> <span class="number">129</span>  <span class="number">82</span> <span class="number">211</span>  <span class="number">38</span>;...</span><br><span class="line">        <span class="number">400</span> <span class="number">256</span> <span class="number">111</span>  <span class="number">73</span> <span class="number">116</span> <span class="number">313</span> <span class="number">410</span> <span class="number">551</span> <span class="number">319</span>  <span class="number">52</span>  <span class="number">66</span> <span class="number">127</span>  <span class="number">76</span> <span class="number">264</span>  <span class="number">39</span>;...</span><br><span class="line">        <span class="number">405</span> <span class="number">254</span> <span class="number">116</span>  <span class="number">73</span> <span class="number">121</span> <span class="number">315</span> <span class="number">464</span> <span class="number">555</span> <span class="number">416</span>  <span class="number">52</span>  <span class="number">67</span> <span class="number">121</span>  <span class="number">68</span> <span class="number">313</span>  <span class="number">39</span>;...</span><br><span class="line">        <span class="number">410</span> <span class="number">252</span> <span class="number">118</span>  <span class="number">74</span> <span class="number">124</span> <span class="number">319</span> <span class="number">492</span> <span class="number">559</span> <span class="number">462</span>  <span class="number">51</span>  <span class="number">68</span> <span class="number">116</span>  <span class="number">64</span> <span class="number">341</span>  <span class="number">40</span>;...</span><br><span class="line">        <span class="number">415</span> <span class="number">248</span> <span class="number">120</span>  <span class="number">74</span> <span class="number">126</span> <span class="number">322</span> <span class="number">508</span> <span class="number">560</span> <span class="number">482</span>  <span class="number">50</span>  <span class="number">69</span> <span class="number">112</span>  <span class="number">65</span> <span class="number">352</span>  <span class="number">41</span>;...</span><br><span class="line">        <span class="number">420</span> <span class="number">244</span> <span class="number">121</span>  <span class="number">74</span> <span class="number">128</span> <span class="number">326</span> <span class="number">517</span> <span class="number">561</span> <span class="number">490</span>  <span class="number">50</span>  <span class="number">69</span> <span class="number">108</span>  <span class="number">75</span> <span class="number">359</span>  <span class="number">42</span>;...</span><br><span class="line">        <span class="number">425</span> <span class="number">240</span> <span class="number">122</span>  <span class="number">73</span> <span class="number">131</span> <span class="number">330</span> <span class="number">524</span> <span class="number">558</span> <span class="number">488</span>  <span class="number">49</span>  <span class="number">70</span> <span class="number">105</span>  <span class="number">93</span> <span class="number">361</span>  <span class="number">42</span>;...</span><br><span class="line">        <span class="number">430</span> <span class="number">237</span> <span class="number">122</span>  <span class="number">73</span> <span class="number">135</span> <span class="number">334</span> <span class="number">531</span> <span class="number">556</span> <span class="number">482</span>  <span class="number">48</span>  <span class="number">72</span> <span class="number">104</span> <span class="number">123</span> <span class="number">364</span>  <span class="number">43</span>;...</span><br><span class="line">        <span class="number">435</span> <span class="number">232</span> <span class="number">122</span>  <span class="number">73</span> <span class="number">139</span> <span class="number">339</span> <span class="number">538</span> <span class="number">551</span> <span class="number">473</span>  <span class="number">47</span>  <span class="number">73</span> <span class="number">104</span> <span class="number">160</span> <span class="number">365</span>  <span class="number">44</span>;...</span><br><span class="line">        <span class="number">440</span> <span class="number">230</span> <span class="number">123</span>  <span class="number">73</span> <span class="number">144</span> <span class="number">346</span> <span class="number">544</span> <span class="number">544</span> <span class="number">462</span>  <span class="number">46</span>  <span class="number">76</span> <span class="number">105</span> <span class="number">207</span> <span class="number">367</span>  <span class="number">44</span>;...</span><br><span class="line">        <span class="number">445</span> <span class="number">226</span> <span class="number">124</span>  <span class="number">73</span> <span class="number">151</span> <span class="number">352</span> <span class="number">551</span> <span class="number">535</span> <span class="number">450</span>  <span class="number">44</span>  <span class="number">78</span> <span class="number">106</span> <span class="number">256</span> <span class="number">369</span>  <span class="number">45</span>;...</span><br><span class="line">        <span class="number">450</span> <span class="number">225</span> <span class="number">127</span>  <span class="number">74</span> <span class="number">161</span> <span class="number">360</span> <span class="number">556</span> <span class="number">522</span> <span class="number">439</span>  <span class="number">42</span>  <span class="number">83</span> <span class="number">110</span> <span class="number">300</span> <span class="number">372</span>  <span class="number">45</span>;...</span><br><span class="line">        <span class="number">455</span> <span class="number">222</span> <span class="number">128</span>  <span class="number">75</span> <span class="number">172</span> <span class="number">369</span> <span class="number">556</span> <span class="number">506</span> <span class="number">426</span>  <span class="number">41</span>  <span class="number">88</span> <span class="number">115</span> <span class="number">331</span> <span class="number">374</span>  <span class="number">46</span>;...</span><br><span class="line">        <span class="number">460</span> <span class="number">220</span> <span class="number">131</span>  <span class="number">77</span> <span class="number">186</span> <span class="number">381</span> <span class="number">554</span> <span class="number">488</span> <span class="number">413</span>  <span class="number">38</span>  <span class="number">95</span> <span class="number">123</span> <span class="number">346</span> <span class="number">376</span>  <span class="number">47</span>;...</span><br><span class="line">        <span class="number">465</span> <span class="number">218</span> <span class="number">134</span>  <span class="number">80</span> <span class="number">205</span> <span class="number">394</span> <span class="number">549</span> <span class="number">469</span> <span class="number">397</span>  <span class="number">35</span> <span class="number">103</span> <span class="number">134</span> <span class="number">347</span> <span class="number">379</span>  <span class="number">48</span>;...</span><br><span class="line">        <span class="number">470</span> <span class="number">216</span> <span class="number">138</span>  <span class="number">85</span> <span class="number">229</span> <span class="number">403</span> <span class="number">541</span> <span class="number">448</span> <span class="number">382</span>  <span class="number">33</span> <span class="number">113</span> <span class="number">148</span> <span class="number">341</span> <span class="number">384</span>  <span class="number">50</span>;...</span><br><span class="line">        <span class="number">475</span> <span class="number">214</span> <span class="number">143</span>  <span class="number">94</span> <span class="number">254</span> <span class="number">410</span> <span class="number">531</span> <span class="number">429</span> <span class="number">366</span>  <span class="number">31</span> <span class="number">125</span> <span class="number">167</span> <span class="number">328</span> <span class="number">389</span>  <span class="number">52</span>;...</span><br><span class="line">        <span class="number">480</span> <span class="number">214</span> <span class="number">150</span> <span class="number">109</span> <span class="number">281</span> <span class="number">415</span> <span class="number">519</span> <span class="number">408</span> <span class="number">352</span>  <span class="number">30</span> <span class="number">142</span> <span class="number">192</span> <span class="number">307</span> <span class="number">397</span>  <span class="number">55</span>;...</span><br><span class="line">        <span class="number">485</span> <span class="number">214</span> <span class="number">159</span> <span class="number">126</span> <span class="number">308</span> <span class="number">418</span> <span class="number">504</span> <span class="number">385</span> <span class="number">337</span>  <span class="number">29</span> <span class="number">162</span> <span class="number">219</span> <span class="number">282</span> <span class="number">405</span>  <span class="number">57</span>;...</span><br><span class="line">        <span class="number">490</span> <span class="number">216</span> <span class="number">174</span> <span class="number">148</span> <span class="number">332</span> <span class="number">419</span> <span class="number">488</span> <span class="number">363</span> <span class="number">325</span>  <span class="number">28</span> <span class="number">189</span> <span class="number">252</span> <span class="number">257</span> <span class="number">416</span>  <span class="number">62</span>;...</span><br><span class="line">        <span class="number">495</span> <span class="number">218</span> <span class="number">190</span> <span class="number">172</span> <span class="number">352</span> <span class="number">417</span> <span class="number">469</span> <span class="number">341</span> <span class="number">310</span>  <span class="number">28</span> <span class="number">219</span> <span class="number">291</span> <span class="number">230</span> <span class="number">429</span>  <span class="number">67</span>;...</span><br><span class="line">        <span class="number">500</span> <span class="number">223</span> <span class="number">207</span> <span class="number">198</span> <span class="number">370</span> <span class="number">413</span> <span class="number">450</span> <span class="number">324</span> <span class="number">299</span>  <span class="number">28</span> <span class="number">262</span> <span class="number">325</span> <span class="number">204</span> <span class="number">443</span>  <span class="number">75</span>;...</span><br><span class="line">        <span class="number">505</span> <span class="number">225</span> <span class="number">225</span> <span class="number">221</span> <span class="number">383</span> <span class="number">409</span> <span class="number">431</span> <span class="number">311</span> <span class="number">289</span>  <span class="number">29</span> <span class="number">305</span> <span class="number">347</span> <span class="number">178</span> <span class="number">454</span>  <span class="number">83</span>;...</span><br><span class="line">        <span class="number">510</span> <span class="number">226</span> <span class="number">242</span> <span class="number">241</span> <span class="number">390</span> <span class="number">403</span> <span class="number">414</span> <span class="number">301</span> <span class="number">283</span>  <span class="number">30</span> <span class="number">365</span> <span class="number">356</span> <span class="number">154</span> <span class="number">461</span>  <span class="number">92</span>;...</span><br><span class="line">        <span class="number">515</span> <span class="number">226</span> <span class="number">253</span> <span class="number">260</span> <span class="number">394</span> <span class="number">396</span> <span class="number">395</span> <span class="number">291</span> <span class="number">276</span>  <span class="number">30</span> <span class="number">416</span> <span class="number">353</span> <span class="number">129</span> <span class="number">466</span> <span class="number">100</span>;...</span><br><span class="line">        <span class="number">520</span> <span class="number">225</span> <span class="number">260</span> <span class="number">278</span> <span class="number">395</span> <span class="number">389</span> <span class="number">377</span> <span class="number">283</span> <span class="number">270</span>  <span class="number">31</span> <span class="number">465</span> <span class="number">346</span> <span class="number">109</span> <span class="number">469</span> <span class="number">108</span>;...</span><br><span class="line">        <span class="number">525</span> <span class="number">225</span> <span class="number">264</span> <span class="number">302</span> <span class="number">392</span> <span class="number">381</span> <span class="number">358</span> <span class="number">273</span> <span class="number">262</span>  <span class="number">31</span> <span class="number">509</span> <span class="number">333</span>  <span class="number">90</span> <span class="number">471</span> <span class="number">121</span>;...</span><br><span class="line">        <span class="number">530</span> <span class="number">227</span> <span class="number">267</span> <span class="number">339</span> <span class="number">385</span> <span class="number">372</span> <span class="number">341</span> <span class="number">265</span> <span class="number">256</span>  <span class="number">32</span> <span class="number">546</span> <span class="number">314</span>  <span class="number">75</span> <span class="number">474</span> <span class="number">133</span>;...</span><br><span class="line">        <span class="number">535</span> <span class="number">230</span> <span class="number">269</span> <span class="number">370</span> <span class="number">377</span> <span class="number">363</span> <span class="number">325</span> <span class="number">260</span> <span class="number">251</span>  <span class="number">32</span> <span class="number">581</span> <span class="number">294</span>  <span class="number">62</span> <span class="number">476</span> <span class="number">142</span>;...</span><br><span class="line">        <span class="number">540</span> <span class="number">236</span> <span class="number">272</span> <span class="number">392</span> <span class="number">367</span> <span class="number">353</span> <span class="number">309</span> <span class="number">257</span> <span class="number">250</span>  <span class="number">33</span> <span class="number">610</span> <span class="number">271</span>  <span class="number">51</span> <span class="number">483</span> <span class="number">150</span>;...</span><br><span class="line">        <span class="number">545</span> <span class="number">245</span> <span class="number">276</span> <span class="number">399</span> <span class="number">354</span> <span class="number">342</span> <span class="number">293</span> <span class="number">257</span> <span class="number">251</span>  <span class="number">34</span> <span class="number">634</span> <span class="number">248</span>  <span class="number">41</span> <span class="number">490</span> <span class="number">154</span>;...</span><br><span class="line">        <span class="number">550</span> <span class="number">253</span> <span class="number">282</span> <span class="number">400</span> <span class="number">341</span> <span class="number">331</span> <span class="number">279</span> <span class="number">259</span> <span class="number">254</span>  <span class="number">35</span> <span class="number">653</span> <span class="number">227</span>  <span class="number">35</span> <span class="number">506</span> <span class="number">155</span>;...</span><br><span class="line">        <span class="number">555</span> <span class="number">262</span> <span class="number">289</span> <span class="number">393</span> <span class="number">327</span> <span class="number">320</span> <span class="number">265</span> <span class="number">260</span> <span class="number">258</span>  <span class="number">37</span> <span class="number">666</span> <span class="number">206</span>  <span class="number">29</span> <span class="number">526</span> <span class="number">152</span>;...</span><br><span class="line">        <span class="number">560</span> <span class="number">272</span> <span class="number">299</span> <span class="number">380</span> <span class="number">312</span> <span class="number">308</span> <span class="number">253</span> <span class="number">260</span> <span class="number">264</span>  <span class="number">41</span> <span class="number">678</span> <span class="number">188</span>  <span class="number">25</span> <span class="number">553</span> <span class="number">147</span>;...</span><br><span class="line">        <span class="number">565</span> <span class="number">283</span> <span class="number">309</span> <span class="number">365</span> <span class="number">296</span> <span class="number">296</span> <span class="number">241</span> <span class="number">258</span> <span class="number">269</span>  <span class="number">44</span> <span class="number">687</span> <span class="number">170</span>  <span class="number">22</span> <span class="number">582</span> <span class="number">140</span>;...</span><br><span class="line">        <span class="number">570</span> <span class="number">298</span> <span class="number">322</span> <span class="number">349</span> <span class="number">280</span> <span class="number">284</span> <span class="number">234</span> <span class="number">256</span> <span class="number">272</span>  <span class="number">48</span> <span class="number">693</span> <span class="number">153</span>  <span class="number">19</span> <span class="number">618</span> <span class="number">133</span>;...</span><br><span class="line">        <span class="number">575</span> <span class="number">318</span> <span class="number">329</span> <span class="number">332</span> <span class="number">263</span> <span class="number">271</span> <span class="number">227</span> <span class="number">254</span> <span class="number">274</span>  <span class="number">52</span> <span class="number">698</span> <span class="number">138</span>  <span class="number">17</span> <span class="number">651</span> <span class="number">125</span>;...</span><br><span class="line">        <span class="number">580</span> <span class="number">341</span> <span class="number">335</span> <span class="number">315</span> <span class="number">247</span> <span class="number">260</span> <span class="number">225</span> <span class="number">254</span> <span class="number">278</span>  <span class="number">60</span> <span class="number">701</span> <span class="number">125</span>  <span class="number">17</span> <span class="number">680</span> <span class="number">118</span>;...</span><br><span class="line">        <span class="number">585</span> <span class="number">367</span> <span class="number">339</span> <span class="number">299</span> <span class="number">229</span> <span class="number">247</span> <span class="number">222</span> <span class="number">259</span> <span class="number">284</span>  <span class="number">76</span> <span class="number">704</span> <span class="number">114</span>  <span class="number">17</span> <span class="number">701</span> <span class="number">112</span>;...</span><br><span class="line">        <span class="number">590</span> <span class="number">390</span> <span class="number">341</span> <span class="number">285</span> <span class="number">214</span> <span class="number">232</span> <span class="number">221</span> <span class="number">270</span> <span class="number">295</span> <span class="number">102</span> <span class="number">705</span> <span class="number">106</span>  <span class="number">16</span> <span class="number">717</span> <span class="number">106</span>;...</span><br><span class="line">        <span class="number">595</span> <span class="number">409</span> <span class="number">341</span> <span class="number">272</span> <span class="number">198</span> <span class="number">220</span> <span class="number">220</span> <span class="number">284</span> <span class="number">316</span> <span class="number">136</span> <span class="number">705</span> <span class="number">100</span>  <span class="number">16</span> <span class="number">729</span> <span class="number">101</span>;...</span><br><span class="line">        <span class="number">600</span> <span class="number">424</span> <span class="number">342</span> <span class="number">264</span> <span class="number">185</span> <span class="number">210</span> <span class="number">220</span> <span class="number">302</span> <span class="number">348</span> <span class="number">190</span> <span class="number">706</span>  <span class="number">96</span>  <span class="number">16</span> <span class="number">736</span>  <span class="number">98</span>;...</span><br><span class="line">        <span class="number">605</span> <span class="number">435</span> <span class="number">342</span> <span class="number">257</span> <span class="number">175</span> <span class="number">200</span> <span class="number">220</span> <span class="number">324</span> <span class="number">384</span> <span class="number">256</span> <span class="number">707</span>  <span class="number">92</span>  <span class="number">16</span> <span class="number">742</span>  <span class="number">95</span>;...</span><br><span class="line">        <span class="number">610</span> <span class="number">442</span> <span class="number">342</span> <span class="number">252</span> <span class="number">169</span> <span class="number">194</span> <span class="number">220</span> <span class="number">344</span> <span class="number">434</span> <span class="number">336</span> <span class="number">707</span>  <span class="number">90</span>  <span class="number">16</span> <span class="number">745</span>  <span class="number">93</span>;...</span><br><span class="line">        <span class="number">615</span> <span class="number">448</span> <span class="number">341</span> <span class="number">247</span> <span class="number">164</span> <span class="number">189</span> <span class="number">220</span> <span class="number">362</span> <span class="number">482</span> <span class="number">418</span> <span class="number">707</span>  <span class="number">87</span>  <span class="number">16</span> <span class="number">747</span>  <span class="number">90</span>;...</span><br><span class="line">        <span class="number">620</span> <span class="number">450</span> <span class="number">341</span> <span class="number">241</span> <span class="number">160</span> <span class="number">185</span> <span class="number">223</span> <span class="number">377</span> <span class="number">528</span> <span class="number">505</span> <span class="number">708</span>  <span class="number">85</span>  <span class="number">16</span> <span class="number">748</span>  <span class="number">89</span>;...</span><br><span class="line">        <span class="number">625</span> <span class="number">451</span> <span class="number">339</span> <span class="number">235</span> <span class="number">156</span> <span class="number">183</span> <span class="number">227</span> <span class="number">389</span> <span class="number">568</span> <span class="number">581</span> <span class="number">708</span>  <span class="number">82</span>  <span class="number">16</span> <span class="number">748</span>  <span class="number">87</span>;...</span><br><span class="line">        <span class="number">630</span> <span class="number">451</span> <span class="number">339</span> <span class="number">229</span> <span class="number">154</span> <span class="number">180</span> <span class="number">233</span> <span class="number">400</span> <span class="number">604</span> <span class="number">641</span> <span class="number">710</span>  <span class="number">80</span>  <span class="number">18</span> <span class="number">748</span>  <span class="number">86</span>;...</span><br><span class="line">        <span class="number">635</span> <span class="number">451</span> <span class="number">338</span> <span class="number">224</span> <span class="number">152</span> <span class="number">177</span> <span class="number">239</span> <span class="number">410</span> <span class="number">629</span> <span class="number">682</span> <span class="number">711</span>  <span class="number">79</span>  <span class="number">18</span> <span class="number">748</span>  <span class="number">85</span>;...</span><br><span class="line">        <span class="number">640</span> <span class="number">451</span> <span class="number">338</span> <span class="number">220</span> <span class="number">151</span> <span class="number">176</span> <span class="number">244</span> <span class="number">420</span> <span class="number">648</span> <span class="number">717</span> <span class="number">712</span>  <span class="number">78</span>  <span class="number">18</span> <span class="number">748</span>  <span class="number">84</span>;...</span><br><span class="line">        <span class="number">645</span> <span class="number">451</span> <span class="number">337</span> <span class="number">217</span> <span class="number">149</span> <span class="number">175</span> <span class="number">251</span> <span class="number">429</span> <span class="number">663</span> <span class="number">740</span> <span class="number">714</span>  <span class="number">78</span>  <span class="number">18</span> <span class="number">748</span>  <span class="number">84</span>;...</span><br><span class="line">        <span class="number">650</span> <span class="number">450</span> <span class="number">336</span> <span class="number">216</span> <span class="number">148</span> <span class="number">175</span> <span class="number">258</span> <span class="number">438</span> <span class="number">676</span> <span class="number">758</span> <span class="number">716</span>  <span class="number">78</span>  <span class="number">19</span> <span class="number">748</span>  <span class="number">84</span>;...</span><br><span class="line">        <span class="number">655</span> <span class="number">450</span> <span class="number">335</span> <span class="number">216</span> <span class="number">148</span> <span class="number">175</span> <span class="number">263</span> <span class="number">445</span> <span class="number">685</span> <span class="number">770</span> <span class="number">718</span>  <span class="number">78</span>  <span class="number">20</span> <span class="number">748</span>  <span class="number">84</span>;...</span><br><span class="line">        <span class="number">660</span> <span class="number">451</span> <span class="number">334</span> <span class="number">219</span> <span class="number">148</span> <span class="number">175</span> <span class="number">268</span> <span class="number">452</span> <span class="number">693</span> <span class="number">781</span> <span class="number">720</span>  <span class="number">81</span>  <span class="number">23</span> <span class="number">747</span>  <span class="number">85</span>;...</span><br><span class="line">        <span class="number">665</span> <span class="number">451</span> <span class="number">332</span> <span class="number">224</span> <span class="number">149</span> <span class="number">177</span> <span class="number">273</span> <span class="number">457</span> <span class="number">700</span> <span class="number">790</span> <span class="number">722</span>  <span class="number">83</span>  <span class="number">24</span> <span class="number">747</span>  <span class="number">87</span>;...</span><br><span class="line">        <span class="number">670</span> <span class="number">453</span> <span class="number">332</span> <span class="number">230</span> <span class="number">151</span> <span class="number">180</span> <span class="number">278</span> <span class="number">462</span> <span class="number">705</span> <span class="number">797</span> <span class="number">725</span>  <span class="number">88</span>  <span class="number">26</span> <span class="number">747</span>  <span class="number">92</span>;...</span><br><span class="line">        <span class="number">675</span> <span class="number">454</span> <span class="number">331</span> <span class="number">238</span> <span class="number">154</span> <span class="number">183</span> <span class="number">281</span> <span class="number">466</span> <span class="number">709</span> <span class="number">803</span> <span class="number">729</span>  <span class="number">93</span>  <span class="number">30</span> <span class="number">747</span>  <span class="number">96</span>;...</span><br><span class="line">        <span class="number">680</span> <span class="number">455</span> <span class="number">331</span> <span class="number">251</span> <span class="number">158</span> <span class="number">186</span> <span class="number">283</span> <span class="number">468</span> <span class="number">712</span> <span class="number">809</span> <span class="number">731</span> <span class="number">102</span>  <span class="number">35</span> <span class="number">747</span> <span class="number">102</span>;...</span><br><span class="line">        <span class="number">685</span> <span class="number">457</span> <span class="number">330</span> <span class="number">269</span> <span class="number">162</span> <span class="number">189</span> <span class="number">286</span> <span class="number">470</span> <span class="number">715</span> <span class="number">814</span> <span class="number">735</span> <span class="number">112</span>  <span class="number">43</span> <span class="number">747</span> <span class="number">110</span>;...</span><br><span class="line">        <span class="number">690</span> <span class="number">458</span> <span class="number">329</span> <span class="number">288</span> <span class="number">165</span> <span class="number">192</span> <span class="number">291</span> <span class="number">473</span> <span class="number">717</span> <span class="number">819</span> <span class="number">739</span> <span class="number">125</span>  <span class="number">56</span> <span class="number">747</span> <span class="number">123</span>;...</span><br><span class="line">        <span class="number">695</span> <span class="number">460</span> <span class="number">328</span> <span class="number">312</span> <span class="number">168</span> <span class="number">195</span> <span class="number">296</span> <span class="number">477</span> <span class="number">719</span> <span class="number">824</span> <span class="number">742</span> <span class="number">141</span>  <span class="number">74</span> <span class="number">746</span> <span class="number">137</span>;...</span><br><span class="line">        <span class="number">700</span> <span class="number">462</span> <span class="number">328</span> <span class="number">340</span> <span class="number">170</span> <span class="number">199</span> <span class="number">302</span> <span class="number">483</span> <span class="number">721</span> <span class="number">828</span> <span class="number">746</span> <span class="number">161</span>  <span class="number">97</span> <span class="number">746</span> <span class="number">152</span>;...</span><br><span class="line">        <span class="number">705</span> <span class="number">463</span> <span class="number">327</span> <span class="number">366</span> <span class="number">171</span> <span class="number">200</span> <span class="number">313</span> <span class="number">489</span> <span class="number">720</span> <span class="number">830</span> <span class="number">748</span> <span class="number">182</span> <span class="number">128</span> <span class="number">746</span> <span class="number">169</span>;...</span><br><span class="line">        <span class="number">710</span> <span class="number">464</span> <span class="number">326</span> <span class="number">390</span> <span class="number">170</span> <span class="number">199</span> <span class="number">325</span> <span class="number">496</span> <span class="number">719</span> <span class="number">831</span> <span class="number">749</span> <span class="number">203</span> <span class="number">166</span> <span class="number">745</span> <span class="number">188</span>;...</span><br><span class="line">        <span class="number">715</span> <span class="number">465</span> <span class="number">325</span> <span class="number">412</span> <span class="number">168</span> <span class="number">198</span> <span class="number">338</span> <span class="number">503</span> <span class="number">722</span> <span class="number">833</span> <span class="number">751</span> <span class="number">223</span> <span class="number">210</span> <span class="number">744</span> <span class="number">207</span>;...</span><br><span class="line">        <span class="number">720</span> <span class="number">466</span> <span class="number">324</span> <span class="number">431</span> <span class="number">166</span> <span class="number">196</span> <span class="number">351</span> <span class="number">511</span> <span class="number">725</span> <span class="number">835</span> <span class="number">753</span> <span class="number">242</span> <span class="number">257</span> <span class="number">743</span> <span class="number">226</span>;...</span><br><span class="line">        <span class="number">725</span> <span class="number">466</span> <span class="number">324</span> <span class="number">447</span> <span class="number">164</span> <span class="number">195</span> <span class="number">364</span> <span class="number">518</span> <span class="number">727</span> <span class="number">836</span> <span class="number">754</span> <span class="number">257</span> <span class="number">305</span> <span class="number">744</span> <span class="number">243</span>;...</span><br><span class="line">        <span class="number">730</span> <span class="number">466</span> <span class="number">324</span> <span class="number">460</span> <span class="number">164</span> <span class="number">195</span> <span class="number">376</span> <span class="number">525</span> <span class="number">729</span> <span class="number">836</span> <span class="number">755</span> <span class="number">270</span> <span class="number">354</span> <span class="number">745</span> <span class="number">260</span>;...</span><br><span class="line">        <span class="number">735</span> <span class="number">466</span> <span class="number">323</span> <span class="number">472</span> <span class="number">165</span> <span class="number">196</span> <span class="number">389</span> <span class="number">532</span> <span class="number">730</span> <span class="number">837</span> <span class="number">755</span> <span class="number">282</span> <span class="number">401</span> <span class="number">748</span> <span class="number">277</span>;...</span><br><span class="line">        <span class="number">740</span> <span class="number">467</span> <span class="number">322</span> <span class="number">481</span> <span class="number">168</span> <span class="number">197</span> <span class="number">401</span> <span class="number">539</span> <span class="number">730</span> <span class="number">838</span> <span class="number">755</span> <span class="number">292</span> <span class="number">446</span> <span class="number">750</span> <span class="number">294</span>;...</span><br><span class="line">        <span class="number">745</span> <span class="number">467</span> <span class="number">321</span> <span class="number">488</span> <span class="number">172</span> <span class="number">200</span> <span class="number">413</span> <span class="number">546</span> <span class="number">730</span> <span class="number">839</span> <span class="number">755</span> <span class="number">302</span> <span class="number">485</span> <span class="number">750</span> <span class="number">310</span>;...</span><br><span class="line">        <span class="number">750</span> <span class="number">467</span> <span class="number">320</span> <span class="number">493</span> <span class="number">177</span> <span class="number">203</span> <span class="number">425</span> <span class="number">553</span> <span class="number">730</span> <span class="number">839</span> <span class="number">756</span> <span class="number">310</span> <span class="number">520</span> <span class="number">749</span> <span class="number">325</span>;...</span><br><span class="line">        <span class="number">755</span> <span class="number">467</span> <span class="number">318</span> <span class="number">497</span> <span class="number">181</span> <span class="number">205</span> <span class="number">436</span> <span class="number">559</span> <span class="number">730</span> <span class="number">839</span> <span class="number">757</span> <span class="number">314</span> <span class="number">551</span> <span class="number">748</span> <span class="number">339</span>;...</span><br><span class="line">        <span class="number">760</span> <span class="number">467</span> <span class="number">316</span> <span class="number">500</span> <span class="number">185</span> <span class="number">208</span> <span class="number">447</span> <span class="number">565</span> <span class="number">730</span> <span class="number">839</span> <span class="number">758</span> <span class="number">317</span> <span class="number">577</span> <span class="number">748</span> <span class="number">353</span>;...</span><br><span class="line">        <span class="number">765</span> <span class="number">467</span> <span class="number">315</span> <span class="number">502</span> <span class="number">189</span> <span class="number">212</span> <span class="number">458</span> <span class="number">570</span> <span class="number">730</span> <span class="number">839</span> <span class="number">759</span> <span class="number">323</span> <span class="number">599</span> <span class="number">747</span> <span class="number">366</span>;...</span><br><span class="line">        <span class="number">770</span> <span class="number">467</span> <span class="number">315</span> <span class="number">505</span> <span class="number">192</span> <span class="number">215</span> <span class="number">469</span> <span class="number">575</span> <span class="number">730</span> <span class="number">839</span> <span class="number">759</span> <span class="number">330</span> <span class="number">618</span> <span class="number">747</span> <span class="number">379</span>;...</span><br><span class="line">        <span class="number">775</span> <span class="number">467</span> <span class="number">314</span> <span class="number">510</span> <span class="number">194</span> <span class="number">217</span> <span class="number">477</span> <span class="number">578</span> <span class="number">730</span> <span class="number">839</span> <span class="number">759</span> <span class="number">334</span> <span class="number">633</span> <span class="number">747</span> <span class="number">390</span>;...</span><br><span class="line">        <span class="number">780</span> <span class="number">467</span> <span class="number">314</span> <span class="number">516</span> <span class="number">197</span> <span class="number">219</span> <span class="number">485</span> <span class="number">581</span> <span class="number">730</span> <span class="number">839</span> <span class="number">759</span> <span class="number">338</span> <span class="number">645</span> <span class="number">747</span> <span class="number">399</span>;...</span><br><span class="line">        <span class="number">785</span> <span class="number">467</span> <span class="number">313</span> <span class="number">520</span> <span class="number">200</span> <span class="number">222</span> <span class="number">493</span> <span class="number">583</span> <span class="number">730</span> <span class="number">839</span> <span class="number">759</span> <span class="number">343</span> <span class="number">656</span> <span class="number">746</span> <span class="number">408</span>;...</span><br><span class="line">        <span class="number">790</span> <span class="number">467</span> <span class="number">313</span> <span class="number">524</span> <span class="number">204</span> <span class="number">226</span> <span class="number">500</span> <span class="number">585</span> <span class="number">731</span> <span class="number">839</span> <span class="number">759</span> <span class="number">348</span> <span class="number">666</span> <span class="number">746</span> <span class="number">416</span>;...</span><br><span class="line">        <span class="number">795</span> <span class="number">466</span> <span class="number">312</span> <span class="number">527</span> <span class="number">210</span> <span class="number">231</span> <span class="number">506</span> <span class="number">587</span> <span class="number">731</span> <span class="number">839</span> <span class="number">759</span> <span class="number">353</span> <span class="number">674</span> <span class="number">746</span> <span class="number">422</span>;...</span><br><span class="line">        <span class="number">800</span> <span class="number">466</span> <span class="number">312</span> <span class="number">531</span> <span class="number">218</span> <span class="number">237</span> <span class="number">512</span> <span class="number">588</span> <span class="number">731</span> <span class="number">839</span> <span class="number">759</span> <span class="number">359</span> <span class="number">680</span> <span class="number">746</span> <span class="number">428</span>;...</span><br><span class="line">        <span class="number">805</span> <span class="number">466</span> <span class="number">311</span> <span class="number">535</span> <span class="number">225</span> <span class="number">243</span> <span class="number">517</span> <span class="number">589</span> <span class="number">731</span> <span class="number">839</span> <span class="number">759</span> <span class="number">365</span> <span class="number">686</span> <span class="number">745</span> <span class="number">434</span>;...</span><br><span class="line">        <span class="number">810</span> <span class="number">466</span> <span class="number">311</span> <span class="number">539</span> <span class="number">233</span> <span class="number">249</span> <span class="number">521</span> <span class="number">590</span> <span class="number">731</span> <span class="number">838</span> <span class="number">758</span> <span class="number">372</span> <span class="number">691</span> <span class="number">745</span> <span class="number">439</span>;...</span><br><span class="line">        <span class="number">815</span> <span class="number">466</span> <span class="number">311</span> <span class="number">544</span> <span class="number">243</span> <span class="number">257</span> <span class="number">525</span> <span class="number">590</span> <span class="number">731</span> <span class="number">837</span> <span class="number">757</span> <span class="number">380</span> <span class="number">694</span> <span class="number">745</span> <span class="number">444</span>;...</span><br><span class="line">        <span class="number">820</span> <span class="number">465</span> <span class="number">311</span> <span class="number">548</span> <span class="number">254</span> <span class="number">265</span> <span class="number">529</span> <span class="number">590</span> <span class="number">731</span> <span class="number">837</span> <span class="number">757</span> <span class="number">388</span> <span class="number">697</span> <span class="number">745</span> <span class="number">448</span>;...</span><br><span class="line">        <span class="number">825</span> <span class="number">464</span> <span class="number">311</span> <span class="number">552</span> <span class="number">264</span> <span class="number">273</span> <span class="number">532</span> <span class="number">591</span> <span class="number">731</span> <span class="number">836</span> <span class="number">756</span> <span class="number">396</span> <span class="number">700</span> <span class="number">745</span> <span class="number">451</span>;...</span><br><span class="line">        <span class="number">830</span> <span class="number">464</span> <span class="number">310</span> <span class="number">555</span> <span class="number">274</span> <span class="number">280</span> <span class="number">535</span> <span class="number">592</span> <span class="number">731</span> <span class="number">836</span> <span class="number">756</span> <span class="number">403</span> <span class="number">702</span> <span class="number">745</span> <span class="number">454</span>];</span><br><span class="line">TCS(:,<span class="number">2</span>:end) = TCS(:,<span class="number">2</span>:end)/<span class="number">1000</span>;        </span><br><span class="line">        </span><br><span class="line">% Data <span class="keyword">for</span> isotemperature lines needed <span class="keyword">for</span> calculating correlated color temperature</span><br><span class="line"></span><br><span class="line">% The following provides a table of isotemperature lines <span class="keyword">for</span> use <span class="keyword">with</span> the Robertson Method</span><br><span class="line">% (Robertson, <span class="number">1968</span>) to interpolate isotemperature lines <span class="keyword">from</span> the CIE <span class="number">1960</span> UCS.</span><br><span class="line">% The spacing of the isotemp lines <span class="keyword">is</span> very small (<span class="number">1</span> <span class="number">1</span>/MK) so very little</span><br><span class="line">% interpolation <span class="keyword">is</span> actually needed <span class="keyword">for</span> determining CCT. The latest (<span class="number">2002</span>)</span><br><span class="line">% recommended values <span class="keyword">for</span> the physical constants determining blackbody</span><br><span class="line">% radiation spectra are used</span><br><span class="line"></span><br><span class="line">dwave = wavelength(<span class="number">2</span>)-wavelength(<span class="number">1</span>); % wavelength increment = <span class="number">1</span> nm</span><br><span class="line"></span><br><span class="line">ubar = (<span class="number">2</span>/<span class="number">3</span>)*xbar;</span><br><span class="line">vbar = ybar;</span><br><span class="line">wbar = -<span class="number">0.5</span>*xbar + (<span class="number">3</span>/<span class="number">2</span>)*ybar + <span class="number">0.5</span>*zbar;</span><br><span class="line"></span><br><span class="line">% <span class="number">2002</span> CODATA recommended values</span><br><span class="line">h = <span class="number">6.6260693e-34</span>;</span><br><span class="line">c = <span class="number">299792458</span>;</span><br><span class="line">k = <span class="number">1.3806505e-23</span>;</span><br><span class="line">c1 = <span class="number">2</span>*pi*h*c^<span class="number">2</span>;</span><br><span class="line">c2 = h*c/k;</span><br><span class="line"></span><br><span class="line">MrecpK = [<span class="number">0.01</span> <span class="number">1</span>:<span class="number">600</span>]; % mega reciprical Kelvin values of isotemperature lines</span><br><span class="line">T = <span class="number">1.</span>/(MrecpK*<span class="number">1e-6</span>);</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:length(T)</span><br><span class="line">   spdref = c1 * (<span class="number">1e-9</span>*wavelength).^-<span class="number">5</span> ./ (exp(c2./(T(i).* <span class="number">1e-9</span>*wavelength)) - <span class="number">1</span>);</span><br><span class="line">   spdref = spdref/<span class="built_in">max</span>(spdref);</span><br><span class="line">   wave = wavelength*<span class="number">1e-9</span>;</span><br><span class="line">   </span><br><span class="line">   % Equations <span class="keyword">from</span> Wyszecki <span class="keyword">and</span> Sitles, Color Science, 2nd ed. <span class="number">1982</span>, page</span><br><span class="line">   % <span class="number">226</span> <span class="keyword">and</span> <span class="number">227</span></span><br><span class="line">   U = <span class="built_in">sum</span>(spdref.*ubar);</span><br><span class="line">   V = <span class="built_in">sum</span>(spdref.*vbar);</span><br><span class="line">   W = <span class="built_in">sum</span>(spdref.*wbar);</span><br><span class="line">   R = U+V+W;</span><br><span class="line">   u(i) = U/R;</span><br><span class="line">   v(i) = V/R;</span><br><span class="line">   </span><br><span class="line">   Uprime = c1*c2*(T(i))^-<span class="number">2</span>*<span class="built_in">sum</span>(wave.^-<span class="number">6.</span>*ubar.*exp(c2./(wave.*T(i))).*(exp(c2./(wave.*(T(i))))-<span class="number">1</span>).^-<span class="number">2</span>)*dwave;</span><br><span class="line">   Vprime = <span class="built_in">sum</span>(c1*c2*T(i)^-<span class="number">2</span>*wave.^-<span class="number">6.</span>*vbar.*exp(c2./(wave.*T(i))).*(exp(c2./(wave.*(T(i))))-<span class="number">1</span>).^-<span class="number">2</span>)*dwave;</span><br><span class="line">   Wprime = <span class="built_in">sum</span>(c1*c2*T(i)^-<span class="number">2</span>*wave.^-<span class="number">6.</span>*wbar.*exp(c2./(wave.*T(i))).*(exp(c2./(wave.*(T(i))))-<span class="number">1</span>).^-<span class="number">2</span>)*dwave;</span><br><span class="line">   Rprime = Uprime+Vprime+Wprime;</span><br><span class="line">   </span><br><span class="line">   sl(i) = (Vprime*R-V*Rprime)/(Uprime*R-U*Rprime);</span><br><span class="line">   m(i) = -<span class="number">1</span>/sl(i);</span><br><span class="line">end</span><br><span class="line">ut = u;</span><br><span class="line">vt = v;</span><br><span class="line">tt = m;</span><br><span class="line">isoTempLinesTable = [T<span class="string">&#x27; u&#x27;</span> v<span class="string">&#x27; m&#x27;</span>];</span><br><span class="line">%save isoTempLinesNewestFine.txt isoTempLinesTable -<span class="built_in">ascii</span>; % Optionally save file</span><br><span class="line"></span><br><span class="line">% Second, calculate Correlated Color Temperature (CCT), Tc</span><br><span class="line"></span><br><span class="line">%load (<span class="string">&#x27;isoTempLinesNewestFine.mat&#x27;</span>, <span class="string">&#x27;T&#x27;</span>, <span class="string">&#x27;ut&#x27;</span>, <span class="string">&#x27;vt&#x27;</span>, <span class="string">&#x27;tt&#x27;</span>); % If read <span class="keyword">from</span> previously saved file</span><br><span class="line"></span><br><span class="line">% Interpolate CIE functions to spd increments</span><br><span class="line">xbar = interp1(wavelength,xbar,wavelength_spd);</span><br><span class="line">xbar(isnan(xbar)) = <span class="number">0.0</span>;</span><br><span class="line">ybar = interp1(wavelength,ybar,wavelength_spd);</span><br><span class="line">ybar(isnan(ybar)) = <span class="number">0.0</span>;</span><br><span class="line">zbar = interp1(wavelength,zbar,wavelength_spd);</span><br><span class="line">zbar(isnan(zbar)) = <span class="number">0.0</span>;</span><br><span class="line">% Calculate Chromaticity Coordinates</span><br><span class="line">X = trapz(wavelength_spd,spd.*xbar);</span><br><span class="line">Y = trapz(wavelength_spd,spd.*ybar);</span><br><span class="line">Z = trapz(wavelength_spd,spd.*zbar);</span><br><span class="line">x = X/(X+Y+Z);</span><br><span class="line">y = Y/(X+Y+Z);</span><br><span class="line">u = <span class="number">4</span>*x/(-<span class="number">2</span>*x+<span class="number">12</span>*y+<span class="number">3</span>);</span><br><span class="line">v = <span class="number">6</span>*y/(-<span class="number">2</span>*x+<span class="number">12</span>*y+<span class="number">3</span>);</span><br><span class="line">fprintf(<span class="number">1</span>,<span class="string">&#x27;x = %.4f\ty = %.4f\n&#x27;</span>,x,y);</span><br><span class="line"></span><br><span class="line">% Find adjacent lines to (us, vs) </span><br><span class="line">n = length (T); </span><br><span class="line">index = <span class="number">0</span>; </span><br><span class="line">d1 = ((v-vt(<span class="number">1</span>)) - tt(<span class="number">1</span>)*(u-ut(<span class="number">1</span>)))/sqrt(<span class="number">1</span>+tt(<span class="number">1</span>)*tt(<span class="number">1</span>)); </span><br><span class="line"><span class="keyword">for</span> i=<span class="number">2</span>:n</span><br><span class="line">    d2 = ((v-vt(i)) - tt(i)*(u-ut(i)))/sqrt(<span class="number">1</span>+tt(i)*tt(i));</span><br><span class="line">    <span class="keyword">if</span> (d1/d2 &lt; <span class="number">0</span>)</span><br><span class="line">        index = i;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        d1 = d2;</span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"><span class="keyword">if</span> index == <span class="number">0</span></span><br><span class="line">    Tc = -<span class="number">1</span>; % Not able to calculate CCT, u, v coordinates outside <span class="built_in">range</span>.</span><br><span class="line">    fprintf(<span class="number">1</span>,<span class="string">&#x27;Not able to calculate CCT, u, v coordinates outside range.\n&#x27;</span>);</span><br><span class="line">    %<span class="keyword">return</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    % Calculate CCT by interpolation between isotemperature lines</span><br><span class="line">    Tc = <span class="number">1</span>/(<span class="number">1</span>/T(index-<span class="number">1</span>)+d1/(d1-d2)*(<span class="number">1</span>/T(index)-<span class="number">1</span>/T(index-<span class="number">1</span>)));</span><br><span class="line">    fprintf(<span class="number">1</span>,<span class="string">&#x27;CCT = %.1f\n&#x27;</span>,Tc);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% Third, calculate the Color Rendering Indices (CRI <span class="keyword">and</span> its <span class="number">14</span> indices)</span><br><span class="line">% Calculate Reference Source Spectrum, spdref. </span><br><span class="line"><span class="keyword">if</span> (Tc &lt; <span class="number">5000</span>)</span><br><span class="line">    c1 = <span class="number">3.7418e-16</span>;</span><br><span class="line">    c2 = <span class="number">1.4388e-2</span>;</span><br><span class="line">    spdref = c1 * (<span class="number">1e-9</span>*wavelength_spd).^-<span class="number">5</span> ./ (exp(c2./(Tc.* <span class="number">1e-9</span>*wavelength_spd)) - <span class="number">1</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">if</span> (Tc &lt;= <span class="number">25000</span>)</span><br><span class="line">        load(<span class="string">&#x27;CIEDaySn&#x27;</span>,<span class="string">&#x27;wavelength&#x27;</span>,<span class="string">&#x27;S0&#x27;</span>,<span class="string">&#x27;S1&#x27;</span>,<span class="string">&#x27;S2&#x27;</span>);</span><br><span class="line">        <span class="keyword">if</span> (Tc &lt;= <span class="number">7000</span>)</span><br><span class="line">            xd = -<span class="number">4.6070e9</span> / Tc.^<span class="number">3</span> + <span class="number">2.9678e6</span> / Tc.^<span class="number">2</span> + <span class="number">0.09911e3</span> / Tc + <span class="number">0.244063</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            xd = -<span class="number">2.0064e9</span> / Tc.^<span class="number">3</span> + <span class="number">1.9018e6</span> / Tc.^<span class="number">2</span> + <span class="number">0.24748e3</span> / Tc + <span class="number">0.237040</span>;</span><br><span class="line">        end</span><br><span class="line">        yd = -<span class="number">3.000</span>*xd*xd + <span class="number">2.870</span>*xd - <span class="number">0.275</span>;</span><br><span class="line">        M1 = (-<span class="number">1.3515</span> - <span class="number">1.7703</span>*xd + <span class="number">5.9114</span>*yd) / (<span class="number">0.0241</span> + <span class="number">0.2562</span>*xd - <span class="number">0.7341</span>*yd);</span><br><span class="line">        M2 = (<span class="number">0.0300</span> - <span class="number">31.4424</span>*xd + <span class="number">30.0717</span>*yd) / (<span class="number">0.0241</span> + <span class="number">0.2562</span>*xd - <span class="number">0.7341</span>*yd);</span><br><span class="line">        spdref = S0 + M1*S1 + M2*S2;</span><br><span class="line">        spdref = interp1(wavelength,spdref,wavelength_spd);</span><br><span class="line">        spdref(isnan(spdref)) = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        R = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% Interpolate TCS values <span class="keyword">from</span> <span class="number">5</span> nm to spd nm increments</span><br><span class="line">TCS_1 = zeros(length(wavelength_spd),<span class="number">14</span>);</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:<span class="number">14</span></span><br><span class="line">    TCS_1(:,i) = interp1(TCS(:,<span class="number">1</span>),TCS(:,i+<span class="number">1</span>),wavelength_spd,<span class="string">&#x27;linear&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% Calculate u, v chromaticity coordinates of samples under test illuminant, uk, vk <span class="keyword">and</span></span><br><span class="line">% reference illuminant, ur, vr.</span><br><span class="line">uki = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line">vki = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line">uri = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line">vri = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line">X = trapz(wavelength_spd,spd .* xbar);</span><br><span class="line">Y = trapz(wavelength_spd,spd .* ybar);</span><br><span class="line">Z = trapz(wavelength_spd,spd .* zbar);</span><br><span class="line">Yknormal = <span class="number">100</span> / Y;</span><br><span class="line">Yk = Y*Yknormal;</span><br><span class="line">uk = <span class="number">4</span>*X/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">vk = <span class="number">6</span>*Y/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">X = trapz(wavelength_spd,spdref .* xbar);</span><br><span class="line">Y = trapz(wavelength_spd,spdref .* ybar);</span><br><span class="line">Z = trapz(wavelength_spd,spdref .* zbar);</span><br><span class="line">Yrnormal = <span class="number">100</span> / Y;</span><br><span class="line">Yr = Y*Yrnormal;</span><br><span class="line">ur = <span class="number">4</span>*X/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">vr = <span class="number">6</span>*Y/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:<span class="number">14</span></span><br><span class="line">X = trapz(wavelength_spd,spd .* TCS_1(:,i) .* xbar);</span><br><span class="line">Y = trapz(wavelength_spd,spd .* TCS_1(:,i) .* ybar);</span><br><span class="line">Z = trapz(wavelength_spd,spd .* TCS_1(:,i) .* zbar);</span><br><span class="line">Yki(i) = Y*Yknormal;</span><br><span class="line">uki(i) = <span class="number">4</span>*X/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">vki(i) = <span class="number">6</span>*Y/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">X = trapz(wavelength_spd,spdref .* TCS_1(:,i) .* xbar);</span><br><span class="line">Y = trapz(wavelength_spd,spdref .* TCS_1(:,i) .* ybar);</span><br><span class="line">Z = trapz(wavelength_spd,spdref .* TCS_1(:,i) .* zbar);</span><br><span class="line">Yri(i) = Y*Yrnormal;</span><br><span class="line">uri(i) = <span class="number">4</span>*X/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">vri(i) = <span class="number">6</span>*Y/(X+<span class="number">15</span>*Y+<span class="number">3</span>*Z);</span><br><span class="line">end</span><br><span class="line">% Check tolorence <span class="keyword">for</span> reference illuminant</span><br><span class="line">DC = sqrt((uk-ur).^<span class="number">2</span> + (vk-vr).^<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">% Apply adaptive (perceived) color shift.</span><br><span class="line">ck = (<span class="number">4</span> - uk - <span class="number">10</span>*vk) / vk;</span><br><span class="line">dk = (<span class="number">1.708</span>*vk + <span class="number">0.404</span> - <span class="number">1.481</span>*uk) / vk;</span><br><span class="line">cr = (<span class="number">4</span> - ur - <span class="number">10</span>*vr) / vr;</span><br><span class="line">dr = (<span class="number">1.708</span>*vr + <span class="number">0.404</span> - <span class="number">1.481</span>*ur) / vr;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:<span class="number">14</span></span><br><span class="line">cki = (<span class="number">4</span> - uki(i) - <span class="number">10</span>*vki(i)) / vki(i);</span><br><span class="line">dki = (<span class="number">1.708</span>*vki(i) + <span class="number">0.404</span> - <span class="number">1.481</span>*uki(i)) / vki(i);</span><br><span class="line">ukip(i) = (<span class="number">10.872</span> + <span class="number">0.404</span>*cr/ck*cki - <span class="number">4</span>*dr/dk*dki) / (<span class="number">16.518</span> + <span class="number">1.481</span>*cr/ck*cki - dr/dk*dki);</span><br><span class="line">vkip(i) = <span class="number">5.520</span> / (<span class="number">16.518</span> + <span class="number">1.481</span>*cr/ck*cki - dr/dk*dki);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%  Transformation into <span class="number">1964</span> Uniform space coordinates.</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:<span class="number">14</span></span><br><span class="line">Wstarr(i) = <span class="number">25</span>*Yri(i).^<span class="number">.333333</span> - <span class="number">17</span>;</span><br><span class="line">Ustarr(i) = <span class="number">13</span>*Wstarr(i)*(uri(i) - ur);</span><br><span class="line">Vstarr(i) = <span class="number">13</span>*Wstarr(i)*(vri(i) - vr);</span><br><span class="line"></span><br><span class="line">Wstark(i) = <span class="number">25</span>*Yki(i).^<span class="number">.333333</span> - <span class="number">17</span>;</span><br><span class="line">Ustark(i) = <span class="number">13</span>*Wstark(i)*(ukip(i) - ur); % after applying the adaptive color shift, <span class="string">u&#x27;k = ur</span></span><br><span class="line"><span class="string">Vstark(i) = 13*Wstark(i)*(vkip(i) - vr); % after applying the adaptive color shift, v&#x27;</span>k = vr</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">% Determination of resultant color shift, delta E.</span><br><span class="line">deltaE = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line">R = zeros(<span class="number">1</span>,<span class="number">14</span>);</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:<span class="number">14</span></span><br><span class="line">deltaE(i) = sqrt((Ustarr(i) - Ustark(i)).^<span class="number">2</span> + (Vstarr(i) - Vstark(i)).^<span class="number">2</span> + (Wstarr(i) - Wstark(i)).^<span class="number">2</span>);</span><br><span class="line">R(i) = <span class="number">100</span> - <span class="number">4.6</span>*deltaE(i);</span><br><span class="line">end</span><br><span class="line">Ra = <span class="built_in">sum</span>(R(<span class="number">1</span>:<span class="number">8</span>))/<span class="number">8</span>;</span><br><span class="line">fprintf(<span class="number">1</span>,<span class="string">&#x27;CRIra = %.1f\n&#x27;</span>,Ra);</span><br><span class="line"></span><br><span class="line">% fourth, calculate the gamut area formed by the <span class="number">8</span> CIE standard color samples</span><br><span class="line">ukii=[uki(:,<span class="number">1</span>:<span class="number">8</span>),uki(<span class="number">1</span>)];</span><br><span class="line">vkii=<span class="number">1.5</span>*[vki(:,<span class="number">1</span>:<span class="number">8</span>),vki(<span class="number">1</span>)];</span><br><span class="line">Ga=polyarea(ukii,vkii);</span><br><span class="line">% Normalize gamut area to equal energy source </span><br><span class="line">Ga=Ga/<span class="number">0.00728468</span>*<span class="number">100</span>;</span><br><span class="line">fprintf(<span class="number">1</span>,<span class="string">&#x27;Gamut Area Index = %.1f\n&#x27;</span>,Ga);</span><br><span class="line"></span><br><span class="line">% Fifth, calculate the FSI (full spectrum index)</span><br><span class="line">% Calculates the Full-spectrum Index</span><br><span class="line"></span><br><span class="line">% Interpolate to wavelength interval of 1nm <span class="keyword">from</span> 380nm to 730nm</span><br><span class="line">numWave = <span class="number">351</span>;</span><br><span class="line">t=(<span class="number">380</span>:<span class="number">1</span>:<span class="number">730</span>)<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">spd=interp1(wavelength_spd,spd,t,&#x27;</span>spline<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">spd(isnan(spd)) = 0.0; </span></span><br><span class="line"><span class="string">spd = spd/sum(spd); % Normalize the relative spd so that the total power equals 1</span></span><br><span class="line"><span class="string">%Equal energy cumulative spd</span></span><br><span class="line"><span class="string">EEcum=(1/numWave:1/numWave:1)&#x27;</span>;</span><br><span class="line">%Calculate FSI</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j=<span class="number">1</span>:numWave </span><br><span class="line">cum = cumsum(spd); % A MatLab function <span class="keyword">for</span> cumulative sums </span><br><span class="line">sqrDiff = (cum-EEcum).^<span class="number">2</span>; </span><br><span class="line">sumSqrDiff(j)=<span class="built_in">sum</span>(sqrDiff); </span><br><span class="line">spd=circshift(spd,<span class="number">1</span>); </span><br><span class="line">end </span><br><span class="line">FSI=mean(sumSqrDiff); </span><br><span class="line">FSCI=<span class="number">100</span>-<span class="number">5.1</span>*FSI;</span><br><span class="line">fprintf(<span class="number">1</span>,<span class="string">&#x27;FSCI = %.3f\n&#x27;</span>,FSCI);</span><br></pre></td></tr></table></figure><h2 id="杂项"><a href="#杂项" class="headerlink" title="杂项"></a>杂项</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helmholtz</span><br><span class="line">axis equal</span><br></pre></td></tr></table></figure><h2 id="MATLAB绘制多条曲线"><a href="#MATLAB绘制多条曲线" class="headerlink" title="MATLAB绘制多条曲线"></a>MATLAB绘制多条曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n = length(a(<span class="number">1</span>,:))-<span class="number">1</span>;  %how much number of color to use</span><br><span class="line">c = colormap(jet(n));  %number of color <span class="keyword">in</span> figure</span><br><span class="line">c1 = <span class="number">0</span>;</span><br><span class="line">figure(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]); </span><br><span class="line"><span class="keyword">for</span> ix = <span class="number">2</span>:length(a(<span class="number">1</span>,:))</span><br><span class="line">    plot(a(:,<span class="number">1</span>),a(:,ix),<span class="string">&#x27;Color&#x27;</span>, c(ix-<span class="number">1</span>,:),  <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line">    hold on;</span><br><span class="line">end</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">20</span>);axis([<span class="built_in">min</span>(a(:,<span class="number">1</span>)),<span class="built_in">max</span>(a(:,<span class="number">1</span>)),<span class="number">0</span>  , <span class="number">0.7</span>]);</span><br><span class="line">xlabel(<span class="string">&#x27;wavelength (nm)&#x27;</span>);ylabel(<span class="string">&#x27;Intensity&#x27;</span>);</span><br></pre></td></tr></table></figure><p>&#96;&#96;python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">%% <span class="built_in">input</span> a(wavelength,curve)</span><br><span class="line">number=length(a(<span class="number">1</span>,:))-<span class="number">1</span>;%总的绘制曲线的条数</span><br><span class="line">photo = <span class="number">6</span> ; %图片个数</span><br><span class="line">curve_n=number/photo; %%每个图片中的曲线</span><br><span class="line">b=a(:,<span class="number">2</span>:number+<span class="number">1</span>); %% curve</span><br><span class="line"></span><br><span class="line">x =a(:,<span class="number">1</span>); %% wavelength</span><br><span class="line">TempNum = <span class="number">6</span> ;%% 颜色的数量</span><br><span class="line">cmap = hsv(TempNum);</span><br><span class="line">figure(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]);</span><br><span class="line"><span class="keyword">for</span> j=<span class="number">1</span>:photo</span><br><span class="line">        subplot(<span class="number">3</span>, <span class="number">2</span>, j);</span><br><span class="line">        k=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> i=(j-<span class="number">1</span>)*curve_n+<span class="number">1</span>:j*curve_n</span><br><span class="line">            y = b(:,i);</span><br><span class="line">            plot(x, y,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">3</span>,<span class="string">&#x27;Color&#x27;</span>,cmap(k,:));hold on;</span><br><span class="line">            k=k+<span class="number">1</span>;</span><br><span class="line">        end</span><br><span class="line">        hold off;</span><br><span class="line">        xlabel(<span class="string">&#x27;Wavelength(nm)&#x27;</span>);</span><br><span class="line">        axis([<span class="number">400</span> <span class="number">1300</span> <span class="number">0</span> <span class="number">1</span>]);</span><br><span class="line">        <span class="built_in">set</span>(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Calibri&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">30</span>);</span><br><span class="line">        h = legend(<span class="string">&#x27;50&#x27;</span>,<span class="string">&#x27;100&#x27;</span>,<span class="string">&#x27;150&#x27;</span>,<span class="string">&#x27;200&#x27;</span>,<span class="string">&#x27;250&#x27;</span>);</span><br><span class="line">        <span class="built_in">set</span>(h, <span class="string">&#x27;Box&#x27;</span>, <span class="string">&#x27;off&#x27;</span>);</span><br><span class="line">end</span><br><span class="line">%         plot(wave,R,<span class="string">&#x27;r&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">3</span>);hold on;plot(wave,T,<span class="string">&#x27;b--&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">3</span>);</span><br><span class="line">%         xlabel(<span class="string">&#x27;Wavelength(nm)&#x27;</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Calibri&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">%         ylabel(<span class="string">&#x27;R&amp;T&#x27;</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Calibri&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">%         <span class="built_in">set</span>(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Calibri&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">%          n=<span class="number">32</span>; colormap(hsv(n)); pcolor([<span class="number">1</span>:n+<span class="number">1</span>;<span class="number">1</span>:n+<span class="number">1</span>]);</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>MATLAB 控制FDTD程序</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">function Y = objectivefunction(X)</span><br><span class="line">    % Note: X <span class="keyword">is</span> a [<span class="number">1</span>*<span class="number">2</span>] vector, i.e. X=[x1 x2]</span><br><span class="line">     x1=X(<span class="number">1</span>,<span class="number">1</span>);x2=X(<span class="number">1</span>,<span class="number">2</span>); % x2=second variable</span><br><span class="line">    path(path,<span class="string">&#x27;C:\Program Files\Lumerical\FDTD\api\matlab&#x27;</span>);%Add Lumerical Matlab API path</span><br><span class="line">    sim_file_path=(<span class="string">&#x27;D:\files\FDTD files\MATLABcomsol\multi&#x27;</span>); % update this path to use<span class="string">r&#x27;s folder 文件路径</span></span><br><span class="line"><span class="string">    sim_file_name=(&#x27;</span>Wu.fsp<span class="string">&#x27;);% 文件名字</span></span><br><span class="line"><span class="string">    h=appopen(&#x27;</span>fdtd<span class="string">&#x27;); %Open FDTD session</span></span><br><span class="line"><span class="string">    %Pass the path variables to FDTD</span></span><br><span class="line"><span class="string">    appputvar(h,&#x27;</span>sim_file_path<span class="string">&#x27;,sim_file_path);</span></span><br><span class="line"><span class="string">    appputvar(h,&#x27;</span>sim_file_name<span class="string">&#x27;,sim_file_name);</span></span><br><span class="line"><span class="string">    appevalscript(h,&#x27;</span>load(<span class="string">&quot;Wu.fsp&quot;</span>);<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">%   appevalscript(h,&#x27;</span>switchtolayout;<span class="string">&#x27;);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%%  set parameter</span></span><br><span class="line"><span class="string">    code=strcat(&#x27;</span>switchtolayout;<span class="string">&#x27;,&#x27;</span>select(<span class="string">&quot;group&quot;</span>);<span class="string">&#x27;,...</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="built_in">set</span>(<span class="string">&quot;h1&quot;</span>,<span class="string">&#x27;,num2str(x1*1e-9,16),&#x27;</span>);<span class="string">&#x27;,...</span></span><br><span class="line"><span class="string">    &#x27;</span><span class="built_in">set</span>(<span class="string">&quot;h3&quot;</span>,<span class="string">&#x27;,num2str(x2*1e-9,16),&#x27;</span>);<span class="string">&#x27;,...</span></span><br><span class="line"><span class="string">    &#x27;</span>run;<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">    appevalscript(h,code);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%     appevalscript(h,&#x27;</span>run;<span class="string">&#x27;);%跑</span></span><br><span class="line"><span class="string">    appevalscript(h,&#x27;</span>A=getresult(<span class="string">&quot;monitor&quot;</span>,<span class="string">&quot;T&quot;</span>);<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">    appevalscript(h,&#x27;</span>A_s=A.getattribute(<span class="string">&quot;T&quot;</span>);<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">    A_spectrum =appgetvar(h,&#x27;</span>A_s<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    A=10; % parameter of the optimization problem</span></span><br><span class="line"><span class="string">    n=2; % parameter of the optimization problem</span></span><br><span class="line"><span class="string">    appclose(h);</span></span><br><span class="line"><span class="string">    Y=sum(A_spectrum);</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">% Y=A*n+[(x1)^2-A*cos(2*pi*x1)]+[(x2)^2-A*cos(2*pi*x2)];</span></span><br><span class="line"><span class="string">% Y=Rastrigin function</span></span><br></pre></td></tr></table></figure><h2 id="MATLAB-绘制多条曲线"><a href="#MATLAB-绘制多条曲线" class="headerlink" title="MATLAB 绘制多条曲线"></a>MATLAB 绘制多条曲线</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n = length(a(<span class="number">1</span>,:))-<span class="number">1</span>;  %how much number of color to use</span><br><span class="line">c = colormap(jet(n));  %number of color <span class="keyword">in</span> figure</span><br><span class="line">c1 = <span class="number">0</span>;</span><br><span class="line">figure(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]); </span><br><span class="line"><span class="keyword">for</span> ix = <span class="number">2</span>:length(a(<span class="number">1</span>,:))</span><br><span class="line">    plot(a(:,<span class="number">1</span>),a(:,ix),<span class="string">&#x27;Color&#x27;</span>, c(ix-<span class="number">1</span>,:),  <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line">    hold on;</span><br><span class="line">end</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">20</span>);axis([<span class="built_in">min</span>(a(:,<span class="number">1</span>)),<span class="built_in">max</span>(a(:,<span class="number">1</span>)),<span class="number">0</span>  , <span class="number">0.7</span>]);</span><br><span class="line">xlabel(<span class="string">&#x27;wavelength (nm)&#x27;</span>);ylabel(<span class="string">&#x27;Intensity&#x27;</span>);</span><br></pre></td></tr></table></figure><h2 id="picture函数导出透明图片"><a href="#picture函数导出透明图片" class="headerlink" title="picture函数导出透明图片"></a>picture函数导出透明图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">img = imread(<span class="string">&#x27;mypicture.png&#x27;</span>);</span><br><span class="line">min_x = <span class="number">0</span>;max_x = <span class="number">0.8</span>;min_y = <span class="number">0</span>;max_y = <span class="number">0.9</span>;</span><br><span class="line">imagesc([min_x max_x], [min_y max_y], flipdim(img,<span class="number">1</span>)); </span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;ydir&#x27;</span>,<span class="string">&#x27;normal&#x27;</span>);</span><br><span class="line">hold on;</span><br><span class="line">plot(<span class="number">0.3333</span>,<span class="number">0.3333</span>,<span class="string">&#x27;r*&#x27;</span>);</span><br></pre></td></tr></table></figure><h2 id="时间计算-tc-m"><a href="#时间计算-tc-m" class="headerlink" title="时间计算 tc.m"></a>时间计算 tc.m</h2><p>用法：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">t1 = clock;</span><br><span class="line"><span class="comment">% 程序</span></span><br><span class="line">t2 = clock;</span><br><span class="line">tc(t2, t1);</span><br></pre></td></tr></table></figure><p>函数：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="params">[Frame_Name]</span>= <span class="title">tc</span><span class="params">(t2,t1)</span></span></span><br><span class="line">    time_distance = etime(t2,t1);</span><br><span class="line">    <span class="comment">% 保留小数点后两位</span></span><br><span class="line">    <span class="keyword">if</span> time_distance &lt;= <span class="number">60</span></span><br><span class="line">        Frame_Name = [ num2str(<span class="built_in">round</span>(time_distance,<span class="number">2</span>)) <span class="string">&#x27;s&#x27;</span>]</span><br><span class="line">        time_distance = time_distance/<span class="number">60</span>;</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(time_distance &gt;<span class="number">60</span> )&amp;&amp;(time_distance &lt;<span class="number">60</span>*<span class="number">60</span>)</span><br><span class="line">        Frame_Name = [ num2str(<span class="built_in">round</span>(time_distance/<span class="number">60</span>,<span class="number">2</span>)) <span class="string">&#x27;min&#x27;</span>]</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> time_distance &gt;= <span class="number">60</span>*<span class="number">60</span></span><br><span class="line">        Frame_Name = [ num2str(<span class="built_in">round</span>(time_distance/<span class="number">60</span>/<span class="number">60</span>,<span class="number">2</span>)) <span class="string">&#x27;h&#x27;</span>]</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">start_time = time.time()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line"><span class="keyword">if</span> end_time - start_time &gt;= <span class="number">3600</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; h&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">3600</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="keyword">elif</span> end_time - start_time &gt;= <span class="number">60</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; min&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">60</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; s&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time), <span class="number">1</span>)))</span><br></pre></td></tr></table></figure><h2 id="黑体辐射强度"><a href="#黑体辐射强度" class="headerlink" title="黑体辐射强度"></a>黑体辐射强度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">% simple model of the black body using MATLAB/Octave/Freemat</span><br><span class="line">wavelength = <span class="number">0.01</span>:<span class="number">0.01</span>:<span class="number">5.0</span>;     % microns sweep over a <span class="built_in">range</span> of wavelengths</span><br><span class="line">T = <span class="number">5000</span>;                       % temperature <span class="keyword">in</span> kelvin</span><br><span class="line">F = <span class="number">3.742</span>./ ((wavelength.^<span class="number">5</span>).*(exp(<span class="number">1.439e4</span>./(wavelength*T))-<span class="number">1</span>)) ; % gives the result <span class="keyword">in</span> W/m2/um x <span class="number">1e8</span></span><br><span class="line">plot(wavelength,F);</span><br><span class="line">xlabel(<span class="string">&#x27;wavelength (\mum)&#x27;</span>);       %  add axis labels <span class="keyword">and</span> plot title</span><br><span class="line">ylabel(<span class="string">&#x27;spectral intensity (W/m^2/\mum) x 10^8&#x27;</span>);</span><br><span class="line">title(<span class="string">&#x27;Blackbody Radiation&#x27;</span>);</span><br><span class="line">legend(sprintf(<span class="string">&#x27;T = %.0f K&#x27;</span>,T));</span><br></pre></td></tr></table></figure><h2 id="画彩色图"><a href="#画彩色图" class="headerlink" title="画彩色图"></a>画彩色图</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">figure</span>(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]);</span><br><span class="line">x = <span class="built_in">linspace</span>(-grating_period, grating_period, <span class="number">100</span>); <span class="comment">% 绘制的范围 两个周期</span></span><br><span class="line">[tab1, z, o] = res3(x, aa, profil1, <span class="number">1</span>, parm); </span><br><span class="line">h = pcolor(x, z, <span class="built_in">real</span>(o)); <span class="comment">% 绘制图像，并返回句柄</span></span><br><span class="line">set(h, <span class="string">&#x27;EdgeColor&#x27;</span>, <span class="string">&#x27;none&#x27;</span>);</span><br><span class="line">axis tight; <span class="comment">% 自动调整坐标轴的范围，使其紧贴着数据的最小值和最大值</span></span><br><span class="line">colorbar;colormap jet;</span><br><span class="line">set(gca, <span class="string">&#x27;TickDir&#x27;</span>, <span class="string">&#x27;in&#x27;</span>, <span class="string">&#x27;Box&#x27;</span>, <span class="string">&#x27;off&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>, <span class="number">1.5</span>);</span><br><span class="line">set(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>); <span class="comment">% Times New Roman</span></span><br><span class="line">xlabel(<span class="string">&#x27;X label range (um)&#x27;</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;Z label (um)&#x27;</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">title(<span class="string">&#x27;两个周期 截面折射率&#x27;</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Monospaced&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">36</span>);</span><br><span class="line">set(gcf,<span class="string">&#x27;unit&#x27;</span>,<span class="string">&#x27;centimeters&#x27;</span>,<span class="string">&#x27;position&#x27;</span>,[<span class="number">-25</span>,<span class="number">10</span>,<span class="number">20</span>,<span class="number">15</span>]) <span class="comment">% [位置横纵 宽 高]</span></span><br></pre></td></tr></table></figure><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230405173146881.png" alt="image-20230405173146881" style="zoom:50%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">%<span class="built_in">input</span> a</span><br><span class="line">[ax,ay]=size(a);</span><br><span class="line">B=a(<span class="number">1</span>,<span class="number">2</span>:ay);</span><br><span class="line">A=a(<span class="number">2</span>:ax,<span class="number">1</span>);</span><br><span class="line">C=a(<span class="number">2</span>:ax,<span class="number">2</span>:ay);</span><br><span class="line">%  C=flipud(C);</span><br><span class="line">[ax,ay]=<span class="built_in">max</span>(<span class="built_in">max</span>(C));</span><br><span class="line">% C=C/ax;</span><br><span class="line">[x,y]=meshgrid(A,B);</span><br><span class="line">figure(<span class="string">&#x27;color&#x27;</span>,[<span class="number">1</span> <span class="number">1</span> <span class="number">1</span>]);</span><br><span class="line">surf(y,x,C<span class="string">&#x27;);shading interp;colorbar;</span></span><br><span class="line"><span class="string"> pcolor(A,B,C&#x27;</span>)</span><br><span class="line">% pcolor(B,A,C)</span><br><span class="line">colorbar,shading interp, hold on;</span><br><span class="line">[c,h] = contour(A,B,C<span class="string">&#x27;,[0.9],&#x27;</span>k--<span class="string">&#x27;,&#x27;</span>LineWidth<span class="string">&#x27;,1.2);%k 黑色</span></span><br><span class="line"><span class="string">[c,h] = contour(A,B,C&#x27;</span>,[<span class="number">0.8</span>],<span class="string">&#x27;b--&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.2</span>);%k 蓝色</span><br><span class="line">[c,h] = contour(A,B,C<span class="string">&#x27;,[0.6 0.6],&#x27;</span>k--<span class="string">&#x27;,&#x27;</span>LineWidth<span class="string">&#x27;,1.2);%k 红色</span></span><br><span class="line"><span class="string">set(gca,&#x27;</span>FontName<span class="string">&#x27;,&#x27;</span>Times New Roman<span class="string">&#x27;,&#x27;</span>FontSize<span class="string">&#x27;,36);</span></span><br><span class="line"><span class="string">colormap hot;</span></span><br><span class="line"><span class="string">% colormap jet;</span></span><br><span class="line"><span class="string">xlabel(&#x27;</span>Wavelength(μm)<span class="string">&#x27;,&#x27;</span>FontName<span class="string">&#x27;,&#x27;</span>Times New Roman<span class="string">&#x27;,&#x27;</span>FontSize<span class="string">&#x27;,36);</span></span><br><span class="line"><span class="string">ylabel(&#x27;</span>Incident angle(degree)<span class="string">&#x27;,&#x27;</span>FontName<span class="string">&#x27;,&#x27;</span>Times New Roman<span class="string">&#x27;,&#x27;</span>FontSize<span class="string">&#x27;,36);</span></span><br><span class="line"><span class="string">set(gcf,&#x27;</span>unit<span class="string">&#x27;,&#x27;</span>centimeters<span class="string">&#x27;,&#x27;</span>position<span class="string">&#x27;,[5 5 25 20]) % 长//宽</span></span><br><span class="line"><span class="string">% set(gca,&#x27;</span>Position<span class="string">&#x27;,[.1 .3 .2 .5]);</span></span><br><span class="line"><span class="string">set(gca, &#x27;</span>yTick<span class="string">&#x27;, [0:30:90]);   %设置轴坐标刻度</span></span><br></pre></td></tr></table></figure><h2 id="螺丝程序"><a href="#螺丝程序" class="headerlink" title="螺丝程序"></a>螺丝程序</h2><p>·&#96;python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">% a = <span class="number">0</span>:<span class="number">0.02</span>:<span class="number">1</span>*<span class="number">2</span>*pi;</span><br><span class="line">% z = sin(a);z=z<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">% le = length(a);</span></span><br><span class="line"><span class="string">% y1 =0*cos(a);</span></span><br><span class="line"><span class="string">% y1 = y1&#x27;</span>;</span><br><span class="line">% y2=cos(a);</span><br><span class="line">% y2 = y2<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">% yy = [y1 ;y2];</span></span><br><span class="line"><span class="string">% YY = yy;</span></span><br><span class="line"><span class="string">% for ix = 1:3</span></span><br><span class="line"><span class="string">% YY = [YY ;yy];</span></span><br><span class="line"><span class="string">% end</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">a = -1:0.02:1;</span></span><br><span class="line"><span class="string">a1 = 0.98:-0.02:-1;</span></span><br><span class="line"><span class="string">b = [a a1];</span></span><br><span class="line"><span class="string">y = asin(b);</span></span><br><span class="line"><span class="string">y = y&#x27;</span>;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="全排列组合"><a href="#全排列组合" class="headerlink" title="全排列组合"></a>全排列组合</h2><p>··&#96;python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cs1 = <span class="number">1</span>:<span class="number">4</span>;</span><br><span class="line">cs2 = <span class="number">1</span>:<span class="number">3</span>;</span><br><span class="line">cs3 = <span class="number">2</span>:<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">[j1,j2,j3]=ndgrid(cs1,cs2,cs3);</span><br><span class="line">COM=[j1(:),j2(:),j3(:)];clear cs1 cs2 cs3 j1 j2 j3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scale = <span class="number">10</span>; % 分辨率</span><br><span class="line">column = DomainElementsY / scale ; % <span class="number">10</span> 划分的个数 矩阵的列数 </span><br><span class="line">A = double(logical(de2bi(<span class="number">0</span>:<span class="number">2</span>^column-<span class="number">1</span>, column)));</span><br></pre></td></tr></table></figure><h2 id="西瓜函数"><a href="#西瓜函数" class="headerlink" title="西瓜函数"></a>西瓜函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">function SolvePde_FrozenWatermelon</span><br><span class="line">% 把西瓜放冰箱里，多长时间才能冰透？</span><br><span class="line">% 求解冰镇西瓜过程中的温度扩散问题（热传导方程）</span><br><span class="line">%       <span class="number">1</span>   ∂T     <span class="number">1</span>   ∂        ∂</span><br><span class="line">%      ---.---- = ---.----( r2.----)</span><br><span class="line">%       a   ∂t     r2  ∂r       ∂r</span><br><span class="line">%</span><br><span class="line">%   初始条件：</span><br><span class="line">%            t = <span class="number">0</span>, <span class="number">0</span> ≤ r ≤ R, T = T0</span><br><span class="line">%   边值条件：</span><br><span class="line">%            t &gt; <span class="number">0</span>, r = <span class="number">0</span>, ∂T/∂r = <span class="number">0</span></span><br><span class="line">%            t &gt; <span class="number">0</span>, r = R, h(T - Tinf) = -k.∂T/∂r</span><br><span class="line">%</span><br><span class="line">%   <span class="number">1.</span> 假设西瓜的外形是一个半径为R的完美的球体</span><br><span class="line">%   <span class="number">2.</span> 假设西瓜没有瓜皮，没有瓜籽，瓜瓤也是完全均匀的，其密度、导热能力、比热容</span><br><span class="line">%      全是均匀的，一切物性参数都不随温度变化而变化</span><br><span class="line">%   <span class="number">3.</span> 冰箱是一个恒温为Tinf ℃的环境</span><br><span class="line">%</span><br><span class="line">%   August <span class="number">4</span>  <span class="number">2017</span>, editted by ZhongHua-Xie, Tianjin University of Science <span class="keyword">and</span> Technology.</span><br><span class="line"></span><br><span class="line">% 相关参数</span><br><span class="line">h = <span class="number">5</span>;%        % 西瓜与静止冷空气的对流换热系数 [w/(㎡.K)]</span><br><span class="line">k = <span class="number">0.48</span>;%     % 西瓜的导热系数 [w/(m.K)]</span><br><span class="line">p = <span class="number">918</span>;      % 西瓜的密度 [kg/m3]</span><br><span class="line">Cp = <span class="number">3990</span>;    % 热容 [J/(kg.K)]</span><br><span class="line">a = k/(p*Cp); % 西瓜的热扩散系数 [㎡/s]</span><br><span class="line">T0 = <span class="number">32</span>;      % 初始温度 [℃]</span><br><span class="line">Tinf = <span class="number">6</span>;     % 终极温度 [℃]</span><br><span class="line"></span><br><span class="line">m = <span class="number">2</span>;                                     % 方程中的m参数</span><br><span class="line">r = linspace(<span class="number">0</span>,<span class="number">9</span>,<span class="number">50</span>)/<span class="number">100</span>;                  % 定义距离向量r</span><br><span class="line">t = linspace(<span class="number">0</span>,<span class="number">10</span>,<span class="number">50</span>)*<span class="number">3600</span>;                % 定义时间向量t</span><br><span class="line">Td = pdepe(m,@pdefun,@pdeic,@pdebc,r,t);   % 方程求解</span><br><span class="line"></span><br><span class="line">% 结果可视化</span><br><span class="line">figure;</span><br><span class="line">surf(r*<span class="number">100</span>,t/<span class="number">3600</span>,Td);                     % 绘制温度T关于距离r和时间t的三维曲面</span><br><span class="line">colorbar;</span><br><span class="line">zlim([<span class="built_in">min</span>(Td(:))-<span class="number">2</span>,<span class="built_in">max</span>(Td(:))+<span class="number">2</span>]);</span><br><span class="line">title(<span class="string">&#x27;T(r,t)&#x27;</span>); </span><br><span class="line">xlabel(<span class="string">&#x27;Distance r&#x27;</span>);</span><br><span class="line">ylabel(<span class="string">&#x27;Time t&#x27;</span>)</span><br><span class="line">view(<span class="number">116</span>,<span class="number">33</span>);</span><br><span class="line">text(<span class="number">8</span>,-<span class="number">0.5</span>,<span class="number">34.5</span>,<span class="string">&#x27;开始冷藏&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">18</span>,<span class="string">&#x27;Rotation&#x27;</span>,<span class="number">40</span>)</span><br><span class="line">text(<span class="number">0</span>,<span class="number">5</span>,<span class="number">26</span>,<span class="string">&#x27;瓜心&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">18</span>)</span><br><span class="line">text(<span class="number">7</span>,<span class="number">2</span>,<span class="number">10.5</span>,<span class="string">&#x27;瓜皮&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">18</span>)</span><br><span class="line"></span><br><span class="line">% 绘制西瓜等效切面温度扩散动画</span><br><span class="line">num = size(Td,<span class="number">2</span>);</span><br><span class="line">thetai = linspace(<span class="number">0</span>,<span class="number">2</span>*pi,<span class="number">50</span>);</span><br><span class="line">[R,Theta] = meshgrid(r,thetai);</span><br><span class="line">X = <span class="number">100</span>*R.*cos(Theta);</span><br><span class="line">Y = <span class="number">100</span>*R.*sin(Theta);</span><br><span class="line">Tdi = ones(size(thetai<span class="string">&#x27;))*Td(1,:);</span></span><br><span class="line"><span class="string">X_bac = linspace(min(X(:))-1,max(X(:))+1,50);</span></span><br><span class="line"><span class="string">Y_bac = linspace(min(Y(:))-1,max(Y(:))+1,50);</span></span><br><span class="line"><span class="string">[X_bac,Y_bac] = meshgrid(X_bac,Y_bac);</span></span><br><span class="line"><span class="string">figure;</span></span><br><span class="line"><span class="string">% 绘制背景温度面</span></span><br><span class="line"><span class="string">surf(X_bac,Y_bac,Tinf*ones(size(X_bac)),&#x27;</span>FaceColo<span class="string">r&#x27;,&#x27;</span>interp<span class="string">&#x27;,&#x27;</span>EdgeColo<span class="string">r&#x27;,&#x27;</span>none<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">hold on;</span></span><br><span class="line"><span class="string">% 绘制零时刻西瓜等效温度切面</span></span><br><span class="line"><span class="string">hs = surf(X,Y,Tdi,&#x27;</span>FaceColo<span class="string">r&#x27;,&#x27;</span>interp<span class="string">&#x27;,&#x27;</span>EdgeColo<span class="string">r&#x27;,&#x27;</span>none<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">axis equal;</span></span><br><span class="line"><span class="string">axis([min(X_bac(:)),max(X_bac(:)),min(Y_bac(:)),max(Y_bac(:))])</span></span><br><span class="line"><span class="string">xlabel(&#x27;</span>X<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">ylabel(&#x27;</span>Y<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">caxis([Tinf,max(Td(:))]);</span></span><br><span class="line"><span class="string">colorbar;</span></span><br><span class="line"><span class="string">view(2);</span></span><br><span class="line"><span class="string">ht = title([&#x27;</span>冷藏<span class="string">&#x27;,num2str(t(1)/3600,&#x27;</span>%<span class="number">2.1</span><span class="string">f&#x27;),&#x27;</span>小时后<span class="string">&#x27;]);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">% filename = &#x27;</span>冰镇西瓜温度扩散动画.gi<span class="string">f&#x27;;</span></span><br><span class="line"><span class="string">% f = getframe(gcf);</span></span><br><span class="line"><span class="string">% IM = frame2im(f);</span></span><br><span class="line"><span class="string">% [IM,map] = rgb2ind(IM,256);</span></span><br><span class="line"><span class="string">% imwrite(IM,map,filename,&#x27;</span>gi<span class="string">f&#x27;, &#x27;</span>Loopcount<span class="string">&#x27;,inf,&#x27;</span>DelayTime<span class="string">&#x27;,0.2);</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">for i = 2:num</span></span><br><span class="line"><span class="string">    Tdi = ones(size(thetai&#x27;</span>))*Td(i,:);</span><br><span class="line">    <span class="built_in">set</span>(hs,<span class="string">&#x27;ZData&#x27;</span>,Tdi);</span><br><span class="line">    <span class="built_in">set</span>(ht,<span class="string">&#x27;String&#x27;</span>,[<span class="string">&#x27;冷藏&#x27;</span>,num2str(t(i)/<span class="number">3600</span>,<span class="string">&#x27;%2.1f&#x27;</span>),<span class="string">&#x27;小时后&#x27;</span>]);</span><br><span class="line">    pause(<span class="number">0.2</span>);</span><br><span class="line"></span><br><span class="line">%     f = getframe(gcf);</span><br><span class="line">%     IM = frame2im(f);</span><br><span class="line">%     [IM,<span class="built_in">map</span>] = rgb2ind(IM,<span class="number">256</span>);</span><br><span class="line">%     imwrite(IM,<span class="built_in">map</span>,filename,<span class="string">&#x27;gif&#x27;</span>,<span class="string">&#x27;WriteMode&#x27;</span>,<span class="string">&#x27;append&#x27;</span>,<span class="string">&#x27;DelayTime&#x27;</span>,<span class="number">0.2</span>);   </span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">    function [c,f,s] = pdefun(r,t,T,dT)</span><br><span class="line">        % 偏微分方程函数</span><br><span class="line">        c = <span class="number">1</span>/a;</span><br><span class="line">        f = dT;</span><br><span class="line">        s = <span class="number">0</span>;</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    function u0 = pdeic(r)</span><br><span class="line">        % 初始条件函数</span><br><span class="line">        u0 = T0;</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    function [pa,qa,pb,qb] = pdebc(ra,Ta,rb,Tb,t)</span><br><span class="line">        % 边值条件函数</span><br><span class="line">        pa = <span class="number">0</span>;</span><br><span class="line">        qa = <span class="number">1</span>;</span><br><span class="line">        pb = h*(Tb - Tinf);</span><br><span class="line">        qb = k;</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">end</span><br></pre></td></tr></table></figure><h2 id="有效折射理论"><a href="#有效折射理论" class="headerlink" title="有效折射理论"></a>有效折射理论</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear;</span><br><span class="line">S11R=importdata(<span class="string">&#x27;real11.txt&#x27;</span>);</span><br><span class="line">S11I=importdata(<span class="string">&#x27;imag11.txt&#x27;</span>);</span><br><span class="line">S21R=importdata(<span class="string">&#x27;real21.txt&#x27;</span>);</span><br><span class="line">S21I=importdata(<span class="string">&#x27;imag21.txt&#x27;</span>);%导入数据</span><br><span class="line">real11=S11R.data;</span><br><span class="line">imag11=S11I.data;</span><br><span class="line">real21=S21R.data;</span><br><span class="line">imag21=S21I.data;</span><br><span class="line">N=<span class="number">1001</span>;</span><br><span class="line">d=<span class="number">0.00002</span>;</span><br><span class="line">c=<span class="number">3e8</span>;</span><br><span class="line"></span><br><span class="line">f=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">s11=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">s21=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">z1=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">z=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">kd=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">n1=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">n=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">e=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">miu=zeros(<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:N</span><br><span class="line">    f(i)=real11(i,<span class="number">1</span>);</span><br><span class="line">    s11(i)=real11(i,<span class="number">2</span>)+<span class="number">1j</span>*imag11(i,<span class="number">2</span>);</span><br><span class="line">    s21(i)=real21(i,<span class="number">2</span>)+<span class="number">1j</span>*imag21(i,<span class="number">2</span>);</span><br><span class="line">end</span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:N</span><br><span class="line">    z1(i)=sqrt(((<span class="number">1</span>+s11(i))^<span class="number">2</span>-s21(i)^<span class="number">2</span>)/((<span class="number">1</span>-s11(i))^<span class="number">2</span>-s21(i)^<span class="number">2</span>));</span><br><span class="line">    <span class="keyword">if</span> real(z1(i))&gt;<span class="number">0</span></span><br><span class="line">        z(i)=z1(i);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        z(i)=-z1(i);</span><br><span class="line">    end</span><br><span class="line">    kd(i)=d*<span class="number">2</span>*pi*f(i)*<span class="number">1e9</span>/c;</span><br><span class="line">    n1(i)=acos((<span class="number">1</span>-s11(i)^<span class="number">2</span>+s21(i)^<span class="number">2</span>)/<span class="number">2</span>/s21(i))/kd(i);</span><br><span class="line">    <span class="keyword">if</span> imag(n1(i))&gt;<span class="number">0</span></span><br><span class="line">        n(i)=n1(i);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        n(i)=-n1(i);</span><br><span class="line">    end</span><br><span class="line">    e(i)=n(i)/z(i);</span><br><span class="line">    miu(i)=n(i)*z(i);</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">figure(<span class="number">1</span>)</span><br><span class="line"> subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line"> plot(f,real(e),f,imag(e),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Permittivity (\epsilon)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(\epsilon)&#x27;</span>,<span class="string">&#x27;Im(\epsilon)&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"> subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"> plot(f,real(miu),f,imag(miu),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Permeability (\mu)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(\mu)&#x27;</span>,<span class="string">&#x27;Im(\mu))&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"> subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"> plot(f,real(z),f,imag(z),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Impedance (z)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(Z)&#x27;</span>,<span class="string">&#x27;Im(Z))&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"> subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line"> plot(f,real(n),f,imag(n),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Refractive Index (n)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(n)&#x27;</span>,<span class="string">&#x27;Im(n))&#x27;</span>);</span><br><span class="line"> hold on</span><br><span class="line"> plot(f,f-f,<span class="string">&#x27;:&#x27;</span>)</span><br><span class="line"> %---------------------------------------------------------</span><br><span class="line"> figure(<span class="number">2</span>)</span><br><span class="line"> plot(f,real(miu),f,imag(miu),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Permeability (\mu)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(\mu)&#x27;</span>,<span class="string">&#x27;Im(\mu))&#x27;</span>);</span><br><span class="line"></span><br><span class="line"> figure(<span class="number">3</span>)</span><br><span class="line"> plot(f,real(e),f,imag(e),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Permittivity (\epsilon)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(\epsilon)&#x27;</span>,<span class="string">&#x27;Im(\epsilon)&#x27;</span>);</span><br><span class="line"> </span><br><span class="line"> figure(<span class="number">4</span>)</span><br><span class="line"> plot(f,real(z),f,imag(z),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27;Impedance (z)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(Z)&#x27;</span>,<span class="string">&#x27;Im(Z))&#x27;</span>);</span><br><span class="line"> </span><br><span class="line">  figure(<span class="number">5</span>)</span><br><span class="line"> plot(f,real(n),f,imag(n),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>);</span><br><span class="line"> xlabel(<span class="string">&#x27;Frequency/THz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> ylabel(<span class="string">&#x27; refractive index(n)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);</span><br><span class="line"> legend(<span class="string">&#x27;Re(n)&#x27;</span>,<span class="string">&#x27;Im(n))&#x27;</span>);</span><br><span class="line"> yy=interp1(f,n,<span class="number">1</span>);</span><br><span class="line"> </span><br><span class="line">% figure(<span class="number">2</span>)</span><br><span class="line">% subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">% plot(f,real(epsilon1),f,imag(epsilon1),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>); xlabel(<span class="string">&#x27;Frequency/GHz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);ylabel(<span class="string">&#x27;Permittivity (\epsilon)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);legend(<span class="string">&#x27;Re(\epsilon1)&#x27;</span>,<span class="string">&#x27;Im(\epsilon1)&#x27;</span>,<span class="number">4</span>);</span><br><span class="line">% subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">% plot(f,real(epsilon2),f,imag(epsilon2),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>); xlabel(<span class="string">&#x27;Frequency/GHz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);ylabel(<span class="string">&#x27;Permittivity (\epsilon)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>); legend(<span class="string">&#x27;Re(\epsilon2)&#x27;</span>,<span class="string">&#x27;Im(\epsilon2)&#x27;</span>,<span class="number">4</span>);</span><br><span class="line">% subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">% plot(f,real(epsilon3),f,imag(epsilon3),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>); xlabel(<span class="string">&#x27;Frequency/GHz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>); ylabel(<span class="string">&#x27;Permittivity (\epsilon)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>); legend(<span class="string">&#x27;Re(\epsilon3)&#x27;</span>,<span class="string">&#x27;Im(\epsilon3)&#x27;</span>,<span class="number">4</span>);</span><br><span class="line">% subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">% plot(f,real(mur),f,imag(mur),<span class="string">&#x27;r:&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">2</span>); xlabel(<span class="string">&#x27;Frequency/GHz&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>); ylabel(<span class="string">&#x27;Permeability (\mu)&#x27;</span>,<span class="string">&#x27;fontsize&#x27;</span>,<span class="number">10</span>,<span class="string">&#x27;fontweight&#x27;</span>,<span class="string">&#x27;b&#x27;</span>);legend(<span class="string">&#x27;Re(\mu)&#x27;</span>,<span class="string">&#x27;Im(\mu))&#x27;</span>,<span class="number">4</span>);</span><br></pre></td></tr></table></figure><h2 id="折射率等差-插值"><a href="#折射率等差-插值" class="headerlink" title="折射率等差 插值"></a>折射率等差 插值</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">clear Z;%%%%%%%%%%% a:原始数据</span><br><span class="line">z1=<span class="number">0.34</span>:<span class="number">0.02</span>:<span class="number">2.5</span>;z1=z1*<span class="number">1000</span>;</span><br><span class="line">n=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i=<span class="number">1</span>:length(a(:,<span class="number">1</span>)) % 原x数据 <span class="number">528</span></span><br><span class="line">    <span class="keyword">for</span> m=<span class="number">1</span>:length(z1) % 等差后的数据 <span class="number">979</span></span><br><span class="line">        <span class="keyword">if</span> (a(i,<span class="number">1</span>)-z1(m)&lt;=<span class="number">0</span>)&amp;&amp;(a(i+<span class="number">1</span>,<span class="number">1</span>)-z1(m)&gt;<span class="number">0</span>)</span><br><span class="line">            y11(n,<span class="number">1</span>)=a(i,<span class="number">2</span>)+(z1(n)-a(i,<span class="number">1</span>))*(a(i+<span class="number">1</span>,<span class="number">2</span>)-a(i,<span class="number">2</span>))/(a(i+<span class="number">1</span>,<span class="number">1</span>)-a(i,<span class="number">1</span>));</span><br><span class="line">            y22(n,<span class="number">1</span>)=a(i,<span class="number">3</span>)+(z1(n)-a(i,<span class="number">1</span>))*(a(i+<span class="number">1</span>,<span class="number">3</span>)-a(i,<span class="number">3</span>))/(a(i+<span class="number">1</span>,<span class="number">1</span>)-a(i,<span class="number">1</span>));</span><br><span class="line">            n=n+<span class="number">1</span>;</span><br><span class="line">        end</span><br><span class="line">    end  </span><br><span class="line">end</span><br><span class="line">%y11=y11<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">z1=z1&#x27;</span>;</span><br><span class="line"> %y22=y22<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">%Z=[z1,y11,y22];</span></span><br><span class="line"><span class="string">clear i;clear m;clear n;</span></span><br><span class="line"><span class="string">% clear y11;clear y22;clear z1;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">% c=roundn(Z,-4); </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[tmp I] = unique(a(:,1), &#x27;</span>first<span class="string">&#x27;);a = a(I,:); % 删除矩阵中第一列重复项</span></span><br><span class="line"><span class="string">wave = 300:20:2500;</span></span><br><span class="line"><span class="string">for ix = 2:length(a(1,:))</span></span><br><span class="line"><span class="string">    b(ix,:) = interp1(a(:,1),a(:,ix),wave,&#x27;</span>spline<span class="string">&#x27;);%  &#x27;</span>nearest<span class="string">&#x27;是最邻近插值， &#x27;</span>linea<span class="string">r&#x27;线性插值； &#x27;</span>spline<span class="string">&#x27;三次样条插值； &#x27;</span>pchip<span class="string">&#x27;立方插值．</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">b=b&#x27;</span>;</span><br><span class="line">wave=wave<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">b(:,1) = wave;</span></span><br></pre></td></tr></table></figure><h2 id="阻抗分析"><a href="#阻抗分析" class="headerlink" title="阻抗分析"></a>阻抗分析</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">function [R] = reflection_disp_norm(n_in, n_out, n_disp, d, <span class="keyword">lambda</span>)</span><br><span class="line">%REFLECTION_DISP_NORM Calculates the normal reflection spectrum of a multi-layer structure</span><br><span class="line">%   R: reflection spectrum</span><br><span class="line">% </span><br><span class="line">%   n_in: scalar/vector that specifies the refractive index of the incident material</span><br><span class="line">%   n_out: scalar/vector that specifies the refractive index of the substrate material</span><br><span class="line">%   n_disp: matrix that specifies the dispersive refractive indices of the structure</span><br><span class="line">%   d: vector that specifies the thicknesses of each layer</span><br><span class="line">%   theta_in: vector that specifies the wavelength of interest</span><br><span class="line">%%</span><br><span class="line">d = <span class="built_in">abs</span>(d);  %<span class="built_in">abs</span>取绝对值</span><br><span class="line">K = length(d); </span><br><span class="line">Z_out = <span class="number">1.</span>/n_out; </span><br><span class="line">Z_in = <span class="number">1</span>/n_in; </span><br><span class="line"></span><br><span class="line">%% Iteratively use the impedance method迭代地使用阻抗法</span><br><span class="line">Z_inter = Z_out; </span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span>:K</span><br><span class="line">    j = K-i+<span class="number">1</span>; </span><br><span class="line">    nj = n_disp(:, j); </span><br><span class="line">    dj = d(j); </span><br><span class="line">    Z_inter = <span class="number">1.</span>/nj .* (Z_inter + 1i*<span class="number">1.</span>/nj .* tan(<span class="number">2</span>*pi*nj./<span class="keyword">lambda</span> * dj)) ./ (<span class="number">1.</span>/nj + 1i.*Z_inter .* tan(<span class="number">2</span>*pi*nj./<span class="keyword">lambda</span> * dj));   </span><br><span class="line">end</span><br><span class="line">R = <span class="built_in">abs</span>((Z_inter - Z_in) ./ (Z_inter + Z_in)).^<span class="number">2</span>; </span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>计算ART 吸收&#x2F;透射&#x2F;反射</p><p>&#96;&#96;python</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">% % M = reflectance_TE(<span class="number">1</span>,<span class="number">1</span>,[<span class="number">3</span> <span class="number">4</span>],[<span class="number">100</span> <span class="number">50</span>]*<span class="number">1e-9</span>,<span class="number">0</span>,<span class="number">400</span>*<span class="number">1e-9</span>)</span><br><span class="line">% n0 = <span class="number">1</span>;</span><br><span class="line">% nsubs = <span class="number">1</span>;</span><br><span class="line">% n_layers = [<span class="number">3</span> <span class="number">4</span>];</span><br><span class="line">% d_layers = [<span class="number">100</span> <span class="number">50</span>]*<span class="number">1e-9</span>;</span><br><span class="line">% theta_in = <span class="number">0</span>;</span><br><span class="line">% <span class="keyword">lambda</span> = <span class="number">400</span>*<span class="number">1e-9</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">function [R_TE,T_TE] = reflectance_TE(n0,nsubs,n_layers,d_layers,theta_in,<span class="keyword">lambda</span>)</span><br><span class="line"></span><br><span class="line">% Mohammad Asif Zaman</span><br><span class="line">% June <span class="number">3</span> <span class="keyword">and</span> <span class="number">4</span>, <span class="number">2018</span></span><br><span class="line">% Reflectance calculaiton</span><br><span class="line">% Arguments: </span><br><span class="line">% n0 = refractive index of the <span class="built_in">input</span> medium</span><br><span class="line">% nsubs = refractive index of the substrate</span><br><span class="line">% n_layers = refractive indices of the thin-film layers</span><br><span class="line">% theta_in = incident angle (<span class="keyword">in</span> radians)</span><br><span class="line">% <span class="keyword">lambda</span> = wavelength</span><br><span class="line">% R_TE = output = reflectivity</span><br><span class="line">% -------------------------------- %</span><br><span class="line">%                                  %</span><br><span class="line">%               Air                %  </span><br><span class="line">%                                  %  </span><br><span class="line">% -------------------------------- % </span><br><span class="line">%             Layer <span class="number">1</span>              %</span><br><span class="line">% -------------------------------- %</span><br><span class="line">%             Layer <span class="number">2</span>              %</span><br><span class="line">% -------------------------------- %</span><br><span class="line">%                .                 %</span><br><span class="line">%                .                 %</span><br><span class="line">%                .                 %</span><br><span class="line">% -------------------------------- %</span><br><span class="line">%             Layer N              %  </span><br><span class="line">% -------------------------------- %</span><br><span class="line">%                                  %</span><br><span class="line">%            Substrate             %   </span><br><span class="line">%                                  %   </span><br><span class="line">% -------------------------------- %</span><br><span class="line">% We calculate the parameter theta, Z, <span class="keyword">and</span> eta on <span class="built_in">all</span> layers</span><br><span class="line">% There are N dielectric layers. The air (<span class="keyword">or</span> other) layer on top. And a</span><br><span class="line">% substrate layer on bottom. So, total N+<span class="number">2</span> layers.</span><br><span class="line">% We define (N+<span class="number">2</span>)x <span class="number">1</span> matrices <span class="keyword">for</span> <span class="built_in">all</span> quantities.</span><br><span class="line">% Haus book.</span><br><span class="line"></span><br><span class="line">Z0 = <span class="number">377</span>;</span><br><span class="line"></span><br><span class="line">theta_out = asin(n0*sin(theta_in)/nsubs); % 正入射=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">N = length(n_layers);   % 结构层数</span><br><span class="line">n = zeros(N+<span class="number">2</span>,<span class="number">1</span>);       % 材料折射率</span><br><span class="line">theta =  zeros(N+<span class="number">2</span>,<span class="number">1</span>);  % 入射角度</span><br><span class="line">Z = zeros(N+<span class="number">2</span>,<span class="number">1</span>);       % 阻抗</span><br><span class="line">eta = zeros(N+<span class="number">2</span>,<span class="number">1</span>);     % 导纳</span><br><span class="line"></span><br><span class="line">n(<span class="number">1</span>) = n0;              % 空气折射率</span><br><span class="line">n(end) = nsubs;         % 最底层 基底折射率</span><br><span class="line">n(<span class="number">2</span>:end-<span class="number">1</span>) = n_layers;% 中间层为多层薄膜结构</span><br><span class="line"></span><br><span class="line">theta(<span class="number">1</span>) = theta_in;    % 入射角度=<span class="number">0</span></span><br><span class="line">theta(end) = theta_out; % 出射角度=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">Z(<span class="number">1</span>) = Z0./(n(<span class="number">1</span>)*cos(theta(<span class="number">1</span>)));        % 第一层阻抗</span><br><span class="line">Z(end) = Z0./(n(end)*cos(theta(end)));  % 最底层阻抗</span><br><span class="line"></span><br><span class="line">eta(<span class="number">1</span>) = Z0./(cos(theta(<span class="number">1</span>)) .*n(<span class="number">1</span>));        % 媒质<span class="number">1</span>波阻抗</span><br><span class="line">eta(end) = Z0./(cos(theta(end)) .*n(end));  % 媒质end波阻抗</span><br><span class="line"></span><br><span class="line">Matrices = [<span class="number">1</span>,<span class="number">0</span>;<span class="number">0</span>,<span class="number">1</span>];</span><br><span class="line">Mcon = Matrices(:,:,<span class="number">1</span>);</span><br><span class="line"><span class="keyword">for</span> k = N:-<span class="number">1</span>:<span class="number">1</span>    % Work backwards <span class="keyword">from</span> the last layer. </span><br><span class="line">%   k represents index over the dielectric layers.</span><br><span class="line">    m = k + <span class="number">1</span>;    % Layer index going <span class="keyword">from</span> N+<span class="number">1</span> to <span class="number">2.</span> </span><br><span class="line">                  % since we know the parameters <span class="keyword">for</span> layer <span class="number">1</span> <span class="keyword">and</span> layer N+<span class="number">2.</span></span><br><span class="line">    </span><br><span class="line">    % Calculate parameters at m layer using data <span class="keyword">from</span> (m+<span class="number">1</span>) layer </span><br><span class="line">    theta(m) = asin( n(m+<span class="number">1</span>)*sin( theta(m+<span class="number">1</span>) ) / n(m)  );        % 入射角度=<span class="number">0</span></span><br><span class="line">    eta(m) = Z0./( cos(theta(m)) .*n(m) );</span><br><span class="line">    </span><br><span class="line">    tmp = <span class="number">2</span>*pi*n(m)/<span class="keyword">lambda</span> * cos(theta(m)) * d_layers(k);       % delta</span><br><span class="line">    Z(m) = eta(m)*( Z(m+<span class="number">1</span>) + i*eta(m)*tan(tmp) ) ./ (eta(m) + i*Z(m+<span class="number">1</span>)*tan(tmp));</span><br><span class="line">    %%</span><br><span class="line">    eta1(m) = n(m)*cos(theta(m));</span><br><span class="line">    Matrices(:,:,m) = [cos(tmp),-1i*sin(tmp)/eta1(m);</span><br><span class="line">        -1i*eta1(m)*sin(tmp),cos(tmp)]; % matrices de cada capa</span><br><span class="line">    Mcon = Mcon*Matrices(:,:,m);</span><br><span class="line">end</span><br><span class="line">BC = Mcon*[<span class="number">1</span>;n(end)*cos(theta(end))];</span><br><span class="line">% BC = Mcon*[<span class="number">1</span>;<span class="number">1</span>];</span><br><span class="line">Y = BC(<span class="number">2</span>)/BC(<span class="number">1</span>);</span><br><span class="line">eta_o = n0*cos(theta_in);</span><br><span class="line">% theta</span><br><span class="line">% eta</span><br><span class="line">% Z</span><br><span class="line">% R_TE = ((eta_o-Y)/(eta_o+Y))*conj((eta_o-Y)/(eta_o+Y)); % reflectancia</span><br><span class="line">% R_TE = <span class="built_in">abs</span>( (Z(<span class="number">2</span>)-Z(<span class="number">1</span>) ) ./ ( Z(<span class="number">2</span>)+Z(<span class="number">1</span>) ) ).^<span class="number">2</span>;</span><br><span class="line">R_TE = ( (Z(<span class="number">2</span>)-Z(<span class="number">1</span>) ) / ( Z(<span class="number">2</span>)+Z(<span class="number">1</span>) ) )    *conj( (Z(<span class="number">2</span>)-Z(<span class="number">1</span>) ) / ( Z(<span class="number">2</span>)+Z(<span class="number">1</span>) ) );</span><br><span class="line">T_TE = real(eta(end)/eta(<span class="number">1</span>))* <span class="built_in">abs</span>( (   <span class="number">2</span>*Z(<span class="number">2</span>) ) ./ ( Z(<span class="number">2</span>)+Z(<span class="number">1</span>) ) ).^<span class="number">2</span>;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line">clc;</span><br><span class="line">clear <span class="built_in">all</span>;</span><br><span class="line">%% Constantes</span><br><span class="line">c_speed = <span class="number">3e17</span>;% 光速/nm</span><br><span class="line">hbar = <span class="number">6.582119514e-16</span>; %eV*s</span><br><span class="line">J = <span class="number">2.6544e-3</span>;% factor admitancia</span><br><span class="line"></span><br><span class="line">Cavidad = &#123;<span class="string">&#x27;sustrato&#x27;</span>,<span class="string">&#x27;plata&#x27;</span>,<span class="string">&#x27;silica&#x27;</span>,<span class="string">&#x27;TDBC&#x27;</span>,<span class="string">&#x27;silica&#x27;</span>,<span class="string">&#x27;plata&#x27;</span>,<span class="string">&#x27;aire&#x27;</span>&#125;;</span><br><span class="line">Ncapas = length(Cavidad);           % layer = <span class="number">7</span></span><br><span class="line">polarizacion = <span class="number">2</span>; %TM = <span class="number">1</span>, TE = <span class="number">2</span>   % TE-polarization</span><br><span class="line"></span><br><span class="line">dEntrada = <span class="number">0</span>;                       % thickness</span><br><span class="line">dAg = <span class="number">30</span>;</span><br><span class="line">dTDBC = <span class="number">20</span>;</span><br><span class="line">dSilicaL = <span class="number">50</span>;</span><br><span class="line">dSilicaR = <span class="number">50</span>;</span><br><span class="line">dS = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">n0 = <span class="number">1</span>;                             % 空气折射率</span><br><span class="line">nEntrada = <span class="number">1.4587</span>;                  % 入射折射率</span><br><span class="line">nS = <span class="number">1</span>;                             % 基底折射率</span><br><span class="line"></span><br><span class="line">%% Definici髇 de par醡etros</span><br><span class="line">x = <span class="number">200</span>;</span><br><span class="line">y = <span class="number">200</span>;</span><br><span class="line">Emin = <span class="number">1.5</span>; % eV</span><br><span class="line">Emax = <span class="number">3.2</span>; % eV</span><br><span class="line"><span class="keyword">lambda</span> = linspace(<span class="number">2</span>*pi*c_speed*hbar/Emax,<span class="number">2</span>*pi*c_speed*hbar/Emin,y); % 波长/nm </span><br><span class="line"></span><br><span class="line">theta = <span class="number">0</span>;%(pi/<span class="number">180</span>)*linspace(<span class="number">0</span>,<span class="number">90</span>,x); % 入射角度-<span class="number">200</span>扫描点</span><br><span class="line">w1 = <span class="number">2</span>*pi*c_speed./<span class="keyword">lambda</span>;</span><br><span class="line">E = hbar*w1;</span><br><span class="line">ko = <span class="number">2</span>*pi./<span class="keyword">lambda</span>;</span><br><span class="line"></span><br><span class="line">kx = zeros(y,x);</span><br><span class="line">R = zeros(length(theta),length(<span class="keyword">lambda</span>));</span><br><span class="line">T = zeros(length(theta),length(<span class="keyword">lambda</span>));</span><br><span class="line">A = zeros(length(theta),length(<span class="keyword">lambda</span>));</span><br><span class="line"></span><br><span class="line">% <span class="keyword">for</span> i = <span class="number">1</span>:y</span><br><span class="line">%     <span class="keyword">for</span> ii = <span class="number">1</span>:x</span><br><span class="line">%         kx(i,ii) = n0*ko(i)*sin(theta(ii)); % 入射角度</span><br><span class="line">%     end</span><br><span class="line">% end</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k = <span class="number">1</span>:length(theta) % incident-angle</span><br><span class="line"><span class="keyword">for</span> l = <span class="number">1</span>:length(<span class="keyword">lambda</span>) % wavelength</span><br><span class="line">    %% Variables</span><br><span class="line">    w = <span class="number">2</span>*pi*c_speed/<span class="keyword">lambda</span>(l);</span><br><span class="line"></span><br><span class="line">eps5a = lorentzAg(w); % silver</span><br><span class="line">eps5a_real = real(eps5a);</span><br><span class="line">eps5a_im = imag(eps5a);</span><br><span class="line"></span><br><span class="line">eps5g = lorentzTDBC(w); % TDBC</span><br><span class="line">eps5g_real = real(eps5g);</span><br><span class="line">eps5g_im = imag(eps5g);</span><br><span class="line"></span><br><span class="line">% Indice de refracci髇 Ag y TBDC</span><br><span class="line">nAg = (eps5a_real+1i*eps5a_im)^<span class="number">0.5</span>;</span><br><span class="line">nTDBC = (eps5g_real+1i*eps5g_im)^<span class="number">0.5</span>;</span><br><span class="line">n_silica = sellmeier(<span class="keyword">lambda</span>(l));</span><br><span class="line">%% 相邻两个界面的入射角度 theta</span><br><span class="line">theta_Entrada = theta(k); % 入射角度</span><br><span class="line">theta_Ag1 = asin((nEntrada/nAg)*sin(theta_Entrada));</span><br><span class="line">theta_silicaL = asin((nAg/n_silica)*sin(theta_Ag1));</span><br><span class="line">theta_TDBC = asin((n_silica/nTDBC)*sin(theta_silicaL));</span><br><span class="line">theta_silicaR = asin((nTDBC/n_silica)*sin(theta_TDBC));</span><br><span class="line">theta_Ag2 = asin((n_silica/nAg)*sin(theta_silicaR));</span><br><span class="line">theta_S = asin((nAg/nS)*sin(theta_Ag2)); % </span><br><span class="line">%% delta</span><br><span class="line">deltaEntrada = <span class="number">2</span>*pi*nEntrada*dEntrada*cos(theta_Entrada)/<span class="keyword">lambda</span>(l);</span><br><span class="line">deltaAg1 = <span class="number">2</span>*pi*nAg*dAg*cos(theta_Ag1)/<span class="keyword">lambda</span>(l);</span><br><span class="line">delta_silicaL = <span class="number">2</span>*pi*n_silica*dSilicaL*cos(theta_silicaL)/<span class="keyword">lambda</span>(l);</span><br><span class="line">deltaTDBC = <span class="number">2</span>*pi*nTDBC*dTDBC*cos(theta_TDBC)/<span class="keyword">lambda</span>(l);</span><br><span class="line">delta_silicaR = <span class="number">2</span>*pi*n_silica*dSilicaR*cos(theta_silicaR)/<span class="keyword">lambda</span>(l);</span><br><span class="line">deltaAg2 = <span class="number">2</span>*pi*nAg*dAg*cos(theta_Ag2)/<span class="keyword">lambda</span>(l);</span><br><span class="line">deltaS = <span class="number">2</span>*pi*nS*dS*cos(theta_S)/<span class="keyword">lambda</span>(l);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> polarizacion == <span class="number">1</span></span><br><span class="line">        etaEntrada = nEntrada/cos(theta_Entrada);        etaAg1 = nAg/cos(theta_Ag1);</span><br><span class="line">        eta_silicaL = n_silica/cos(theta_silicaL);        etaTDBC = nTDBC/cos(theta_TDBC);</span><br><span class="line">        eta_silicaR = n_silica/cos(theta_silicaR);        etaAg2 = nAg/cos(theta_Ag2);</span><br><span class="line">        etaS = nS/cos(theta_S);        eta_m = etaS;        eta_o = n0/cos(theta(k));</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        etaEntrada = nEntrada*cos(theta_Entrada);</span><br><span class="line">        etaAg1 = nAg*cos(theta_Ag1);</span><br><span class="line">        eta_silicaL = n_silica*cos(theta_silicaL);</span><br><span class="line">        etaTDBC = nTDBC*cos(theta_TDBC);</span><br><span class="line">        eta_silicaR = n_silica*cos(theta_silicaR);</span><br><span class="line">        etaAg2 = nAg*cos(theta_Ag2);</span><br><span class="line">        etaS = nS*cos(theta_S);</span><br><span class="line">        eta_m = etaS;</span><br><span class="line">        eta_o = n0*cos(theta(k));</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">delta = [deltaEntrada deltaAg1 delta_silicaL deltaTDBC delta_silicaR deltaAg2 deltaS];</span><br><span class="line">eta   = [etaEntrada   etaAg1   eta_silicaL   etaTDBC   eta_silicaR   etaAg2   etaS  ];</span><br><span class="line"></span><br><span class="line">%% Matriz de matrices de cada capa</span><br><span class="line">Matrices = [cos(deltaEntrada),-1i*sin(deltaEntrada)/etaEntrada; % primera matriz</span><br><span class="line">           -1i*etaEntrada*sin(deltaEntrada),cos(deltaEntrada)];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i=<span class="number">2</span>:Ncapas</span><br><span class="line">        Matrices(:,:,i) = [cos(delta(i)),-1i*sin(delta(i))/eta(i); % matrices de cada capa</span><br><span class="line">                           -1i*eta(i)*sin(delta(i)),cos(delta(i))];</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">%% Matriz <span class="keyword">del</span> conjunto</span><br><span class="line">Mcon = Matrices(:,:,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i=<span class="number">2</span>:Ncapas</span><br><span class="line">        Mcon = Mcon*Matrices(:,:,i); % matriz <span class="keyword">del</span> conjunto</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">%% C醠culo de la reflectancia</span><br><span class="line">BC = Mcon*[<span class="number">1</span>;etaS];</span><br><span class="line">Y = BC(<span class="number">2</span>)/BC(<span class="number">1</span>);</span><br><span class="line">R(k,l) = ((eta_o-Y)/(eta_o+Y))*conj((eta_o-Y)/(eta_o+Y)); % reflectancia</span><br><span class="line">A(k,l) = (<span class="number">4</span>*eta_o*real(BC(<span class="number">1</span>)*conj(BC(<span class="number">2</span>))-eta_m))   /((eta_o*BC(<span class="number">1</span>)+BC(<span class="number">2</span>))*conj(eta_o*BC(<span class="number">1</span>)+BC(<span class="number">2</span>))); % absorbancia</span><br><span class="line">T(k,l) = (<span class="number">4</span>*eta_o*real(eta_m))/((eta_o*BC(<span class="number">1</span>)+BC(<span class="number">2</span>))*conj(eta_o*BC(<span class="number">1</span>)+BC(<span class="number">2</span>))); % transmitancia</span><br><span class="line"></span><br><span class="line">end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">%% Curva de Dispersi髇</span><br><span class="line">% figure (<span class="number">1</span>)</span><br><span class="line">% E = repmat(E,x,<span class="number">1</span>);</span><br><span class="line">% h = surf(kx<span class="string">&#x27;,E,R);</span></span><br><span class="line"><span class="string">% colormap (parula)</span></span><br><span class="line"><span class="string">% ylim([Emin,Emax])</span></span><br><span class="line"><span class="string">% xlim([0,max(max(kx))+0.05*max(max(kx))])</span></span><br><span class="line"><span class="string">% set(h,&#x27;</span>edgecolo<span class="string">r&#x27;,&#x27;</span>none<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">% colorbar</span></span><br><span class="line"><span class="string">% view(2)</span></span><br><span class="line"><span class="string">% ylabel(&#x27;</span>Energ韆 [eV]<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">% xlabel(&#x27;</span>k_&#123;||&#125; [nm^&#123;-<span class="number">1</span>&#125;]<span class="string">&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">%% Reflectancia, Absortancia y Transmitancia</span></span><br><span class="line"><span class="string">figure (2)</span></span><br><span class="line"><span class="string">plot(lambda,T(1,:),&#x27;</span><span class="string">b&#x27;,lambda,R(1,:),&#x27;</span><span class="string">r&#x27;,lambda,A(1,:),&#x27;</span>g<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">legend(&#x27;</span>\fontsize&#123;<span class="number">9</span>&#125;Transmitancia<span class="string">&#x27;,&#x27;</span>\fontsize&#123;<span class="number">9</span>&#125;Reflectancia<span class="string">&#x27;,&#x27;</span>\fontsize&#123;<span class="number">9</span>&#125;Absortancia<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">xlabel(&#x27;</span>Longitud de onda [nm]<span class="string">&#x27;)</span></span><br><span class="line"><span class="string">ylabel(&#x27;</span>Intensidad<span class="string">&#x27;)</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure><h2 id="MATLAB绘制不同Ra-距离不同的图片"><a href="#MATLAB绘制不同Ra-距离不同的图片" class="headerlink" title="MATLAB绘制不同Ra 距离不同的图片"></a>MATLAB绘制不同Ra 距离不同的图片</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ix = <span class="number">1</span>:length(a(:,<span class="number">1</span>)) % 最里面</span><br><span class="line">        plot(a(ix,<span class="number">1</span>),a(ix,<span class="number">2</span>),<span class="string">&#x27;ko&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.2</span>);hold on; </span><br><span class="line">end  </span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;times new Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">20</span>);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">0.9</span>,<span class="number">0</span>,<span class="number">0.9</span>]);box on;hold on;</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;linewidth&#x27;</span>,<span class="number">1.2</span>);</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;XTick&#x27;</span>,[<span class="number">0</span>:<span class="number">0.3</span>:<span class="number">0.9</span>]);   % 修改x轴坐标间隔</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;YTick&#x27;</span>,[<span class="number">0</span>:<span class="number">0.3</span>:<span class="number">0.9</span>]);   % 修改x轴坐标间隔</span><br><span class="line">% xlabel(<span class="string">&#x27;Δ&#123;\itA&#125;_&#123;sol&#125;&#x27;</span>); ylabel(<span class="string">&#x27;&#123;\itT&#125;_&#123;lum&#125;&#x27;</span>);</span><br><span class="line"><span class="keyword">for</span> ix = <span class="number">1</span>:length(a(:,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">if</span> a(ix,<span class="number">4</span>) &lt;= <span class="number">0.02</span></span><br><span class="line">        plot(a(ix,<span class="number">1</span>),a(ix,<span class="number">2</span>),<span class="string">&#x27;ro&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">0.6</span>);hold on;</span><br><span class="line">    end</span><br><span class="line">    <span class="keyword">if</span> a(ix,<span class="number">4</span>) &lt;= <span class="number">0.04</span> &amp;&amp; a(ix,<span class="number">4</span>) &gt; <span class="number">0.02</span></span><br><span class="line">        plot(a(ix,<span class="number">1</span>),a(ix,<span class="number">2</span>),<span class="string">&#x27;b.&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">0.1</span>);hold on;</span><br><span class="line">    end</span><br><span class="line">    <span class="keyword">if</span> a(ix,<span class="number">4</span>) &gt; <span class="number">0.04</span></span><br><span class="line">        plot(a(ix,<span class="number">1</span>),a(ix,<span class="number">2</span>),<span class="string">&#x27;k.&#x27;</span>,<span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">0.05</span>);hold on;</span><br><span class="line">    end</span><br><span class="line">    </span><br><span class="line">end</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;times new Roman&#x27;</span>,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">20</span>);</span><br><span class="line">axis([<span class="number">0</span>,<span class="number">0.9</span>,<span class="number">0</span>,<span class="number">0.9</span>]);box on;hold on;</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;linewidth&#x27;</span>,<span class="number">1.2</span>);</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;XTick&#x27;</span>,[<span class="number">0</span>:<span class="number">0.3</span>:<span class="number">0.9</span>]);   % 修改x轴坐标间隔</span><br><span class="line"><span class="built_in">set</span>(gca,<span class="string">&#x27;YTick&#x27;</span>,[<span class="number">0</span>:<span class="number">0.3</span>:<span class="number">0.9</span>]);   % 修改x轴坐标间隔</span><br><span class="line">% xlabel(<span class="string">&#x27;Δ&#123;\itA&#125;_&#123;sol&#125;&#x27;</span>); ylabel(<span class="string">&#x27;&#123;\itT&#125;_&#123;lum&#125;&#x27;</span>);</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="TETM折射率有效折射率"><a href="#TETM折射率有效折射率" class="headerlink" title="TETM折射率有效折射率"></a>TETM折射率有效折射率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">a1 = <span class="number">3.47</span>;</span><br><span class="line">a2 = <span class="number">1.45</span>;</span><br><span class="line">f = <span class="number">0</span>:<span class="number">0.01</span>:<span class="number">1</span>;</span><br><span class="line">t = <span class="number">0</span>;</span><br><span class="line">Py = <span class="number">400</span>;</span><br><span class="line">lam = <span class="number">1550</span>;</span><br><span class="line"><span class="keyword">for</span>   ix = f</span><br><span class="line">    t = t+<span class="number">1</span>;</span><br><span class="line">    te = (    ix/a2^<span class="number">2</span>+(<span class="number">1</span>-ix)/a1^<span class="number">2</span>   )^-<span class="number">0.5</span>;</span><br><span class="line">    n_TE(t,<span class="number">1</span>) = te;</span><br><span class="line">    tm = (    ix*a2^<span class="number">2</span>+(<span class="number">1</span>-ix)*a1^<span class="number">2</span>   )^<span class="number">0.5</span>;</span><br><span class="line">    n_TM(t,<span class="number">1</span>) = tm;</span><br><span class="line">    te2 = te*(<span class="number">1</span>+pi^<span class="number">2</span>/<span class="number">3</span>*(Py/lam)^<span class="number">2</span>*ix^<span class="number">2</span>*(<span class="number">1</span>-ix)^<span class="number">2</span>*( a1^<span class="number">2</span>-a2^<span class="number">2</span>)^<span class="number">2</span>* tm^<span class="number">2</span>*(te/a1/a2)^<span class="number">4</span>    )^<span class="number">0.5</span>;</span><br><span class="line">    %     te*(<span class="number">1</span>+pi*pi/<span class="number">3</span>*(Py/lam)^<span class="number">2</span>*f^<span class="number">2</span>*(<span class="number">1</span>-f)^<span class="number">2</span>*( a1^<span class="number">2</span>-a1^<span class="number">2</span>)^<span class="number">2</span>* tm^<span class="number">2</span>*(te/a1/a2)^<span class="number">4</span>    )^<span class="number">0.5</span>;</span><br><span class="line">    n_TE2(t,<span class="number">1</span>) = te2;</span><br><span class="line">    tm2 = tm*(<span class="number">1</span>+pi^<span class="number">2</span>/<span class="number">3</span>*(Py/lam)^<span class="number">2</span>*ix^<span class="number">2</span>*(<span class="number">1</span>-ix)^<span class="number">2</span>*( a1^<span class="number">2</span>-a2^<span class="number">2</span>)^<span class="number">2</span>/tm^<span class="number">2</span>   )^<span class="number">0.5</span>;</span><br><span class="line">    n_TM2(t,<span class="number">1</span>) = tm2;</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">plot(f,n_TE);hold on;plot(f,n_TM);      hold on;plot(f,n_TE2);hold on;plot(f,n_TM2);</span><br></pre></td></tr></table></figure><h2 id="chen-shuo神经网络生成-代码"><a href="#chen-shuo神经网络生成-代码" class="headerlink" title="chen_shuo神经网络生成_代码"></a>chen_shuo神经网络生成_代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">% clc;clear <span class="built_in">all</span>;</span><br><span class="line">% close <span class="built_in">all</span>;</span><br><span class="line">t1=clock;</span><br><span class="line">%%</span><br><span class="line">% wave_range = [<span class="number">300</span>:<span class="number">10</span>:<span class="number">2000</span>, <span class="number">2100</span>:<span class="number">100</span>:<span class="number">10000</span>];</span><br><span class="line">wave_range = <span class="number">400</span>:<span class="number">5</span>:<span class="number">1300</span>; save(<span class="string">&#x27;wave_range.mat&#x27;</span>,<span class="string">&#x27;wave_range&#x27;</span>);</span><br><span class="line">M_mat = nk_data(wave_range);</span><br><span class="line">shoulian = <span class="number">1</span>;save(<span class="string">&#x27;shoulian.mat&#x27;</span>,<span class="string">&#x27;shoulian&#x27;</span>);</span><br><span class="line">%%</span><br><span class="line">% <span class="number">1</span>  MgF2     % <span class="number">11</span> W</span><br><span class="line">% <span class="number">2</span>  SiO2     % <span class="number">12</span> Mo</span><br><span class="line">% <span class="number">3</span>  Al2O3    % <span class="number">13</span> Cr</span><br><span class="line">% <span class="number">4</span>  Si3N4    % <span class="number">14</span> Fe</span><br><span class="line">% <span class="number">5</span>  Si3N41直 % <span class="number">15</span> Ti</span><br><span class="line">% <span class="number">6</span>  TiO2     % <span class="number">16</span> Ag</span><br><span class="line">% <span class="number">7</span>  SiN      % <span class="number">17</span> Al</span><br><span class="line">% <span class="number">8</span>  Ge       % <span class="number">18</span> Cu-<span class="number">0.29</span>-SiO2</span><br><span class="line">% <span class="number">9</span>  Au</span><br><span class="line">% <span class="number">10</span> Cu</span><br><span class="line">load(<span class="string">&#x27;matlab.mat&#x27;</span>); % 结构<span class="number">2</span>--尺寸</span><br><span class="line">% <span class="keyword">for</span> ink = <span class="number">9</span>:<span class="number">17</span>     cool(<span class="number">1</span>,<span class="number">1</span>) = ink   ;</span><br><span class="line"></span><br><span class="line">lb = cool(:,<span class="number">2</span>)<span class="string">&#x27;;st1 = cool(:,3)&#x27;</span>;ub = cool(:,<span class="number">4</span>)<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">nk_M = M_mat(:,cool(1,1)); for nx = 2:length(cool(:,1))  nk_M = [nk_M,M_mat(:,cool(nx,1))]; end</span></span><br><span class="line"><span class="string">nk_M = [nk_M M_mat(:,2)];   save(&#x27;</span>nk_M.mat<span class="string">&#x27;,&#x27;</span>nk_M<span class="string">&#x27;);    % save nk_M;    % W基底</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PopulationSize_Data = 0.1*10000 ;  Generations = 8; StallGenerations = Generations; InitialPopulation=st1; nvars = length(lb); % number of variables</span></span><br><span class="line"><span class="string">[x,Aa,exitflag,output,population,score] = GA_code(nvars,lb,ub,PopulationSize_Data,Generations,StallGenerations,InitialPopulation);</span></span><br><span class="line"><span class="string">Aa = -roundn(Aa,-4);   t2=clock;tc(t2,t1);x=roundn(x&#x27;</span>,-<span class="number">0</span>);    wave_range = wave_range<span class="string">&#x27;;</span></span><br><span class="line"><span class="string">%% plot</span></span><br><span class="line"><span class="string">% for dd=5:2:30</span></span><br><span class="line"><span class="string">%     x(3,1)=dd;</span></span><br><span class="line"><span class="string">%%</span></span><br><span class="line"><span class="string">cs1 = 2:2:20;</span></span><br><span class="line"><span class="string">cs2 = 10:10:300;</span></span><br><span class="line"><span class="string">cs3 = 2:2:20;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[j1,j2,j3]=ndgrid(cs1,cs2,cs3);</span></span><br><span class="line"><span class="string">com=[j1(:),j2(:),j3(:)];clear cs1 cs2 cs3 j1 j2 j3</span></span><br><span class="line"><span class="string">for ix = 1:length(com)</span></span><br><span class="line"><span class="string">    x = com(ix,:)&#x27;</span>;</span><br><span class="line">    shoulian = <span class="number">2</span>;save(<span class="string">&#x27;shoulian.mat&#x27;</span>,<span class="string">&#x27;shoulian&#x27;</span>);</span><br><span class="line">    RTA = <span class="built_in">round</span>(objectivefunction(x<span class="string">&#x27;),4); </span></span><br><span class="line"><span class="string">    R1(:,ix) = RTA(:,1);</span></span><br><span class="line"><span class="string">    T1(:,ix) = RTA(:,2);</span></span><br><span class="line"><span class="string">    A1(:,ix) = RTA(:,3);</span></span><br><span class="line"><span class="string">    R2(:,ix) = RTA(:,4);</span></span><br><span class="line"><span class="string">    T2(:,ix) = RTA(:,5);</span></span><br><span class="line"><span class="string">    A2(:,ix) = RTA(:,6);</span></span><br><span class="line"><span class="string">end</span></span><br><span class="line"><span class="string">%  Tt(:,ink) = RTA(:,3);end</span></span><br><span class="line"><span class="string">figure(&#x27;</span>colo<span class="string">r&#x27;,[1 1 1]); </span></span><br><span class="line"><span class="string">plot(wave_range,RTA(:,1),&#x27;</span><span class="string">b&#x27;,  wave_range,RTA(:,2),&#x27;</span><span class="string">r&#x27;,  wave_range,RTA(:,3),&#x27;</span>g<span class="string">&#x27;,  &#x27;</span>LineWidth<span class="string">&#x27;,2);hold on;</span></span><br><span class="line"><span class="string">plot(wave_range,RTA(:,4),&#x27;</span>b--<span class="string">&#x27;,wave_range,RTA(:,5),&#x27;</span>r--<span class="string">&#x27;,wave_range,RTA(:,6),&#x27;</span>g--<span class="string">&#x27;,&#x27;</span>LineWidth<span class="string">&#x27;,2);hold on;</span></span><br><span class="line"><span class="string">legend(&#x27;</span>\fontsize&#123;<span class="number">20</span>&#125;<span class="string">R&#x27;,&#x27;</span>\fontsize&#123;<span class="number">20</span>&#125;T<span class="string">&#x27;,&#x27;</span>\fontsize&#123;<span class="number">20</span>&#125;A<span class="string">&#x27;); xlabel(&#x27;</span>wavelength (nm)<span class="string">&#x27;);ylabel(&#x27;</span>Intensity<span class="string">&#x27;);</span></span><br><span class="line"><span class="string">set(gca,&#x27;</span>FontSize<span class="string">&#x27;,20);axis([min(wave_range),max(wave_range),0,1]);</span></span><br><span class="line"><span class="string">% aZ = [cool(:,1),x];% z_1 = [x ;-fval*100; A_spectrum];% A_avg(mx)=Aa; % print(gcf,&#x27;</span>-dpng<span class="string">&#x27;,&#x27;</span><span class="number">1.</span>png<span class="string">&#x27;);picture(1);  semilogx(wave_range,a,&#x27;</span>k<span class="string">&#x27;,&#x27;</span>LineWidth<span class="string">&#x27;,1);axis([300 20000 0 1]);</span></span><br><span class="line"><span class="string">clear st1 t1 t2 ub lb score population nx exitflag shoulian CrossoverFraction_Data InitialPopulationMatrix_Data MaxGenerations_Data;clear MaxStallGenerations_Data PopulationSize_Data nvars output ans</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>博客图片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>莫烦Matplotlib Python 画图教程</title>
    <link href="/2023/11/08/%E8%8E%AB%E7%83%A6/"/>
    <url>/2023/11/08/%E8%8E%AB%E7%83%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="莫烦Matplotlib-Python-画图教程"><a href="#莫烦Matplotlib-Python-画图教程" class="headerlink" title="莫烦Matplotlib Python 画图教程"></a>莫烦Matplotlib Python 画图教程</h1><h2 id="p2-基本用法"><a href="#p2-基本用法" class="headerlink" title="p2 基本用法"></a>p2 基本用法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">50</span>)</span><br><span class="line">y = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212230501.png" alt="image-20220421223009461"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">50</span>)</span><br><span class="line">#y = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y = x**<span class="number">2</span></span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212232224.png" alt="image-20220421223230174"></p><h2 id="p4-figure图像"><a href="#p4-figure图像" class="headerlink" title="p4 figure图像"></a>p4 figure图像</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212235814.png" alt="image-20220421223546751"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">3</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line"></span><br><span class="line">plt.show()#压扁了一些</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212237946.png" alt="image-20220421223731895"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">3</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">10</span>,linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212243730.png" alt="image-20220421224306663"></p><h2 id="p5-设置坐标轴1"><a href="#p5-设置坐标轴1" class="headerlink" title="p5 设置坐标轴1"></a>p5 设置坐标轴1</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">30</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">1</span>,linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>,<span class="number">2</span>)) #取值范围</span><br><span class="line">plt.ylim((-<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212247907.png" alt="image-20220421224724855"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">30</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">1</span>,linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>,<span class="number">2</span>)) #取值范围</span><br><span class="line">plt.ylim((-<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks)</span><br><span class="line">plt.yticks([-<span class="number">2</span>,-<span class="number">1.8</span>,-<span class="number">1</span>,<span class="number">1.22</span>,<span class="number">3</span>],</span><br><span class="line">           [r<span class="string">&#x27;$really\ bad$&#x27;</span>,r<span class="string">&#x27;$bad\ \alpha$&#x27;</span>,r<span class="string">&#x27;$normal$&#x27;</span>,r<span class="string">&#x27;$good$&#x27;</span>,r<span class="string">&#x27;really good&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212254791.png" alt="image-20220421225453749"></p><h2 id="p6-设置坐标轴"><a href="#p6-设置坐标轴" class="headerlink" title="p6 设置坐标轴"></a>p6 设置坐标轴</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num=<span class="number">30</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">1</span>,linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>,<span class="number">2</span>)) #取值范围</span><br><span class="line">plt.ylim((-<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks)</span><br><span class="line">plt.yticks([-<span class="number">2</span>,-<span class="number">1.8</span>,-<span class="number">1</span>,<span class="number">1.22</span>,<span class="number">3</span>],</span><br><span class="line">[r<span class="string">&#x27;$really\ bad$&#x27;</span>,r<span class="string">&#x27;$bad\ \alpha$&#x27;</span>,r<span class="string">&#x27;$normal$&#x27;</span>,r<span class="string">&#x27;$good$&#x27;</span>,r<span class="string">&#x27;really good&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line"># gca = <span class="string">&#x27;get current axis&#x27;</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) #图片的脊梁</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,-<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212304400.png" alt="image-20220421230411356"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num = <span class="number">1</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y2)</span><br><span class="line">plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">1</span>,linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>,<span class="number">2</span>)) #取值范围</span><br><span class="line">plt.ylim((-<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks)</span><br><span class="line">plt.yticks([-<span class="number">2</span>,-<span class="number">1.8</span>,-<span class="number">1</span>,<span class="number">1.22</span>,<span class="number">3</span>],</span><br><span class="line">[r<span class="string">&#x27;$really\ bad$&#x27;</span>,r<span class="string">&#x27;$bad\ \alpha$&#x27;</span>,r<span class="string">&#x27;$normal$&#x27;</span>,r<span class="string">&#x27;$good$&#x27;</span>,r<span class="string">&#x27;really good&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line"># gca = <span class="string">&#x27;get current axis&#x27;</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) #图片的脊梁</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) #outward, axes</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212306486.png" alt="image-20220421230651447"></p><h2 id="p7-Legend图例"><a href="#p7-Legend图例" class="headerlink" title="p7 Legend图例"></a>p7 Legend图例</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">y2 = x**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">plt.figure(num = <span class="number">1</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.xlim((-<span class="number">1</span>,<span class="number">2</span>)) #取值范围</span><br><span class="line">plt.ylim((-<span class="number">2</span>,<span class="number">3</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;I am x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;I am y&#x27;</span>)</span><br><span class="line"></span><br><span class="line">new_ticks = np.linspace(-<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>)</span><br><span class="line">print(new_ticks)</span><br><span class="line">plt.xticks(new_ticks)</span><br><span class="line">plt.yticks([-<span class="number">2</span>,-<span class="number">1.8</span>,-<span class="number">1</span>,<span class="number">1.22</span>,<span class="number">3</span>],</span><br><span class="line">[r<span class="string">&#x27;$really\ bad$&#x27;</span>,r<span class="string">&#x27;$bad\ \alpha$&#x27;</span>,r<span class="string">&#x27;$normal$&#x27;</span>,r<span class="string">&#x27;$good$&#x27;</span>,r<span class="string">&#x27;really good&#x27;</span>]</span><br><span class="line">           )</span><br><span class="line"># gca = <span class="string">&#x27;get current axis&#x27;</span></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) #图片的脊梁</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) #outward, axes</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">l1, = plt.plot(x,y2,label=<span class="string">&#x27;up&#x27;</span>)</span><br><span class="line">l2, = plt.plot(x,y1,color=<span class="string">&#x27;red&#x27;</span>,linewidth=<span class="number">1</span>,linestyle=<span class="string">&#x27;--&#x27;</span>,label=<span class="string">&#x27;down&#x27;</span>)</span><br><span class="line">plt.legend(handles=[l1,l2,],labels=[<span class="string">&#x27;aaa&#x27;</span>,<span class="string">&#x27;bbb&#x27;</span>],loc=<span class="string">&#x27;best&#x27;</span>)</span><br><span class="line"># handles 线条</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212315342.png" alt="image-20220421231533300"></p><h2 id="p8-Annotation注解-添加注解"><a href="#p8-Annotation注解-添加注解" class="headerlink" title="p8 Annotation注解 添加注解"></a>p8 Annotation注解 添加注解</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">2</span>*x+<span class="number">1</span></span><br><span class="line">plt.figure(num = <span class="number">1</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y1)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) #图片的脊梁</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) #outward, axes</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">x0 = <span class="number">1</span></span><br><span class="line">y0 = <span class="number">2</span>*x0+<span class="number">1</span></span><br><span class="line">plt.scatter(x0,y0,s=<span class="number">50</span>,color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.plot([x0,x0],[y0,<span class="number">0</span>],<span class="string">&#x27;k--&#x27;</span>,lw=<span class="number">2.5</span>)</span><br><span class="line"></span><br><span class="line"># method <span class="number">1</span></span><br><span class="line">plt.annotate(r<span class="string">&#x27;$2x+1=%s$&#x27;</span>% y0,xy=(x0,y0),xycoords=<span class="string">&#x27;data&#x27;</span>,</span><br><span class="line">             xytext=(+<span class="number">30</span>,-<span class="number">30</span>),textcoords=<span class="string">&#x27;offset points&#x27;</span>,</span><br><span class="line">             fontsize=<span class="number">16</span>,arrowprops=dict(arrowstyle=<span class="string">&#x27;-&gt;&#x27;</span>,</span><br><span class="line">             connectionstyle=<span class="string">&#x27;arc3,rad=.2&#x27;</span>))</span><br><span class="line"># method <span class="number">2</span></span><br><span class="line">plt.text(-<span class="number">3.7</span>,<span class="number">3</span>,r<span class="string">&#x27;$This\ is\ the\ some\ text.\ \mu\ \sigma_i\ \alpha_t$&#x27;</span>,</span><br><span class="line">         fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">16</span>,<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;r&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212334611.png" alt="image-20220421233410565"></p><h2 id="p9-tick能见度"><a href="#p9-tick能见度" class="headerlink" title="p9 tick能见度"></a>p9 tick能见度</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt # plt:缩写</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"><span class="variable">x</span> <span class="operator">=</span> np.linspace(-<span class="number">3</span>,<span class="number">3</span>,<span class="number">50</span>)</span><br><span class="line">y1 = <span class="number">0.1</span>*x</span><br><span class="line">plt.figure(num = <span class="number">1</span>,figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line">plt.plot(x,y1,linewidth=<span class="number">10</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">ax = plt.gca()</span><br><span class="line">ax.spines[<span class="string">&#x27;right&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>) #图片的脊梁</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;top&#x27;</span>].set_color(<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">ax.xaxis.set_ticks_position(<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;bottom&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>)) #outward, axes</span><br><span class="line">ax.yaxis.set_ticks_position(<span class="string">&#x27;left&#x27;</span>)</span><br><span class="line">ax.spines[<span class="string">&#x27;left&#x27;</span>].set_position((<span class="string">&#x27;data&#x27;</span>,<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">x0 = <span class="number">1</span></span><br><span class="line">y0 = <span class="number">2</span>*x0+<span class="number">1</span></span><br><span class="line">plt.scatter(x0,y0,s=<span class="number">50</span>,color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">plt.plot([x0,x0],[y0,<span class="number">0</span>],<span class="string">&#x27;k--&#x27;</span>,lw=<span class="number">2.5</span>)</span><br><span class="line"></span><br><span class="line"># method <span class="number">2</span></span><br><span class="line">plt.text(-<span class="number">3.7</span>,<span class="number">3</span>,r<span class="string">&#x27;$This\ is\ the\ some\ text.\ \mu\ \sigma_i\ \alpha_t$&#x27;</span>,</span><br><span class="line">         fontdict=&#123;<span class="string">&#x27;size&#x27;</span>:<span class="number">16</span>,<span class="string">&#x27;color&#x27;</span>:<span class="string">&#x27;r&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> label in ax.get_xticklabels()+ax.get_yticklabels():</span><br><span class="line">    label.set_fontsize(<span class="number">12</span>)</span><br><span class="line">    label.set_bbox(dict(facecolor=<span class="string">&#x27;white&#x27;</span>,edgecolor=<span class="string">&#x27;None&#x27;</span>,alpha=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212345019.png" alt="image-20220421234514980"></p><h2 id="p10-Scatter散点图"><a href="#p10-Scatter散点图" class="headerlink" title="p10 Scatter散点图"></a>p10 Scatter散点图</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"></span><br><span class="line"><span class="variable">n</span> <span class="operator">=</span> <span class="number">1024</span></span><br><span class="line">X = np.random.normal(<span class="number">0</span>,<span class="number">1</span>,n)</span><br><span class="line">Y = np.random.normal(<span class="number">0</span>,<span class="number">1</span>,n)</span><br><span class="line">T = np.arctan2(Y,X) #<span class="keyword">for</span> color value</span><br><span class="line"></span><br><span class="line">plt.scatter(X,Y,s=<span class="number">75</span>,c=T,alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.xlim((-<span class="number">1.5</span>,<span class="number">1.5</span>))</span><br><span class="line">plt.ylim((-<span class="number">1.5</span>,<span class="number">1.5</span>))</span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204212351858.png" alt="image-20220421235132802"></p><h2 id="p11-Bar柱状图"><a href="#p11-Bar柱状图" class="headerlink" title="p11 Bar柱状图"></a>p11 Bar柱状图</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as <span class="type">np</span></span><br><span class="line"></span><br><span class="line"><span class="variable">n</span> <span class="operator">=</span> <span class="number">12</span></span><br><span class="line">X = np.arange(n)</span><br><span class="line">Y1 = (<span class="number">1</span>-X/<span class="type">float</span>(n))*np.random.uniform(<span class="number">0.5</span>,<span class="number">1.0</span>,n)</span><br><span class="line">Y2 = (<span class="number">1</span>-X/<span class="type">float</span>(n))*np.random.uniform(<span class="number">0.5</span>,<span class="number">1.0</span>,n)</span><br><span class="line"></span><br><span class="line">plt.bar(X,+Y1,facecolor=<span class="string">&#x27;#9999ff&#x27;</span>,edgecolor=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line">plt.bar(X,-Y2,facecolor=<span class="string">&#x27;#ff9999&#x27;</span>,edgecolor=<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y in <span class="title function_">zip</span><span class="params">(X,Y1)</span>:</span><br><span class="line">    # ha:horizontal alignment</span><br><span class="line">    plt.text(x+<span class="number">0.04</span>,y+<span class="number">0.005</span>,<span class="string">&#x27;%.2f&#x27;</span>%y,ha=<span class="string">&#x27;center&#x27;</span>,va=<span class="string">&#x27;bottom&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x,y in <span class="title function_">zip</span><span class="params">(X,Y2)</span>:</span><br><span class="line">    # ha:horizontal alignment</span><br><span class="line">    plt.text(x+<span class="number">0.04</span>,-y-<span class="number">0.05</span>,<span class="string">&#x27;-%.2f&#x27;</span>%y,ha=<span class="string">&#x27;center&#x27;</span>,va=<span class="string">&#x27;top&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlim(-<span class="number">0.5</span>,n)</span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.ylim(-<span class="number">1.25</span>,<span class="number">1.25</span>)</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204221028569.png" alt="image-20220422102818516"></p><h2 id="p11-Contours等高线图"><a href="#p11-Contours等高线图" class="headerlink" title="p11 Contours等高线图"></a>p11 Contours等高线图</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np</span><br><span class="line"></span><br><span class="line">def <span class="title function_">f</span><span class="params">(x,y)</span>:</span><br><span class="line">    # the height function</span><br><span class="line">    <span class="title function_">return</span> <span class="params">(<span class="number">1</span>-x/<span class="number">2</span>+x**<span class="number">5</span>+y**<span class="number">3</span>)</span>*np.exp(-x**<span class="number">2</span>-y**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">n = <span class="number">256</span></span><br><span class="line">x = np.linspace(-<span class="number">3</span>,<span class="number">3</span>,n)</span><br><span class="line">y = np.linspace(-<span class="number">3</span>,<span class="number">3</span>,n)</span><br><span class="line">X,Y = np.meshgrid(x,y)</span><br><span class="line"></span><br><span class="line">#use plt.contourf to filling contours</span><br><span class="line">#X,Y and value <span class="title function_">for</span> <span class="params">(X,Y)</span> point</span><br><span class="line">plt.contourf(X,Y,f(X,Y),<span class="number">5</span>,alpha=<span class="number">0.75</span>,cmap=plt.cm.hot)</span><br><span class="line"></span><br><span class="line">#use plit.contour to add contour <span class="type">lines</span></span><br><span class="line"><span class="variable">C</span> <span class="operator">=</span> plt.contour(X,Y,f(X,Y),<span class="number">10</span>,colors=<span class="string">&#x27;black&#x27;</span>,linewidths=<span class="number">0.5</span>)</span><br><span class="line"># adding label</span><br><span class="line">plt.clabel(C,inline=True,fontsize=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204221042107.png" alt="image-20220422104237057"></p><h2 id="P13-Image图片"><a href="#P13-Image图片" class="headerlink" title="P13 Image图片"></a>P13 Image图片</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># View more python tutorials on my Youtube and Youku channel!!!</span><br><span class="line"></span><br><span class="line"># Youtube video tutorial: https:<span class="comment">//www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg</span></span><br><span class="line"># Youku video tutorial: http:<span class="comment">//i.youku.com/pythontutorial</span></span><br><span class="line"></span><br><span class="line"># <span class="number">13</span> - image</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Please note, this script is for python3+.</span></span><br><span class="line"><span class="string">If you are using python2+, please modify it accordingly.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot as plt</span><br><span class="line"><span class="keyword">import</span> numpy as np</span><br><span class="line"></span><br><span class="line"># image <span class="type">data</span></span><br><span class="line"><span class="variable">a</span> <span class="operator">=</span> np.array([<span class="number">0.313660827978</span>, <span class="number">0.365348418405</span>, <span class="number">0.423733120134</span>,</span><br><span class="line">              <span class="number">0.365348418405</span>, <span class="number">0.439599930621</span>, <span class="number">0.525083754405</span>,</span><br><span class="line">              <span class="number">0.423733120134</span>, <span class="number">0.525083754405</span>, <span class="number">0.651536351379</span>]).reshape(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">plt.imshow(a,interpolation=<span class="string">&#x27;nearest&#x27;</span>,cmap=<span class="string">&#x27;bone&#x27;</span>,origin=<span class="string">&#x27;lower&#x27;</span>)</span><br><span class="line">plt.colorbar(shrink=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">plt.xticks(())</span><br><span class="line">plt.yticks(())</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204221059782.png" alt="image-20220422105922736"></p><h2 id="p14-3D数据"><a href="#p14-3D数据" class="headerlink" title="p14 3D数据"></a>p14 3D数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># View more python tutorials on my Youtube and Youku channel!!!</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Youtube video tutorial: https://www.youtube.com/channel/UCdyjiB5H8Pu7aDTNVXTTpcg</span></span><br><span class="line"><span class="comment"># Youku video tutorial: http://i.youku.com/pythontutorial</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 14 - 3d</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Please note, this script is for python3+.</span></span><br><span class="line"><span class="string">If you are using python2+, please modify it accordingly.</span></span><br><span class="line"><span class="string">Tutorial reference:</span></span><br><span class="line"><span class="string">http://www.python-course.eu/matplotlib_multiple_figures.php</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = Axes3D(fig)</span><br><span class="line"><span class="comment"># X, Y value</span></span><br><span class="line">X = np.arange(-<span class="number">4</span>, <span class="number">4</span>, <span class="number">0.25</span>)</span><br><span class="line">Y = np.arange(-<span class="number">4</span>, <span class="number">4</span>, <span class="number">0.25</span>)</span><br><span class="line">X, Y = np.meshgrid(X, Y)</span><br><span class="line">R = np.sqrt(X ** <span class="number">2</span> + Y ** <span class="number">2</span>)</span><br><span class="line"><span class="comment"># height value</span></span><br><span class="line">Z = np.sin(R)</span><br><span class="line"></span><br><span class="line">ax.plot_surface(X, Y, Z, rstride=<span class="number">1</span>, cstride=<span class="number">1</span>, cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">============= ================================================</span></span><br><span class="line"><span class="string">        Argument      Description</span></span><br><span class="line"><span class="string">        ============= ================================================</span></span><br><span class="line"><span class="string">        *X*, *Y*, *Z* Data values as 2D arrays</span></span><br><span class="line"><span class="string">        *rstride*     Array row stride (step size), defaults to 10</span></span><br><span class="line"><span class="string">        *cstride*     Array column stride (step size), defaults to 10</span></span><br><span class="line"><span class="string">        *color*       Color of the surface patches</span></span><br><span class="line"><span class="string">        *cmap*        A colormap for the surface patches.</span></span><br><span class="line"><span class="string">        *facecolors*  Face colors for the individual patches</span></span><br><span class="line"><span class="string">        *norm*        An instance of Normalize to map values to colors</span></span><br><span class="line"><span class="string">        *vmin*        Minimum value to map</span></span><br><span class="line"><span class="string">        *vmax*        Maximum value to map</span></span><br><span class="line"><span class="string">        *shade*       Whether to shade the facecolors</span></span><br><span class="line"><span class="string">        ============= ================================================</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># I think this is different from plt12_contours</span></span><br><span class="line">ax.contourf(X, Y, Z, zdir=<span class="string">&#x27;z&#x27;</span>, offset=-<span class="number">2</span>, cmap=plt.get_cmap(<span class="string">&#x27;rainbow&#x27;</span>))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">==========  ================================================</span></span><br><span class="line"><span class="string">        Argument    Description</span></span><br><span class="line"><span class="string">        ==========  ================================================</span></span><br><span class="line"><span class="string">        *X*, *Y*,   Data values as numpy.arrays</span></span><br><span class="line"><span class="string">        *Z*</span></span><br><span class="line"><span class="string">        *zdir*      The direction to use: x, y or z (default)</span></span><br><span class="line"><span class="string">        *offset*    If specified plot a projection of the filled contour</span></span><br><span class="line"><span class="string">                    on this position in plane normal to zdir</span></span><br><span class="line"><span class="string">        ==========  ================================================</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">ax.set_zlim(-<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241121725.png" alt="image-20220424112147652"></p><h2 id="p15-Subplot多合一显示"><a href="#p15-Subplot多合一显示" class="headerlink" title="p15 Subplot多合一显示"></a>p15 Subplot多合一显示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">1</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>,<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241127897.png" alt="image-20220424112722847"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure()</span><br><span class="line">plt.subplot(<span class="number">211</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">234</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">235</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">236</span>)</span><br><span class="line">plt.plot([<span class="number">0</span>,<span class="number">1</span>],[<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241130820.png" alt="image-20220424113048775"></p><h2 id="p16-Subplot分格显示"><a href="#p16-Subplot分格显示" class="headerlink" title="p16 Subplot分格显示"></a>p16 Subplot分格显示</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1: subplot2grid</span></span><br><span class="line">plt.figure()</span><br><span class="line">ax1 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>),(<span class="number">0</span>,<span class="number">0</span>),rowspan=<span class="number">1</span>,colspan=<span class="number">3</span>)</span><br><span class="line">ax1.plot([<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>])</span><br><span class="line">ax1.set_title(<span class="string">&#x27;ax1_title&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">0</span>),rowspan=<span class="number">1</span>,colspan=<span class="number">2</span>)</span><br><span class="line">ax3 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">2</span>),rowspan=<span class="number">2</span>,colspan=<span class="number">1</span>)</span><br><span class="line">ax4 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">0</span>),rowspan=<span class="number">1</span>,colspan=<span class="number">1</span>)</span><br><span class="line">ax5 = plt.subplot2grid((<span class="number">3</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">1</span>),rowspan=<span class="number">1</span>,colspan=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241141934.png" alt="image-20220424114155887"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1: subplot2grid</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># method2: gridspec</span></span><br><span class="line">plt.figure()</span><br><span class="line">gs = gridspec.GridSpec(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">ax1 = plt.subplot(gs[<span class="number">0</span>,:])</span><br><span class="line">ax2 = plt.subplot(gs[<span class="number">1</span>,:<span class="number">2</span>])</span><br><span class="line">ax3 = plt.subplot(gs[<span class="number">1</span>:,<span class="number">2</span>])</span><br><span class="line">ax4 = plt.subplot(gs[-<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">ax5 = plt.subplot(gs[-<span class="number">1</span>,-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241144771.png" alt="image-20220424114456728"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line"><span class="comment"># method 1: subplot2grid</span></span><br><span class="line"><span class="comment"># method 2: gridspec</span></span><br><span class="line"><span class="comment">#method 3: essy to define structure</span></span><br><span class="line">f, ((ax11,ax12),(ax21,ax22)) = plt.subplots(<span class="number">2</span>,<span class="number">2</span>,sharex=<span class="literal">True</span>,sharey=<span class="literal">True</span>)</span><br><span class="line">ax11.scatter([<span class="number">1</span>,<span class="number">2</span>],[<span class="number">2</span>,<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241147049.png" alt="image-20220424114749992"></p><h2 id="p17-图中图"><a href="#p17-图中图" class="headerlink" title="p17 图中图"></a>p17 图中图</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]</span><br><span class="line">y = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">left,bottom,width,height = <span class="number">0.1</span>,<span class="number">0.1</span>,<span class="number">0.8</span>,<span class="number">0.8</span></span><br><span class="line">ax1 = fig.add_axes([left,bottom,width,height])</span><br><span class="line">ax1.plot(x,y,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;title&#x27;</span>)</span><br><span class="line"></span><br><span class="line">left,bottom,width,height = <span class="number">0.2</span>,<span class="number">0.6</span>,<span class="number">0.25</span>,<span class="number">0.25</span></span><br><span class="line">ax2 = fig.add_axes([left,bottom,width,height])</span><br><span class="line">ax2.plot(y,x,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;title inside 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241156062.png" alt="image-20220424115622008"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.gridspec <span class="keyword">as</span> gridspec</span><br><span class="line"></span><br><span class="line">fig = plt.figure()</span><br><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>]</span><br><span class="line">y = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">8</span>,<span class="number">6</span>]</span><br><span class="line"></span><br><span class="line">left,bottom,width,height = <span class="number">0.1</span>,<span class="number">0.1</span>,<span class="number">0.8</span>,<span class="number">0.8</span></span><br><span class="line">ax1 = fig.add_axes([left,bottom,width,height])</span><br><span class="line">ax1.plot(x,y,<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">ax1.set_title(<span class="string">&#x27;title&#x27;</span>)</span><br><span class="line"></span><br><span class="line">left,bottom,width,height = <span class="number">0.2</span>,<span class="number">0.6</span>,<span class="number">0.25</span>,<span class="number">0.25</span></span><br><span class="line">ax2 = fig.add_axes([left,bottom,width,height])</span><br><span class="line">ax2.plot(y,x,<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">ax2.set_xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;title inside 1&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.axes([<span class="number">0.6</span>,<span class="number">0.2</span>,<span class="number">0.25</span>,<span class="number">0.25</span>])</span><br><span class="line">plt.plot(y[::-<span class="number">1</span>],x,<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;title inside 2&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241200118.png" alt="image-20220424120030072"></p><h2 id="P178次坐标轴"><a href="#P178次坐标轴" class="headerlink" title="P178次坐标轴"></a>P178次坐标轴</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>,<span class="number">10</span>,<span class="number">0.1</span>)</span><br><span class="line">y1 = <span class="number">0.05</span>*x**<span class="number">2</span></span><br><span class="line">y2 = -<span class="number">1</span>*y1</span><br><span class="line"></span><br><span class="line">fig,ax1 = plt.subplots()</span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax1.plot(x,y1,<span class="string">&#x27;g-&#x27;</span>)</span><br><span class="line">ax2.plot(x,y2,<span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line"></span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;X data&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;Y1 data&#x27;</span>,color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;Y2 data&#x27;</span>,color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241210774.png" alt="image-20220424121057704"></p><h2 id="p19-Animation动画"><a href="#p19-Animation动画" class="headerlink" title="p19 Animation动画"></a>p19 Animation动画</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> animation</span><br><span class="line"></span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line"></span><br><span class="line">x = np.arange(<span class="number">0</span>,<span class="number">2</span>*np.pi,<span class="number">0.01</span>)</span><br><span class="line">line, = ax.plot(x,np.sin(x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">animate</span>(<span class="params">i</span>):</span><br><span class="line">    line.set_ydata(np.sin(x+i/<span class="number">10</span>))</span><br><span class="line">    <span class="keyword">return</span> line,</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init</span>():</span><br><span class="line">    line.set_ydata(np.sin)</span><br><span class="line">    <span class="keyword">return</span> line,</span><br><span class="line"></span><br><span class="line">ani = animation.FuncAnimation(fig=fig,func=animate,frames=<span class="number">100</span>,init_func=init,interval=<span class="number">20</span>,blit=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://myxpz.oss-cn-beijing.aliyuncs.com/img/202204241224173.png" alt="image-20220424122416105"></p>]]></content>
    
    
    <categories>
      
      <category>绘图</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>match</title>
    <link href="/2023/11/08/match/"/>
    <url>/2023/11/08/match/</url>
    
    <content type="html"><![CDATA[<hr /><h1 id="match">match</h1><h2 id="主程序1233434">主程序1233434</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs matlab">clc;clear;close all;t1  =clock;<br>[num, boy_txt, raw] = xlsread(<span class="hljs-string">&#x27;C:\Users\Administrator\Desktop\boy.xlsx&#x27;</span>);fclose(<span class="hljs-string">&#x27;all&#x27;</span>);boy_txt = boy_txt(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>,:);<br>[num, girl_txt, raw] = xlsread(<span class="hljs-string">&#x27;C:\Users\Administrator\Desktop\girl.xlsx&#x27;</span>);fclose(<span class="hljs-string">&#x27;all&#x27;</span>);girl_txt = girl_txt(<span class="hljs-number">2</span>:<span class="hljs-keyword">end</span>,:);<br><br><span class="hljs-keyword">for</span> ix = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(girl_txt(:,<span class="hljs-number">2</span>)) girl_W1_M(ix) = W1_structure(girl_txt&#123;ix,<span class="hljs-number">2</span>&#125;); <span class="hljs-keyword">end</span><br><span class="hljs-keyword">for</span> ix = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(boy_txt(:,<span class="hljs-number">2</span>)) boy_W1_M(ix) = W1_structure(boy_txt&#123;ix,<span class="hljs-number">2</span>&#125;); <span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">for</span> ix = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(girl_txt(:,<span class="hljs-number">2</span>)) girl_W2_M(ix) = W1_structure(girl_txt&#123;ix,<span class="hljs-number">3</span>&#125;); <span class="hljs-keyword">end</span><br><span class="hljs-keyword">for</span> ix = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(boy_txt(:,<span class="hljs-number">2</span>)) boy_W2_M(ix) = W1_structure(boy_txt&#123;ix,<span class="hljs-number">3</span>&#125;); <span class="hljs-keyword">end</span><br><br><span class="hljs-keyword">for</span> ix = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(girl_txt(:,<span class="hljs-number">2</span>))<br>    <span class="hljs-keyword">for</span> iy =<span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(boy_txt(:,<span class="hljs-number">2</span>))       <br>        <br>        girl_W1_one = girl_W1_M(ix);<br>        boy_W1_one = boy_W1_M(iy);<br>        match_result(ix, iy) = W1_match(girl_W1_one, boy_W1_one) * W1_match(boy_W1_one, girl_W1_one);<br><br><br>        girl_W2_one = girl_W2_M(ix);<br>        boy_W2_one = boy_W2_M(iy);<br>        <br>        W2_total(ix, iy) = ( W2_cal(girl_W2_one, boy_W2_one) + W2_cal(boy_W2_one, girl_W2_one) ) *<span class="hljs-number">0.5</span><br>        <br>    <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br><br><br><span class="hljs-comment">%% girl - match </span><br>t2=clock;tc(t2,t1);<br><br></code></pre></td></tr></table></figure><h2 id="w1_match">W1_match</h2><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs HTML"><br>function Y = W1_match(girl_W1_one, boy_W1_one)<br><br>    match_W1 = 1;<br>    match_score = 0;<br>    if abs( boy_W1_one.height(1) - girl_W1_one.height(2) ) &lt;= girl_W1_one.height(3) <br>        match_score = 1; <br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0;<br>    if abs( boy_W1_one.weight(1) - girl_W1_one.weight(2) ) &lt;= girl_W1_one.weight(3) <br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0; % 判断元素是否在数组中        <br>    if ismember(boy_W1_one.course(1), girl_W1_one.course(2:end) )<br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0; % 判断元素是否在数组中        <br>    if ismember(boy_W1_one.grade(1), girl_W1_one.grade(2:end) )<br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0; % 判断元素是否在数组中        <br>    if ismember(boy_W1_one.constellation(1), girl_W1_one.constellation(2:end) )<br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0;<br>    if abs( boy_W1_one.birth(1) - girl_W1_one.birth(2) ) &lt;= girl_W1_one.birth(3) <br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0;<br>    if distance(boy_W1_one.my(2), boy_W1_one.my(1), girl_W1_one.my(2), girl_W1_one.my(1), referenceEllipsoid(&#x27;WGS 84&#x27;, &#x27;kilometer&#x27;)) &lt;=  girl_W1_one.my(3)<br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>    match_score = 0;<br>    if distance(boy_W1_one.your(2), boy_W1_one.my(1), girl_W1_one.your(2), girl_W1_one.my(1), referenceEllipsoid(&#x27;WGS 84&#x27;, &#x27;kilometer&#x27;)) &lt;=  girl_W1_one.your(3)<br>        match_score = 1;<br>    end<br>    match_W1 = match_W1 * match_score;<br><br>Y = match_W1;<br></code></pre></td></tr></table></figure><h2 id="w2_cal">W2_cal</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">Y</span> = <span class="hljs-title">W2_cal</span><span class="hljs-params">(girl_W2_one, boy_W2_one)</span></span><br><br>    field_names = fieldnames(boy_W2_one);<br>    n_instances = <span class="hljs-built_in">numel</span>(field_names);<br>    boy_W2_one_Matrix = <span class="hljs-built_in">zeros</span>(n_instances,<span class="hljs-number">3</span>);<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:n_instances boy_W2_one_Matrix(<span class="hljs-built_in">i</span>,:) = boy_W2_one.(field_names&#123;<span class="hljs-built_in">i</span>&#125;);<span class="hljs-keyword">end</span><br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:n_instances girl_W2_one_Matrix(<span class="hljs-built_in">i</span>,:) = girl_W2_one.(field_names&#123;<span class="hljs-built_in">i</span>&#125;);<span class="hljs-keyword">end</span><br>    <br>    sum1 = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">for</span> iz = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(boy_W2_one_Matrix(:,<span class="hljs-number">1</span>))<br>        sum1 = sum1 + girl_W2_one_Matrix(iz,<span class="hljs-number">1</span>) * W2_fx(girl_W2_one_Matrix(iz,<span class="hljs-number">3</span>), boy_W2_one_Matrix(iz,<span class="hljs-number">2</span>));<br>    <span class="hljs-keyword">end</span><br>    W2_score = sum1 / (sum(girl_W2_one_Matrix(:, <span class="hljs-number">1</span>)) + <span class="hljs-number">0.0001</span> );<br>    <br>Y = W2_score;<br></code></pre></td></tr></table></figure><h2 id="w2_fx">W2_fx</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">Y</span> = <span class="hljs-title">W2_fx</span><span class="hljs-params">(x, y)</span></span><br>x = x / <span class="hljs-number">100</span>;<br>y = y / <span class="hljs-number">100</span>;<br><br>Y = <span class="hljs-number">0</span>;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(x-y)&lt;= <span class="hljs-number">0.6</span><br>    Y = -<span class="hljs-built_in">abs</span>(x-y) * <span class="hljs-number">1</span> / <span class="hljs-number">0.6</span> + <span class="hljs-number">1</span>;<br><span class="hljs-keyword">end</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">abs</span>(x-y)&lt;= <span class="hljs-number">0.1</span><br>    Y = <span class="hljs-number">1</span>;<br><span class="hljs-keyword">end</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MATLAB</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo个人博客搭建</title>
    <link href="/2023/11/08/Hexo%20%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/"/>
    <url>/2023/11/08/Hexo%20%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="Hexo个人博客搭建"><a href="#Hexo个人博客搭建" class="headerlink" title="Hexo个人博客搭建"></a>Hexo个人博客搭建</h1><p>$a$</p><hr><ol><li>安装nodejs、git</li></ol><p>首先、需要安装 Node.js(<a href="http://nodejs.cn/download/">http://nodejs.cn/download/</a>) 和 Git(<a href="https://git-scm.com/downloads)%EF%BC%8C%E5%A4%A7%E5%AE%B6%E5%B0%BD%E9%87%8F%E5%8E%BB%E4%B8%8B%E8%BD%BD.exe%E6%89%A9%E5%B1%95%E5%90%8D%E7%9A%84%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%EF%BC%8C%E8%BF%99%E6%A0%B7%E7%9A%84%E5%A5%BD%E5%A4%84%E6%98%AF%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85%E3%80%81%E7%9C%81%E5%8E%BB%E4%BA%86%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE%E3%80%82%E5%AE%89%E8%A3%85%E7%89%88%E6%9C%AC%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%AE%89%E8%A3%85%E6%9C%80%E6%96%B0%E7%9A%84%E7%89%88%E6%9C%AC%E3%80%82%E5%A6%82%E6%9E%9C%E6%9C%89%E9%97%AE%E9%A2%98%E5%8D%B8%E8%BD%BD%E5%AE%89%E8%A3%85%E6%97%A7%E7%89%88%E3%80%82">https://git-scm.com/downloads)，大家尽量去下载.exe扩展名的可执行文件，这样的好处是一键安装、省去了一些配置。安装版本也可以安装最新的版本。如果有问题卸载安装旧版。</a> </p><p><code>验证安装是否成功</code>，打开CMD</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">验证Node.js的方法<br>node -v<br>npm -v<br>输入后能够显示版本说明安装成功<br></code></pre></td></tr></table></figure><ol><li><p>在文件夹中右击 <code>Git Bash Here</code> </p></li><li><p>使用npm命令安装Hexo，输入：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python">npm install -g hexo-cli <span class="hljs-comment"># 安装hexo可略过</span><br>hexo init<br>hexo new 我的新博客<br>hexo g <span class="hljs-comment">#生成</span><br>hexo s <span class="hljs-comment">#启动服务预览</span><br>git config --<span class="hljs-keyword">global</span> user.name <span class="hljs-string">&quot;wbupt&quot;</span><br>git config --<span class="hljs-keyword">global</span> user.email <span class="hljs-string">&quot;34@qq.com&quot;</span><br>npm install hexo-deployer-git --save <span class="hljs-comment"># 安装上传文件</span><br>npm install hexo-renderer-pug hexo-renderer-stylus <span class="hljs-comment"># 安装 butterfly插件</span><br>npm install hexo-generator-index-pin-top --save <span class="hljs-comment"># 文章置顶插件</span><br>npm install hexo-hide-posts --save <span class="hljs-comment"># 隐藏文章</span><br>npm install hexo-math --save <span class="hljs-comment"># 安装公式</span><br>npm i hexo-renderer-pandoc<br>hexo s -p  <span class="hljs-number">5000</span> <span class="hljs-comment"># 更改localhost值</span><br>hexo d <span class="hljs-comment">#部署</span><br><span class="hljs-comment"># 打开浏览器输入地址</span><br>localhost:<span class="hljs-number">4000</span><br>hexo clean <span class="hljs-comment">#清除缓存，若是网页正常情况下可以忽略这条命令</span><br></code></pre></td></tr></table></figure><p>隐藏文章地址<a href="https://www.cnblogs.com/yangstar/articles/16690342.html">https://www.cnblogs.com/yangstar/articles/16690342.html</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">ssh-keygen -t rsa -C <span class="hljs-string">&quot;34@qq.com&quot;</span><br><span class="hljs-comment"># 创建一个 ssh key, 用准备好的email作为标签</span><br>Generating public/private rsa key pair.<br>Enter file <span class="hljs-keyword">in</span> which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter]<br></code></pre></td></tr></table></figure></li><li><h2 id="配置网站"><a href="#配置网站" class="headerlink" title="配置网站"></a>配置网站</h2></li></ol><p>进入根目录里的themes文件夹，里面也有个<code>_config.yml</code>文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">deploy:<br>  <span class="hljs-built_in">type</span>: git<br>  repo: git@github.com:仓库名/仓库名.github.io.git<br>  branch: main <br></code></pre></td></tr></table></figure><ul><li>安装Git部署插件</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">npm install hexo-deployer-git --save <span class="hljs-comment"># 安装上传文件</span><br>hexo clean <br>hexo g <br>hexo d<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">ssh-keygen -t rsa -f  ~/.ssh/wbupt -C <span class="hljs-string">&quot;34@qq.com&quot;</span><br>ssh -T [<span class="hljs-number">34</span>@qq.com protected]<br>ssh -T git@wbupt.github.com <span class="hljs-comment">#新的ssh_key验证</span><br><br>git config --<span class="hljs-keyword">global</span> user.name Github_name<br>git config --<span class="hljs-keyword">global</span> user.email ww@<span class="hljs-number">163.</span>com<br>ssh-keygen -t rsa -C wz@<span class="hljs-number">163.</span>com<br></code></pre></td></tr></table></figure><h2 id="配置文件设置："><a href="#配置文件设置：" class="headerlink" title="配置文件设置："></a>配置文件设置：</h2><p><code>_config.yml</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">skip_render: <span class="hljs-comment">#跳过文件</span><br>  - <span class="hljs-string">&quot;HTML/*&quot;</span><br>  - <span class="hljs-string">&quot;about/*&quot;</span><br>banner_img: <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">---<br>title: Hexo个人博客搭建<br>tags: [Gridea,Hexo,Python] <span class="hljs-comment"># 标题</span><br>published: true<br>hideInList: false<br>isTop: true<br>abbrlink: <span class="hljs-number">20929</span><br>date: <span class="hljs-number">2023</span>-03-<span class="hljs-number">14</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:08<br>feature:<br>sticky: <span class="hljs-number">101</span><br>top: <span class="hljs-number">101</span><br>---<br></code></pre></td></tr></table></figure><h2 id="跳过文件"><a href="#跳过文件" class="headerlink" title="跳过文件"></a>跳过文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">skip_render: <br>  - <span class="hljs-string">&quot;HTML/*&quot;</span><br>  - <span class="hljs-string">&quot;about/*&quot;</span><br>banner_img: <span class="hljs-string">&quot;&quot;</span><br></code></pre></td></tr></table></figure><h2 id="Hexo-顶面配置"><a href="#Hexo-顶面配置" class="headerlink" title="Hexo 顶面配置"></a>Hexo 顶面配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">title: Hexo个人博客搭建<br>tags: [Gridea,Hexo,Python] <span class="hljs-comment"># 标签</span><br>published: true <span class="hljs-comment"># 未知</span><br>hidden: false<br>hide: false<br>isTop: true <span class="hljs-comment"># ?</span><br>abbrlink: <span class="hljs-number">20929</span> <span class="hljs-comment"># ?</span><br>date: <span class="hljs-number">2023</span>-03-<span class="hljs-number">14</span> <span class="hljs-number">10</span>:<span class="hljs-number">19</span>:08 <span class="hljs-comment"># time</span><br>feature:<br>sticky: <span class="hljs-number">101</span><br>top: <span class="hljs-number">101</span><br>category: Hexo <span class="hljs-comment"># 分类 category</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>北邮地图</title>
    <link href="/2023/11/08/bupt_map/"/>
    <url>/2023/11/08/bupt_map/</url>
    
    <content type="html"><![CDATA[<!DOCTYPE html><html lang="en"><head>     <meta charset="UTF-8">     <meta name="viewport" content="width=device-width, initial-scale=1.0">     <meta http-equiv="X-UA-Compatible" content="ie=edge">     <title>北邮地图</title>     <style>          :root {               --sushe-color: #d2a8ef;               --lvse-color: #62be9d;               --color-jiao_xue_lou: #cae270;               --color-shi_tang: #e36297;               --color-sports: #b7c2ee;               --entrance-color: #e2e8cd;               --jiashuqu-color: #09f5f5;               --color-li-fa: #bbf1d4; /* 理发店*/               /* 北边的路*/               --d: 20;               --a: 0.7;               --x_distance: var(--d);               --y_distance: 100;               --x_scale: var(--a);               --y_scale: var(--a);               --x_scale_little: var(--a);               --y_scale_little: var(--a);               /* 字体大小 */               --font_size_first: 10;               --font_size_second: 18;               --font_size_third: 5;          }          /* 1设置弹框 */          .modal {               display: none;               position: fixed;               z-index: 1;               left: 1px;               top: 30px;               width: 100%;               height: 300%;               overflow: auto;               background-color: rgba(0, 0, 0, 0.4);          }          .modal-content {               background-color: #fefefe;               margin: 10% auto;               padding: 20px;               border: 0 solid #888;               width: 50%;               border-radius: 15px;          }          .close {               color: #aaa;               float: right;               font-size: 28px;               font-weight: bold;               border-radius: 15px;          }          .close:hover,          .close:focus {               color: black;               text-decoration: none;               cursor: pointer;          }          /* 全局整体 */          .box {               color: black;               position: absolute;               letter-spacing: 0; /* 文字间水平距离 */               line-height: calc((var(--font_size_first) + 2 ) * 1px); /* 文字间垂直距离 */               display: flex;  /* 设置为flex布局 */               align-items: center; /* 垂直居中 */               justify-content: center; /* 水平居中 */               font-size: calc(var(--font_size_first) * 1px);               text-align: center;               top: 0px;               left: var(--d);               width: 300px;               height: 200px;          }          .beiyoukeji {               color: black;               background-color: #c75779;               z-index: 1;               left: calc((var(--x_distance) + 0)*var(--x_scale)*1px);               top: calc((var(--y_distance) + 100)*var(--y_scale)*1px);               width: calc(75 * var(--x_scale_little)*1px);               height: calc(130 * var(--y_scale_little)*1px);          }          .xue11 {               color: black;               background-color: var(--sushe-color);               left: calc((var(--x_distance) + 75)*var(--x_scale)*1px);               top: calc((var(--y_distance) + 100)*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little)*1px);               height: calc(45 * var(--y_scale_little)*1px);               z-index: 1;          }          .xue9 {               background-color: var(--sushe-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((190 + var(--y_distance))*var(--y_scale)*1px);               width: calc(73 * var(--x_scale_little)*1px);               height: calc(45 * var(--y_scale_little)*1px);               z-index: 1;          }          .j9 {               background-color: var(--color-jiao_xue_lou);               z-index: 1;               left: calc((148 + var(--x_distance))*var(--x_scale)*1px);               top: calc((190 + var(--y_distance))*var(--y_scale)*1px);               width: calc(27 * var(--x_scale_little) * 1px);               height: calc(45 * var(--y_scale_little) * 1px);          }          .x10 {               background-color: var(--sushe-color);               z-index: 1;               left: calc((191 + var(--x_distance))*var(--x_scale)*1px);               top: calc((130 + var(--y_distance))*var(--y_scale)*1px);               width: calc(105 * var(--x_scale_little) * 1px);               height: calc(100 * var(--y_scale_little) * 1px);          }          .jg {               background-color: var(--sushe-color);               left: calc((var(--x_distance) + 350)*var(--x_scale)*1px);               top: calc((var(--y_distance) + 130)*var(--y_scale)*1px);               width: calc(95 * var(--x_scale_little)*1px);               height: calc(60 * var(--y_scale_little)*1px);               z-index: 1;          }          .zhong_you {               background-color: #eec0c0;               line-height: calc((var(--font_size_first) + 0 ) * 1px);               font-size: calc(var(--font_size_first) * 1px);               left: calc((var(--x_distance) + 390)*var(--x_scale)*1px);               top: calc((var(--y_distance) + 110)*var(--y_scale)*1px);               width: calc(55 * var(--x_scale_little)*1px);               height: calc(30 * var(--y_scale_little)*1px);               z-index: 1;          }          .xh {               letter-spacing: 0;               background-color: var(--sushe-color);               left: calc((var(--x_distance) + 350)*var(--x_scale)*1px);               top: calc((var(--y_distance) + 208)*var(--y_scale)*1px);               width: calc(93 * var(--x_scale_little)*1px);               height: calc(100 * var(--y_scale_little)*1px);               z-index: 1;          }          .x6 {               background-color: var(--sushe-color);               left: calc((460 + var(--x_distance))*var(--x_scale)*1px);               top: calc((130 + var(--y_distance))*var(--y_scale)*1px);               width: calc(45 * var(--x_scale_little) * 1px);               height: calc(100 * var(--y_scale_little) * 1px);               z-index: 1;          }          .x61 {               background-color: var(--sushe-color);               left: calc((505 + var(--x_distance))*var(--x_scale)*1px);               top: calc((130 + var(--y_distance))*var(--y_scale)*1px);               width: calc(65 * var(--x_scale_little) * 1px);               height: calc(37 * var(--y_scale_little) * 1px);               z-index: 1;          }          .x62 {               background-color: var(--sushe-color);               left: calc((505 + var(--x_distance))*var(--x_scale)*1px);               top: calc((195 + var(--y_distance))*var(--y_scale)*1px);               width: calc(35 * var(--x_scale_little) * 1px);               height: calc(35 * var(--y_scale_little) * 1px);               z-index: 1;          }          .xi_hong_dian1 {               background-color: red;               left: calc((500 + var(--x_distance))*var(--x_scale)*1px);               top: calc((165 + var(--y_distance))*var(--y_scale)*1px);               width: calc(17 * var(--x_scale_little) * 1px);               height: calc(17 * var(--y_scale_little) * 1px);               z-index: 1;          }          .zao_tang {               background-color: #7be7ad;               font-size: calc((var(--font_size_first) + 0 )* 1px);               line-height: calc(((--font_size_first) + 0 ) * 1px);               left: calc((458 + var(--x_distance))*var(--x_scale)*1px);               top: calc((245 + var(--y_distance))*var(--y_scale)*1px);               width: calc(28 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);               z-index: 1;          }          .ge_ge_li_fa_dian {               background-color: var(--color-li-fa);               left: calc((486 + var(--x_distance))*var(--x_scale)*1px);               top: calc((245 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_first) + 0 )* 1px);               line-height: calc(((--font_size_first) + 0 ) * 1px);               z-index: 1;          }          .tai_yang_neng_shui_fang {               background-color: #96e3ba;               left: calc((516 + var(--x_distance))*var(--x_scale)*1px);               top: calc((245 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);               font-size: calc(var(--font_size_third) * 1px);               line-height: calc((var(--font_size_third) + 7 ) * 1px); /* 文字间垂直距离 */          }          .guo_lu_fang {               background-color: #78d7db;               left: calc((546 + var(--x_distance))*var(--x_scale)*1px);               top: calc((245 + var(--y_distance))*var(--y_scale)*1px);               width: calc(28 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);               font-size: calc(var(--font_size_third) * 1px);               line-height: calc((var(--font_size_third) + 7 ) * 1px);          }          .jsq {               background-color: var(--jiashuqu-color);               left: calc((597 + var(--x_distance))*var(--x_scale)*1px);               top: calc((129 + var(--y_distance))*var(--y_scale)*1px);               width: calc(215 * var(--x_scale_little) * 1px);               height: calc(69 * var(--y_scale_little) * 1px);          }          .qing_nian_guo_yu {               line-height: 15px;               background-color: #6aacd5;               left: calc((710 + var(--x_distance))*var(--x_scale)*1px);               top: calc((170 + var(--y_distance))*var(--y_scale)*1px);               width: calc(102 * var(--x_scale_little) * 1px);               height: calc(28 * var(--y_scale_little) * 1px);          }          .ke_yan_lou {               background-color: var(--color-jiao_xue_lou);               left: calc((579 + var(--x_distance))*var(--x_scale)*1px);               top: calc((218 + var(--y_distance))*var(--y_scale)*1px);               width: calc(102 * var(--x_scale_little) * 1px);               height: calc(94 * var(--y_scale_little) * 1px);          }          .Jia_shu_qu2 {               background-color: var(--jiashuqu-color);               left: calc((712 + var(--x_distance))*var(--x_scale)*1px);               top: calc((218 + var(--y_distance))*var(--y_scale)*1px);               width: calc(102 * var(--x_scale_little) * 1px);               height: calc(83 * var(--y_scale_little) * 1px);          }          .qngy {               background-color: var(--sushe-color);               left: calc((0 + var(--x_distance))*var(--x_scale)*1px);               top: calc((238 + var(--y_distance))*var(--y_scale)*1px);               width: calc(45 * var(--x_scale_little) * 1px);               height: calc(90 * var(--y_scale_little) * 1px);               line-height: calc((var(--font_size_second) + 0 ) * 1px);          }          .lxs {               background-color: var(--sushe-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((255 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(41 * var(--y_scale_little) * 1px);               line-height: calc((var(--font_size_first) + 0 ) * 1px);          }          .xin_shi_tang {               background-color: var(--color-shi_tang);               left: calc((193 + var(--x_distance))*var(--x_scale)*1px);               top: calc((250 + var(--y_distance))*var(--y_scale)*1px);               width: calc(105 * var(--x_scale_little) * 1px);               height: calc(52 * var(--y_scale_little) * 1px);          }          .x13 {               background-color: var(--sushe-color);               left: calc((0 + var(--x_distance))*var(--x_scale)*1px);               top: calc((344 + var(--y_distance))*var(--y_scale)*1px);               width: calc(47 * var(--x_scale_little) * 1px);               height: calc(168 * var(--y_scale_little) * 1px);          }          .x5 {               background-color: var(--sushe-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((320 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(42 * var(--y_scale_little) * 1px);          }          .cd1 {               background-color: var(--lvse-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((373 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }          .x3 {               background-color: var(--sushe-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((435 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(40 * var(--y_scale_little) * 1px);          }          .x8 {               background-color: var(--sushe-color);               left: calc((192 + var(--x_distance))*var(--x_scale)*1px);               top: calc((320 + var(--y_distance))*var(--y_scale)*1px);               width: calc(108 * var(--x_scale_little) * 1px);               height: calc(42 * var(--y_scale_little) * 1px);          }          .cd2 {               background-color: var(--lvse-color);               left: calc((192 + var(--x_distance))*var(--x_scale)*1px);               top: calc((372 + var(--y_distance))*var(--y_scale)*1px);               width: calc(108 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }          .x4 {               background-color: var(--sushe-color);               left: calc((192 + var(--x_distance))*var(--x_scale)*1px);               top: calc((435 + var(--y_distance))*var(--y_scale)*1px);               width: calc(108 * var(--x_scale_little) * 1px);               height: calc(40 * var(--y_scale_little) * 1px);          }          .cd3 {               background-color: var(--lvse-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((478 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(45 * var(--y_scale_little) * 1px);          }          .cd4 {               background-color: var(--lvse-color);               left: calc((192 + var(--x_distance))*var(--x_scale)*1px);               top: calc((478 + var(--y_distance))*var(--y_scale)*1px);               width: calc(108 * var(--x_scale_little) * 1px);               height: calc(45 * var(--y_scale_little) * 1px);          }          .x1 {               background-color: var(--sushe-color);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((527 + var(--y_distance))*var(--y_scale)*1px);               width: calc(100 * var(--x_scale_little) * 1px);               height: calc(38 * var(--y_scale_little) * 1px);          }          .x2 {               background-color: var(--sushe-color);               left: calc((192 + var(--x_distance))*var(--x_scale)*1px);               top: calc((527 + var(--y_distance))*var(--y_scale)*1px);               width: calc(108 * var(--x_scale_little) * 1px);               height: calc(38 * var(--y_scale_little) * 1px);          }          .kd1 {               background-color: var(--sushe-color);               left: calc((342 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(37 * var(--x_scale_little) * 1px);               height: calc(74 * var(--y_scale_little) * 1px);          }          .mai_dang_lao {               background-color: var(--sushe-color);               left: calc((410 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(25 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_third) + 0 )* 1px);               line-height: calc(((--font_size_third) + 0 ) * 1px);          }          .wu_mei {               background-color: #eeb1b1;               left: calc((435 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(50 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);          }          .mlt {               background-color: #eaf2b6;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((480 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(27 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);          }          .shui_guo_dian {               background-color: #e35770;                    left: calc((507 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(27 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_third) + 0 )* 1px);               line-height: calc(((--font_size_third) + 0 ) * 1px);          }          .da_yin_dian {               background-color: #e26f47;               left: calc((534 + var(--x_distance))*var(--x_scale)*1px);               top: calc((327 + var(--y_distance))*var(--y_scale)*1px);               width: calc(39 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_third) + 0 )* 1px);               line-height: calc(((--font_size_third) - 5 ) * 1px);          }          .jiao_gong_can_ting {               background-color: var(--color-shi_tang);               left: calc((470 + var(--x_distance))*var(--x_scale)*1px);               top: calc((347 + var(--y_distance))*var(--y_scale)*1px);               width: calc(103 * var(--x_scale_little) * 1px);               height: calc(30 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_third) + 4 )* 1px);               line-height: calc(((--font_size_third) + 2 ) * 1px);          }          .xue_sheng_shu_wu {               background-color: #bbc660;               left: calc((490 + var(--x_distance))*var(--x_scale)*1px);               top: calc((377 + var(--y_distance))*var(--y_scale)*1px);               width: calc(83 * var(--x_scale_little) * 1px);               height: calc(22 * var(--y_scale_little) * 1px);          }          .xue_sheng_chu {               background-color: #efbaba;               left: calc((435 + var(--x_distance))*var(--x_scale)*1px);               top: calc((377 + var(--y_distance))*var(--y_scale)*1px);               width: calc(72 * var(--x_scale_little) * 1px);               height: calc(22 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_third) + 0 )* 1px);               line-height: calc(((--font_size_third) + 0 ) * 1px);          }          .lao_shi_tang {               background-color: var(--color-shi_tang);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((598 + var(--x_distance))*var(--x_scale)*1px);               top: calc((337 + var(--y_distance))*var(--y_scale)*1px);               width: calc(80 * var(--x_scale_little) * 1px);               height: calc(92 * var(--y_scale_little) * 1px);          }          .jsq2 {               background-color:  var(--jiashuqu-color);               left: calc((688 + var(--x_distance))*var(--x_scale)*1px);               top: calc((337 + var(--y_distance))*var(--y_scale)*1px);               width: calc(45 * var(--x_scale_little) * 1px);               height: calc(92 * var(--y_scale_little) * 1px);          }          .bwi {               background-color: #a4d45b;               left: calc((748 + var(--x_distance))*var(--x_scale)*1px);               top: calc((317 + var(--y_distance))*var(--y_scale)*1px);               width: calc(65 * var(--x_scale_little) * 1px);               height: calc(112 * var(--y_scale_little) * 1px);          }          .tug {               background-color: var(--sushe-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((457 + var(--x_distance))*var(--x_scale)*1px);               top: calc((427 + var(--y_distance))*var(--y_scale)*1px);               width: calc(112 * var(--x_scale_little) * 1px);               height: calc(140 * var(--y_scale_little) * 1px);          }          .lan_qiu_chang {               background-color: var(--color-sports);               left: calc((598 + var(--x_distance))*var(--x_scale)*1px);               top: calc((453 + var(--y_distance))*var(--y_scale)*1px);               width: calc(80 * var(--x_scale_little) * 1px);               height: calc(112 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_second) - 2 )* 1px);               line-height: calc((var(--font_size_second) + 0 ) * 1px);          }          .wqi {               background-color: #68e37b;               left: calc((678 + var(--x_distance))*var(--x_scale)*1px);               top: calc((453 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(112 * var(--y_scale_little) * 1px);          }          .pqi {               background-color: #67e2d0;               left: calc((708 + var(--x_distance))*var(--x_scale)*1px);               top: calc((453 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(112 * var(--y_scale_little) * 1px);          }          .x29 {               background-color: var(--sushe-color);               left: calc((758 + var(--x_distance))*var(--x_scale)*1px);               top: calc((453 + var(--y_distance))*var(--y_scale)*1px);               width: calc(55 * var(--x_scale_little) * 1px);               height: calc(112 * var(--y_scale_little) * 1px);          }          .ti_yu_guan {               background-color: var(--color-sports);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((707 + var(--x_distance))*var(--x_scale)*1px);               top: calc((600 + var(--y_distance))*var(--y_scale)*1px);               width: calc(77 * var(--x_scale_little) * 1px);               height: calc(126 * var(--y_scale_little) * 1px);          }          .ygr {               background-color: #deb476;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((784 + var(--x_distance))*var(--x_scale)*1px);               top: calc((600 + var(--y_distance))*var(--y_scale)*1px);               width: calc(37 * var(--x_scale_little) * 1px);               height: calc(189 * var(--y_scale_little) * 1px);          }          .cao_chang {               background-color: var(--color-sports);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((714 + var(--x_distance))*var(--x_scale)*1px);               top: calc((805 + var(--y_distance))*var(--y_scale)*1px);               width: calc(110 * var(--x_scale_little) * 1px);               height: calc(259 * var(--y_scale_little) * 1px);          }          .qmjs {               background-color: #ded684;               left: calc((714 + var(--x_distance))*var(--x_scale)*1px);               top: calc((750 + var(--y_distance))*var(--y_scale)*1px);               width: calc(53 * var(--x_scale_little) * 1px);               height: calc(49 * var(--y_scale_little) * 1px);          }          .dks {               background-color: var(--lvse-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((598 + var(--x_distance))*var(--x_scale)*1px);               top: calc((600 + var(--y_distance))*var(--y_scale)*1px);               width: calc(89 * var(--x_scale_little) * 1px);               height: calc(126 * var(--y_scale_little) * 1px);          }          .j1 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((348 + var(--x_distance))*var(--x_scale)*1px);               top: calc((670 + var(--y_distance))*var(--y_scale)*1px);               width: calc(222 * var(--x_scale_little) * 1px);               height: calc(56 * var(--y_scale_little) * 1px);          }          .j11 {               background-color: #cae270;               left: calc((348 + var(--x_distance))*var(--x_scale)*1px);               top: calc((648 + var(--y_distance))*var(--y_scale)*1px);               width: calc(48 * var(--x_scale_little) * 1px);               height: calc(92 * var(--y_scale_little) * 1px);          }          .j12 {               background-color: #cae270;               left: calc((523 + var(--x_distance))*var(--x_scale)*1px);               top: calc((648 + var(--y_distance))*var(--y_scale)*1px);               width: calc(46 * var(--x_scale_little) * 1px);               height: calc(92 * var(--y_scale_little) * 1px);          }          .vl {               background-color: #cae270;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((475 + var(--x_distance))*var(--x_scale)*1px);               top: calc((760 + var(--y_distance))*var(--y_scale)*1px);               width: calc(98 * var(--x_scale_little) * 1px);               height: calc(128 * var(--y_scale_little) * 1px);          }          .kxht {               background-color: #cae270;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((597 + var(--x_distance))*var(--x_scale)*1px);               top: calc((760 + var(--y_distance))*var(--y_scale)*1px);               width: calc(92 * var(--x_scale_little) * 1px);               height: calc(108 * var(--y_scale_little) * 1px);          }          .j2 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((351 + var(--x_distance))*var(--x_scale)*1px);               top: calc((950 + var(--y_distance))*var(--y_scale)*1px);               width: calc(209 * var(--x_scale_little) * 1px);               height: calc(58 * var(--y_scale_little) * 1px);          }          .j21 {               background-color: #cae270;               left: calc((351 + var(--x_distance))*var(--x_scale)*1px);               top: calc((920 + var(--y_distance))*var(--y_scale)*1px);               width: calc(45 * var(--x_scale_little) * 1px);               height: calc(115 * var(--y_scale_little) * 1px);          }          .j22 {               background-color: #cae270;               left: calc((515 + var(--x_distance))*var(--x_scale)*1px);               top: calc((920 + var(--y_distance))*var(--y_scale)*1px);               width: calc(45 * var(--x_scale_little) * 1px);               height: calc(115 * var(--y_scale_little) * 1px);          }          .bm {               background-color: var(--entrance-color);               font-size: calc((var(--font_size_first) + 5) * 1px);               line-height: calc((var(--font_size_first) + 5 ) * 1px);               left: calc((290 + var(--x_distance))*var(--x_scale)*1px);               top: calc((100 + var(--y_distance))*var(--y_scale)*1px);               width: calc(65 * var(--x_scale_little) * 1px);               height: calc(15 * var(--y_scale_little) * 1px);          }          .xi_men {               background-color: var(--entrance-color);               font-size: calc((var(--font_size_first) + 5) * 1px);               line-height: calc((var(--font_size_first) + 5 ) * 1px);               left: calc((0 + var(--x_distance))*var(--x_scale)*1px);               top: calc((782 + var(--y_distance))*var(--y_scale)*1px);               width: calc(20 * var(--x_scale_little) * 1px);               height: calc(90 * var(--y_scale_little) * 1px);          }          .dong_men {               background-color: var(--entrance-color);               font-size: calc((var(--font_size_first) + 5) * 1px);               line-height: calc((var(--font_size_first) + 5 ) * 1px);               left: calc((832 + var(--x_distance))*var(--x_scale)*1px);               top: calc((542 + var(--y_distance))*var(--y_scale)*1px);               width: calc(20 * var(--x_scale_little) * 1px);               height: calc(76 * var(--y_scale_little) * 1px);          }          .j4 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((640 + var(--y_distance))*var(--y_scale)*1px);               width: calc(222 * var(--x_scale_little) * 1px);               height: calc(55 * var(--y_scale_little) * 1px);          }          .j41 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((610 + var(--y_distance))*var(--y_scale)*1px);               width: calc(49 * var(--x_scale_little) * 1px);               height: calc(110 * var(--y_scale_little) * 1px);          }          .j42 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((250 + var(--x_distance))*var(--x_scale)*1px);               top: calc((610 + var(--y_distance))*var(--y_scale)*1px);               width: calc(49 * var(--x_scale_little) * 1px);               height: calc(110 * var(--y_scale_little) * 1px);          }          .j3 {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((75 + var(--x_distance))*var(--x_scale)*1px);               top: calc((920 + var(--y_distance))*var(--y_scale)*1px);               width: calc(225 * var(--x_scale_little) * 1px);               height: calc(110 * var(--y_scale_little) * 1px);          }          .j3_da_yin_dian {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_third) *2 ) * 1px);              font-size: calc(var(--font_size_third) *2* 1px);               left: calc((245 + var(--x_distance))*var(--x_scale)*1px);               top: calc((960 + var(--y_distance))*var(--y_scale)*1px);               width: calc(25 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }          .xyy {               background-color: #63e21a;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((79 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1065 + var(--y_distance))*var(--y_scale)*1px);               width: calc(220 * var(--x_scale_little) * 1px);               height: calc(40 * var(--y_scale_little) * 1px);          }          .zhong_men {               background-color: var(--entrance-color);               font-size: calc((var(--font_size_first) + 5) * 1px);               line-height: calc((var(--font_size_first) + 5 ) * 1px);               left: calc((308 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1090 + var(--y_distance))*var(--y_scale)*1px);               width: calc(60 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);          }          .nan_qu_chao_shi {               background-color: #2abd65;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((191 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1130 + var(--y_distance))*var(--y_scale)*1px);               width: calc(106 * var(--x_scale_little) * 1px);               height: calc(56 * var(--y_scale_little) * 1px);          }          .qmjs2 {               background-color: #2abd65;               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((365 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1132 + var(--y_distance))*var(--y_scale)*1px);               width: calc(240 * var(--x_scale_little) * 1px);               height: calc(36 * var(--y_scale_little) * 1px);          }          .gan_xi_feng_ren_dian {               background-color: #e3d4c4;               line-height: calc((var(--font_size_second)  ) *0.7* 1px);               font-size: calc(var(--font_size_second)*0.7 * 1px);               left: calc((455 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1070 + var(--y_distance))*var(--y_scale)*1px);               width: calc(40 * var(--x_scale_little) * 1px);               height: calc(36 * var(--y_scale_little) * 1px);          }          .bwyey {               background-color: #2abd65;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((610 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1132 + var(--y_distance))*var(--y_scale)*1px);               width: calc(95 * var(--x_scale_little) * 1px);               height: calc(132 * var(--y_scale_little) * 1px);          }          .njuq {               background-color: var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((389 + var(--x_distance))*var(--x_scale)*1px);               top: calc((1059 + var(--y_distance))*var(--y_scale)*1px);               width: calc(300 * var(--x_scale_little) * 1px);               height: calc(48 * var(--y_scale_little) * 1px);          }          .njuq1 {               background-color:  var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((730 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1072 + var(--y_distance))*var(--y_scale)*1px);               width: calc(85 * var(--x_scale_little) * 1px);               height: calc(85 * var(--y_scale_little) * 1px);          }          .lsvw1 {               background-color: var(--lvse-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((75 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((760 + var(--y_distance))*var(--y_scale)*1px);               width: calc(106 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);          }          .lsvw2 {               background-color: var(--lvse-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((200 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((760 + var(--y_distance))*var(--y_scale)*1px);               width: calc(102 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);          }          .lsvw3 {               background-color: var(--lvse-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((75 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((830 + var(--y_distance))*var(--y_scale)*1px);               width: calc(106 * var(--x_scale_little) * 1px);               height: calc(65 * var(--y_scale_little) * 1px);          }          .lsvw4 {               background-color: var(--lvse-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((200 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((830 + var(--y_distance))*var(--y_scale)*1px);               width: calc(102 * var(--x_scale_little) * 1px);               height: calc(65 * var(--y_scale_little) * 1px);          }          .zxx {               background-color: #c3d1ef;               font-size: calc((var(--font_size_first) + 2 )* 1px);               line-height: calc(((--font_size_first) + 2 ) * 1px);               left: calc((235 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((795 + var(--y_distance))*var(--y_scale)*1px);               width: calc(36 * var(--x_scale_little) * 1px);               height: calc(67 * var(--y_scale_little) * 1px);          }          .xiao_xun_shi {               background-color: #b9cef5;               font-size: calc((var(--font_size_first) + 2 )* 1px);               line-height: calc(((--font_size_first) + 2 ) * 1px);               left: calc((175 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((799 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);          }          .ke_xin_wang_luo {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_first) + 5 ) * 1px);               font-size: calc((var(--font_size_first) + 4) * 1px);               left: calc((577 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((920 + var(--y_distance))*var(--y_scale)*1px);               width: calc(113 * var(--x_scale_little) * 1px);               height: calc(115 * var(--y_scale_little) * 1px);          }          .hong_tong_lou {               background-color: var(--color-jiao_xue_lou);               font-size: calc((var(--font_size_second) - 2 )* 1px);               line-height: calc((var(--font_size_second) - 2 ) * 1px);               left: calc(( var(--d))*var(--x_scale)*1px);               top: calc((565 + var(--y_distance))*var(--y_scale)*1px);               width: calc(47 * var(--x_scale_little) * 1px);               height: calc(65 * var(--y_scale_little) * 1px);          }          .xsl {               background-color: palevioletred;               left: calc((356 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((427 + var(--y_distance))*var(--y_scale)*1px);               width: calc(79 * var(--x_scale_little) * 1px);               height: calc(40 * var(--y_scale_little) * 1px);          }          .shi_guang_guang_chang {               background-color: palevioletred;               left: calc((356 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((529 + var(--y_distance))*var(--y_scale)*1px);               width: calc(79 * var(--x_scale_little) * 1px);               height: calc(38 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_second) - 0 )* 1px);               line-height: calc((var(--font_size_second) - 0 ) * 1px);          }          .xing_zheng_ban_gong_lou {               background-color: palevioletred;               /*line-height: calc((var(--font_size_second) + 2 ) * 1px);*/               /*font-size: calc(var(--font_size_second) * 1px);*/               left: calc((430 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((593 + var(--y_distance))*var(--y_scale)*1px);               width: calc(79 * var(--x_scale_little) * 1px);               height: calc(77 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_second) - 5 )* 1px);               line-height: calc(((--font_size_second) - 5 ) * 1px);          }          .cai_wu_chu {               background-color: palevioletred;               left: calc((350 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((593 + var(--y_distance))*var(--y_scale)*1px);               width: calc(70 * var(--x_scale_little) * 1px);               height: calc(25 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_second) - 7 )* 1px);               line-height: calc(((--font_size_second) + 2 ) * 1px);          }          .hou_qin_lou {               background-color: #a48ce8;               left: calc((350 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((617 + var(--y_distance))*var(--y_scale)*1px);               width: calc(70 * var(--x_scale_little) * 1px);               height: calc(25 * var(--y_scale_little) * 1px);               font-size: calc((var(--font_size_second) - 7 )* 1px);               line-height: calc(((--font_size_second) + 2 ) * 1px);          }          .bj {               background-color: #5dd0db;               left: calc((580 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1278 + var(--y_distance))*var(--y_scale)*1px);               width: calc(155 * var(--x_scale_little) * 1px);               height: calc(54 * var(--y_scale_little) * 1px);               line-height: calc((var(--font_size_second) - 1 ) * 1px);               font-size: calc((var(--font_size_second) - 1 )  * 1px);          }          .jsq3 {               background-color:  var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((460 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1278 + var(--y_distance))*var(--y_scale)*1px);               width: calc(115 * var(--x_scale_little) * 1px);               height: calc(54 * var(--y_scale_little) * 1px);          }          .jsq4 {               background-color:  var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);               font-size: calc(var(--font_size_second) * 1px);               left: calc((365 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1174 + var(--y_distance))*var(--y_scale)*1px);               width: calc(240 * var(--x_scale_little) * 1px);               height: calc(89 * var(--y_scale_little) * 1px);          }          .jsq5 {               background-color:  var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((80 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1180 + var(--y_distance))*var(--y_scale)*1px);               width: calc(175 * var(--x_scale_little) * 1px);               height: calc(78 * var(--y_scale_little) * 1px);          }          .sd {               background-color: #7e8def;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((255 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1180 + var(--y_distance))*var(--y_scale)*1px);               width: calc(43 * var(--x_scale_little) * 1px);               height: calc(78 * var(--y_scale_little) * 1px);          }          .xue_yuan_li_fa {               background-color: #e4f5bf;               line-height: calc((var(--font_size_third) + 5 ) * 1px);              font-size: calc(var(--font_size_third) * 2px);               left: calc((255 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1200 + var(--y_distance))*var(--y_scale)*1px);               width: calc(43 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);          }          .nan_men_shuo_guo {               background-color: #e3d6d3;               line-height: calc((var(--font_size_third) + 5 ) * 1px);              font-size: calc(var(--font_size_third) * 2px);               left: calc((255 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1183 + var(--y_distance))*var(--y_scale)*1px);               width: calc(43 * var(--x_scale_little) * 1px);               height: calc(20 * var(--y_scale_little) * 1px);          }          .jsq6 {               background-color: var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);              font-size: calc(var(--font_size_second) * 1px);               left: calc((80 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1265 + var(--y_distance))*var(--y_scale)*1px);               width: calc(183 * var(--x_scale_little) * 1px);               height: calc(90 * var(--y_scale_little) * 1px);          }          .jsq7 {               background-color: var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((260 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1305 + var(--y_distance))*var(--y_scale)*1px);               width: calc(97 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }          .hcp {               background-color: #765de7;               line-height: calc((var(--font_size_second) + 2 ) * 1px);              font-size: calc(var(--font_size_second) * 1px);               left: calc((362 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1305 + var(--y_distance))*var(--y_scale)*1px);               width: calc(52 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }           .nan_men {                background-color: var(--entrance-color);                font-size: calc((var(--font_size_first) + 0) * 1px);                line-height: calc((var(--font_size_first) - 5 ) * 1px);                left: calc((420 + var(--x_distance)) * var(--x_scale) * 1px);                top: calc((1345 + var(--y_distance))*var(--y_scale)*1px);                width: calc(60 * var(--x_scale_little) * 1px);                height: calc(20 * var(--y_scale_little) * 1px);          }          .ming_guang_lou {               background-color: var(--color-jiao_xue_lou);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((743 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1178 + var(--y_distance))*var(--y_scale)*1px);               width: calc(70 * var(--x_scale_little) * 1px);               height: calc(183 * var(--y_scale_little) * 1px);          }          .jsq8 {               background-color:  var(--jiashuqu-color);               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc(( var(--d))*var(--x_scale)*1px);               top: calc((1065 + var(--y_distance))*var(--y_scale)*1px);               width: calc(68 * var(--x_scale_little) * 1px);               height: calc(290 * var(--y_scale_little) * 1px);          }          .shang_pu {               background-color: #eebcf6;               line-height: calc((var(--font_size_second) + 2 ) * 1px);font-size: calc(var(--font_size_second) * 1px);               left: calc((80 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1130 + var(--y_distance))*var(--y_scale)*1px);               width: calc(110 * var(--x_scale_little) * 1px);               height: calc(50 * var(--y_scale_little) * 1px);          }          .sheng_shi_hao {               background-color: var(--color-li-fa);               line-height: calc((var(--font_size_second) *0.7 ) * 1px);              font-size: calc(var(--font_size_second) *0.6* 1px);               left: calc((40 + var(--x_distance)) * var(--x_scale) * 1px);               top: calc((1120 + var(--y_distance))*var(--y_scale)*1px);               width: calc(30 * var(--x_scale_little) * 1px);               height: calc(60 * var(--y_scale_little) * 1px);          }     </style></head><body>     <p style="color: white;font-size:500px;line-height: 1.0">.</p>     <p style="color: white;font-size:500px;line-height: 1.0">.</p>     <div class="box beiyoukeji"><p style="color: black">北邮科技酒店</p></div>     <div class="box xue11"><p style="color: black">学11</p></div>     <div class="box xue9"><p style="color: black">学9</p></div>     <div class="box j9"><p style="color: black">教9</p></div>     <div class="box x10"><p style="color: black">学10</p></div>     <div class="box jg"><p style="color: black">经管楼</p></div>     <div class="box xh"><p style="color: black">学生活动中心</p></div>     <div class="box x6"><p style="color: black">学6</p></div>     <div class="box x61"><p style="color: black"></p></div>     <div class="box x62"><p style="color: black"></p></div>     <button class="box xi_hong_dian1" onclick="openModal('modal6')">洗烘店</button>     <div id="modal6" class="modal"><div class="modal-content">         <span class="close" onclick="closeModal('modal6')">&times;&times;&times;</span>         <p>24小时开放</p>         <a href="https://www.bupt.life/hong_xi_dian">具体详情</a>     </div></div>     <button class="box zao_tang" onclick="openModal('moda20')">澡堂</button>     <div id="moda20" class="modal"><div class="modal-content">         <span class="close" onclick="closeModal('moda20')">&times;&times;&times;</span>         <p>澡堂开放:15:00-23:30</p></div></div>     <button class="box ge_ge_li_fa_dian" onclick="openModal('modal19')">理发店</button>     <div id="modal19" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal19')">&times;&times;&times;</span>          <p>格格理发店 营业时间 08:00-20:00</p></div></div>     <div class="box tai_yang_neng_shui_fang"><a style="color: black" href="#" title="开放:08:00-22:00">水房</a></div>     <div class="box guo_lu_fang"><p style="color: black">锅炉房</p></div>     <div class="box jsq"><p style="color: black">家属区</p></div>     <div class="box qing_nian_guo_yu"><p style="color: black"></p></div>     <div class="box ke_yan_lou"><p style="color: black">科研楼</p></div>     <div class="box Jia_shu_qu2"><p style="color: black">家属区</p></div>     <div class="box qngy"><p style="color: black">青年公寓</p></div>     <div class="box lxs"><p style="color: black">留学生公寓</p></div>     <div class="box xin_shi_tang"><p style="color: black">新食堂</p></div>     <button class="box xin_shi_tang" onclick="openModal('modal7')">新食堂</button><div id="modal7" class="modal"><div class="modal-content">    <span class="close" onclick="closeModal('modal7')">&times;&times;&times;</span>    <p>新食堂：待添加</p></div></div>     <div class="box x13"><p style="color: black">学13</p></div>     <div class="box x5"><p style="color: black">学5</p></div>     <div class="box cd1"><p style="color: black">草地</p></div>     <div class="box x3"><p style="color: black">学3</p></div>     <div class="box x8"><p style="color: black">学8</p></div>     <div class="box cd2"><p style="color: black">草地</p></div>     <div class="box x4"><p style="color: black">学4</p></div>     <div class="box cd3"><p style="color: black">草地</p></div>     <div class="box cd4"><p style="color: black">草地</p></div>     <div class="box x1"><p style="color: black">学1</p></div>     <div class="box x2"><p style="color: black">学2</p></div>     <div class="box kd1"><p style="color: black"></p></div>     <button class="box mai_dang_lao" onclick="openModal('modal8')">麦当劳</button>     <div id="modal8" class="modal"><div class="modal-content">         <span class="close" onclick="closeModal('modal8')">&times;&times;&times;</span>         <p>麦当劳 拟开业</p></div></div>     <button class="box wu_mei" onclick="openModal('modal9')">物美</button>     <div id="modal9" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal9')">&times;&times;&times;</span>          <p>物美 待添加</p></div></div>     <div class="box mlt"><p style="color: black"></p></div>     <div class="box shui_guo_dian"><a style="color: black" href="#" title="开放:14:00-16:00">水果店</a></div>     <div class="box da_yin_dian"><p style="color: black">打印店</p></div>     <button class="box jiao_gong_can_ting" onclick="openModal('modal10')">教工餐厅</button>     <div id="modal10" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal10')">&times;&times;&times;</span>          <p>教工餐厅开放:08:00-21:00</p></div></div>     <div class="box xue_sheng_shu_wu"><p style="color: black"></p></div> <!-- 学苑书屋-->     <div class="box xue_sheng_chu"><p style="color: black">学生处</p></div>     <button class="box lao_shi_tang" onclick="openModal('modal11')">老食堂</button>     <div id="modal11" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal11')">&times;&times;&times;</span>          <p>老食堂开放:08:00-21:00</p></div></div>     <div class="box jsq2"><p style="color: black">家属区</p></div>     <div class="box bwi"><p style="color: black">保卫处&基建处</p></div>     <button class="box tug" onclick="openModal('modal3')">图书馆</button>     <div id="modal3" class="modal">          <div class="modal-content">               <span class="close" onclick="closeModal('modal3')">&times;&times;&times;</span>               <p>图书馆放时间:08:00-21:00</p></div></div>     <button class="box lan_qiu_chang" onclick="openModal('modal1')">篮球场</button>     <div id="modal1" class="modal">          <div class="modal-content">               <span class="close" onclick="closeModal('modal1')">&times;&times;&times;</span>               <p>篮球场开放时间</p>               <a href="https://www.bupt.life/lan_qiu_chang">具体详情</a>               <p>08:00-21:00</p></div></div>     <div class="box wqi"><p style="color: black">网球场</p></div>     <div class="box pqi"><p style="color: black">排球场</p></div>     <div class="box x29"><p style="color: black">学29</p></div><!--     <div class="box ti_yu_guan"><p style="color: black">体育馆</p></div>-->     <button class="box ti_yu_guan" onclick="openModal('modal12')">体育馆</button>     <div id="modal12" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal12')">&times;&times;&times;</span>          <p>体育馆 待添加</p></div></div>     <button class="box ygr" onclick="openModal('modal13')">游泳馆</button>     <div id="modal13" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal13')">&times;&times;&times;</span>          <p>游泳馆 待添加</p></div></div>     <button class="box cao_chang" onclick="openModal('modal2')">操场</button>     <div id="modal2" class="modal">          <div class="modal-content">               <span class="close" onclick="closeModal('modal2')">&times;&times;&times;</span>               <p>操场开放时间:08:00-21:00</p></div></div>     <div class="box qmjs"><p style="color: black">全民健身</p></div>     <div class="box dks"><p style="color: black">大空地</p></div>     <div class="box j1"><p style="color: black">教一楼</p></div>     <div class="box j11"><p style="color: black"></p></div>     <div class="box j12"><p style="color: black"></p></div>     <div class="box vl"><p style="color: black">主楼</p></div>     <div class="box kxht"><p style="color: black">科学会堂</p></div>     <div class="box j2"><p style="color: black">教二楼</p></div>     <div class="box j21"><p style="color: black"></p></div>     <div class="box j22"><p style="color: black"></p></div>     <button class="box bm" onclick="openModal('modal5')">北门</button>     <div id="modal5" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal5')">&times;&times;&times;</span>          <p>北门已开</p>          <p>开放时间：06:00 - 24:00</p>         <a href="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/20230331191350.png">北门最新图片</a>     </div></div>     <button class="box xi_men" onclick="openModal('modal4')">西门</button>     <div id="modal4" class="modal">          <div class="modal-content">               <span class="close" onclick="closeModal('modal4')">&times;&times;&times;</span>               <p>西门开放时间:早8:00 - 晚11:00</p></div></div>     <button class="box dong_men" onclick="openModal('modal14')">东门</button>     <div id="modal14" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal14')">&times;&times;&times;</span>          <p>东门 24小时开放</p>     </div></div>     <div class="box j4"><p style="color: black">教四楼</p></div>     <div class="box j41"><p style="color: black"></p></div>     <div class="box j42"><p style="color: black"></p></div>     <div class="box j3"><p style="color: black">教三楼</p></div>      <button class="box j3_da_yin_dian" onclick="openModal('modal20')">打印店</button>     <div id="modal20" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal20')">&times;&times;&times;</span>          <p>教三 打印店</p>          <p>营业时间:早8:00 - 晚9:30，节假日不休</p>          <p>价格和其他家一样</p>     </div></div>     <button class="box xyy" onclick="openModal('modal15')">校医院</button>     <div id="modal15" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal15')">&times;&times;&times;</span>          <p>校医院 待添加</p></div></div>     <button class="box zhong_men" onclick="openModal('modal16')">中门</button>     <div id="modal16" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal16')">&times;&times;&times;</span>          <p>中门开放时间:早8:00 - 晚11:00</p></div></div>     <div class="box nan_qu_chao_shi"><p style="color: black">超市</p></div>     <div class="box qmjs2"><p style="color: black"></p></div>  <!-- 家属南区 全民健身-->               <div class="box bwyey"><p style="color: black">北邮幼儿园</p></div>     <div class="box njuq"><p style="color: black">家属区</p></div>  <!-- 家属区教二下边-->     <div class="box njuq1"><p style="color: black">家属区</p></div>  <!-- 家属区操场下面-->     <div class="box lsvw1"><p style="color: black"></p></div>     <div class="box lsvw2"><p style="color: black"></p></div>     <div class="box lsvw3"><p style="color: black"></p></div>     <div class="box lsvw4"><p style="color: black"></p></div>     <div class="box zxx"><p style="color: black">主席像</p></div>     <div class="box xiao_xun_shi"><p style="color: black">校训石</p></div>     <div class="box ke_xin_wang_luo"><p style="color: black">可信网络通信协同创新中心</p></div>     <div class="box hong_tong_lou"><p style="color: black">鸿通楼</p></div>     <div class="box xsl"><p style="color: black">小松林</p></div>     <div class="box shi_guang_guang_chang"><p style="color: black">时光广场</p></div>     <div class="box xing_zheng_ban_gong_lou"><p style="color: black">行政办公楼</p></div>     <div class="box cai_wu_chu"><p style="color: black">财务处</p></div>     <div class="box hou_qin_lou"><p style="color: black">后勤楼</p></div>     <div class="box bj"><p style="color: black">北交附属中学</p></div>     <div class="box jsq3"><p style="color: black">家属区</p></div>     <div class="box jsq4"><p style="color: black">家属区</p></div>     <div class="box jsq5"><p style="color: black">家属区</p></div>  <!-- 家属区商铺下面-->     <div class="box sd"><p style="color: black"></p></div>     <button class="box xue_yuan_li_fa" onclick="openModal('modal22')">理发</button>     <div id="modal22" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal22')">&times;&times;&times;</span>     <p>学苑造型理发店 营业时间：早8:00 - 晚10:00</p><p>男士35，女士40</p>     </div></div>      <button class="box nan_men_shuo_guo" onclick="openModal('modal23')">水果</button>     <div id="modal23" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal23')">&times;&times;&times;</span>        <p>北邮南区便民菜站</p>        <p>营业时间：早6:00-晚10:00</p>        <p>卖应季水果和日常水果</p>         <a href="https://www.bupt.life/nan_men_shui_guo">具体详情</a>     </div></div>     <button class="box gan_xi_feng_ren_dian" onclick="openModal('modal21')">干洗店</button>     <div id="modal21" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal21')">&times;&times;&times;</span>          <p>可缝纫 干洗 换拉链 修电瓶车、自行车</p>          <a href="https://www.bupt.life/nan_men_gan_xi_dian">具体详情</a>     </div></div>     <div class="box jsq6"><p style="color: black"></p></div>  <!-- 家属区商铺下下面1-->     <div class="box jsq7"><p style="color: black"></p></div>  <!-- 家属区南门左边2-->     <div class="box hcp"><p style="color: black"></p></div>     <div class="box nan_men"><p style="color: black">南门</p></div>     <div class="box ming_guang_lou"><p style="color: black">明光楼</p></div>     <div class="box jsq8"><p style="color: black"></p></div>   <!-- 左下边家属区-->     <div class="box shang_pu"><p style="color: black">商铺</p></div>     <button class="box sheng_shi_hao" onclick="openModal('modal18')">圣士豪</button>     <div id="modal18" class="modal"><div class="modal-content">          <span class="close" onclick="closeModal('modal18')">&times;&times;&times;</span>          <p>圣士豪理发店 营业时间：早10:00 - 晚9:30</p>            <a href="https://www.bupt.life/sheng_shi_hao">具体详情</a>     </div></div>     <button class="box zhong_you" onclick="openModal('modal24')">快递</button>     <div id="modal24" class="modal">          <div class="modal-content">               <span class="close" onclick="closeModal('modal24')">&times;&times;&times;</span>               <p>中邮快递</p> <p>营业时间:早8:00-晚8:00</p>          </div></div>     <script>          // 1打开弹窗          function openModal(modalId) { var modal = document.getElementById(modalId); modal.style.display = "block"; }          // 2关闭弹窗          function closeModal(modalId) { var modal = document.getElementById(modalId); modal.style.display = "none"; }          // 3点击模态框外部区域也可以关闭弹窗          window.onclick = function (event) {               var modals = document.getElementsByClassName("modal");               for (var i = 0; i < modals.length; i++) { if (event.target === modals[i]) { modals[i].style.display = "none"; } }          }     </script></body></html>]]></content>
    
    
    
    <tags>
      
      <tag>北邮地图</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客图片使用的图片v4545</title>
    <link href="/2023/11/08/1%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%872088/"/>
    <url>/2023/11/08/1%E5%8D%9A%E5%AE%A2%E5%9B%BE%E7%89%872088/</url>
    
    <content type="html"><![CDATA[<p>https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/stalks-7723029_19201.jpghttps://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/spider-web-76724202.jpghttps://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/forest-7670068_1920.jpg12</p><p><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/main.jpg" /><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/spider-web-7672420.jpg" /><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/waterfall-7845023.jpg" /><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/bird-7785106.jpg" /><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/insect-7757601.jpg" /><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/leaves-7845964.jpg" /></p><hr /><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/bupt-map.png"alt="北邮地图" /><figcaption aria-hidden="true">北邮地图</figcaption></figure><p>0</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/0.jpg"alt="0" /><figcaption aria-hidden="true">0</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/1.jpg"alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><p>3</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/3.jpg"alt="3" /><figcaption aria-hidden="true">3</figcaption></figure><p>4</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/4.jpg"alt="4" /><figcaption aria-hidden="true">4</figcaption></figure><p>5</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/5.jpg"alt="5" /><figcaption aria-hidden="true">5</figcaption></figure><p>6</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/6.jpg"alt="6" /><figcaption aria-hidden="true">6</figcaption></figure><p>7</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/7.jpg"alt="7" /><figcaption aria-hidden="true">7</figcaption></figure><p>8</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/8.jpg"alt="8" /><figcaption aria-hidden="true">8</figcaption></figure><p>9</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/9.jpg"alt="9" /><figcaption aria-hidden="true">9</figcaption></figure><p>10</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/10.jpg"alt="10" /><figcaption aria-hidden="true">10</figcaption></figure><p>11</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/11.jpg"alt="11" /><figcaption aria-hidden="true">11</figcaption></figure><p>12</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/12.jpg"alt="12" /><figcaption aria-hidden="true">12</figcaption></figure><p>13</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/13.jpg"alt="13" /><figcaption aria-hidden="true">13</figcaption></figure><p>14</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/14.jpg"alt="14" /><figcaption aria-hidden="true">14</figcaption></figure><p>15</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/15.jpg"alt="15" /><figcaption aria-hidden="true">15</figcaption></figure><p>16</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/16.jpg"alt="16" /><figcaption aria-hidden="true">16</figcaption></figure><p>17</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/17.jpg"alt="17" /><figcaption aria-hidden="true">17</figcaption></figure><p>18</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/18.jpg"alt="18" /><figcaption aria-hidden="true">18</figcaption></figure><p>19</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/19.jpg"alt="19" /><figcaption aria-hidden="true">19</figcaption></figure><p>20</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/20.jpg"alt="20" /><figcaption aria-hidden="true">20</figcaption></figure><p>21</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/21.jpg"alt="21" /><figcaption aria-hidden="true">21</figcaption></figure><p>22</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/22.jpg"alt="22" /><figcaption aria-hidden="true">22</figcaption></figure><p>23</p><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/23.jpg"alt="23" /><figcaption aria-hidden="true">23</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/24.jpg"alt="24" /><figcaption aria-hidden="true">24</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/25.jpg"alt="25" /><figcaption aria-hidden="true">25</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/26.jpg"alt="26" /><figcaption aria-hidden="true">26</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/27.jpg"alt="27" /><figcaption aria-hidden="true">27</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/28.jpg"alt="28" /><figcaption aria-hidden="true">28</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/29.jpg"alt="29" /><figcaption aria-hidden="true">29</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/favicon.png"alt="favicon" /><figcaption aria-hidden="true">favicon</figcaption></figure><hr /><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/01.jpg"alt="01" /><figcaption aria-hidden="true">01</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/02.jpg"alt="02" /><figcaption aria-hidden="true">02</figcaption></figure><figure><imgsrc="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/03.jpg"alt="03" /><figcaption aria-hidden="true">03</figcaption></figure>]]></content>
    
    
    
    <tags>
      
      <tag>博客图片</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/11/08/hello-world/"/>
    <url>/2023/11/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p>···matlab</p><h2 id="跳转页面成功"><a href="#跳转页面成功" class="headerlink" title="跳转页面成功"></a>跳转页面成功</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;meta charset=<span class="string">&quot;UTF-8&quot;</span>&gt;</span><br><span class="line">&lt;title&gt;需要验证码验证的页面&lt;/title&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">&quot;text/javascript&quot;</span> src=<span class="string">&quot;./gVerify.js&quot;</span>&gt;&lt;/script&gt;&lt;!-- 引入验证码js文件 --&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;欢迎访问本网页&lt;/h1&gt;</span><br><span class="line">&lt;p&gt;请输入下方验证码，验证成功后才能进入其他页面：&lt;/p&gt;</span><br><span class="line">&lt;form action=<span class="string">&quot;测试.html&quot;</span> method=<span class="string">&quot;get&quot;</span> onsubmit=<span class="string">&quot;return validate()&quot;</span>&gt;</span><br><span class="line">&lt;input <span class="built_in">type</span>=<span class="string">&quot;text&quot;</span> id=<span class="string">&quot;code_input&quot;</span> placeholder=<span class="string">&quot;请输入验证码&quot;</span>&gt;</span><br><span class="line">&lt;canvas id=<span class="string">&quot;verifyCanvas&quot;</span>&gt;&lt;/canvas&gt;</span><br><span class="line">&lt;button <span class="built_in">type</span>=<span class="string">&quot;submit&quot;</span>&gt;进入其他页面&lt;/button&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;script <span class="built_in">type</span>=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><br><span class="line">var verifyCode = new GVerify(<span class="string">&quot;verifyCanvas&quot;</span>); // 初始化验证码</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">validate</span><span class="params">()</span>&#123;</span></span><br><span class="line">var res = verifyCode.validate(document.getElementById(<span class="string">&quot;code_input&quot;</span>).value); // 验证码验证结果</span><br><span class="line"><span class="keyword">if</span>(res)&#123; // 如果验证成功，跳转到其他页面</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">true</span>;</span><br><span class="line">&#125;</span><br><span class="line">alert(<span class="string">&quot;验证码错误，请重新输入&quot;</span>);</span><br><span class="line"><span class="keyword">return</span> <span class="built_in">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Typora 相关设置</title>
    <link href="/2023/03/14/Typora%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/"/>
    <url>/2023/03/14/Typora%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/yyywxk/article/details/125133205">Typora更新问题</a></p><h1 id="2022-7-16-更新"><a href="#2022-7-16-更新" class="headerlink" title="2022.7.16 更新"></a>2022.7.16 更新</h1><p>今天又不行了，只能安装一个老版本试试<a href="https://blog.csdn.net/yyywxk/article/details/125133205#fn4">4</a>：<a href="https://pan.baidu.com/s/1DE1onEjoGYyGDUnXHI8BvQ?pwd=c1se">下载地址【提取密码：c1se】</a></p><p>2022.7.24 更新<br>经网友评论提醒，又提供了一个新方案。</p><p>方案四：修改 Typora 相应注册表的权限56 (详细步骤见参考博文，作为旧版本失效后的一种补充)：<br>打开注册表：按Windows+R打开运行窗口，输入 regedit。<br>进入路径计算机\HKEY_CURRENT_USER\SOFTWARE\Typora。<br>在右键菜单选择权限，把各个用户的权限全部设置为 拒绝。<br>————————————————<br>版权声明：本文为CSDN博主「yyywxk」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a href="https://blog.csdn.net/yyywxk/article/details/125133205">https://blog.csdn.net/yyywxk/article/details/125133205</a></p><p><code>操作</code></p><p><code>获取SESSDATA: 登录哔哩哔哩→F12打开控制台→Application→Cookies→SESSDATA</code></p><p><code>获取csrf: 登录哔哩哔哩→F12打开控制台→Application→Cookies→bili_jct</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">D:\Downloads\typora-plugin-bilibili-win.exe token=你的SESSDATA csrf=你的bili_jct</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">‪C:\Windows\main.exe token=9796b94a%2C1694331119%2Cc7a4d%2A32 csrf=f780fb4a980d7203f0e61bba0cf34fd1</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">‪C:\Windows\main.exe token=d63e6f5b%2C1694331008%2C28318%2A32 csrf=e54ac5c6cd02e9f968054d3a8402160f</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">‪C:\Windows\main.exe token=86c56aea%2C1694329649%2Ce15ee%2A32 csrf=c4728b0aa2fe78fed8b3a55e5de82795</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">‪C:\Windows\main.exe token=86c56aea%2C1694329649%2Ce15ee%2A32 csrf=c4728b0aa2fe78fed8b3a55e5de82795</span><br></pre></td></tr></table></figure><p>‪C:\Program Files\Typora\main.exe</p><h2 id="typora-plugin-bilibili"><a href="#typora-plugin-bilibili" class="headerlink" title="typora-plugin-bilibili"></a>typora-plugin-bilibili</h2><p>哔哩哔哩图片上传, Typora插件，实现图片粘贴即可上传到哔哩哔哩，并替换链接</p><h3 id="重要提示"><a href="#重要提示" class="headerlink" title="重要提示"></a>重要提示</h3><p><strong>由于B站相簿的上传API自身出现问题，现在切换到动态的图片API，因此需要多加一个参数csrf(为Cookie里面的bili_jct)</strong></p><p>示例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">插件客户端路径 token=0829d25Cdd19b*b1 csrf=cb397c0fbf619237</span><br></pre></td></tr></table></figure><h3 id="用Go重写，产物缩小5倍体积，点击下载即可"><a href="#用Go重写，产物缩小5倍体积，点击下载即可" class="headerlink" title="用Go重写，产物缩小5倍体积，点击下载即可"></a>用Go重写，产物缩小5倍体积，点击下载即可</h3><h1 id="B站图床、短链-Firefox、Chrome、Edge"><a href="#B站图床、短链-Firefox、Chrome、Edge" class="headerlink" title="B站图床、短链(Firefox、Chrome、Edge)"></a>B站图床、短链(Firefox、Chrome、Edge)</h1><p>哔哩哔哩图床插件，速度快,多种图片压缩格式选择，自动读取Bilibili的Cookie，不再需要手动输入。 基于<a href="https://github.com/xlzy520/vitesse-webext">vitesse-webext</a> 重构</p><h3 id="在线安装"><a href="#在线安装" class="headerlink" title="在线安装"></a>在线安装</h3><p><a href="https://chrome.google.com/webstore/detail/b%E7%AB%99%E5%9B%BE%E5%BA%8A/domljbndjbjgpkhdbmfgmiclggdfojnd?hl=zh-CN">Chrome、Edge</a></p><p><a href="https://addons.mozilla.org/addon/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%9B%BE%E5%BA%8A/">Firefox</a></p><h3 id="本地安装"><a href="#本地安装" class="headerlink" title="本地安装"></a>本地安装</h3><p><a href="https://jiali0126.oss-cn-shenzhen.aliyuncs.com/share/extension.zip">下载</a></p><h3 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h3><ol><li>进入<code>拓展程序</code>,可以通过地址栏输入<code>chrome://extensions/</code>，也可以从 <code>更多工具</code>-&gt;<code>拓展程序</code>进入</li><li>右上角开启<code>开发者模式</code></li><li>左侧点击 <code>加载已解压的拓展程序</code>,然后选择上面下载好的压缩包解压后的文件夹即可。</li></ol><h3 id="本地开发-支持热更新"><a href="#本地开发-支持热更新" class="headerlink" title="本地开发(支持热更新)"></a>本地开发(支持热更新)</h3><ol><li>执行<code>npm i</code>或者<code>pnpm i</code>, 执行<code>npm run dev</code>或<code>pnpm run dev</code></li><li>上一步(安装步骤)将文件夹选择为<code>extension</code>文件夹</li></ol><h3 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h3><p>执行<code>npm run build</code>或<code>pnpm run build</code></p><h3 id="截屏"><a href="#截屏" class="headerlink" title="截屏"></a>截屏</h3>]]></content>
    
    
    
    <tags>
      
      <tag>Tpyora</tag>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FDTD 相关</title>
    <link href="/2023/03/14/FDTD/FDTD%20%E7%9B%B8%E5%85%B3/"/>
    <url>/2023/03/14/FDTD/FDTD%20%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<h2 id="常用代码"><a href="#常用代码" class="headerlink" title="常用代码"></a>常用代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#mesh1</span></span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;x span&#x27;</span>,y2);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;y span&#x27;</span>,y2);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;z max&#x27;</span>,<span class="number">0</span>-h_1);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;z min&#x27;</span>,-h1-h2-h3-h_1);</span><br><span class="line"></span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;dx&#x27;</span>,mesh_a);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;dy&#x27;</span>,mesh_a);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh1&#x27;</span>,<span class="string">&#x27;dz&#x27;</span>,mesh_z);</span><br><span class="line"></span><br><span class="line"><span class="comment">#mesh2</span></span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;x&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;x span&#x27;</span>,w);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;y&#x27;</span>,<span class="number">0</span>);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;y span&#x27;</span>,w);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;z min&#x27;</span>,-t_sub+h_2);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;z max&#x27;</span>,-t_sub+h6+h5+h4+h_2);</span><br><span class="line"></span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;dx&#x27;</span>,mesh_a);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;dy&#x27;</span>,mesh_a);</span><br><span class="line">setnamed(<span class="string">&#x27;mesh2&#x27;</span>,<span class="string">&#x27;dz&#x27;</span>,mesh_z);</span><br></pre></td></tr></table></figure><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">deleteall;</span><br><span class="line">addrect;</span><br><span class="line">set(<span class="string">&quot;x&quot;</span>,<span class="number">0</span>);</span><br><span class="line">set(<span class="string">&quot;x span&quot;</span>,(h1) * <span class="number">2</span>* scale);</span><br><span class="line">set(<span class="string">&quot;y max&quot;</span>,<span class="number">0</span>); # y</span><br><span class="line">set(<span class="string">&quot;y min&quot;</span>, -thick); </span><br><span class="line">set(<span class="string">&quot;material&quot;</span>, material); set(<span class="string">&quot;index&quot;</span>, nk);</span><br><span class="line"></span><br><span class="line">w = [<span class="number">50</span>,    <span class="number">14</span>,    <span class="number">12</span>,    <span class="number">68</span>,    <span class="number">38</span>,    <span class="number">74</span>,    <span class="number">20</span>,    <span class="number">52</span>,    <span class="number">32</span>,    <span class="number">38</span>,     <span class="number">2</span>]*<span class="number">1e-9</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> ( <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">1</span>:<span class="number">4</span> )</span><br><span class="line">&#123;</span><br><span class="line">    addrect;    </span><br><span class="line">    set(<span class="string">&quot;x&quot;</span>,(sum(w(<span class="number">1</span>:<span class="number">2</span>*<span class="built_in">i</span>))+w(<span class="number">2</span>*<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>)*scale);</span><br><span class="line">    set(<span class="string">&quot;x span&quot;</span>,w(<span class="number">2</span>*<span class="built_in">i</span>+<span class="number">1</span>)*scale);</span><br><span class="line">    set(<span class="string">&quot;y max&quot;</span>,<span class="number">0</span>); set(<span class="string">&quot;y min&quot;</span>, -thick); </span><br><span class="line">    set(<span class="string">&quot;material&quot;</span>, material); set(<span class="string">&quot;index&quot;</span>, nk);</span><br><span class="line">    #set(<span class="string">&quot;x&quot;</span>,(h1+h2+h3/<span class="number">2</span>)*scale);     </span><br><span class="line">    addrect;</span><br><span class="line">    set(<span class="string">&quot;x&quot;</span>,-(sum(w(<span class="number">1</span>:<span class="number">2</span>*<span class="built_in">i</span>))+w(<span class="number">2</span>*<span class="built_in">i</span>+<span class="number">1</span>)/<span class="number">2</span>)*scale);</span><br><span class="line">    set(<span class="string">&quot;x span&quot;</span>,w(<span class="number">2</span>*<span class="built_in">i</span>+<span class="number">1</span>)*scale);</span><br><span class="line">    set(<span class="string">&quot;y max&quot;</span>,<span class="number">0</span>); set(<span class="string">&quot;y min&quot;</span>, -thick); </span><br><span class="line">    set(<span class="string">&quot;material&quot;</span>, material); set(<span class="string">&quot;index&quot;</span>, nk);  </span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230506110907422.png" alt="image-20230506110907422"></p><h2 id="绘制图形"><a href="#绘制图形" class="headerlink" title="绘制图形"></a>绘制图形</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_func(<span class="number">3</span>,[<span class="number">1</span> <span class="number">2</span> <span class="number">2</span> <span class="number">0</span>],  <span class="number">1</span>:length(field(<span class="number">1</span>,:)),<span class="number">1</span>:length(field(:,<span class="number">1</span>)), field, <span class="number">15</span>,<span class="number">1.5</span>,  <span class="number">100</span>,<span class="number">100</span>,<span class="number">1000</span>,<span class="number">400</span>,<span class="string">&#x27;X&#x27;</span>,<span class="string">&#x27;Z&#x27;</span>,<span class="string">&#x27;|Ez|^2 &amp; FOM&#x27;</span>);</span><br><span class="line"><span class="built_in">set</span>(gca, <span class="string">&#x27;YDir&#x27;</span>, <span class="string">&#x27;reverse&#x27;</span>); </span><br><span class="line">title(sprintf(<span class="string">&#x27;|Ez|^2 &amp; FOM = %4f&#x27;</span>, -FOM ));</span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>FDTD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch实践学习</title>
    <link href="/2023/03/14/2%20Pytorch%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/03/14/2%20Pytorch%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="P-1-Overview"><a href="#P-1-Overview" class="headerlink" title="P 1 Overview"></a>P 1 Overview</h2><ol><li><p>Knowledge bases涉及泵及涂布装置.提供一种耐久性优异,可排出高粘度液体的泵及涂装置.泵包括:壳体;挠性部件,与壳体同轴地配置在壳体内,收容液体;工作缸部,收容工作流体;柱塞,可相对于工作缸部往返移动地插入于工作缸部,向壳体与挠性部件的间隙供给工作流体而使液体从挠性部件排出;第一密封部件及第二密封部件,配置在$$a$$$工作缸部中的柱塞的插入部,与柱塞滑动接触.第一密封部件是配置在比第二密封部件更靠柱塞的顶端侧,且具有耐压功能的密封部件,第二密封部件是具有防漏功能的密封部件.</p></li><li><p>3</p></li><li><p>3423</p></li></ol><p>涉及泵及涂布装置.提供一种耐久性优异,可排出高粘度液体的泵及涂布装置.泵包括:壳体;挠性部件,与壳体同轴地配置在壳体内,收容液体;工作缸部,收容工作流体;柱塞,可相对于工作缸部往返移动地插入于工作缸部,向壳体与挠性部件的间隙供给工作流体而使液体从挠性部件排出;第一密封部件及第二密封部件,配置在工作缸部中的柱塞的插入部,与柱塞滑动接触.第一密封部件是配置在比第二密封部件更靠柱塞的顶端侧,且具有耐压功能的密封部件,第二密封部件是具有防漏功能的密封部件. </p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306161838698.png" alt="image-20230306161838698"></p><p>链式法则</p><p>Deep learning is not too difficult</p><p>basic algebra probability python</p><p>There are lots of deep learning framework</p><ul><li>starting from scratch do not be required</li><li>enabled efficient and convient use of GPU</li><li>lots of components of neural networks provided by framewokd</li></ul><p>Popular deep learning frameworks</p><ul><li>theano</li><li>Caffe</li><li>Torch &#x2F; Pytorch.</li></ul><p>Dynamical graph</p><p>More flexible </p><p>easy to debug</p><p>intuitive and cleaner code</p><p>More neural netoworkic</p><h2 id="2-线性模型"><a href="#2-线性模型" class="headerlink" title="2 线性模型"></a>2 线性模型</h2><ol><li>DataSet</li><li>Mode</li><li>Training</li></ol><p>training数据：平时练习题；</p><p>validating数据：诊断；</p><p>test数据：考试题</p><p>overfit 过拟合泛化</p><p>What would be the best model for the data?</p><p>Linear model?</p><p>Training Loss (Error)</p><p>损失函数</p><p>mean sqrt error</p><p>###Mean Square Error（均方误差）</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306164815661.png" alt="image-20230306164815661"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306164833614.png" alt="image-20230306164833614"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306170357312.png" alt="image-20230306170357312"></p><h2 id="03-梯度下降算法"><a href="#03-梯度下降算法" class="headerlink" title="03 梯度下降算法"></a>03 梯度下降算法</h2><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306171118394.png" alt="image-20230306171118394"></p><p>$$<br>cost(\omega)&#x3D;\dfrac{1}{N}\sum_{n&#x3D;1}^N(\hat y_n-y_n)^2<br>$$</p><ul><li>注意：只能实现算法的局部最优</li></ul><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230307165249276.png" alt="image-20230307165249276"></p><p>鞍点：梯度为0的点$a$</p><p>Do the update<br>$$<br>\omega&#x3D;\omega-\alpha\dfrac{\partial{cost}}{\partial\omega}<br>$$<br>公式更新$$a+b$$公式</p><p>Update weight by every grad of sample of train_set.$w&#x3D;w-a{w}&#x2F;{3}$接口</p><h2 id="04-反向传播"><a href="#04-反向传播" class="headerlink" title="04 反向传播"></a>04 反向传播</h2><p>Linear Model $\hat{y}&#x3D;x*\omega$</p><p>Stochastic Gradient Descent $\omega&#x3D;\omega-\alpha\dfrac{\partial loss}{\partial\omega}$</p><img src="../../../AppData/Roaming/Typora/typora-user-images/image-20230307173428700.png" alt="image-20230307173428700" style="zoom:50%;" /><p>In PyTorch, Tensor is the important component in constructing dynamic computational graph.</p><p>It contains data and grad, which storage the value of node and gradient w.r.t loss respectively.</p><p>1<div class="class1 class2"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.box &#123;</span><br><span class="line">  word-wrap: break-word; /* 允许单词内换行 */</span><br><span class="line">  overflow-wrap: break-word; /* 允许单词内换行 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>qnjugs</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">letter-spacing: 0px; /* 文字间水平距离 */</span><br><span class="line">line-height: 25px; /* 文字间垂直距离 */</span><br></pre></td></tr></table></figure><p>t1&#x3D;clock;</p><p>t2&#x3D;clock;tc(t2,t1);</p><h2 id="P6-逻辑斯蒂回归-Logistic-Regression–分类问题"><a href="#P6-逻辑斯蒂回归-Logistic-Regression–分类问题" class="headerlink" title="P6 逻辑斯蒂回归 Logistic Regression–分类问题"></a>P6 逻辑斯蒂回归 Logistic Regression–分类问题</h2><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310104957472.png" alt="image-20230310104957472"></p><p><strong>In classification, the output of model is the probability of input belongs to the exact clss.</strong></p><p>Logistic function: $\sigma(x)&#x3D;\dfrac{1}{1+e^{-x}}$</p><p>在[-00, +00]区间的函数关系</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310105326421.png" alt="image-20230310105326421"></p><p>Logistic function</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ix = <span class="number">1</span>;</span><br><span class="line">wave = <span class="number">-10</span>:<span class="number">0.1</span>:<span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> x = wave(ix)</span><br><span class="line">    y(ix) = <span class="number">1</span> / (<span class="number">1</span> + <span class="built_in">exp</span>(<span class="number">1</span>)^(-x) );</span><br><span class="line">    ix = ix + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>(wave,y,<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">.5</span>);<span class="built_in">hold</span> on;</span><br><span class="line">colorbar;axis equal;<span class="built_in">hold</span> on;colormap jet;</span><br><span class="line">set(gca,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">30</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.5</span>);</span><br></pre></td></tr></table></figure><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310110316830.png" alt="image-20230310110316830" style="zoom: 50%;" /><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310111136283.png" alt="image-20230310111136283"><br>$$<br>loss&#x3D;-(y\log\hat y+(1-y)\log(1-\hat y))<br>$$<br><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310111303257.png" alt="image-20230310111303257"><br>$$<br>loss&#x3D;-\dfrac{1}{N}\sum_{n&#x3D;1}^N y_n\log\hat y_n+(1-y_n)\log(1-\hat y_n)<br>$$</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = torch.nn.BCELoss(size_average=False)</span><br></pre></td></tr></table></figure><ol><li><strong>Prepare Dataset</strong> - we shall talk about this later</li><li><strong>Design model using Class</strong> - inherit from nn.Module</li><li><strong>Construct loss and optimizer</strong> - using PyTorch API </li><li><strong>Training Cycle</strong> - Forward, backward, update</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"># Prepare dataset</span><br><span class="line">x_data = torch.Tensor([[1.0], [2.0], [3.0]])</span><br><span class="line">y_data = torch.Tensor([[0], [0], [1]])</span><br><span class="line"># Design model using Class</span><br><span class="line">class LogisticRegressionModel(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(LogisticRegressionModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(1, 1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        y_pred = F.sigmoid(self.linear(x))</span><br><span class="line">        return y_pred</span><br><span class="line">model = LogisticRegressionModel()</span><br><span class="line"></span><br><span class="line"># Construct loss and optimizer using PyTorch API</span><br><span class="line">criterion = torch.nn.BCELoss(size_average=False)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span><br><span class="line"># Training cycle</span><br><span class="line">for epoch in range(1000):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    print(&#x27;epoch=&#123;&#125;, loss=&#123;&#125;&#x27;.format(epoch, loss.data))</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">x = np.linspace(0, 10, 200)</span><br><span class="line">x_t = torch.Tensor(x).view((200, 1))</span><br><span class="line">y_t = model(x_t)</span><br><span class="line">y = y_t.data.numpy()</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.plot([0, 10], [0.5, 0.5], c=&#x27;r&#x27;)</span><br><span class="line">plt.xlabel(&#x27;Hours&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Probability of Pass&#x27;)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310112103083.png" alt="image-20230310112103083"></p><h2 id="P-7-处理多维特征的输入"><a href="#P-7-处理多维特征的输入" class="headerlink" title="P 7  处理多维特征的输入"></a>P 7  处理多维特征的输入</h2><p>Logistic regression model$\hat{y}^{(i)}&#x3D;\sigma(x^{(i)}*\omega+b)$</p><p>Logistic regression model$\hat{y}^{(i)}&#x3D;\sigma(\sum\limits_{n&#x3D;1}^{8}x_n^{(i)}\cdot\omega_n+b)$<br>$$<br>\sum\limits_{n&#x3D;1}^8x_n^{(i)}\cdot\omega_n&#x3D;\begin{bmatrix}x_1^{(i)}&amp;…&amp;x_8^{(i)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}<br>$$<br>Logistic regression Model</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310112846700.png" alt="image-20230310112846700"></p><p>Sigmoid function is in an element-wise fashion.<br>$$<br>\begin{bmatrix}\hat{y}^{(1)}\ \vdots\ \hat{y}^{(N)}\end{bmatrix}&#x3D;\begin{bmatrix}\sigma\bigl(z^{(1)}\bigr)\ \vdots\ \sigma\bigl(z^{(N)}\bigr)\end{bmatrix}&#x3D;\sigma\bigl(\begin{bmatrix}z^{(1)}\ \vdots\ Z^{(N)}\end{bmatrix}\bigr)<br>$$</p><p>$$<br>z^{(1)}&#x3D;\begin{bmatrix}x_1^{(1)}&amp;\cdots&amp;x_8^{(1)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+b<br>$$</p><p>$$<br>z^{(N)}&#x3D;\begin{bmatrix}&amp;\vdots\ x_1^{(N)}&amp;\cdots&amp;x_8^{(N)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+b<br>$$</p><p>$$<br>\begin{bmatrix}Z^{(1)}\ \vdots\ Z^{(N)}\end{bmatrix}&#x3D;\begin{bmatrix}x_1^{(1)}&amp;…&amp;x_8^{(1)}\ \vdots&amp;\ddots&amp;\vdots\ x_1^{(N)}&amp;…&amp;x_8^{(N)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+\begin{bmatrix}b\ \vdots\ b\end{bmatrix}<br>$$</p><p>矩阵化 向量化 便于运行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.linear = torch.nn.Linear(8,1)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310113341902.png" alt="image-20230310113341902"></p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114142966.png" alt="image-20230310114142966" style="zoom: 80%;" /><ol><li>扣书本</li><li>读文档，基本的架构（泛化能力）</li></ol><p>Example: artificial neural network</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114513426.png" alt="image-20230310114513426"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114608659.png" alt="image-20230310114608659"></p><p>Diabetes Prediction</p><ol><li>Prepare dataset</li><li>Design model using Class</li><li>Construct loss and optimizer</li><li>Training cycle</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># Forward</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line">    <span class="comment"># Backward</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># Update</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># Forward前馈</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line">    <span class="comment"># Backward反馈</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># Update更新</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以使用各种各样的激活函数</p><h2 id="P-8-加载数据集"><a href="#P-8-加载数据集" class="headerlink" title="P 8 加载数据集"></a>P 8 加载数据集</h2><p><strong>Dataset and DataLoader</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training clcle</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">    <span class="comment"># Loop over all batches</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(totaol_batch):</span><br></pre></td></tr></table></figure><ul><li>Definition: Epoch</li></ul><p>One forward pass and one backward pass of all the training examples.</p><ul><li>Definition: Batch_Size</li></ul><p>The number of training examples in one forward backward pass.</p><ul><li>Definition: Iteration</li></ul><p>Number of passes, each pass using [<strong>batch size</strong>] number of examples.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># The expression, dataset[index], will call this magic function.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># This magic function returns length of dataset.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># Construct DiabetesDataset object.</span></span><br><span class="line">dataset = DiabetesDataset()</span><br><span class="line"><span class="comment"># Initialize loader with batch-size,shuffle, num_workers=2:读取两个进程process number.</span></span><br><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>Dataset is an abstract class. We can define our class inherited from this class.</p><p>几乎每个魔法方法是python的内置方法。方法都有对应的内置函数，或者运算符，对这个对象使用这些函数或者运算符时就会调用类中的对应魔法方法，可以理解为重写这些python的内置函</p><p>The implementation of multiprocessing is different on Windows, which uses <strong>spawn</strong> instead of <strong>fork</strong>.<br>So left code will cause: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br><span class="line">……</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        ……</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br><span class="line">……</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br></pre></td></tr></table></figure><p>So we have to wrap the code with an if-clause to protect the code from executing multiple times.  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):</span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">            <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line">        </span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare dataset</span></span><br><span class="line"><span class="comment"># Dataset and Dataloader</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):  <span class="comment"># Diabetes is inherited from abstract class Dataset. N行（8特征列，1目标列）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):  <span class="comment"># filepath路径</span></span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)  <span class="comment"># 读取32浮点数</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]  <span class="comment"># xy.shape = [N, 0]  xy.shape[0] = N</span></span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  <span class="comment"># The expression, dataset[index], will call this magic function.</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  <span class="comment"># This magic function returns length of dataset.</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)  <span class="comment"># shuffle 打乱</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Design model using Class</span></span><br><span class="line"><span class="comment"># inherit from nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># Construct loss and optimizer</span></span><br><span class="line"><span class="comment"># using PyTorch API</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training cycle</span></span><br><span class="line"><span class="comment"># forward, backward, update</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="comment"># for i, data in enumerate(train_loader, 0): # train_loader (x, y) 赋值在data里 8:25</span></span><br><span class="line">        <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):  <span class="comment"># train_loader (x, y) 赋值在data里 8:25</span></span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br><span class="line">            <span class="comment"># inputs, labels = data</span></span><br><span class="line">            <span class="comment"># 2. Forward</span></span><br><span class="line">            y_pred = model(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;epoch= &#123;&#125;, i= &#123;&#125;, loss= &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, i, loss.item()))</span><br><span class="line">            <span class="comment"># 3. Backward</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 4. Update</span></span><br><span class="line">            optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               transform= transforms.ToTensor(),</span><br><span class="line">                               download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              transform= transforms.ToTensor(),</span><br><span class="line">                              download=<span class="literal">True</span>)</span><br><span class="line">train_loader = DataLoader(dataset=train_dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(dataset=test_dataset,</span><br><span class="line">                         batch_size=<span class="number">32</span>,</span><br><span class="line">                         shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> batch_idx, (inputs, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure><p>Build DataLoader for</p><p>Build a classifier using the DataLoader.</p><h2 id="P-9-多分类问题"><a href="#P-9-多分类问题" class="headerlink" title="P 9  多分类问题"></a>P 9  多分类问题</h2><p>How to design the neural network?  </p><p>There are 10 labels in minist dataset.</p><ol><li>Linear layer</li><li>Sigmoid layer</li><li>Input layer</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">z = np.array([<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>])</span><br><span class="line">y_pred = np.exp(z) / np.exp(z).<span class="built_in">sum</span>()</span><br><span class="line">loss = (- y * np.log(y_pred)).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>])</span><br><span class="line">z = torch.Tensor([[<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>]])</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">loss = criterion(z, y)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">Y = torch.LongTensor([<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">Y_pred1 = torch.Tensor([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.9</span>],</span><br><span class="line">                        [<span class="number">1.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">2.1</span>, <span class="number">0.1</span>]])</span><br><span class="line">Y_pred2 = torch.Tensor([[<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.3</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]])</span><br><span class="line">l1 = criterion(Y_pred1, Y)</span><br><span class="line">l2 = criterion(Y_pred2, Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Batch Loss1 = &quot;</span>, l1.data, <span class="string">&quot;\nBatch Loss2=&quot;</span>, l2.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">self.l1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p><code>48:00</code>部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 一轮训练，一轮测试</span></span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><p><code>or</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 一轮训练，一轮测试</span></span><br><span class="line">        train(epoch)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">10</span> = <span class="number">9</span> <span class="comment"># 每10轮测试一次</span></span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><h2 id="P-10-卷积神经网络-基础篇"><a href="#P-10-卷积神经网络-基础篇" class="headerlink" title="P 10 卷积神经网络(基础篇)"></a>P 10 卷积神经网络(基础篇)</h2><p><code>a</code></p><ol><li>Convolution</li><li>Subsampling</li><li>Convolution</li><li>Subsampling</li><li>Fully Connected</li><li>Fully</li><li>Connected</li></ol><p><code>图像可以表示为像素</code>–RGB栅格图像 <code>P10-12:00</code></p><p><code>==a==</code></p><p><img src="I:\web\Gridea\md_picture\image-20230314114425455.png" alt="image-20230314114425455"></p><p><code>标红</code></p><p>&#x3D;&#x3D;其他色&#x3D;&#x3D;</p><p><font color='orange'>橙色</font></p><p><font color='red'>红色</font></p><p><font color='cornflowerblue'>浅蓝色</font></p><p><font color='cornflowerblue'>a</font></p><ol><li>Input</li><li>Kernel</li><li>Output</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch实践学习</title>
    <link href="/2023/03/14/Pytorch%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/03/14/Pytorch%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>I:\PyTorch深度学习实践 《PyTorch深度学习实践》完结合集</p><h2 id="P-1-Overview"><a href="#P-1-Overview" class="headerlink" title="P 1 Overview"></a>P 1 Overview</h2><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306161838698.png" alt="image-20230306161838698"></p><p>链式法则</p><p>Deep learning is not too difficult</p><p>basic algebra probability python</p><p>There are lots of deep learning framework</p><ul><li>starting from scratch do not be required</li><li>enabled efficient and convient use of GPU</li><li>lots of components of neural networks provided by framewokd</li></ul><p>Popular deep learning frameworks</p><ul><li>theano</li><li>Caffe</li><li>Torch &#x2F; Pytorch.</li></ul><p>Dynamical graph</p><p>More flexible </p><p>easy to debug</p><p>intuitive and cleaner code</p><p>More neural netoworkic</p><h2 id="2-线性模型"><a href="#2-线性模型" class="headerlink" title="2 线性模型"></a>2 线性模型</h2><ol><li>DataSet</li><li>Mode</li><li>Training</li></ol><p>training数据：平时练习题；</p><p>validating数据：诊断；</p><p>test数据：考试题</p><p>overfit 过拟合泛化</p><p>What would be the best model for the data?</p><p>Linear model?</p><p>Training Loss (Error)</p><p>损失函数</p><p>mean sqrt error</p><p>###Mean Square Error（均方误差）</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306164815661.png" alt="image-20230306164815661"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306164833614.png" alt="image-20230306164833614"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306170357312.png" alt="image-20230306170357312"></p><h2 id="03-梯度下降算法"><a href="#03-梯度下降算法" class="headerlink" title="03 梯度下降算法"></a>03 梯度下降算法</h2><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230306171118394.png" alt="image-20230306171118394"></p><p>$$<br>cost(\omega)&#x3D;\dfrac{1}{N}\sum_{n&#x3D;1}^N(\hat y_n-y_n)^2<br>$$</p><ul><li>注意：只能实现算法的局部最优</li></ul><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230307165249276.png" alt="image-20230307165249276"></p><p>鞍点：梯度为0的点$a$</p><p>Do the update<br>$$<br>\omega&#x3D;\omega-\alpha\dfrac{\partial{cost}}{\partial\omega}<br>$$<br>公式更新$$a+b$$公式</p><p>Update weight by every grad of sample of train_set.$w&#x3D;w-a{w}&#x2F;{3}$接口</p><h2 id="04-反向传播"><a href="#04-反向传播" class="headerlink" title="04 反向传播"></a>04 反向传播</h2><p>Linear Model $\hat{y}&#x3D;x*\omega$</p><p>Stochastic Gradient Descent $\omega&#x3D;\omega-\alpha\dfrac{\partial loss}{\partial\omega}$</p><img src="../../../AppData/Roaming/Typora/typora-user-images/image-20230307173428700.png" alt="image-20230307173428700" style="zoom:50%;" /><p>In PyTorch, Tensor is the important component in constructing dynamic computational graph.</p><p>It contains data and grad, which storage the value of node and gradient w.r.t loss respectively.</p><p>1<div class="class1 class2"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.box &#123;</span><br><span class="line">  word-wrap: break-word; /* 允许单词内换行 */</span><br><span class="line">  overflow-wrap: break-word; /* 允许单词内换行 */</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>qnjugs</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">letter-spacing: 0px; /* 文字间水平距离 */</span><br><span class="line">line-height: 25px; /* 文字间垂直距离 */</span><br></pre></td></tr></table></figure><p>t1&#x3D;clock;</p><p>t2&#x3D;clock;tc(t2,t1);</p><h2 id="P6-逻辑斯蒂回归-Logistic-Regression–分类问题"><a href="#P6-逻辑斯蒂回归-Logistic-Regression–分类问题" class="headerlink" title="P6 逻辑斯蒂回归 Logistic Regression–分类问题"></a>P6 逻辑斯蒂回归 Logistic Regression–分类问题</h2><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310104957472.png" alt="image-20230310104957472"></p><p><strong>In classification, the output of model is the probability of input belongs to the exact clss.</strong></p><p>Logistic function: $\sigma(x)&#x3D;\dfrac{1}{1+e^{-x}}$</p><p>在[-00, +00]区间的函数关系</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310105326421.png" alt="image-20230310105326421"></p><p>Logistic function</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ix = <span class="number">1</span>;</span><br><span class="line">wave = <span class="number">-10</span>:<span class="number">0.1</span>:<span class="number">10</span></span><br><span class="line"><span class="keyword">for</span> x = wave(ix)</span><br><span class="line">    y(ix) = <span class="number">1</span> / (<span class="number">1</span> + <span class="built_in">exp</span>(<span class="number">1</span>)^(-x) );</span><br><span class="line">    ix = ix + <span class="number">1</span>;</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">plot</span>(wave,y,<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">.5</span>);<span class="built_in">hold</span> on;</span><br><span class="line">colorbar;axis equal;<span class="built_in">hold</span> on;colormap jet;</span><br><span class="line">set(gca,<span class="string">&#x27;FontSize&#x27;</span>,<span class="number">30</span>,<span class="string">&#x27;FontName&#x27;</span>,<span class="string">&#x27;Times New Roman&#x27;</span>, <span class="string">&#x27;LineWidth&#x27;</span>,<span class="number">1.5</span>);</span><br></pre></td></tr></table></figure><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310110316830.png" alt="image-20230310110316830" style="zoom: 50%;" /><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310111136283.png" alt="image-20230310111136283"><br>$$<br>loss&#x3D;-(y\log\hat y+(1-y)\log(1-\hat y))<br>$$<br><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310111303257.png" alt="image-20230310111303257"><br>$$<br>loss&#x3D;-\dfrac{1}{N}\sum_{n&#x3D;1}^N y_n\log\hat y_n+(1-y_n)\log(1-\hat y_n)<br>$$</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">criterion = torch.nn.BCELoss(size_average=False)</span><br></pre></td></tr></table></figure><ol><li><strong>Prepare Dataset</strong> - we shall talk about this later</li><li><strong>Design model using Class</strong> - inherit from nn.Module</li><li><strong>Construct loss and optimizer</strong> - using PyTorch API </li><li><strong>Training Cycle</strong> - Forward, backward, update</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import numpy as np</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"># Prepare dataset</span><br><span class="line">x_data = torch.Tensor([[1.0], [2.0], [3.0]])</span><br><span class="line">y_data = torch.Tensor([[0], [0], [1]])</span><br><span class="line"># Design model using Class</span><br><span class="line">class LogisticRegressionModel(torch.nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(LogisticRegressionModel, self).__init__()</span><br><span class="line">        self.linear = torch.nn.Linear(1, 1)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        y_pred = F.sigmoid(self.linear(x))</span><br><span class="line">        return y_pred</span><br><span class="line">model = LogisticRegressionModel()</span><br><span class="line"></span><br><span class="line"># Construct loss and optimizer using PyTorch API</span><br><span class="line">criterion = torch.nn.BCELoss(size_average=False)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=0.01)</span><br><span class="line"># Training cycle</span><br><span class="line">for epoch in range(1000):</span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    print(&#x27;epoch=&#123;&#125;, loss=&#123;&#125;&#x27;.format(epoch, loss.data))</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">x = np.linspace(0, 10, 200)</span><br><span class="line">x_t = torch.Tensor(x).view((200, 1))</span><br><span class="line">y_t = model(x_t)</span><br><span class="line">y = y_t.data.numpy()</span><br><span class="line">plt.plot(x, y)</span><br><span class="line">plt.plot([0, 10], [0.5, 0.5], c=&#x27;r&#x27;)</span><br><span class="line">plt.xlabel(&#x27;Hours&#x27;)</span><br><span class="line">plt.ylabel(&#x27;Probability of Pass&#x27;)</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310112103083.png" alt="image-20230310112103083"></p><h2 id="P-7-处理多维特征的输入"><a href="#P-7-处理多维特征的输入" class="headerlink" title="P 7  处理多维特征的输入"></a>P 7  处理多维特征的输入</h2><p>Logistic regression model$\hat{y}^{(i)}&#x3D;\sigma(x^{(i)}*\omega+b)$</p><p>Logistic regression model$\hat{y}^{(i)}&#x3D;\sigma(\sum\limits_{n&#x3D;1}^{8}x_n^{(i)}\cdot\omega_n+b)$<br>$$<br>\sum\limits_{n&#x3D;1}^8x_n^{(i)}\cdot\omega_n&#x3D;\begin{bmatrix}x_1^{(i)}&amp;…&amp;x_8^{(i)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}<br>$$<br>Logistic regression Model 广播机制</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310112846700.png" alt="image-20230310112846700"></p><p>Sigmoid function is in an element-wise fashion.<br>$$<br>\begin{bmatrix}\hat{y}^{(1)}\ \vdots\ \hat{y}^{(N)}\end{bmatrix}&#x3D;\begin{bmatrix}\sigma\bigl(z^{(1)}\bigr)\ \vdots\ \sigma\bigl(z^{(N)}\bigr)\end{bmatrix}&#x3D;\sigma\bigl(\begin{bmatrix}z^{(1)}\ \vdots\ Z^{(N)}\end{bmatrix}\bigr)<br>$$</p><p>$$<br>z^{(1)}&#x3D;\begin{bmatrix}x_1^{(1)}&amp;\cdots&amp;x_8^{(1)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+b<br>$$</p><p>$$<br>z^{(N)}&#x3D;\begin{bmatrix}&amp;\vdots\ x_1^{(N)}&amp;\cdots&amp;x_8^{(N)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+b<br>$$</p><p>$$<br>\begin{bmatrix}Z^{(1)}\ \vdots\ Z^{(N)}\end{bmatrix}&#x3D;\begin{bmatrix}x_1^{(1)}&amp;…&amp;x_8^{(1)}\ \vdots&amp;\ddots&amp;\vdots\ x_1^{(N)}&amp;…&amp;x_8^{(N)}\end{bmatrix}\begin{bmatrix}\omega_1\ \vdots\ \omega_8\end{bmatrix}+\begin{bmatrix}b\ \vdots\ b\end{bmatrix}<br>$$</p><p>矩阵化 向量化 便于运行</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.linear = torch.nn.Linear(<span class="number">8</span>,<span class="number">2</span>)</span><br><span class="line"><span class="comment"># 从8维空间 - 映射到 2维空间</span></span><br><span class="line">8D - 24D - 12D 超参数搜索</span><br></pre></td></tr></table></figure><p><code>矩阵</code> 从n维空间映射到m维空间 </p><p>空间变换的函数</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310113341902.png" alt="image-20230310113341902"></p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114142966.png" alt="image-20230310114142966" style="zoom: 80%;" /><ol><li>扣书本</li><li>读文档，基本的架构（泛化能力）</li></ol><p>Example: artificial neural network</p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114513426.png" alt="image-20230310114513426"></p><p><img src="https://cdn.jsdelivr.net/gh/yangmulao/aya/image-20230310114608659.png" alt="image-20230310114608659"></p><p>Diabetes Prediction</p><ol><li>Prepare dataset</li><li>Design model using Class</li><li>Construct loss and optimizer</li><li>Training cycle</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># Forward</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line">    <span class="comment"># Backward</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># Update</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">xy = np.loadtxt(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"></span><br><span class="line">criterion = torch.nn.BCELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="comment"># Forward前馈</span></span><br><span class="line">    y_pred = model(x_data)</span><br><span class="line">    loss = criterion(y_pred, y_data)</span><br><span class="line">    <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line">    <span class="comment"># Backward反馈</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># Update更新</span></span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以使用各种各样的激活函数</p><h2 id="P-8-加载数据集"><a href="#P-8-加载数据集" class="headerlink" title="P 8 加载数据集"></a>P 8 加载数据集</h2><p><strong>Dataset and DataLoader</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training clcle</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(training_epochs):</span><br><span class="line">    <span class="comment"># Loop over all batches</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(totaol_batch):</span><br></pre></td></tr></table></figure><ul><li>Definition: Epoch</li></ul><p>One forward pass and one backward pass of all the training examples.</p><ul><li>Definition: Batch_Size</li></ul><p>The number of training examples in one forward backward pass.</p><ul><li>Definition: Iteration</li></ul><p>Number of passes, each pass using [<strong>batch size</strong>] number of examples.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># The expression, dataset[index], will call this magic function.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="comment"># This magic function returns length of dataset.</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"><span class="comment"># Construct DiabetesDataset object.</span></span><br><span class="line">dataset = DiabetesDataset()</span><br><span class="line"><span class="comment"># Initialize loader with batch-size,shuffle, num_workers=2:读取两个进程process number.</span></span><br><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><p>Dataset is an abstract class. We can define our class inherited from this class.</p><p>几乎每个魔法方法是python的内置方法。方法都有对应的内置函数，或者运算符，对这个对象使用这些函数或者运算符时就会调用类中的对应魔法方法，可以理解为重写这些python的内置函</p><p>The implementation of multiprocessing is different on Windows, which uses <strong>spawn</strong> instead of <strong>fork</strong>.<br>So left code will cause: </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br><span class="line">……</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        ……</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_loader = DataLoader(dataset=dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>,</span><br><span class="line">                          num_workers=<span class="number">2</span>)</span><br><span class="line">……</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br></pre></td></tr></table></figure><p>So we have to wrap the code with an if-clause to protect the code from executing multiple times.  </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):</span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)</span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]</span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):</span><br><span class="line">            <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">            <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line">        </span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Prepare dataset</span></span><br><span class="line"><span class="comment"># Dataset and Dataloader</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DiabetesDataset</span>(<span class="title class_ inherited__">Dataset</span>):  <span class="comment"># Diabetes is inherited from abstract class Dataset. N行（8特征列，1目标列）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filepath</span>):  <span class="comment"># filepath路径</span></span><br><span class="line">        xy = np.loadtxt(filepath, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=np.float32)  <span class="comment"># 读取32浮点数</span></span><br><span class="line">        self.<span class="built_in">len</span> = xy.shape[<span class="number">0</span>]  <span class="comment"># xy.shape = [N, 0]  xy.shape[0] = N</span></span><br><span class="line">        self.x_data = torch.from_numpy(xy[:, :-<span class="number">1</span>])</span><br><span class="line">        self.y_data = torch.from_numpy(xy[:, [-<span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  <span class="comment"># The expression, dataset[index], will call this magic function.</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  <span class="comment"># This magic function returns length of dataset.</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dataset = DiabetesDataset(<span class="string">&#x27;diabetes.csv.gz&#x27;</span>)</span><br><span class="line">train_loader = DataLoader(dataset=dataset, batch_size=<span class="number">32</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)  <span class="comment"># shuffle 打乱</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Design model using Class</span></span><br><span class="line"><span class="comment"># inherit from nn.Module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Model, self).__init__()</span><br><span class="line">        self.linear1 = torch.nn.Linear(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(<span class="number">6</span>, <span class="number">4</span>)</span><br><span class="line">        self.linear3 = torch.nn.Linear(<span class="number">4</span>, <span class="number">1</span>)</span><br><span class="line">        self.sigmoid = torch.nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.sigmoid(self.linear1(x))</span><br><span class="line">        x = self.sigmoid(self.linear2(x))</span><br><span class="line">        x = self.sigmoid(self.linear3(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># Construct loss and optimizer</span></span><br><span class="line"><span class="comment"># using PyTorch API</span></span><br><span class="line">criterion = torch.nn.BCELoss(reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training cycle</span></span><br><span class="line"><span class="comment"># forward, backward, update</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        <span class="comment"># for i, data in enumerate(train_loader, 0): # train_loader (x, y) 赋值在data里 8:25</span></span><br><span class="line">        <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):  <span class="comment"># train_loader (x, y) 赋值在data里 8:25</span></span><br><span class="line">            <span class="comment"># 1. Prepare data</span></span><br><span class="line">            <span class="comment"># inputs, labels = data</span></span><br><span class="line">            <span class="comment"># 2. Forward</span></span><br><span class="line">            y_pred = model(inputs)</span><br><span class="line">            loss = criterion(y_pred, labels)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;epoch= &#123;&#125;, i= &#123;&#125;, loss= &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, i, loss.item()))</span><br><span class="line">            <span class="comment"># 3. Backward</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            <span class="comment"># 4. Update</span></span><br><span class="line">            optimizer.step()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                               train=<span class="literal">True</span>,</span><br><span class="line">                               transform= transforms.ToTensor(),</span><br><span class="line">                               download=<span class="literal">True</span>)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;../dataset/mnist&#x27;</span>,</span><br><span class="line">                              train=<span class="literal">False</span>,</span><br><span class="line">                              transform= transforms.ToTensor(),</span><br><span class="line">                              download=<span class="literal">True</span>)</span><br><span class="line">train_loader = DataLoader(dataset=train_dataset,</span><br><span class="line">                          batch_size=<span class="number">32</span>,</span><br><span class="line">                          shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(dataset=test_dataset,</span><br><span class="line">                         batch_size=<span class="number">32</span>,</span><br><span class="line">                         shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="keyword">for</span> batch_idx, (inputs, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">    ……</span><br></pre></td></tr></table></figure><p>Build DataLoader for</p><p>Build a classifier using the DataLoader.</p><h2 id="P-9-多分类问题"><a href="#P-9-多分类问题" class="headerlink" title="P 9  多分类问题"></a>P 9  多分类问题</h2><p>How to design the neural network?  </p><p>There are 10 labels in minist dataset.</p><ol><li>Linear layer</li><li>Sigmoid layer</li><li>Input layer</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line">z = np.array([<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>])</span><br><span class="line">y_pred = np.exp(z) / np.exp(z).<span class="built_in">sum</span>()</span><br><span class="line">loss = (- y * np.log(y_pred)).<span class="built_in">sum</span>()</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br><span class="line">y = torch.LongTensor([<span class="number">0</span>])</span><br><span class="line">z = torch.Tensor([[<span class="number">0.2</span>, <span class="number">0.1</span>, -<span class="number">0.1</span>]])</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">loss = criterion(z, y)</span><br><span class="line"><span class="built_in">print</span>(loss)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">Y = torch.LongTensor([<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">Y_pred1 = torch.Tensor([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.9</span>],</span><br><span class="line">                        [<span class="number">1.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">2.1</span>, <span class="number">0.1</span>]])</span><br><span class="line">Y_pred2 = torch.Tensor([[<span class="number">0.8</span>, <span class="number">0.2</span>, <span class="number">0.3</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.5</span>],</span><br><span class="line">                        [<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.5</span>]])</span><br><span class="line">l1 = criterion(Y_pred1, Y)</span><br><span class="line">l2 = criterion(Y_pred2, Y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Batch Loss1 = &quot;</span>, l1.data, <span class="string">&quot;\nBatch Loss2=&quot;</span>, l2.data)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = x.view(-<span class="number">1</span>, <span class="number">784</span>)</span><br><span class="line">self.l1 = torch.nn.Linear(<span class="number">784</span>, <span class="number">512</span>)</span><br><span class="line">x</span><br></pre></td></tr></table></figure><p><code>48:00</code>部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            images, labels = data</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 一轮训练，一轮测试</span></span><br><span class="line">        train(epoch)</span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><p><code>or</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 一轮训练，一轮测试</span></span><br><span class="line">        train(epoch)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">10</span> = <span class="number">9</span> <span class="comment"># 每10轮测试一次</span></span><br><span class="line">        test()</span><br></pre></td></tr></table></figure><h2 id="P-10-卷积神经网络-基础篇"><a href="#P-10-卷积神经网络-基础篇" class="headerlink" title="P 10 卷积神经网络(基础篇)"></a>P 10 卷积神经网络(基础篇)</h2><p><code>a</code></p><ol><li>Convolution</li><li>Subsampling</li><li>Convolution</li><li>Subsampling</li><li>Fully Connected</li><li>Fully</li><li>Connected</li></ol><p><code>图像可以表示为像素</code>–RGB栅格图像 <code>P10-12:00</code></p><p><code>==a==</code></p><p><img src="https://cdn.staticaly.com/gh/yangmulao/blogcdn@master/img/image-20230422205932775.png" alt="image-20230422205932775"></p><ol><li>Input</li><li>Kernel</li><li><h6 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h6></li></ol><p>这个是普通的文本文字<br><strong>这个是粗体</strong><br><em>这个是斜体</em><br><code>这个用于突出显示，或者说是高亮</code><br><code>a</code></p><p><img src="https://cdn.jsdelivr.net/gh/wbupt/blog1/image-20230314165217313.png" alt="image-20230314165217313"></p><p>卷积核有多少个</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">; Typora</span><br><span class="line">; 快捷增加字体颜色</span><br><span class="line">; SendInput &#123;Text&#125; 解决中文输入法问题</span><br><span class="line"></span><br><span class="line"><span class="comment">#IfWinActive ahk_exe Typora.exe</span></span><br><span class="line">&#123;</span><br><span class="line">    ; Ctrl+Alt+o 橙色</span><br><span class="line">    ^!o::addFontColor(<span class="string">&quot;orange&quot;</span>)</span><br><span class="line"></span><br><span class="line">    ; Ctrl+Alt+r 红色</span><br><span class="line">    ^!r::addFontColor(<span class="string">&quot;red&quot;</span>)</span><br><span class="line"></span><br><span class="line">    ; Ctrl+Alt+b 浅蓝色</span><br><span class="line">    ^!b::addFontColor(<span class="string">&quot;cornflowerblue&quot;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">; 快捷增加字体颜色</span><br><span class="line">addFontColor(color)&#123;</span><br><span class="line">    clipboard := <span class="string">&quot;&quot;</span> ; 清空剪切板</span><br><span class="line">    Send &#123;ctrl down&#125;c&#123;ctrl up&#125; ; 复制</span><br><span class="line">    SendInput &#123;TEXT&#125;&lt;font color=<span class="string">&#x27;%color%&#x27;</span>&gt;</span><br><span class="line">    SendInput &#123;ctrl down&#125;v&#123;ctrl up&#125; ; 粘贴</span><br><span class="line">    If(clipboard = <span class="string">&quot;&quot;</span>)&#123;</span><br><span class="line">        SendInput &#123;TEXT&#125;&lt;/font&gt; ; Typora 在这不会自动补充</span><br><span class="line">    &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">        SendInput &#123;TEXT&#125;&lt;/ ; Typora中自动补全标签</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#IfWinActive ahk_exe Typora.exe</span></span><br><span class="line">&#123;</span><br><span class="line">    ; Ctrl+Alt+K javaCode    </span><br><span class="line">    ; crtl是  ^ , shift是 + , k是  k键</span><br><span class="line">    ^+k::addCodeJava()</span><br><span class="line">&#125;</span><br><span class="line">addCodeJava()&#123;</span><br><span class="line">Send,&#123;```&#125;</span><br><span class="line">Send,&#123;```&#125;</span><br><span class="line">Send,&#123;```&#125;</span><br><span class="line">Send,python</span><br><span class="line">Send,&#123;Enter&#125;</span><br><span class="line">Return</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>卷积核大小</code><br>$$<br>n(个数)\times kernel\text{<em>size}</em>{width}(卷积核的大小)\times kernel\text{<em>size}</em>{height}(卷积核)<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">in_channels, out_channels= <span class="number">5</span>, <span class="number">10</span></span><br><span class="line">width, height = <span class="number">100</span>, <span class="number">100</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(batch_size, <span class="comment"># ba</span></span><br><span class="line">                    in_channels, <span class="comment"># n</span></span><br><span class="line">                    width,<span class="comment"># W</span></span><br><span class="line">                    height) <span class="comment"># H</span></span><br><span class="line">conv_layer = torch.nn.Conv2d(in_channels, <span class="comment"># n</span></span><br><span class="line">                             out_channels, <span class="comment"># m</span></span><br><span class="line">                             kernel_size=kernel_size) <span class="comment"># (5,3)</span></span><br><span class="line">output = conv_layer(<span class="built_in">input</span>) <span class="comment"># 卷积层</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(conv_layer.weight.shape)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/wbupt/blog1/image-20230314171723480.png" alt="image-20230314171723480"></p><h3 id="padding"><a href="#padding" class="headerlink" title="padding"></a><code>padding</code></h3><p>补零 填充。一般(3*3)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">input</span> = [<span class="number">3</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">7</span>,</span><br><span class="line">         <span class="number">2</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">8</span>,<span class="number">2</span>,</span><br><span class="line">         <span class="number">1</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">4</span>,</span><br><span class="line">         <span class="number">9</span>,<span class="number">7</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">2</span>,</span><br><span class="line">         <span class="number">3</span>,<span class="number">7</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">1</span>]</span><br><span class="line"><span class="built_in">input</span> = torch.Tensor(<span class="built_in">input</span>).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">conv_layer = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">1</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">kernel = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>) <span class="comment"># 构造卷积核 # (O I W H)</span></span><br><span class="line">conv_layer.weight.data = kernel.data</span><br><span class="line">output = conv_layer(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure><p><img src="https://article.biliimg.com/bfs/article/5e9d93cce8a669b044868d5614e30ebb86293cac.png" alt="padding=1"></p><h3 id="stride"><a href="#stride" class="headerlink" title="stride"></a><code>stride</code></h3><p>卷积步长</p><h3 id="MaxPooling"><a href="#MaxPooling" class="headerlink" title="MaxPooling"></a><code>MaxPooling</code></h3><p>下采样：<code>最大</code>池化层:默认：stride&#x3D;2</p><p><img src="https://article.biliimg.com/bfs/article/98197f929812c18861300006c6e3f8692037061c.png"></p><p>可以理解为： <code>给图像打马赛克</code></p><p><img src="https://article.biliimg.com/bfs/article/457475798b3b37855b4e3e257a20929ec4f2b671.png"></p><p><img src="https://article.biliimg.com/bfs/article/01145c6d488594cc0a0bedf8f4228a956921566f.png"></p><p>sdf</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">in_channels, out_channels= <span class="number">5</span>, <span class="number">10</span></span><br><span class="line">width, height = <span class="number">100</span>, <span class="number">100</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">batch_size = <span class="number">1</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(batch_size,</span><br><span class="line">                    in_channels,</span><br><span class="line">                    width,</span><br><span class="line">                    height)</span><br><span class="line">conv_layer = torch.nn.Conv2d(in_channels,</span><br><span class="line">                             out_channels,</span><br><span class="line">                             kernel_size=kernel_size)</span><br><span class="line">output = conv_layer(<span class="built_in">input</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"><span class="built_in">print</span>(conv_layer.weight.shape)</span><br></pre></td></tr></table></figure><p>df</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>) <span class="comment"># flatten</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure><p><code>Input Layer</code> .<code>Conv2d Layer </code>.<code>ReLU layer. ``Pooling Layer</code> .<code>Linear Layer </code>.<code>Output Layer </code>.</p><ul><li>CPU: time_cost: <code>1.74min</code></li></ul><img src="https://article.biliimg.com/bfs/article/40801fd69a25f75aeaecab2712f2d0081c316958.png" style="zoom:80%;" /><ul><li>GPU: time_cost: <code>1.29min</code></li></ul><img src="https://article.biliimg.com/bfs/article/f2cc0b433db07b6e33abf095e1fcce3a5b4a4c62.png" style="zoom: 80%;" /><p><code>Compare CPU &amp; GPU</code></p><img src="https://article.biliimg.com/bfs/article/c199f728e7be7a948a7a10d5f35e8fccc4a5f523.png" style="zoom: 80%;" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> optimizer</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># from main_09 import criterion</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="comment"># Important</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)  <span class="comment"># Important</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(device))  <span class="comment"># Important</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])  <span class="comment"># 均值 标准差</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>)  <span class="comment"># flatten</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct criterion and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 冲量0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            inputs, target = data</span><br><span class="line">            inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %% [%d/%d]&#x27;</span> % (<span class="number">100</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            test()</span><br><span class="line">            <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">            end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">            <span class="keyword">if</span> end_time - start_time &gt;= <span class="number">3600</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; h&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">3600</span>, <span class="number">2</span>)))</span><br><span class="line">            <span class="keyword">elif</span> end_time - start_time &gt;= <span class="number">60</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; min&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">60</span>, <span class="number">2</span>)))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; s&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time), <span class="number">1</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="P11-卷积神经网络-高级篇"><a href="#P11-卷积神经网络-高级篇" class="headerlink" title="P11 卷积神经网络(高级篇)"></a>P11 卷积神经网络(高级篇)</h2><h3 id="Google-network"><a href="#Google-network" class="headerlink" title="Google network"></a>Google network</h3><p><img src="https://article.biliimg.com/bfs/article/4bf292fe9482243132b60b6ec611ecc7594b0e4d.png"></p><p><code>不知道哪个好用，每个都用一下，全都要</code></p><p>保持图像的宽度（W）和高度（H）保持一致。</p><p><img src="https://article.biliimg.com/bfs/article/9bda660a8fb848119de0a0d4b9a453681404be1a.png"></p><p><code>Averaage Pooling</code>:　均值池化。padding, stride </p><p><img src="https://article.biliimg.com/bfs/article/34020b1a67736ebb0803f9d57362e2e325097886.png"></p><h3 id="1-1的卷积的作用"><a href="#1-1的卷积的作用" class="headerlink" title="1 * 1的卷积的作用"></a>1 * 1的卷积的作用</h3><p>信息融合</p><ul><li>取决于输入张量的通道</li></ul><p><img src="https://article.biliimg.com/bfs/article/4c3ceadd3b27afa70034c602e6b6d1c4cda62805.png"></p><p><code>卷积后的中间的值，融合了三个图像中三个图像中间值。</code></p><table><thead><tr><th></th><th>语文</th><th>数学</th><th>物理</th><th>化学</th><th>生物</th><th></th></tr></thead><tbody><tr><td>权重</td><td>1</td><td>0.8</td><td>0.9</td><td>1</td><td>0.7</td><td>加权</td></tr><tr><td>同学a</td><td>120</td><td>135</td><td>96</td><td>87</td><td>88</td><td>加权后总分</td></tr><tr><td>同学b</td><td>110</td><td>128</td><td>80</td><td>90</td><td>100</td><td>加权后总和</td></tr></tbody></table><p><img src="https://article.biliimg.com/bfs/article/c28576a572cab61cbfa9b39942c98b381ebe8a04.png"></p><ol><li>A计算量：$5^2<em>28^2</em>192*32&#x3D;1.2042.2400$</li><li>B计算量：$1^2<em>28^2</em>196<em>16+5^2</em>28^2<em>16</em>32&#x3D;1243.3648$</li></ol><p><img src="https://article.biliimg.com/bfs/article/c75a0e3af7884d288f5dd2d22175cd2e42febcb3.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">self.branch_pool = nn.Conv2d(in_channels, <span class="number">24</span>, kernel_size=<span class="number">1</span>) <span class="comment"># 池化分支</span></span><br><span class="line"></span><br><span class="line">branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">branch_pool = self.branch_pool(branch_pool)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">self.branch1x1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">branch1x1 = self.branch1x1(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">self.branch5x5_1 = nn.Conv2d(in_channels,<span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">self.branch5x5_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">branch5x5 = self.branch5x5_1(x)</span><br><span class="line">branch5x5 = self.branch5x5_2(branch5x5)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">self.branch3x3_1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">self.branch3x3_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">self.branch3x3_3 = nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">branch3x3 = self.branch3x3_1(x)</span><br><span class="line">branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">branch3x3 = self.branch3x3_3(branch3x3)</span><br></pre></td></tr></table></figure><p><img src="https://article.biliimg.com/bfs/article/d8386091e74f74280cfd0fef5dfc4d204bd6065e.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">outputs = [branch1x1, branch5x5, branch3x3, branch_pool]</span><br><span class="line"><span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionA</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels</span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionA, self).__init__()</span><br><span class="line">        self.branch1x1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.branch5x5_1 = nn.Conv2d(in_channels,<span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch5x5_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.branch3x3_1 = nn.Conv2d(in_channels, <span class="number">16</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.branch3x3_3 = nn.Conv2d(<span class="number">24</span>, <span class="number">24</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.branch_pool = nn.Conv2d(in_channels, <span class="number">24</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        branch1x1 = self.branch1x1(x)</span><br><span class="line">        </span><br><span class="line">        branch5x5 = self.branch5x5_1(x)</span><br><span class="line">        branch5x5 = self.branch5x5_2(branch5x5)</span><br><span class="line">        </span><br><span class="line">        branch3x3 = self.branch3x3_1(x)</span><br><span class="line">        branch3x3 = self.branch3x3_2(branch3x3)</span><br><span class="line">        branch3x3 = self.branch3x3_3(branch3x3)</span><br><span class="line">        </span><br><span class="line">        branch_pool = F.avg_pool2d(x, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        branch_pool = self.branch_pool(branch_pool)</span><br><span class="line">        </span><br><span class="line">        outputs = [branch1x1, branch5x5, branch3x3, branch_pool]</span><br><span class="line">        <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">88</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.incep1 = InceptionA(in_channels=<span class="number">10</span>)</span><br><span class="line">        self.incep2 = InceptionA(in_channels=<span class="number">20</span>)</span><br><span class="line">        self.mp = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1408</span>, <span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        in_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.mp(self.conv1(x)))</span><br><span class="line">        x = self.incep1(x)</span><br><span class="line">        x = F.relu(self.mp(self.conv2(x)))</span><br><span class="line">        x = self.incep2(x)</span><br><span class="line">        x = x.view(in_size, -<span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="更上一层楼"><a href="#更上一层楼" class="headerlink" title="更上一层楼"></a>更上一层楼</h3><ol><li>理论角度 《程度学习 花书》</li><li>阅读PyTorch文档（通读文档）</li><li>复现经典工作（读代码，写代码）</li><li>扩充视野</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>李沐动手学深度学习</title>
    <link href="/2023/03/14/%E6%9D%8E%E6%B2%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/03/14/%E6%9D%8E%E6%B2%90%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h2 id="P-1"><a href="#P-1" class="headerlink" title="P 1"></a>P 1</h2><p>从0开始学习线性回归。<br>$$<br>\mathbf{\hat{y}}&#x3D;Xw+b<br>$$</p>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习总结</title>
    <link href="/2023/03/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"/>
    <url>/2023/03/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<blockquote><p>I:\PyTorch深度学习实践</p></blockquote><h3 id="经典代码"><a href="#经典代码" class="headerlink" title="经典代码"></a>经典代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> optimizer</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># from main_09 import criterion</span></span><br><span class="line">start_time = time.time()</span><br><span class="line"><span class="comment"># Important</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)  <span class="comment"># Important</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;device=&#123;&#125;&quot;</span>.<span class="built_in">format</span>(device))  <span class="comment"># Important</span></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])  <span class="comment"># 均值 标准差</span></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">train_loader = DataLoader(train_dataset, shuffle=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;mnist&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">test_loader = DataLoader(test_dataset, shuffle=<span class="literal">False</span>, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.conv1 = torch.nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = torch.nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.pooling = torch.nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc = torch.nn.Linear(<span class="number">320</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># Flatten data from (n, 1, 28, 28) to (n, 784)</span></span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x)))</span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">        x = x.view(batch_size, -<span class="number">1</span>)  <span class="comment"># flatten</span></span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Net()</span><br><span class="line">model.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Construct criterion and optimizer</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)  <span class="comment"># 冲量0.5</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">epoch</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader, <span class="number">0</span>):</span><br><span class="line">        inputs, target = data</span><br><span class="line">        inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># forward + backward + update</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">300</span> == <span class="number">299</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % (epoch + <span class="number">1</span>, batch_idx + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">            inputs, target = data</span><br><span class="line">            inputs, target = inputs.to(device), target.to(device)</span><br><span class="line">            outputs = model(inputs)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, dim=<span class="number">1</span>)</span><br><span class="line">            total += target.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == target).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %d %% [%d/%d]&#x27;</span> % (<span class="number">100</span> * correct / total, correct, total))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        train(epoch)</span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            test()</span><br><span class="line">            <span class="keyword">import</span> time</span><br><span class="line">            end_time = time.time()  <span class="comment"># calculate time</span></span><br><span class="line">            <span class="keyword">if</span> end_time - start_time &gt;= <span class="number">3600</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; h&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">3600</span>, <span class="number">2</span>)))</span><br><span class="line">            <span class="keyword">elif</span> end_time - start_time &gt;= <span class="number">60</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; min&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time) / <span class="number">60</span>, <span class="number">2</span>)))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125; s&quot;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>((end_time - start_time), <span class="number">1</span>)))</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>深度学习</tag>
      
      <tag>总结</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>旧的-深度学习相关</title>
    <link href="/2023/03/14/Python/%E6%97%A7%E7%9A%84-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/"/>
    <url>/2023/03/14/Python/%E6%97%A7%E7%9A%84-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/</url>
    
    <content type="html"><![CDATA[<hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd <span class="comment"># Excel</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mlpNetWork <span class="keyword">import</span> * <span class="comment">#model</span></span><br><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm, trange <span class="comment">#output</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">DEBUG = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">basedir = <span class="string">&#x27;./logs&#x27;</span></span><br><span class="line"></span><br><span class="line">expname = <span class="string">&#x27;material_test&#x27;</span></span><br><span class="line">lrate = <span class="number">5e-4</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DataProcess</span>():</span><br><span class="line">    <span class="comment">####------------------- get the step length ---------------------#####</span></span><br><span class="line">    workSheet = xlrd.open_workbook(<span class="string">r&#x27;wavelength.xlsx&#x27;</span>)</span><br><span class="line">    wavelength = workSheet.sheet_by_name(<span class="string">&#x27;wavelength&#x27;</span>)</span><br><span class="line">    wavelength = wavelength.col_values(<span class="number">0</span>)<span class="comment">#get the step length</span></span><br><span class="line">    <span class="comment">#print(wavelength)</span></span><br><span class="line">    <span class="comment">#fig = plt.figure()</span></span><br><span class="line">    <span class="comment">#ax = fig.add_subplot(1, 1, 1)</span></span><br><span class="line">    <span class="comment">#for i in range(curve1.ncols):</span></span><br><span class="line">    <span class="comment">#    ax.plot(wavelength, curve1DataVector[i])</span></span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line">    <span class="comment">#####--------------- get the curve information -----------------#####</span></span><br><span class="line">    workSheet = xlrd.open_workbook(<span class="string">r&#x27;curve1.xlsx&#x27;</span>)</span><br><span class="line">    curve1 = workSheet.sheet_by_name(<span class="string">&#x27;curve1&#x27;</span>)</span><br><span class="line">    <span class="comment">#curve1 = curve1.col_values(0)</span></span><br><span class="line">    curve1DataVector = [curve1.col_values(r) <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(curve1.ncols)]</span><br><span class="line">    curve1DataVector = np.stack(curve1DataVector, <span class="number">0</span>) <span class="comment">#get the curve information [3000 181]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#fig = plt.figure()</span></span><br><span class="line">    <span class="comment">#ax = fig.add_subplot(1, 1, 1)</span></span><br><span class="line">    <span class="comment">#for i in range(curve1.ncols):</span></span><br><span class="line">    <span class="comment">#    ax.plot(wavelength, curve1DataVector[i])</span></span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">####------------------- get the material -----------------------#####</span></span><br><span class="line">    workSheet = xlrd.open_workbook(<span class="string">r&#x27;material.xlsx&#x27;</span>)</span><br><span class="line">    material = workSheet.sheet_by_name(<span class="string">&#x27;material&#x27;</span>)</span><br><span class="line">    materialVector = [material.col_values(r) <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(material.ncols)]</span><br><span class="line">    materialVector = np.stack(materialVector, -<span class="number">1</span>) <span class="comment">#get the material[3000 3]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> wavelength, curve1DataVector, materialVector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DataProcessMaterial</span>():</span><br><span class="line"></span><br><span class="line">    <span class="comment">#####--------------- get the curve information -----------------#####</span></span><br><span class="line">    workSheet = xlrd.open_workbook(<span class="string">r&#x27;input.xlsx&#x27;</span>)</span><br><span class="line">    curve1 = workSheet.sheet_by_name(<span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line">    <span class="comment">#curve1 = curve1.col_values(0)</span></span><br><span class="line">    heightAndWide = [curve1.col_values(r) <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(curve1.ncols)]</span><br><span class="line">    heightAndWide = np.stack(heightAndWide, <span class="number">0</span>) <span class="comment">#get the curve information [3000 181]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#fig = plt.figure()</span></span><br><span class="line">    <span class="comment">#ax = fig.add_subplot(1, 1, 1)</span></span><br><span class="line">    <span class="comment">#for i in range(curve1.ncols):</span></span><br><span class="line">    <span class="comment">#    ax.plot(wavelength, curve1DataVector[i])</span></span><br><span class="line">    <span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">####------------------- get the material -----------------------#####</span></span><br><span class="line">    workSheet = xlrd.open_workbook(<span class="string">r&#x27;output.xlsx&#x27;</span>)</span><br><span class="line">    material = workSheet.sheet_by_name(<span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line">    metricPerform = [material.col_values(r) <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(material.ncols)]</span><br><span class="line">    metricPerform = np.stack(metricPerform, -<span class="number">1</span>) <span class="comment">#get the material[3000 3]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> heightAndWide, metricPerform</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batchify</span>(<span class="params">fn, chunk</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Constructs a version of &#x27;fn&#x27; that applies to smaller batches.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> chunk <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        <span class="keyword">return</span> fn</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ret</span>(<span class="params">inputs</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.cat([fn(inputs[i:i+chunk]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, inputs.shape[<span class="number">0</span>], chunk)], <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run_network</span>(<span class="params">inputs, fn, embed_fn, netchunk=<span class="number">1024</span>*<span class="number">64</span></span>):</span><br><span class="line">    inputs_flat = torch.reshape(inputs, [-<span class="number">1</span>, inputs.shape[-<span class="number">1</span>]])</span><br><span class="line">    embedded = embed_fn(inputs_flat)</span><br><span class="line"></span><br><span class="line">    outputs_flat = batchify(fn, netchunk)(embedded)</span><br><span class="line">    outputs = torch.reshape(outputs_flat, <span class="built_in">list</span>(inputs.shape[:-<span class="number">1</span>]) + [outputs_flat.shape[-<span class="number">1</span>]])</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"><span class="comment">####-------------------- model the MLP NetWork -----------------#####</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_mlp</span>():</span><br><span class="line"></span><br><span class="line">    multires = <span class="number">10</span></span><br><span class="line">    i_embed = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    embed_fn, input_ch = get_embedder(multires, i_embed)</span><br><span class="line"></span><br><span class="line">    output_ch = <span class="number">3</span></span><br><span class="line">    skips = [<span class="number">4</span>]</span><br><span class="line">    netdepth = <span class="number">8</span></span><br><span class="line">    netwidth = <span class="number">256</span></span><br><span class="line"></span><br><span class="line">    modelMaterial = mlpNetwork(D=netdepth, W=netwidth,</span><br><span class="line">                 input_ch=input_ch, output_ch=output_ch, skips=skips).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(modelMaterial)</span><br><span class="line">    grad_vars = <span class="built_in">list</span>(modelMaterial.parameters())</span><br><span class="line"></span><br><span class="line">    netchunk = <span class="number">1024</span> * <span class="number">64</span></span><br><span class="line">    network_query_fn = <span class="keyword">lambda</span> inputs, network_fn : run_network(inputs, network_fn,</span><br><span class="line">                                                                embed_fn=embed_fn,</span><br><span class="line">                                                                netchunk=netchunk)</span><br><span class="line">    <span class="comment"># Create optimizer</span></span><br><span class="line">    optimizer = torch.optim.Adam(params=grad_vars, lr=lrate, betas=(<span class="number">0.9</span>, <span class="number">0.999</span>))</span><br><span class="line"></span><br><span class="line">    start = <span class="number">0</span></span><br><span class="line">    <span class="keyword">global</span> basedir</span><br><span class="line">    <span class="keyword">global</span> expname</span><br><span class="line"></span><br><span class="line">    <span class="comment">##########################</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">##########################</span></span><br><span class="line"></span><br><span class="line">    render_kwargs_train = &#123;</span><br><span class="line">        <span class="string">&#x27;network_query_fn&#x27;</span> : network_query_fn,</span><br><span class="line">        <span class="string">&#x27;network_fnMaterial&#x27;</span> : modelMaterial,</span><br><span class="line">    &#125;</span><br><span class="line">    render_kwargs_test = &#123;k : render_kwargs_train[k] <span class="keyword">for</span> k <span class="keyword">in</span> render_kwargs_train&#125;</span><br><span class="line">    <span class="keyword">return</span> render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">####--------------------- MLP predict Data-------------------------####</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predictCurve</span>(<span class="params">batchMaterial, network_query_fn, network_fnMaterial</span>):</span><br><span class="line">    rawRayStep = network_query_fn(batchMaterial, network_fnMaterial)</span><br><span class="line">    predictStep = torch.sigmoid(rawRayStep)  <span class="comment"># [N_rays, 64(predivt)]</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> predictStep</span><br><span class="line"></span><br><span class="line"><span class="comment">####-------------------------core process--------------------------####</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    heightAndWide, metricPerform = DataProcessMaterial()</span><br><span class="line">    heightAndWide, metricPerform = np.array(heightAndWide), np.array(metricPerform)</span><br><span class="line">    heightAndWide = np.transpose(heightAndWide, [<span class="number">1</span>,<span class="number">0</span>])</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;heightAndWide.shape = &#x27;</span>, heightAndWide.shape, <span class="string">&#x27;metricPerform.shape = &#x27;</span>, metricPerform.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    render_kwargs_train, render_kwargs_test, start, grad_vars, optimizer = create_mlp()</span><br><span class="line">    global_step = start</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">#testData</span></span><br><span class="line">    material_num_curve = np.concatenate([heightAndWide, metricPerform], -<span class="number">1</span>) <span class="comment">#[materialNum 3000, var 3 + curve 181]</span></span><br><span class="line">    material_num_curve = material_num_curve.astype(np.float32)</span><br><span class="line">    np.random.shuffle(material_num_curve)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    testMaterialData = material_num_curve[<span class="number">93</span>]</span><br><span class="line">    testMaterialData = torch.Tensor(testMaterialData).to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    material_num_curve = np.delete(material_num_curve, <span class="number">93</span>, axis=<span class="number">0</span>)</span><br><span class="line">    material_num_curve = torch.Tensor(material_num_curve).to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    N_iters = <span class="number">15000</span> + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    start = start + <span class="number">1</span></span><br><span class="line">    i_print = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">global</span> basedir</span><br><span class="line">    <span class="keyword">global</span> expname</span><br><span class="line">    <span class="keyword">global</span> lrate</span><br><span class="line"></span><br><span class="line">    lrate_decay = <span class="number">250</span></span><br><span class="line">    N_rand = <span class="number">100</span></span><br><span class="line">    i_batch = <span class="number">0</span></span><br><span class="line">    i_test = <span class="number">3000</span></span><br><span class="line"></span><br><span class="line">    plt.ion()</span><br><span class="line"></span><br><span class="line">    trainFlag = <span class="number">0</span></span><br><span class="line">    <span class="comment">#数据测试</span></span><br><span class="line">    <span class="keyword">if</span> trainFlag == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;cs&#x27;</span>)</span><br><span class="line">        modelWeight = torch.load(<span class="string">&#x27;networkFinal.ckpt&#x27;</span>)</span><br><span class="line">        render_kwargs_train[<span class="string">&#x27;network_fnMaterial&#x27;</span>].load_state_dict(modelWeight)</span><br><span class="line">        <span class="comment">#read data</span></span><br><span class="line">        workSheet = xlrd.open_workbook(<span class="string">r&#x27;input2.xlsx&#x27;</span>)</span><br><span class="line">        testData = workSheet.sheet_by_name(<span class="string">&#x27;Sheet1&#x27;</span>)</span><br><span class="line">        testData = [testData.col_values(r) <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(testData.ncols)]</span><br><span class="line">        testData = np.array(np.stack(testData, <span class="number">0</span>))  <span class="comment"># get the curve information [3000 181]</span></span><br><span class="line">        testData = np.transpose(testData, [<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        testData = testData.astype(np.float32)</span><br><span class="line">        testData = torch.tensor(testData).to(device)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(testData.shape)</span><br><span class="line">            predictData = predictCurve(testData, **render_kwargs_train)</span><br><span class="line"></span><br><span class="line">        predictData = predictData.cpu()</span><br><span class="line">        np.savetxt(<span class="string">&#x27;./1.txt&#x27;</span>, predictData)</span><br><span class="line">        <span class="built_in">print</span>(predictData)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#数据训练</span></span><br><span class="line">    <span class="keyword">if</span> trainFlag:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> trange(start, N_iters):</span><br><span class="line"></span><br><span class="line">            batch = material_num_curve[i_batch: i_batch + N_rand]</span><br><span class="line">            batchMaterial, batchTarget = batch[:, :<span class="number">5</span>], batch[:, <span class="number">5</span>:]</span><br><span class="line"></span><br><span class="line">            i_batch += N_rand</span><br><span class="line">            <span class="keyword">if</span> i_batch &gt;= material_num_curve.shape[<span class="number">0</span>]:</span><br><span class="line">                rand_idx = torch.randperm(material_num_curve.shape[<span class="number">0</span>])</span><br><span class="line">                material_num_curve = material_num_curve[rand_idx]</span><br><span class="line">                i_batch = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            predictData = predictCurve(batchMaterial, **render_kwargs_train)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            img_loss = predict2mse(predictData, batchTarget)</span><br><span class="line">            loss = img_loss</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            decay_rate = <span class="number">0.1</span></span><br><span class="line">            decay_steps = lrate_decay * <span class="number">1000</span></span><br><span class="line">            new_lrate = lrate * (decay_rate ** (global_step / decay_steps))</span><br><span class="line">            <span class="keyword">for</span> param_group <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">                param_group[<span class="string">&#x27;lr&#x27;</span>] = new_lrate</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % i_print == <span class="number">0</span>:</span><br><span class="line">                <span class="comment">#tqdm.write(&quot;[TRAIN] Iter: &#123;i&#125; Loss: &#123;loss.item()&#125; &quot;)</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;[TRAIN] Iter: &#x27;</span>, i, <span class="string">&#x27;Loss: &#x27;</span>, loss)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % i_test == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                    test_material, test_curve = testMaterialData[:<span class="number">5</span>], testMaterialData[<span class="number">5</span>:]</span><br><span class="line">                    test_material = test_material[<span class="literal">None</span>, :]</span><br><span class="line">                    predictData = predictCurve(test_material, **render_kwargs_test)</span><br><span class="line">                    <span class="comment">#print(&#x27;predictData = &#x27;, predictData)</span></span><br><span class="line">                    <span class="comment">#print(&#x27;test_curve = &#x27;, test_curve)</span></span><br><span class="line"></span><br><span class="line">                    test_curve_cpu = test_curve.cpu()</span><br><span class="line"></span><br><span class="line">                    predictData_cpu = predictData.cpu()</span><br><span class="line">                    predictData_cpu = predictData_cpu.detach().numpy()</span><br><span class="line">                    <span class="comment">#print(predictData_cpu.shape)</span></span><br><span class="line"></span><br><span class="line">                    predictData_cpu = predictData_cpu[<span class="number">0</span>, :]</span><br><span class="line">                    <span class="built_in">print</span>(test_curve_cpu, predictData_cpu)</span><br><span class="line">                    <span class="comment"># plt.clf()</span></span><br><span class="line">                    <span class="comment"># plt.plot(wavelength, test_curve_cpu)</span></span><br><span class="line">                    <span class="comment"># plt.plot(wavelength, predictData_cpu)</span></span><br><span class="line">                    <span class="comment"># plt.pause(0.5)</span></span><br><span class="line">            <span class="keyword">if</span> i == N_iters - <span class="number">1</span>:</span><br><span class="line">                torch.save(render_kwargs_train[<span class="string">&#x27;network_fnMaterial&#x27;</span>].state_dict(), <span class="string">&#x27;networkFinal.ckpt&#x27;</span>)</span><br><span class="line">            global_step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    plt.ioff()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    torch.set_default_tensor_type(<span class="string">&#x27;torch.cuda.FloatTensor&#x27;</span>)</span><br><span class="line">    train()</span><br></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>github</tag>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>河工大-Python光速入门</title>
    <link href="/2023/03/14/Python/%E6%B2%B3%E5%B7%A5%E5%A4%A7-Python%E5%85%89%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <url>/2023/03/14/Python/%E6%B2%B3%E5%B7%A5%E5%A4%A7-Python%E5%85%89%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="【合集】Python光速入门"><a href="#【合集】Python光速入门" class="headerlink" title="【合集】Python光速入门"></a>【合集】Python光速入门</h1><h2 id="01-环境配置"><a href="#01-环境配置" class="headerlink" title="01 环境配置"></a>01 环境配置</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a_xy(inx,<span class="number">1</span>:<span class="number">2</span>) = axy;</span><br><span class="line">a_xy(inx,<span class="number">3</span>) = [(axy(<span class="number">1</span>)-<span class="number">1</span>/<span class="number">3</span>)^<span class="number">2</span>+(axy(<span class="number">2</span>)-<span class="number">1</span>/<span class="number">3</span>)^<span class="number">2</span>]^<span class="number">0.5</span>; %%%半径求解</span><br><span class="line">a_xy(inx,<span class="number">3</span>) = [(axy(<span class="number">1</span>)-<span class="number">0.3260</span>)^<span class="number">2</span>+(axy(<span class="number">2</span>)-<span class="number">0.3353</span>)^<span class="number">2</span>]^<span class="number">0.5</span>; %%% 5800K</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;button <span class="keyword">class</span>=<span class="string">&quot;box cao_chang&quot;</span> onclick=<span class="string">&quot;openModal(&#x27;modal2&#x27;)&quot;</span>&gt;操场&lt;/button&gt;</span><br><span class="line">  &lt;div <span class="built_in">id</span>=<span class="string">&quot;modal2&quot;</span> <span class="keyword">class</span>=<span class="string">&quot;modal&quot;</span>&gt;</span><br><span class="line">       &lt;div <span class="keyword">class</span>=<span class="string">&quot;modal-content&quot;</span>&gt;</span><br><span class="line">            &lt;span <span class="keyword">class</span>=<span class="string">&quot;close&quot;</span> onclick=<span class="string">&quot;closeModal(&#x27;modal2&#x27;)&quot;</span>&gt;&amp;times;&amp;times;&amp;times;&lt;/span&gt;</span><br><span class="line">            &lt;p&gt;操场开放时间:08:<span class="number">00</span>-<span class="number">21</span>:<span class="number">00</span>&lt;/p&gt;&lt;/div&gt;</span><br><span class="line">  &lt;/div&gt;</span><br></pre></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">&quot;box ygr&quot;</span> <span class="attr">onclick</span>=<span class="string">&quot;openModal(&#x27;modal13&#x27;)&quot;</span>&gt;</span>游泳馆<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">id</span>=<span class="string">&quot;modal13&quot;</span> <span class="attr">class</span>=<span class="string">&quot;modal&quot;</span>&gt;</span><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">&quot;modal-content&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;close&quot;</span> <span class="attr">onclick</span>=<span class="string">&quot;closeModal(&#x27;modal13&#x27;)&quot;</span>&gt;</span><span class="symbol">&amp;times;</span><span class="symbol">&amp;times;</span><span class="symbol">&amp;times;</span><span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">p</span>&gt;</span>游泳馆 待添加<span class="tag">&lt;/<span class="name">p</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
  
  
</search>
